{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "sem12-active-learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizagonch/NLP/blob/master/sem12_active_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnpgYnUmQHws",
        "colab_type": "text"
      },
      "source": [
        "## Active Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STnT4_AgQHww",
        "colab_type": "text"
      },
      "source": [
        "Активное обучение $-$ класс алгоритмов обучения моделей машинного обучения. Алгоритмы активного обучения отличаются тем, могут интерактивно запрашивать пользователя (или некоторый другой источник информации) для разметки новых примеров данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRsdGy_qQHwz",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"active_learning.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR4ozncbQHw2",
        "colab_type": "text"
      },
      "source": [
        "## Active Learning Strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTjIbkfbQHw4",
        "colab_type": "text"
      },
      "source": [
        "#### Pool-Based Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqlDEQjSQHw6",
        "colab_type": "text"
      },
      "source": [
        "В этом сценарии экземпляры извлекаются из всего пула данных и им присваивается информативная оценка, которая показывает, насколько хорошо текущий алгоритм «понимает» данные. \n",
        "\n",
        "Затем система выбираются и размечаются наиболее информативные примеры."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRAfnQqRQHw8",
        "colab_type": "text"
      },
      "source": [
        "#### Uncertainty sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chHgEhD6QHw9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "В рамках этого алгоритма размечаются те примеры, на которых текущая модель наименее уверена.\n",
        "\n",
        "В качестве функций \"уверенности\" можно использовать вероятности классов или расстояния до разделяющей гиперплоскости."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzcGR_KOQHw_",
        "colab_type": "text"
      },
      "source": [
        "#### Membership Query Synthesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCQEHZKUQHxA",
        "colab_type": "text"
      },
      "source": [
        "Здесь алгритм обучения модели генерирует свои собственные примеры из некоторого настраиваемого распределения. \n",
        "Эти сгенерированные примеры отправляются на разметку и модель дообучается с учетом разметки этих примеров."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKdPrUBRQHxC",
        "colab_type": "text"
      },
      "source": [
        "#### Query by Committee"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQ8FecaQHxD",
        "colab_type": "text"
      },
      "source": [
        "Идея: построить ансамбль моделей $a_1,...,a_T$. \n",
        "\n",
        "Выбирать новые объекты $x_i$ с наибольшей несогласованностью решений ансамбля моделей.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PteZpgfAQHxE",
        "colab_type": "text"
      },
      "source": [
        "Принцип максимума энтропии: выбираем $x_i$, на котором $a_t(x_i)$ максимально различны."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS2SwV8hQHxG",
        "colab_type": "text"
      },
      "source": [
        "Принцип максимума средней $KL$-дивергенции:выбираем $x_i$ , на котором $P_t(y|x_i)$ максимально различны:\n",
        "\n",
        "$С(y|u) = \\frac{1}{T}\\sum_{t=1}^T P_t(y|u)$ - консенсус комитета "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShV-KB1dQHxH",
        "colab_type": "text"
      },
      "source": [
        "## SVM для Active Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-a4EWz7QHxI",
        "colab_type": "text"
      },
      "source": [
        "Некоторые активные алгоритмы обучения построены на алгоритме SVM и используют структуру SVM для определения того, какие точки данных нужно размечать. \n",
        "\n",
        "SVM используется для определения уверенности модели в предсказании на каждом из примеров выборки. \n",
        "В качестве меры уверенности служит расстояние от объекта до построенной не текущей итерации разделяющей гиперплоскости."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LG4otYEQHxJ",
        "colab_type": "text"
      },
      "source": [
        "## Active Learning for texts classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCUi39NXQHxK",
        "colab_type": "text"
      },
      "source": [
        "Рассмотрим алгоритм pool-based active learning на примере задачи классификации твитов по тональности."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WK3ABBAQHxL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "1. Разделить данные на X_pool (выборка, которую можно размечать) и X_test.\n",
        "2. Выбрать $k$ примеров из X_pool для начального X_train и разметить их. Остальные данные в X_pool $-$ валидационное множество. \n",
        "3. Обучить модель на  X_train.\n",
        "5. Сделать predict обученной моделью на X_pool, вычислить вероятности для каждого $x_i$.\n",
        "6. Вычислить качество работы модели на X_test.\n",
        "7. Выбрать $k$ наиболее информативных объектов из X_pool, основываясь на уверенности модели в каждом из объектов (например, вероятности классов).\n",
        "8. Переменести эти $k$ выбранных объектов в X_train.\n",
        "9. Если качество работы модели на X_test достаточное, то останавливаемся, иначе возвращаемся к шагу 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k01mb1uQHxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbmV1RyqQHxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk import ngrams\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0Fg0-CWQZs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "180e3221-8023-4ccc-cc40-32cccc706e99"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/PragmaticsLab/NLP-course-AMI/dev/seminars/sem12_active_learning/spam_text_classification_data.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-27 05:07:36--  https://raw.githubusercontent.com/PragmaticsLab/NLP-course-AMI/dev/seminars/sem12_active_learning/spam_text_classification_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 485702 (474K) [text/plain]\n",
            "Saving to: ‘spam_text_classification_data.csv’\n",
            "\n",
            "spam_text_classific 100%[===================>] 474.32K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-11-27 05:07:41 (7.61 MB/s) - ‘spam_text_classification_data.csv’ saved [485702/485702]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz_HZydiQHxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "bd385e63-63bf-4c66-925b-f9bbf23f5d87"
      },
      "source": [
        "df = pd.read_csv('spam_text_classification_data.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5572, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Ko5XrIQHxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['label'] = [0 if category == 'ham' else 1 for category in df['Category']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdpSkqCQHxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,X_test,y,y_test = train_test_split(np.array(df['Message']), np.array(df['label']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMq2qmUGQHxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_confidence(class_probs):\n",
        "    return abs(0.5-class_probs[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-xljqorQHxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = 50\n",
        "\n",
        "dataset_size = X.shape[0]\n",
        "target_score = 0.95\n",
        "score = 0\n",
        "step = 10\n",
        "\n",
        "X_train = X[:train_size]\n",
        "y_train = y[:train_size]\n",
        "X_pool = X[train_size:]\n",
        "y_pool = y[train_size:]\n",
        "\n",
        "scores = [0]\n",
        "train_szs = [0]\n",
        "\n",
        "while score < target_score and train_size <= dataset_size:\n",
        "    vec = CountVectorizer(ngram_range=(1, 1))\n",
        "    bow = vec.fit_transform(X_train)\n",
        "    clf = LogisticRegression()\n",
        "    clf = clf.fit(bow,y_train)\n",
        "    pred = clf.predict(vec.transform(X_test))\n",
        "    \n",
        "    print(\"{0} train samples\".format(train_size))\n",
        "    print(classification_report(pred, y_test))\n",
        "    score = f1_score(pred, y_test)\n",
        "    scores.append(score)\n",
        "    train_szs.append(train_size)\n",
        "    \n",
        "    pred_probs = clf.predict_proba(vec.transform(X_pool))\n",
        "    confidences = [get_confidence(probs) for probs in pred_probs]\n",
        "    \n",
        "    X_train = np.concatenate([X_train, X_pool[np.argsort(confidences)[:step]]])\n",
        "    y_train = np.concatenate([y_train, y_pool[np.argsort(confidences)[:step]]])\n",
        "    X_pool = X_pool[sorted(np.argsort(confidences)[step:])]\n",
        "    y_pool = y_pool[sorted(np.argsort(confidences)[step:])]\n",
        "    train_size += step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJTP6QKbSCOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "abd086e7-1482-4496-f36b-71c71949193a"
      },
      "source": [
        "train_size = 50\n",
        "\n",
        "dataset_size = X.shape[0]\n",
        "target_score = 0.95\n",
        "score = 0\n",
        "step = 10\n",
        "\n",
        "X_train = X[:train_size]\n",
        "y_train = y[:train_size]\n",
        "X_pool = X[train_size:]\n",
        "y_pool = y[train_size:]\n",
        "\n",
        "scores = [0]\n",
        "train_szs = [0]\n",
        "\n",
        "while score < target_score and train_size <= dataset_size:\n",
        "    vec = CountVectorizer(ngram_range=(1, 1))\n",
        "    bow = vec.fit_transform(X_train)\n",
        "    clf = LogisticRegression()\n",
        "    clf = clf.fit(bow,y_train)\n",
        "    pred = clf.predict(vec.transform(X_test))\n",
        "    \n",
        "    print(\"{0} train samples\".format(train_size))\n",
        "    print(classification_report(pred, y_test))\n",
        "    score = f1_score(pred, y_test)\n",
        "    scores.append(score)\n",
        "    train_szs.append(train_size)\n",
        "    \n",
        "    pred_probs = clf.predict_proba(vec.transform(X_pool))\n",
        "    #confidences = [get_confidence(probs) for probs in pred_probs]\n",
        "    e = (-pred_probs * np.log2(pred_probs)).sum(axis=1)\n",
        "    print (e)\n",
        "    \n",
        "    X_train = np.concatenate([X_train, X_pool[np.argsort(e)[::-1][:step]]])\n",
        "    y_train = np.concatenate([y_train, y_pool[np.argsort(e)[::-1][:step]]])\n",
        "    X_pool = X_pool[sorted(np.argsort(e)[::-1][step:])]\n",
        "    y_pool = y_pool[sorted(np.argsort(e)[::-1][step:])]\n",
        "    train_size += step"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.93      1392\n",
            "           1       0.01      1.00      0.01         1\n",
            "\n",
            "    accuracy                           0.88      1393\n",
            "   macro avg       0.50      0.94      0.47      1393\n",
            "weighted avg       1.00      0.88      0.93      1393\n",
            "\n",
            "[0.1581867  0.46981259 0.37086783 ... 0.45746971 0.50768414 0.43528067]\n",
            "60 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.94      1378\n",
            "           1       0.09      1.00      0.16        15\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.54      0.94      0.55      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "[0.15410785 0.48566504 0.36322672 ... 0.45717283 0.54895692 0.5198989 ]\n",
            "70 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1344\n",
            "           1       0.27      0.96      0.42        49\n",
            "\n",
            "    accuracy                           0.91      1393\n",
            "   macro avg       0.63      0.93      0.68      1393\n",
            "weighted avg       0.97      0.91      0.93      1393\n",
            "\n",
            "[0.14013193 0.53412113 0.36079038 ... 0.45851486 0.63266283 0.57375234]\n",
            "80 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.92      0.95      1320\n",
            "           1       0.38      0.90      0.53        73\n",
            "\n",
            "    accuracy                           0.92      1393\n",
            "   macro avg       0.69      0.91      0.74      1393\n",
            "weighted avg       0.96      0.92      0.93      1393\n",
            "\n",
            "[0.12343259 0.53494179 0.33622532 ... 0.47971092 0.72726715 0.58985901]\n",
            "90 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.93      0.96      1297\n",
            "           1       0.51      0.93      0.66        96\n",
            "\n",
            "    accuracy                           0.93      1393\n",
            "   macro avg       0.75      0.93      0.81      1393\n",
            "weighted avg       0.96      0.93      0.94      1393\n",
            "\n",
            "[0.12318485 0.56733954 0.35276825 ... 0.49837782 0.71294784 0.68538667]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97      1266\n",
            "           1       0.65      0.89      0.75       127\n",
            "\n",
            "    accuracy                           0.95      1393\n",
            "   macro avg       0.82      0.92      0.86      1393\n",
            "weighted avg       0.96      0.95      0.95      1393\n",
            "\n",
            "[0.09863605 0.56306073 0.39684579 ... 0.55531347 0.76725327 0.8118951 ]\n",
            "110 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97      1252\n",
            "           1       0.71      0.88      0.78       141\n",
            "\n",
            "    accuracy                           0.95      1393\n",
            "   macro avg       0.85      0.92      0.88      1393\n",
            "weighted avg       0.96      0.95      0.95      1393\n",
            "\n",
            "[0.08389759 0.5289699  0.39953238 ... 0.48654647 0.75506665 0.86686542]\n",
            "120 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.98      1251\n",
            "           1       0.73      0.90      0.81       142\n",
            "\n",
            "    accuracy                           0.96      1393\n",
            "   macro avg       0.86      0.93      0.89      1393\n",
            "weighted avg       0.96      0.96      0.96      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.08581144 0.5565315  0.41415954 ... 0.50471723 0.74377006 0.9469874 ]\n",
            "130 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      1245\n",
            "           1       0.75      0.89      0.82       148\n",
            "\n",
            "    accuracy                           0.96      1393\n",
            "   macro avg       0.87      0.93      0.90      1393\n",
            "weighted avg       0.96      0.96      0.96      1393\n",
            "\n",
            "[0.11167343 0.59264863 0.47099395 ... 0.55547788 0.75190693 0.93505338]\n",
            "140 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      1248\n",
            "           1       0.77      0.93      0.84       145\n",
            "\n",
            "    accuracy                           0.96      1393\n",
            "   macro avg       0.88      0.95      0.91      1393\n",
            "weighted avg       0.97      0.96      0.97      1393\n",
            "\n",
            "[0.15481753 0.68593766 0.53166708 ... 0.53010975 0.77342824 0.94405272]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "150 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      1249\n",
            "           1       0.77      0.94      0.85       144\n",
            "\n",
            "    accuracy                           0.96      1393\n",
            "   macro avg       0.88      0.95      0.91      1393\n",
            "weighted avg       0.97      0.96      0.97      1393\n",
            "\n",
            "[0.1431578  0.72970354 0.51222891 ... 0.67532038 0.71181661 0.9122718 ]\n",
            "160 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      1241\n",
            "           1       0.81      0.93      0.87       152\n",
            "\n",
            "    accuracy                           0.97      1393\n",
            "   macro avg       0.90      0.95      0.93      1393\n",
            "weighted avg       0.97      0.97      0.97      1393\n",
            "\n",
            "[0.18120836 0.71117919 0.50550994 ... 0.69061649 0.73450328 0.93876992]\n",
            "170 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      1238\n",
            "           1       0.81      0.91      0.85       155\n",
            "\n",
            "    accuracy                           0.97      1393\n",
            "   macro avg       0.90      0.94      0.92      1393\n",
            "weighted avg       0.97      0.97      0.97      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.16984828 0.72448443 0.54128205 ... 0.67455187 0.72872551 0.95906718]\n",
            "180 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      1247\n",
            "           1       0.79      0.95      0.87       146\n",
            "\n",
            "    accuracy                           0.97      1393\n",
            "   macro avg       0.89      0.96      0.92      1393\n",
            "weighted avg       0.97      0.97      0.97      1393\n",
            "\n",
            "[0.15366505 0.65289053 0.5184381  ... 0.5607818  0.69262093 0.90906155]\n",
            "190 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      1235\n",
            "           1       0.82      0.91      0.86       158\n",
            "\n",
            "    accuracy                           0.97      1393\n",
            "   macro avg       0.91      0.94      0.92      1393\n",
            "weighted avg       0.97      0.97      0.97      1393\n",
            "\n",
            "[0.14438143 0.70210698 0.56335217 ... 0.58649623 0.7009999  0.9414999 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "200 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98      1233\n",
            "           1       0.85      0.93      0.88       160\n",
            "\n",
            "    accuracy                           0.97      1393\n",
            "   macro avg       0.92      0.95      0.93      1393\n",
            "weighted avg       0.97      0.97      0.97      1393\n",
            "\n",
            "[0.15275506 0.63475556 0.51743299 ... 0.55261909 0.6845116  0.88561946]\n",
            "210 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98      1236\n",
            "           1       0.84      0.94      0.89       157\n",
            "\n",
            "    accuracy                           0.97      1393\n",
            "   macro avg       0.92      0.96      0.94      1393\n",
            "weighted avg       0.97      0.97      0.97      1393\n",
            "\n",
            "[0.14116798 0.63937491 0.54091559 ... 0.50989221 0.63031739 0.9050245 ]\n",
            "220 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99      1239\n",
            "           1       0.84      0.95      0.89       154\n",
            "\n",
            "    accuracy                           0.97      1393\n",
            "   macro avg       0.92      0.97      0.94      1393\n",
            "weighted avg       0.98      0.97      0.98      1393\n",
            "\n",
            "[0.11417459 0.53176974 0.58774742 ... 0.54199909 0.50244173 0.8519836 ]\n",
            "230 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.83      0.96      0.89       152\n",
            "\n",
            "    accuracy                           0.97      1393\n",
            "   macro avg       0.91      0.97      0.94      1393\n",
            "weighted avg       0.98      0.97      0.98      1393\n",
            "\n",
            "[0.10279041 0.47824627 0.56320228 ... 0.48211673 0.51477426 0.80286246]\n",
            "240 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1238\n",
            "           1       0.86      0.97      0.91       155\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.97      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.10041448 0.49369665 0.63108418 ... 0.47327767 0.51753292 0.76369135]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "250 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1234\n",
            "           1       0.87      0.96      0.92       159\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.97      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.09419883 0.53087853 0.52128775 ... 0.51049066 0.57437708 0.80426266]\n",
            "260 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1232\n",
            "           1       0.89      0.96      0.92       161\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.94      0.97      0.96      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.10412802 0.50401332 0.62152487 ... 0.53929042 0.6003379  0.72931711]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "270 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1235\n",
            "           1       0.87      0.96      0.91       158\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.97      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.08746088 0.48788638 0.57606468 ... 0.53666858 0.57678235 0.71985453]\n",
            "280 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1238\n",
            "           1       0.86      0.97      0.91       155\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.97      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.1220363  0.45293357 0.55628566 ... 0.50065949 0.58896754 0.62164151]\n",
            "290 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1237\n",
            "           1       0.86      0.97      0.91       156\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.97      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.12942702 0.43977949 0.48778389 ... 0.52158193 0.59237234 0.61081484]\n",
            "300 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.13171794 0.39407452 0.4589357  ... 0.54173265 0.60054422 0.62677059]\n",
            "310 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.85      0.98      0.91       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.11990764 0.38393084 0.478043   ... 0.5044477  0.58759269 0.63200118]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "320 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.97      0.91       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.10333294 0.40610443 0.42628484 ... 0.48470347 0.57363875 0.65043483]\n",
            "330 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1237\n",
            "           1       0.87      0.97      0.92       156\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.09779156 0.39943327 0.42954872 ... 0.51283768 0.58043265 0.66849824]\n",
            "340 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.11779926 0.34315467 0.42141919 ... 0.51833198 0.54100298 0.66724091]\n",
            "350 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.98      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.07810086 0.31950623 0.38230795 ... 0.49127809 0.54388325 0.66070124]\n",
            "360 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.85      0.98      0.91       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.07239995 0.30993034 0.38576478 ... 0.46216123 0.50437952 0.64560817]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "370 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.85      0.99      0.91       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.07055378 0.30888968 0.33473232 ... 0.38459956 0.48181202 0.63167715]\n",
            "380 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1243\n",
            "           1       0.85      0.99      0.91       150\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.06841062 0.29735228 0.34196982 ... 0.36539846 0.47308545 0.6190493 ]\n",
            "390 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1243\n",
            "           1       0.85      0.99      0.91       150\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.07963468 0.29928039 0.33310015 ... 0.35599463 0.44934557 0.57152982]\n",
            "400 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.85      0.99      0.91       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.08617459 0.3116363  0.33751151 ... 0.35416994 0.42956185 0.63384953]\n",
            "410 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.85      0.98      0.91       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.07395867 0.31198723 0.34102973 ... 0.32674269 0.42395913 0.58159985]\n",
            "420 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.98      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.07362354 0.27760626 0.3246465  ... 0.32118018 0.42593777 0.58711416]\n",
            "430 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.07491662 0.27947987 0.32751337 ... 0.32664853 0.40145386 0.5830016 ]\n",
            "440 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.98      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.06401443 0.24634924 0.30909555 ... 0.30314349 0.39459276 0.54509857]\n",
            "450 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.06089805 0.24704501 0.29647075 ... 0.30290357 0.33056802 0.55173147]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "460 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.05059123 0.24340728 0.29351864 ... 0.27657566 0.32571688 0.54249398]\n",
            "470 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.05237123 0.23153842 0.28128268 ... 0.2648954  0.31393817 0.5440296 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "480 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.05349162 0.26131822 0.26903596 ... 0.25596849 0.31629539 0.5124251 ]\n",
            "490 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.04762712 0.25962775 0.27012924 ... 0.23335816 0.31022046 0.50375025]\n",
            "500 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.04609475 0.24040016 0.24869487 ... 0.22822978 0.30116147 0.49975244]\n",
            "510 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.04010328 0.22327124 0.22262448 ... 0.22858302 0.28630159 0.47506677]\n",
            "520 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03918538 0.22571844 0.22504388 ... 0.22490467 0.28965982 0.47663973]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "530 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03588357 0.21909935 0.22222931 ... 0.22099034 0.26981732 0.4630645 ]\n",
            "540 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03866327 0.21677391 0.21801778 ... 0.21855925 0.26447136 0.46801607]\n",
            "550 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.04261502 0.20469354 0.2099842  ... 0.20905473 0.26416068 0.46336024]\n",
            "560 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.04224229 0.1960232  0.20615199 ... 0.198374   0.25986331 0.45490894]\n",
            "570 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03834208 0.19032426 0.20226099 ... 0.17937636 0.19094293 0.24721119]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "580 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03589126 0.19621576 0.20088113 ... 0.18124935 0.19273791 0.23190818]\n",
            "590 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03665781 0.18144247 0.19483681 ... 0.18284809 0.18853252 0.22796235]\n",
            "600 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03628902 0.17849478 0.18795349 ... 0.17442554 0.18033905 0.22566601]\n",
            "610 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03840199 0.19199372 0.17634924 ... 0.16512023 0.1738746  0.24604971]\n",
            "620 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03422465 0.18224888 0.16565833 ... 0.15741976 0.16819339 0.24655241]\n",
            "630 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.98      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03261911 0.1823613  0.15203018 ... 0.14907766 0.16753833 0.24217715]\n",
            "640 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.03299768 0.17987673 0.15418203 ... 0.14659468 0.16387082 0.23841815]\n",
            "650 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02999267 0.17110682 0.15588588 ... 0.15129663 0.17113192 0.22511846]\n",
            "660 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.03233187 0.17834826 0.15618452 ... 0.16311444 0.17497947 0.21551161]\n",
            "670 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02855848 0.17306022 0.14626195 ... 0.16294829 0.1640566  0.21600108]\n",
            "680 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.02816454 0.16790053 0.14413457 ... 0.15490127 0.15332714 0.21062925]\n",
            "690 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02466616 0.16806748 0.14367715 ... 0.134142   0.15348806 0.20644763]\n",
            "700 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0254693  0.15954903 0.14474492 ... 0.12964639 0.14814877 0.20433512]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "710 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02564459 0.15967686 0.14363837 ... 0.12850423 0.14757209 0.19565763]\n",
            "720 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02404959 0.15610104 0.14140858 ... 0.12250148 0.14395972 0.19588588]\n",
            "730 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.02375026 0.15131569 0.13812848 ... 0.12110497 0.14325848 0.188528  ]\n",
            "740 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.86      0.98      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02347608 0.14846585 0.1345765  ... 0.11982417 0.13997705 0.18617802]\n",
            "750 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.97      0.91       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02798466 0.14954336 0.12380906 ... 0.1138973  0.14224339 0.17238397]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "760 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03527486 0.1446185  0.12466081 ... 0.11188982 0.15371011 0.1674238 ]\n",
            "770 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1238\n",
            "           1       0.86      0.97      0.92       155\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03470999 0.13789824 0.12553979 ... 0.10906524 0.14844368 0.165131  ]\n",
            "780 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1238\n",
            "           1       0.86      0.97      0.92       155\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0344285  0.13812447 0.12156208 ... 0.10774924 0.14806996 0.16478065]\n",
            "790 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1238\n",
            "           1       0.86      0.97      0.92       155\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03171777 0.13639986 0.12144835 ... 0.10796035 0.14930299 0.16314614]\n",
            "800 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.98      0.92       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.03214104 0.13000974 0.119129   ... 0.10714341 0.14689572 0.15457281]\n",
            "810 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.97      0.91       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02911465 0.13025606 0.1181066  ... 0.10549453 0.14001764 0.15381003]\n",
            "820 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.97      0.91       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.02724037 0.12970505 0.11751066 ... 0.10432865 0.1374192  0.15197062]\n",
            "830 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.97      0.91       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.027659   0.12947157 0.11733758 ... 0.10135961 0.13450169 0.15102359]\n",
            "840 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1239\n",
            "           1       0.86      0.97      0.91       154\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.93      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02624085 0.12431508 0.1166907  ... 0.09672592 0.13510212 0.1500841 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "850 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.98      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02401377 0.12005334 0.11629469 ... 0.09951398 0.1396971  0.1426404 ]\n",
            "860 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02344267 0.11886465 0.1133054  ... 0.09714863 0.13573926 0.143509  ]\n",
            "870 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02225625 0.11693097 0.11222896 ... 0.09721296 0.13217489 0.14031414]\n",
            "880 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02223089 0.11143347 0.11090312 ... 0.09398775 0.12732426 0.13948844]\n",
            "890 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02243201 0.11135741 0.10960516 ... 0.09203289 0.12665147 0.13866336]\n",
            "900 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.02197627 0.10913678 0.10817232 ... 0.09160145 0.1245148  0.137903  ]\n",
            "910 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01920422 0.10074434 0.10768538 ... 0.0885746  0.13127675 0.13685784]\n",
            "920 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01928252 0.09735181 0.10387178 ... 0.09038171 0.13799508 0.13479935]\n",
            "930 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01797083 0.09611291 0.10263487 ... 0.08715183 0.12947674 0.13610058]\n",
            "940 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0176482  0.09355083 0.10060151 ... 0.08706688 0.12802754 0.13288659]\n",
            "950 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01720555 0.09279203 0.10007834 ... 0.0847734  0.12361462 0.13079009]\n",
            "960 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01685945 0.09284991 0.09792798 ... 0.08464782 0.1235061  0.1299445 ]\n",
            "970 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01674602 0.09285984 0.09778344 ... 0.08172767 0.12066691 0.12863971]\n",
            "980 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01608101 0.09356682 0.0957292  ... 0.07984214 0.11985001 0.12994467]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "990 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01594856 0.09162264 0.09437243 ... 0.07934839 0.11804981 0.12324107]\n",
            "1000 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01580896 0.09228073 0.09379025 ... 0.08001491 0.11736093 0.12301883]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1010 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01451618 0.09241128 0.09385606 ... 0.07324927 0.11619086 0.12183146]\n",
            "1020 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01413437 0.09174296 0.09317163 ... 0.07244262 0.11512277 0.12055963]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1030 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01395158 0.09014759 0.09154538 ... 0.07203965 0.11423339 0.11676373]\n",
            "1040 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01378055 0.08923979 0.09035165 ... 0.07140128 0.11359745 0.1159808 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1050 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01430097 0.0887462  0.08911339 ... 0.07079098 0.11255385 0.11585321]\n",
            "1060 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01420934 0.08867666 0.08863474 ... 0.07074012 0.11260589 0.11449793]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1070 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01435722 0.08840166 0.08911755 ... 0.06881035 0.1078447  0.1137454 ]\n",
            "1080 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01410979 0.08844476 0.08654325 ... 0.06798343 0.10763715 0.11122178]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1090 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01399377 0.08643961 0.08368638 ... 0.06676813 0.1053471  0.10978702]\n",
            "1100 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01353177 0.08552458 0.08394505 ... 0.06710543 0.10542478 0.10575206]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1110 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01353323 0.08444846 0.08264346 ... 0.06637204 0.10495677 0.1058083 ]\n",
            "1120 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01356975 0.08391333 0.08128308 ... 0.06618576 0.1046165  0.10553154]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1130 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01334932 0.0831029  0.080786   ... 0.0665394  0.10472157 0.10428208]\n",
            "1140 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01290436 0.08182744 0.08039161 ... 0.06524821 0.10233807 0.10411218]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1150 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01296136 0.08074923 0.07917019 ... 0.06451508 0.10096531 0.10374016]\n",
            "1160 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01296506 0.08108569 0.079603   ... 0.0643479  0.10124359 0.10210765]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1170 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01308703 0.07997777 0.07915924 ... 0.06406423 0.09976129 0.09961503]\n",
            "1180 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01284462 0.07885663 0.07805635 ... 0.0634994  0.09952091 0.09931285]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1190 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01259959 0.07866136 0.07773007 ... 0.06114212 0.09837359 0.0988634 ]\n",
            "1200 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0123481  0.07637196 0.07691492 ... 0.06058435 0.09679834 0.09663363]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1210 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01226497 0.07629407 0.07630801 ... 0.06017469 0.09632174 0.09631549]\n",
            "1220 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01231148 0.07552429 0.07601119 ... 0.0593615  0.09437293 0.09545784]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1230 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01204233 0.07429394 0.07576158 ... 0.05908833 0.09247314 0.09524157]\n",
            "1240 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01205566 0.07399688 0.07501546 ... 0.05850185 0.09028943 0.09188862]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1250 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0119765  0.07235291 0.07369746 ... 0.05836528 0.08965389 0.09096273]\n",
            "1260 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01208388 0.07182723 0.07280584 ... 0.05805759 0.08908761 0.09030186]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1270 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01217977 0.07965497 0.07966185 ... 0.06409539 0.10035256 0.09884462]\n",
            "1280 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01223123 0.0856578  0.08544021 ... 0.06888005 0.10926108 0.10551246]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1290 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01229463 0.08477032 0.08447941 ... 0.06830459 0.10812988 0.10443549]\n",
            "1300 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0121749  0.08413934 0.08349598 ... 0.06777334 0.1072108  0.10372348]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1310 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01209272 0.08354618 0.08212835 ... 0.06727965 0.10634966 0.10280439]\n",
            "1320 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01199247 0.08146451 0.08154776 ... 0.06667739 0.10567645 0.1024618 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1330 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01202267 0.08138196 0.08122419 ... 0.06574221 0.10545746 0.10179173]\n",
            "1340 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01193109 0.08067412 0.08059424 ... 0.06491617 0.10400262 0.10127863]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1350 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01108713 0.07794507 0.07950597 ... 0.06626099 0.10617981 0.10074152]\n",
            "1360 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01094321 0.07801543 0.0797918  ... 0.06592811 0.10647133 0.100702  ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1370 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01087327 0.07865144 0.07985597 ... 0.06534439 0.1055281  0.10115807]\n",
            "1380 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01090817 0.0768208  0.07894663 ... 0.06497745 0.10509388 0.10064529]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1390 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01075872 0.07610676 0.07857076 ... 0.06450356 0.10435182 0.10030379]\n",
            "1400 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01095833 0.07557133 0.07834788 ... 0.06363646 0.10334979 0.10000147]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1410 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01056901 0.07575935 0.07703623 ... 0.06280216 0.101772   0.09901683]\n",
            "1420 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01047209 0.07513967 0.07639356 ... 0.06264112 0.10136067 0.09819766]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1430 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01053224 0.07535609 0.07628334 ... 0.06267073 0.10014134 0.09782962]\n",
            "1440 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01063282 0.07502026 0.07563313 ... 0.06227786 0.09945051 0.09747332]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1450 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01034322 0.07491537 0.0754244  ... 0.06134874 0.09879416 0.09716098]\n",
            "1460 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01044327 0.07500102 0.07499923 ... 0.06076871 0.097269   0.09591622]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1470 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01016942 0.07532015 0.07498672 ... 0.06021454 0.09708666 0.0959007 ]\n",
            "1480 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.01003564 0.07471893 0.07452273 ... 0.05939319 0.09659221 0.09587335]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1490 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0100377  0.07407435 0.07281483 ... 0.05924506 0.09634429 0.09564604]\n",
            "1500 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00987538 0.0741263  0.07258589 ... 0.05909733 0.09513012 0.09423191]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1510 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0098068  0.07277801 0.07150128 ... 0.05884971 0.09527346 0.09369971]\n",
            "1520 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00962682 0.07263493 0.07149855 ... 0.05872541 0.09418929 0.09324308]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1530 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00934216 0.07241959 0.0706491  ... 0.05857348 0.09369296 0.0931327 ]\n",
            "1540 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00933676 0.072062   0.07044505 ... 0.05794124 0.09262496 0.09320102]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1550 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00920668 0.072064   0.07024058 ... 0.05750732 0.09216348 0.0929034 ]\n",
            "1560 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00923348 0.0713507  0.07014599 ... 0.05637523 0.09032722 0.09255186]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1570 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00911803 0.07107475 0.06908067 ... 0.05611175 0.09012883 0.09225544]\n",
            "1580 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00914746 0.0703706  0.06807433 ... 0.0557082  0.0897041  0.09238189]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1590 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00898111 0.07059679 0.06773733 ... 0.05487101 0.08876459 0.0924049 ]\n",
            "1600 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00876608 0.06890366 0.06771805 ... 0.05461348 0.08836903 0.09241087]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1610 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00876197 0.06877002 0.06724257 ... 0.05432386 0.08796258 0.09180268]\n",
            "1620 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00870798 0.06890813 0.06711876 ... 0.05405696 0.08741199 0.09150161]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1630 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00877323 0.06865392 0.06631914 ... 0.0538496  0.08736496 0.09148519]\n",
            "1640 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00866641 0.0685078  0.06574893 ... 0.05346135 0.0867904  0.09123523]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1650 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00839857 0.06874901 0.06498122 ... 0.0531638  0.08654738 0.09124104]\n",
            "1660 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00823224 0.06754057 0.06478343 ... 0.05288673 0.08599728 0.09086741]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1670 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00796488 0.06734264 0.06457987 ... 0.05262785 0.08564736 0.09043907]\n",
            "1680 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0079954  0.06743146 0.06448171 ... 0.05190418 0.08462864 0.09056781]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1690 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00779078 0.06633653 0.06414324 ... 0.05155832 0.08420329 0.09036317]\n",
            "1700 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00782046 0.06640229 0.0638803  ... 0.05130597 0.08404166 0.09017426]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1710 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00768116 0.06643671 0.0637737  ... 0.05075381 0.08319964 0.08918375]\n",
            "1720 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00761465 0.06569077 0.06323379 ... 0.05048334 0.08353137 0.08893258]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1730 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00702796 0.06551671 0.06304278 ... 0.05025536 0.08316172 0.0887658 ]\n",
            "1740 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00704908 0.06494989 0.06290874 ... 0.05018533 0.08315114 0.08866283]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1750 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00675189 0.06494193 0.06303797 ... 0.05024866 0.08341064 0.08784973]\n",
            "1760 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00672205 0.06508275 0.06267257 ... 0.05000836 0.08296189 0.08773642]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1770 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00653832 0.06507685 0.06264382 ... 0.0498738  0.08277388 0.08725472]\n",
            "1780 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00644498 0.06540558 0.06260461 ... 0.0496604  0.08211617 0.0858481 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1790 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00650158 0.06544441 0.06236522 ... 0.04932869 0.08163465 0.08577088]\n",
            "1800 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00634289 0.06512855 0.06151512 ... 0.04899167 0.08104264 0.08579037]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1810 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00632314 0.06506322 0.0612076  ... 0.04862405 0.08027133 0.08505519]\n",
            "1820 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00628051 0.06503031 0.06110724 ... 0.04842067 0.08001864 0.0845183 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1830 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00615524 0.06512066 0.06111494 ... 0.04816488 0.07927696 0.08420991]\n",
            "1840 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00598413 0.06519641 0.06079919 ... 0.04770846 0.07913076 0.08414311]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1850 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0059112  0.06460261 0.06072012 ... 0.04743599 0.07848476 0.08386921]\n",
            "1860 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00583151 0.06442153 0.0603882  ... 0.04733233 0.07845272 0.08377816]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1870 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00571794 0.064023   0.06028748 ... 0.04693836 0.07818232 0.08377323]\n",
            "1880 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0054474  0.06412997 0.06027217 ... 0.04579405 0.07726635 0.08375501]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1890 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00538328 0.06431315 0.06011413 ... 0.0457938  0.0762059  0.08353192]\n",
            "1900 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00538862 0.06400279 0.05916054 ... 0.0452533  0.07590976 0.08300865]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1910 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00533132 0.06363308 0.05900306 ... 0.04492351 0.07543592 0.08281311]\n",
            "1920 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00536288 0.06380582 0.05810341 ... 0.0448934  0.07538896 0.08235273]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1930 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0052483  0.06308505 0.05799183 ... 0.04477801 0.07499062 0.08202507]\n",
            "1940 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00516958 0.06304643 0.05779333 ... 0.04011846 0.04480586 0.07446679]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1950 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00513979 0.06254033 0.05749534 ... 0.03977708 0.04474027 0.07439118]\n",
            "1960 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00510931 0.06254221 0.0572255  ... 0.03928626 0.04466862 0.07435862]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1970 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00510741 0.06245169 0.05708745 ... 0.03925426 0.0445429  0.07382407]\n",
            "1980 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00506434 0.06236072 0.05716786 ... 0.03927489 0.04443603 0.07417773]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1990 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00592349 0.06104496 0.06231348 ... 0.03850107 0.04923774 0.08172525]\n",
            "2000 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00592679 0.06091066 0.06216994 ... 0.03849882 0.0486404  0.08107847]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2010 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00588476 0.06100472 0.06189778 ... 0.07328926 0.03836562 0.0483178 ]\n",
            "2020 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00578039 0.06125308 0.06215986 ... 0.07313156 0.03814553 0.04827196]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2030 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00565577 0.060957   0.06184903 ... 0.07288703 0.03792964 0.04778655]\n",
            "2040 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00559034 0.0608088  0.06160085 ... 0.07257787 0.03786069 0.04758306]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2050 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00552042 0.06077089 0.06146271 ... 0.07275519 0.03763627 0.04763684]\n",
            "2060 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00548218 0.06046753 0.06110336 ... 0.07264713 0.03763074 0.04735106]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2070 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00544643 0.06021018 0.06090201 ... 0.07270237 0.03716876 0.04719163]\n",
            "2080 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00538754 0.05984285 0.06082425 ... 0.07211306 0.0370852  0.04694206]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2090 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00531112 0.05997494 0.06039385 ... 0.04909085 0.03702911 0.04656171]\n",
            "2100 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00525146 0.05897598 0.06050311 ... 0.04862173 0.03703047 0.04660132]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2110 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00524108 0.05901273 0.06039641 ... 0.04856495 0.03685083 0.04624738]\n",
            "2120 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00523995 0.05908173 0.06048859 ... 0.04858962 0.03684509 0.04595916]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2130 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00520059 0.05906424 0.0593274  ... 0.04836358 0.03680166 0.04566524]\n",
            "2140 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00515005 0.0585974  0.05929556 ... 0.04812149 0.03665967 0.0456465 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2150 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00510012 0.05861968 0.0592661  ... 0.04805242 0.03652236 0.04542298]\n",
            "2160 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00510249 0.05785106 0.05907767 ... 0.04785034 0.03656456 0.04529946]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2170 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00504871 0.05789795 0.05912799 ... 0.04771424 0.03632094 0.04520288]\n",
            "2180 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00500499 0.05788166 0.0587344  ... 0.0477141  0.03619879 0.04510124]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2190 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00497901 0.05727033 0.05848054 ... 0.04729678 0.03620115 0.045105  ]\n",
            "2200 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00496631 0.05732472 0.05846352 ... 0.04731542 0.03625212 0.04491593]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2210 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00497758 0.05708057 0.05837229 ... 0.0468487  0.0363059  0.04467869]\n",
            "2220 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00497661 0.05708886 0.0582178  ... 0.04646568 0.03599923 0.04462247]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2230 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00490244 0.05665303 0.05800351 ... 0.04684871 0.03573122 0.04447055]\n",
            "2240 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00487051 0.05658891 0.0579705  ... 0.04665299 0.03564684 0.04437172]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2250 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00483143 0.05622877 0.05768569 ... 0.04573449 0.03553948 0.04430454]\n",
            "2260 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00487837 0.05607928 0.05703923 ... 0.04577994 0.03552185 0.04422676]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2270 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00480748 0.05606136 0.05698934 ... 0.04572443 0.03503004 0.04410053]\n",
            "2280 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00476654 0.05587067 0.05689775 ... 0.04582594 0.03508091 0.04372411]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2290 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00471637 0.05587495 0.05680513 ... 0.04581712 0.03512302 0.04369865]\n",
            "2300 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00465781 0.05574073 0.05668033 ... 0.04556803 0.03486697 0.04351601]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2310 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00463396 0.05570832 0.05665135 ... 0.04562619 0.03470226 0.0430021 ]\n",
            "2320 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00460936 0.05548257 0.05637061 ... 0.04544642 0.03456932 0.0429747 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2330 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00461485 0.05544406 0.05598911 ... 0.04548875 0.03444025 0.04287543]\n",
            "2340 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0045503  0.05528067 0.05558147 ... 0.04527261 0.03411886 0.04283222]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2350 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00455283 0.05504245 0.05557306 ... 0.04477068 0.03416583 0.04282779]\n",
            "2360 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0045099  0.05506704 0.05555588 ... 0.04485657 0.03420888 0.04258818]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2370 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00451484 0.05482507 0.05560424 ... 0.04483208 0.03417872 0.04243086]\n",
            "2380 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00446782 0.05464645 0.05542588 ... 0.04479383 0.03412776 0.04236879]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2390 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00443852 0.05439349 0.05534093 ... 0.04444054 0.03402486 0.04244094]\n",
            "2400 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00436305 0.05431879 0.05464958 ... 0.04451862 0.03368841 0.04237138]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2410 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00423661 0.05430039 0.00591503 ... 0.04452367 0.03358328 0.04230448]\n",
            "2420 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00422703 0.00591479 0.02277287 ... 0.04425351 0.03360087 0.04231261]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2430 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00420553 0.00587229 0.02261799 ... 0.04427577 0.03351993 0.04218716]\n",
            "2440 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00418581 0.00587155 0.02254279 ... 0.0442854  0.03354776 0.04216882]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2450 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00414191 0.00584319 0.02246572 ... 0.04426904 0.0333125  0.04192837]\n",
            "2460 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00408486 0.00583731 0.02239515 ... 0.04427199 0.03315951 0.04196536]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2470 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00402424 0.00580129 0.02227354 ... 0.04416546 0.03288527 0.0419329 ]\n",
            "2480 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00399802 0.00570811 0.02224818 ... 0.04408143 0.03280154 0.04171742]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2490 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00397403 0.0057051  0.02218507 ... 0.04409866 0.0326959  0.04168643]\n",
            "2500 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00395296 0.0057152  0.02209215 ... 0.04384207 0.03251264 0.04152237]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2510 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00393789 0.00570584 0.02199045 ... 0.0438328  0.03239172 0.04145524]\n",
            "2520 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00394623 0.00563024 0.02186242 ... 0.04328236 0.03231762 0.04130565]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2530 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00388562 0.00565388 0.02184866 ... 0.04320847 0.03214251 0.04116614]\n",
            "2540 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00385377 0.00562229 0.02181391 ... 0.04299286 0.03204973 0.04117243]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2550 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00384532 0.00563616 0.02170306 ... 0.04271877 0.032076   0.04089415]\n",
            "2560 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00385113 0.00561176 0.02161211 ... 0.0427093  0.03161399 0.04080413]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2570 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00379628 0.00558258 0.02161629 ... 0.0426075  0.03143855 0.04077622]\n",
            "2580 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00373993 0.00554193 0.02151194 ... 0.0424303  0.03132185 0.04053751]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2590 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00372756 0.00555677 0.02147132 ... 0.04200439 0.0312383  0.04046233]\n",
            "2600 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00373454 0.00547822 0.02140929 ... 0.04200226 0.03114553 0.04026168]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2610 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1242\n",
            "           1       0.84      0.97      0.90       151\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.94      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0037124  0.00541145 0.02134471 ... 0.04184077 0.03101169 0.04021244]\n",
            "2620 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00372143 0.00536657 0.0211987  ... 0.04180806 0.03131771 0.04005929]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2630 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00367537 0.00533979 0.02118495 ... 0.04179516 0.03117564 0.04006427]\n",
            "2640 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00367734 0.00529073 0.02100881 ... 0.04180042 0.0311476  0.04002218]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2650 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00411867 0.00513111 0.01964804 ... 0.03937444 0.03006947 0.0407234 ]\n",
            "2660 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0040698  0.00511349 0.01960393 ... 0.03938416 0.03005394 0.04057605]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2670 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0040151  0.00511618 0.01953473 ... 0.03938343 0.02983015 0.04049325]\n",
            "2680 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00403513 0.00510261 0.01952333 ... 0.03922134 0.02974854 0.04029361]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2690 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00399899 0.00511687 0.01947128 ... 0.0392163  0.02972973 0.04026597]\n",
            "2700 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00398069 0.0050685  0.0194334  ... 0.03926941 0.02970914 0.04019726]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2710 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00396473 0.00507106 0.01936331 ... 0.03930966 0.02978025 0.04019876]\n",
            "2720 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00391537 0.00507875 0.01925171 ... 0.03913758 0.02970198 0.04007224]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2730 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00387936 0.00506973 0.01921193 ... 0.03915884 0.02954621 0.03986887]\n",
            "2740 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00388386 0.00506875 0.01902178 ... 0.03909429 0.02953241 0.03981207]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2750 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00389313 0.00505569 0.01906359 ... 0.03908402 0.02957731 0.03975569]\n",
            "2760 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00386861 0.00501748 0.01899154 ... 0.03882442 0.02940391 0.03965296]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2770 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00386539 0.00497668 0.0189292  ... 0.03863854 0.02944723 0.03961803]\n",
            "2780 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00384855 0.00498764 0.01892422 ... 0.03861958 0.02936673 0.03960978]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2790 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00385908 0.00497114 0.01871671 ... 0.00442509 0.03862029 0.02918594]\n",
            "2800 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00384505 0.00498548 0.01866507 ... 0.0043843  0.03848352 0.02900621]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2810 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00381549 0.00497414 0.01857522 ... 0.00070236 0.00437885 0.02899161]\n",
            "2820 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00379639 0.00495469 0.01849441 ... 0.00070234 0.0043745  0.02894646]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2830 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00380417 0.00493832 0.01850207 ... 0.00070046 0.0043772  0.02897828]\n",
            "2840 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00379868 0.0049474  0.01850434 ... 0.00069661 0.00434699 0.0290011 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2850 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0037976  0.00493085 0.01845457 ... 0.00069606 0.00434727 0.02901149]\n",
            "2860 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00378394 0.0049082  0.01840873 ... 0.00069249 0.0043254  0.02886101]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2870 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00378938 0.00489745 0.01833006 ... 0.00068528 0.00431679 0.02882819]\n",
            "2880 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00375693 0.00488095 0.01828892 ... 0.00068608 0.00430319 0.0287958 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2890 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0037486  0.00484215 0.01817834 ... 0.00067422 0.0042702  0.02881387]\n",
            "2900 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00371763 0.00483602 0.01814312 ... 0.00066943 0.0042699  0.02879668]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2910 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00371601 0.00482978 0.01811314 ... 0.00067036 0.00423149 0.02869531]\n",
            "2920 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0037046  0.00476392 0.01808663 ... 0.00067045 0.00421299 0.0286215 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2930 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00367747 0.0047444  0.01798556 ... 0.00066502 0.00419019 0.02853145]\n",
            "2940 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00364631 0.00474388 0.01798332 ... 0.00066467 0.00417943 0.02852622]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2950 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00361101 0.00468825 0.01800389 ... 0.00066331 0.0041758  0.02849338]\n",
            "2960 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00355578 0.00468893 0.0179844  ... 0.00065422 0.00416214 0.02841071]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2970 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00354884 0.00468718 0.01791494 ... 0.00064841 0.004166   0.02839607]\n",
            "2980 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00352543 0.00468143 0.01789248 ... 0.00065011 0.00414033 0.02839779]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2990 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00352781 0.00466823 0.01787309 ... 0.00064727 0.00412769 0.02842887]\n",
            "3000 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00351878 0.00465464 0.01787528 ... 0.00064677 0.00410937 0.02835416]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3010 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0034694  0.00462891 0.01785373 ... 0.00064703 0.00406955 0.02812111]\n",
            "3020 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00346553 0.00462496 0.01783436 ... 0.00064624 0.00405978 0.02814258]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3030 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00345449 0.00461481 0.01782333 ... 0.00064617 0.00404309 0.02814216]\n",
            "3040 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00344136 0.00456613 0.01780292 ... 0.00064572 0.00404113 0.02801545]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3050 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00342092 0.00455867 0.01775823 ... 0.00064586 0.00401277 0.02790609]\n",
            "3060 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00340675 0.00453698 0.01768363 ... 0.00064553 0.00396965 0.0278727 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3070 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00339207 0.00452718 0.01762717 ... 0.0006399  0.00393221 0.02783624]\n",
            "3080 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.003248   0.00475309 0.01820032 ... 0.00098699 0.00451759 0.02703752]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3090 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00324436 0.00471448 0.01795352 ... 0.00097791 0.00446732 0.02691024]\n",
            "3100 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00322001 0.00471935 0.01787566 ... 0.00095534 0.00439099 0.02690023]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3110 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0032194  0.00469759 0.01785334 ... 0.00095108 0.00439272 0.02683286]\n",
            "3120 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00321005 0.00469178 0.01782579 ... 0.00094765 0.00438273 0.0267327 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3130 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0031961  0.00466612 0.01777027 ... 0.00094281 0.00438652 0.02673801]\n",
            "3140 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00319029 0.00466099 0.01774267 ... 0.00093813 0.00433484 0.02669707]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3150 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.00319545 0.00464831 0.0177318  ... 0.000933   0.00431969 0.02671199]\n",
            "3160 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0031667  0.00462576 0.01769349 ... 0.00713554 0.00093256 0.00429128]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3170 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[0.0031633  0.00460438 0.01763173 ... 0.00711773 0.00092524 0.00426715]\n",
            "3180 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.15114876e-03 4.60762076e-03 1.75678135e-02 2.27849110e-02\n",
            " 1.75737843e-02 4.91391293e-03 4.32733417e-03 1.99781163e-02\n",
            " 1.54091555e-02 2.44758981e-02 7.20346642e-04 1.31200648e-02\n",
            " 1.00359985e-02 4.30753857e-03 7.04418206e-03 1.32032244e-02\n",
            " 8.85274537e-03 1.63526389e-02 2.39432618e-02 1.89046848e-02\n",
            " 1.21306114e-02 2.10679891e-02 2.37312325e-02 2.29900956e-02\n",
            " 2.08807889e-02 8.68300278e-03 2.13660832e-02 1.09078211e-02\n",
            " 1.12131347e-02 1.25096707e-02 6.77656215e-03 1.49578561e-02\n",
            " 6.15495391e-03 1.91571943e-02 7.79398060e-03 5.74237233e-03\n",
            " 8.74365217e-03 1.55552334e-03 1.00864022e-02 5.24383727e-03\n",
            " 5.72338287e-03 1.91571943e-02 3.91311384e-03 1.60693852e-05\n",
            " 2.42870901e-02 2.40959310e-02 6.21148317e-03 1.31723947e-02\n",
            " 1.45670858e-02 1.56013416e-02 3.02466348e-03 1.14406155e-02\n",
            " 1.44469434e-02 2.08356761e-02 1.85494903e-02 1.21794929e-04\n",
            " 1.03590444e-02 1.31723947e-02 1.35819683e-02 2.11797940e-03\n",
            " 7.77952594e-09 3.10862903e-03 2.33303058e-05 7.01373871e-03\n",
            " 1.34454187e-02 9.03989189e-03 4.91955279e-04 2.51926262e-07\n",
            " 1.21415582e-02 8.33131068e-03 7.71786922e-03 2.91481123e-03\n",
            " 7.97280281e-03 1.11885664e-02 9.95130960e-03 1.78352990e-02\n",
            " 5.94823511e-03 2.46483033e-02 9.54205142e-03 2.31337564e-03\n",
            " 1.22227322e-02 1.91528306e-02 2.28467169e-02 1.45284259e-02\n",
            " 9.70039383e-03 1.70726836e-02 1.93564610e-02 2.35234543e-02\n",
            " 2.28710669e-02 2.08776678e-02 2.43024201e-02 1.41820611e-02\n",
            " 2.17297170e-02 1.96838224e-02 1.19947000e-02 1.16791881e-02\n",
            " 1.79191847e-02 1.18741528e-03 2.44286274e-02 7.65404907e-03\n",
            " 1.96534762e-02 3.27236902e-03 2.24246035e-02 1.68026699e-02\n",
            " 4.35058911e-04 1.78196041e-02 1.25513068e-03 1.54147205e-02\n",
            " 2.46483033e-02 8.92485611e-03 3.59955912e-03 1.06842002e-02\n",
            " 1.87014449e-02 1.88905628e-02 1.94764050e-02 1.45393647e-02\n",
            " 9.95130960e-03 1.30870959e-02 4.33330518e-04 1.46278461e-02\n",
            " 7.88109070e-03 5.76692228e-03 2.23289317e-02 5.32638854e-03\n",
            " 2.21046207e-02 2.07159260e-02 1.99781163e-02 1.24077237e-02\n",
            " 5.48644534e-04 2.22503405e-02 1.16933119e-02 1.08831340e-02\n",
            " 4.50985702e-03 4.68153392e-03 1.27091590e-03 1.67090091e-02\n",
            " 6.25472005e-03 2.46483033e-02 1.14424356e-02 1.94194890e-02\n",
            " 6.55941939e-04 1.14758301e-03 2.44026191e-02 1.09792547e-02\n",
            " 2.09567265e-02 5.82283183e-03 7.57576986e-05 3.90798436e-03\n",
            " 1.36327715e-02 2.19595300e-02 1.85943061e-02 1.02182409e-02\n",
            " 1.15109455e-02 1.16135945e-02 2.05210720e-02 1.94578250e-03\n",
            " 8.16807531e-03 2.01257236e-02 9.18003671e-03 7.68036406e-04\n",
            " 1.54628202e-02 2.21028559e-03 1.52818393e-02 1.13628261e-02\n",
            " 2.28482211e-02 2.43778095e-02 1.04296986e-02 2.04546077e-02\n",
            " 1.50642396e-02 8.18040525e-03 2.24904731e-02 1.77112340e-02\n",
            " 9.76763749e-03 2.25287358e-02 1.95578921e-02 5.41604043e-03\n",
            " 1.35819683e-02 3.83673222e-03 8.26206625e-05 1.70086218e-02\n",
            " 2.38591204e-02 9.59931803e-03 1.43337598e-02 2.52808349e-02\n",
            " 4.50907143e-03 1.52130300e-02 1.93394154e-02 1.70442902e-02\n",
            " 3.83673222e-03 1.27018413e-02 1.27881961e-02 9.41406435e-03\n",
            " 1.52037171e-02 7.16145940e-03 1.05073828e-03 1.31583607e-02\n",
            " 1.57950807e-02 1.98459795e-02 1.00075740e-02 7.85698431e-03\n",
            " 1.25256928e-02 1.62466318e-03 2.29699444e-02 1.86265267e-02\n",
            " 1.76038816e-02 1.33947494e-02 5.24745298e-05 1.76455891e-02\n",
            " 9.52865436e-03 1.52549003e-02 2.44615467e-02 1.64817885e-02\n",
            " 4.82657366e-03 3.36978677e-03 1.09059080e-02 7.47306809e-03\n",
            " 1.78196041e-02 9.75692193e-03 5.02633459e-03 9.54440584e-03\n",
            " 1.11907360e-02 2.50522894e-02 1.01143129e-02 1.06363789e-02\n",
            " 2.37732992e-02 7.77952594e-09 2.44209867e-02 4.19165449e-03\n",
            " 9.57374089e-03 1.59669036e-02 8.93489006e-03 2.19527838e-02\n",
            " 1.25808887e-03 1.37054326e-02 1.37101967e-02 4.45381662e-03\n",
            " 1.53291177e-02 8.57664671e-03 2.07809060e-03 1.99622263e-02\n",
            " 8.22378950e-03 1.53146601e-02 2.24245263e-03 1.95701134e-02\n",
            " 2.31798575e-02 2.41758768e-02 7.86089225e-03 4.26275947e-03\n",
            " 1.23869502e-02 1.67845575e-02 2.32733117e-02 9.09720408e-03\n",
            " 6.01104656e-03 2.08178206e-02 5.99539302e-03 2.09851973e-02\n",
            " 1.89695685e-02 2.38499207e-02 6.85665111e-03 3.08154809e-03\n",
            " 8.85274537e-03 1.39279969e-02 1.34503239e-02 1.02402714e-02\n",
            " 5.51602208e-03 1.13012054e-02 2.22263014e-02 4.50985702e-03\n",
            " 1.14406155e-02 9.91950988e-03 8.29340926e-03 2.36205069e-02\n",
            " 1.30291385e-02 9.74047723e-03 5.85388441e-03 1.16855988e-02\n",
            " 8.38329085e-03 1.28245178e-02 1.92207851e-02 2.65234624e-03\n",
            " 1.43173858e-02 1.87377229e-04 4.42028314e-03 1.71631143e-02\n",
            " 2.04623237e-02 1.13786442e-02 1.87871224e-02 1.18086418e-02\n",
            " 4.27842275e-03 1.06253186e-02 3.52220801e-03 1.49207696e-02\n",
            " 1.91017369e-02 6.46960423e-03 7.96454033e-03 2.48497870e-02\n",
            " 2.01382722e-02 1.08794642e-02 2.50000549e-02 1.92108257e-02\n",
            " 5.89864909e-04 3.45489249e-03 1.19293042e-02 1.64817885e-02\n",
            " 1.58055422e-02 6.32292872e-03 2.54225795e-02 1.39593951e-02\n",
            " 1.77342052e-06 1.20717944e-02 2.40917155e-02 1.07631319e-04\n",
            " 8.85620079e-04 3.20291569e-03 1.32187371e-02 7.05296920e-03\n",
            " 2.18296191e-02 3.22642214e-03 2.33063739e-02 9.91504453e-03\n",
            " 5.40293939e-03 1.97379215e-02 4.62382605e-04 2.49303669e-02\n",
            " 2.42522736e-02 2.28753538e-02 2.11967485e-02 1.53871558e-02\n",
            " 5.63034873e-03 2.40917155e-02 2.11077322e-02 5.96781941e-03\n",
            " 1.34320060e-02 1.34824832e-03 2.27921730e-02 1.41366078e-02\n",
            " 1.13353237e-02 9.44293380e-04 1.83809712e-02 4.76921517e-03\n",
            " 1.31200648e-02 7.21506671e-03 2.42220152e-02 2.50000549e-02\n",
            " 8.91636865e-03 5.76252053e-03 1.58424270e-02 6.48818486e-03\n",
            " 1.51504823e-02 4.87036796e-03 2.13236343e-02 2.41120911e-02\n",
            " 1.95701134e-02 6.00092813e-03 1.86658298e-02 5.70619186e-03\n",
            " 3.67595477e-03 8.17068054e-03 4.50985702e-03 1.71343060e-02\n",
            " 2.38928819e-02 1.06505805e-02 1.82305274e-02 8.53187147e-03\n",
            " 3.98921537e-03 2.47626994e-02 1.79599008e-02 1.33719312e-03\n",
            " 1.65677893e-03 2.09074665e-02 1.74707825e-02 9.63632563e-03\n",
            " 2.50017334e-02 2.36561984e-02 4.50232185e-03 1.07309958e-02\n",
            " 1.25635760e-02 2.10102951e-02 1.72626759e-03 5.59064734e-03\n",
            " 9.84608879e-03 1.80662271e-02 1.08372847e-04 8.54801031e-03\n",
            " 1.78654304e-02 6.35627208e-16 3.32424094e-03 1.67115555e-02\n",
            " 1.55803320e-02 6.39384900e-03 2.43114887e-02 1.34874810e-02\n",
            " 1.99750210e-02 1.14046505e-02 1.91449849e-02 1.48833413e-02\n",
            " 1.19825507e-02 1.76062418e-02 2.76211423e-04 8.68407389e-03\n",
            " 1.99015364e-02 2.51079513e-02 1.08633759e-02 1.66746905e-02\n",
            " 2.40249580e-02 1.06253186e-02 7.65404907e-03 3.10643130e-03\n",
            " 4.29185950e-03 3.33395583e-03 1.25256928e-02 2.22243583e-03\n",
            " 1.70406483e-02 4.07366350e-03 1.30590278e-02 7.29561837e-03\n",
            " 7.68224738e-03 1.83400856e-03 2.91959632e-04 7.45332866e-03\n",
            " 1.36325740e-02 5.07231207e-03 7.20695182e-03 1.30172172e-02\n",
            " 4.47136062e-03 4.68754275e-04 1.51027364e-02 2.32366616e-02\n",
            " 9.10638113e-03 2.27200113e-02 1.92202580e-02 2.17557271e-03\n",
            " 4.63244053e-03 3.77382564e-03 7.51805404e-03 8.17981335e-03\n",
            " 2.01609735e-04 4.84079481e-03 1.56191848e-02 3.87846685e-03\n",
            " 8.76354764e-03 1.50029543e-02 5.04894827e-03 3.44168213e-03\n",
            " 9.70359747e-03 9.76236460e-03 2.34615435e-02 6.97377212e-03\n",
            " 1.43612032e-02 2.49989768e-02 1.75624728e-02 5.19387344e-03\n",
            " 9.90230088e-03 5.74237233e-03 1.01622639e-02 2.09005976e-02\n",
            " 1.49807277e-02 5.18373137e-03 1.06708337e-02 2.46671818e-02\n",
            " 2.20653219e-04 9.75805478e-03 1.24725510e-02 2.11366841e-02\n",
            " 1.86467478e-03 8.84347025e-03 1.04917223e-02 8.41608868e-03\n",
            " 1.98420029e-02 7.34619634e-03 2.42604182e-02 3.90798436e-03\n",
            " 1.45544554e-03 2.50000549e-02 1.99421710e-02 1.28932478e-02\n",
            " 3.31558681e-03 2.06121102e-03 1.59879654e-02 1.53644239e-02\n",
            " 1.48666323e-02 1.32529329e-03 5.17072687e-03 2.04518700e-02\n",
            " 1.62146256e-02 2.01382722e-02 1.92198085e-03 1.87543359e-02\n",
            " 5.85388441e-03 4.19786718e-03 1.68779971e-02 1.35851314e-02\n",
            " 1.68678555e-03 1.24027399e-02 2.41176881e-02 8.05357313e-03\n",
            " 3.34286693e-03 3.28821378e-03 6.79202327e-03 2.40910690e-03\n",
            " 1.55273360e-02 1.93195258e-02 5.83952201e-06 2.26378963e-02\n",
            " 2.26029590e-02 1.27880710e-02 9.23691474e-04 1.58054185e-02\n",
            " 4.00168265e-03 1.34894727e-03 1.15301204e-02 1.11335504e-02\n",
            " 1.26394493e-05 1.13248645e-02 1.17234200e-02 1.54053789e-02\n",
            " 2.30367137e-02 2.49921289e-03 1.93539018e-04 2.40917155e-02\n",
            " 9.47630740e-03 1.43612032e-02 4.02183317e-03 3.33730358e-03\n",
            " 9.70060800e-03 1.94356031e-03 8.36473245e-04 2.30936112e-03\n",
            " 1.53412655e-02 7.00960868e-04 2.14976943e-02 2.21245897e-03\n",
            " 1.19556337e-03 2.01382722e-02 2.35342397e-02 1.62594734e-02\n",
            " 3.95267024e-03 1.61266829e-02 1.49115824e-02 2.39703150e-02\n",
            " 1.15558127e-02 8.18473430e-03 5.86612261e-05 1.42163242e-02\n",
            " 6.56185458e-04 1.16097048e-02 2.37851908e-02 9.88028628e-04\n",
            " 1.30588388e-02 1.10565769e-02 1.92108257e-02 1.35026889e-02\n",
            " 1.08915841e-02 1.32494127e-02 1.45223878e-02 1.45753960e-02\n",
            " 9.95130960e-03 9.99107328e-03 2.30598393e-02 5.70936379e-03\n",
            " 2.02010180e-02 1.92481677e-02 2.27484119e-02 8.82592198e-03\n",
            " 9.17212358e-03 8.43063178e-03 1.04798085e-02 1.94356031e-03\n",
            " 1.62262818e-02 2.14037893e-02 2.02797270e-02 1.21292430e-02\n",
            " 1.10927899e-02 1.83330123e-02 2.32307941e-03 1.27575776e-02\n",
            " 3.51187409e-03 2.21808387e-02 1.04345059e-02 2.25673368e-02\n",
            " 1.80398724e-02 5.10281398e-03 2.00044968e-02 1.11415561e-02\n",
            " 2.00134670e-03 1.36459084e-02 4.46949218e-03 1.23597574e-02\n",
            " 1.74409737e-02 1.63174764e-02 8.03752136e-03 2.08741353e-02\n",
            " 1.30334961e-02 1.33385548e-02 4.79900272e-03 9.54295037e-03\n",
            " 5.92896059e-04 3.13498124e-03 9.83326330e-03 4.17422067e-03\n",
            " 1.84305561e-02 8.51619094e-03 1.78597174e-02 8.36909177e-03\n",
            " 2.20653219e-04 4.97279832e-03 2.35871531e-02 1.87795179e-02\n",
            " 1.14238312e-02 3.10254471e-03 1.57187661e-02 2.25977591e-02\n",
            " 4.18713124e-03 1.76110196e-02 1.08786453e-02 8.43233054e-03\n",
            " 2.02299715e-02 2.45147262e-02 4.71329194e-03 6.98516044e-04\n",
            " 1.51426799e-03 1.34847672e-02 2.23881916e-02 1.22615542e-03\n",
            " 1.94512162e-02 1.67714167e-02 7.84496582e-03 5.35509246e-03\n",
            " 1.68809675e-02 7.20346642e-04 2.30251287e-02 4.85492362e-03\n",
            " 1.48312508e-02 1.97708112e-02 1.95441684e-02 1.23066633e-02\n",
            " 3.43985618e-04 7.86670598e-03 2.34548545e-02 1.94356031e-03\n",
            " 7.96544929e-03 2.22587553e-02 1.45337574e-02 1.18685384e-02\n",
            " 1.35638803e-02 2.53035512e-02 5.92572911e-03 7.79799476e-03\n",
            " 8.95942443e-03 1.18751425e-02 1.54999169e-02 2.08356761e-02\n",
            " 1.06338952e-02 2.41690578e-03 1.36129813e-02 3.85358323e-03\n",
            " 2.05223789e-02 1.27946476e-03 7.74160924e-03 2.19372115e-02\n",
            " 1.97526895e-02 8.57181864e-03 9.34093402e-03 2.62188507e-04\n",
            " 1.15431767e-02 3.90798436e-03 1.70476107e-02 6.41695339e-03\n",
            " 4.00168265e-03 9.66150322e-03 1.90406638e-02 4.14963325e-04\n",
            " 2.88431338e-03 1.54217411e-02 2.40028737e-02 2.10566156e-02\n",
            " 1.64214310e-02 2.30577613e-02 2.02804749e-02 5.54834472e-04\n",
            " 8.58829519e-03 2.34695803e-02 9.96127449e-03 2.06248910e-03\n",
            " 5.01228712e-03 1.63589605e-03 1.04470222e-02 1.96031560e-02\n",
            " 1.78646037e-02 1.59695249e-02 1.23989535e-02 1.06721994e-02\n",
            " 1.50386482e-02 7.11951116e-03 1.01000517e-02 1.09082757e-02\n",
            " 1.38763274e-04 7.42181804e-03 2.43994239e-03 2.10320702e-02\n",
            " 2.32993872e-02 3.45876405e-03 1.44856298e-02 1.75624728e-02\n",
            " 3.34998189e-03 4.82657366e-03 9.06299350e-03 1.90594063e-02\n",
            " 1.25022391e-02 4.50907143e-03 1.73037502e-02 6.65592681e-03\n",
            " 2.85461927e-03 1.92929390e-02 1.13953322e-02 9.98855546e-03\n",
            " 2.03975067e-03 6.28983025e-04 1.99809203e-02 2.90077480e-03\n",
            " 1.43944036e-02 1.46776867e-02 1.71661046e-02 1.79599008e-02\n",
            " 1.96593041e-02 4.45419942e-03 1.03502426e-02 1.49207696e-02\n",
            " 1.46107901e-02 1.91208028e-02 8.17590009e-03 2.08782778e-02\n",
            " 4.29641272e-03 2.14120906e-02 1.63899403e-02 6.66466343e-04\n",
            " 1.72995214e-02 1.76637818e-02 3.63737249e-03 2.38361516e-02\n",
            " 6.72352173e-03 5.57092102e-03 8.33406837e-03 5.20512124e-03\n",
            " 1.64817885e-02 1.70069400e-02 1.66675090e-02 2.07587784e-02\n",
            " 3.58138733e-04 2.89440258e-03 2.35660842e-02 3.18666838e-03\n",
            " 8.48999164e-03 1.39470581e-02 1.48143058e-02 8.71057401e-03\n",
            " 2.32307941e-03 1.46654961e-02 1.75230104e-02 2.46788186e-02\n",
            " 1.48446406e-03 1.18653879e-02 1.61464465e-02 2.52226468e-03\n",
            " 2.21002160e-02 6.31324827e-03 1.11035937e-02 1.46016451e-02\n",
            " 1.20019014e-02 4.08168931e-03 1.46685097e-02 1.98576942e-02\n",
            " 1.17525011e-02 5.62447477e-03 9.53586526e-04 1.10236450e-02\n",
            " 7.00652910e-03 4.50683376e-03 1.61732809e-02 5.26960986e-03\n",
            " 3.98837652e-03 2.23170412e-02 7.45903679e-03 5.31566123e-03\n",
            " 4.75565712e-03 2.92909054e-03 6.82725291e-03 1.88353745e-02\n",
            " 1.87348358e-02 1.10397548e-02 2.46808148e-02 2.29554298e-02\n",
            " 1.19823194e-03 6.91835828e-04 2.51935051e-02 2.31745115e-02\n",
            " 6.21148317e-03 1.38491018e-02 1.07564329e-03 2.21564193e-04\n",
            " 1.21283912e-02 1.03931960e-02 1.12666160e-02 1.39781540e-03\n",
            " 1.98438565e-02 1.66699450e-02 1.50385832e-03 2.19985989e-03\n",
            " 2.91481123e-03 8.64117056e-05 1.55375934e-02 2.37732992e-02\n",
            " 3.99886347e-03 2.14976943e-02 1.85632072e-02 5.56613410e-03\n",
            " 5.44432857e-03 2.69509595e-06 1.27774066e-02 2.34093859e-02\n",
            " 7.22097451e-04 2.44857408e-02 6.37051332e-07 2.05424566e-02\n",
            " 1.16112192e-02 2.05322618e-02 1.97942213e-02 2.60788119e-05\n",
            " 1.77808886e-02 4.23721756e-05 2.52787863e-02 2.27081657e-02\n",
            " 1.39965447e-02 1.74748204e-02 1.08235759e-02 1.12612326e-02\n",
            " 1.61813935e-03 2.49490638e-02 8.95167811e-04 1.19844002e-02\n",
            " 2.23666774e-02 1.69708737e-02 4.73871292e-03 2.20853944e-02\n",
            " 1.73729425e-02 1.61679074e-02 3.91311384e-03 1.46747487e-02\n",
            " 5.12756896e-03 1.12017108e-02 5.12756896e-03 7.68873875e-03\n",
            " 2.00148000e-02 1.91598623e-02 1.06948033e-03 2.33557102e-02\n",
            " 7.54666380e-03 2.00882935e-03 1.85242171e-02 4.32637320e-03\n",
            " 3.46520385e-04 2.33128629e-02 1.57216123e-02 4.28122344e-04\n",
            " 1.10425616e-02 1.44474412e-02 3.30946849e-03 1.44231483e-02\n",
            " 5.20834067e-03 2.38341781e-02 1.84984315e-02 2.07586944e-02\n",
            " 2.12194572e-02 4.56482336e-03 2.71040984e-04 5.42740399e-03\n",
            " 2.48564294e-02 2.30912697e-02 6.48674996e-03 1.87739131e-02\n",
            " 6.83515052e-03 1.35488996e-02 1.64976720e-02 5.84378232e-03\n",
            " 1.73825751e-02 4.75722676e-03 5.04894827e-03 7.68461517e-03\n",
            " 1.99781163e-02 1.21690368e-02 3.16833153e-03 1.37692094e-02\n",
            " 1.54898396e-02 1.78107091e-02 1.14862295e-02 1.52055525e-02\n",
            " 2.04781051e-02 5.76726580e-03 1.75748703e-02 6.16868382e-03\n",
            " 1.33393660e-02 1.96591264e-02 2.15965451e-02 1.87983818e-02\n",
            " 1.99048628e-02 2.24238737e-02 5.09911089e-03 3.91311384e-03\n",
            " 1.38054397e-02 2.07440143e-02 1.46468680e-02 8.31080653e-03\n",
            " 1.11078903e-02 1.54461562e-03 1.32942404e-03 3.97770906e-03\n",
            " 1.62981618e-02 5.47222976e-03 2.06194644e-02 4.19770892e-03\n",
            " 7.76361289e-04 1.83049886e-02 9.44595478e-03 1.12943152e-02\n",
            " 8.87676548e-03 5.89035695e-03 2.51240633e-03 8.33014651e-04\n",
            " 9.75050399e-03 1.96769371e-02 7.49740812e-03 7.90135642e-03\n",
            " 9.41391677e-03 2.51351407e-02 2.00638258e-02 1.17332795e-02\n",
            " 1.01903719e-02 3.11217662e-03 2.53570612e-02 1.61992219e-03\n",
            " 1.38886912e-03 2.07039754e-02 1.50738195e-02 6.76207193e-03\n",
            " 1.03107432e-02 1.12333054e-02 7.61285226e-03 1.79369305e-02\n",
            " 2.50080954e-02 9.12240031e-03 1.41780565e-02 4.46392058e-03\n",
            " 2.20581085e-02 1.43393414e-02 8.36964794e-03 3.98887382e-03\n",
            " 9.42854337e-03 2.29512052e-02 1.39792379e-02 1.89046848e-02\n",
            " 1.92017968e-02 1.98819899e-02 1.33687112e-02 3.41274545e-03\n",
            " 1.58006890e-02 1.40597426e-02 3.39609338e-03 9.45049194e-03\n",
            " 5.20010097e-04 9.62225708e-04 9.22511610e-03 1.44856298e-02\n",
            " 8.86178773e-03 2.82344012e-03 9.95130960e-03 6.19958902e-03\n",
            " 8.56934555e-03 2.19085063e-02 1.70852948e-02 4.36471438e-04\n",
            " 5.70482809e-03 1.50084550e-02 7.82574526e-03 3.95405763e-03\n",
            " 1.08186456e-02 7.11532497e-03 3.63873736e-03 8.14326316e-03\n",
            " 1.56013416e-02 9.99611586e-03 1.02220712e-02 7.51256363e-03\n",
            " 1.82320740e-02 4.96291066e-03 2.34834479e-02 6.00281282e-03\n",
            " 7.11566792e-03 9.23691474e-04 4.23115565e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3190 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.13783909e-03 4.59890973e-03 1.74975890e-02 2.26900799e-02\n",
            " 1.75369711e-02 4.90056329e-03 4.31997714e-03 1.98780860e-02\n",
            " 1.54273968e-02 2.43954278e-02 7.21832233e-04 1.30345963e-02\n",
            " 1.00141799e-02 4.28444157e-03 7.00614556e-03 1.31684665e-02\n",
            " 8.85270648e-03 1.63446489e-02 2.39574896e-02 1.89330274e-02\n",
            " 1.21169827e-02 2.09486607e-02 2.37064175e-02 2.29687297e-02\n",
            " 2.08574462e-02 8.68378037e-03 2.13760784e-02 1.08571644e-02\n",
            " 1.12276859e-02 1.24867223e-02 6.76126825e-03 1.49401735e-02\n",
            " 6.12908520e-03 1.90597037e-02 7.79670204e-03 5.73480121e-03\n",
            " 8.71995264e-03 1.54373565e-03 1.00813561e-02 5.20942562e-03\n",
            " 5.71244009e-03 1.90597037e-02 3.91756317e-03 1.59069683e-05\n",
            " 2.42353672e-02 2.40561932e-02 6.19556568e-03 1.31420169e-02\n",
            " 1.45618770e-02 1.55876623e-02 3.01684866e-03 1.14138654e-02\n",
            " 1.43804448e-02 2.08346896e-02 1.85277146e-02 1.20488293e-04\n",
            " 1.02735093e-02 1.31420169e-02 1.35630812e-02 2.10912121e-03\n",
            " 7.72002796e-09 3.08758014e-03 2.34028067e-05 6.99399372e-03\n",
            " 1.33500538e-02 9.01443407e-03 4.90055520e-04 2.46633097e-07\n",
            " 1.20875182e-02 8.32264957e-03 7.69964956e-03 2.91778555e-03\n",
            " 7.91791012e-03 1.11336488e-02 9.92396931e-03 1.77865999e-02\n",
            " 5.91849378e-03 2.46524254e-02 9.50398672e-03 2.30746678e-03\n",
            " 1.21432572e-02 1.91555804e-02 2.28444639e-02 1.45253554e-02\n",
            " 9.71218693e-03 1.69891708e-02 1.92900173e-02 2.34382374e-02\n",
            " 2.28157432e-02 2.08275716e-02 2.42855758e-02 1.41152943e-02\n",
            " 2.17072454e-02 1.97176971e-02 1.19550439e-02 1.16802221e-02\n",
            " 1.78723831e-02 1.18061306e-03 2.43622848e-02 7.66168463e-03\n",
            " 1.96293768e-02 3.26525710e-03 2.23341475e-02 1.68084172e-02\n",
            " 4.31632636e-04 1.78090291e-02 1.24297760e-03 1.53891613e-02\n",
            " 2.46524254e-02 8.90611120e-03 3.60235605e-03 1.06981578e-02\n",
            " 1.87025029e-02 1.88443701e-02 1.94430816e-02 1.44933060e-02\n",
            " 9.92396931e-03 1.30539209e-02 4.34816531e-04 1.46159834e-02\n",
            " 7.86925797e-03 5.75160905e-03 2.23836004e-02 5.31595538e-03\n",
            " 2.20960666e-02 2.07557716e-02 1.98780860e-02 1.23174836e-02\n",
            " 5.47817629e-04 2.22229970e-02 1.16510505e-02 1.07999023e-02\n",
            " 4.50517680e-03 4.66426560e-03 1.27180587e-03 1.66894242e-02\n",
            " 6.23560439e-03 2.46524254e-02 1.14396525e-02 1.94368430e-02\n",
            " 6.52994975e-04 1.13857590e-03 2.43747345e-02 1.08940293e-02\n",
            " 2.09428502e-02 5.79991070e-03 7.49312751e-05 3.89852632e-03\n",
            " 1.35847330e-02 2.18801249e-02 1.85901304e-02 1.02162933e-02\n",
            " 1.14915225e-02 1.15573078e-02 2.04728018e-02 1.94115964e-03\n",
            " 8.08689376e-03 2.00397783e-02 9.13382581e-03 7.61469838e-04\n",
            " 1.54679938e-02 2.20065010e-03 1.52835526e-02 1.13399304e-02\n",
            " 2.28012227e-02 2.43630786e-02 1.04146654e-02 2.04125203e-02\n",
            " 1.49535855e-02 8.16586562e-03 2.24631827e-02 1.77362923e-02\n",
            " 9.76284629e-03 2.25310005e-02 1.95594761e-02 5.40794402e-03\n",
            " 1.35630812e-02 3.83525161e-03 8.15094166e-05 1.69860940e-02\n",
            " 2.38183141e-02 9.54208729e-03 1.43040612e-02 4.49709464e-03\n",
            " 1.51882111e-02 1.93268783e-02 1.69863302e-02 3.83525161e-03\n",
            " 1.26906740e-02 1.27785166e-02 9.39418505e-03 1.51898793e-02\n",
            " 7.15285714e-03 1.04884710e-03 1.31182836e-02 1.57449799e-02\n",
            " 1.98395919e-02 9.96337088e-03 7.83419542e-03 1.25013061e-02\n",
            " 1.61666414e-03 2.29076429e-02 1.85936043e-02 1.75756790e-02\n",
            " 1.33743040e-02 5.24118815e-05 1.76505636e-02 9.50834715e-03\n",
            " 1.52396067e-02 2.44204360e-02 1.64915270e-02 4.81805916e-03\n",
            " 3.35790977e-03 1.08896834e-02 7.47107627e-03 1.78090291e-02\n",
            " 9.71636913e-03 5.02232074e-03 9.51979205e-03 1.11952812e-02\n",
            " 1.00939443e-02 1.05818758e-02 2.36605517e-02 7.72002796e-09\n",
            " 2.43578967e-02 4.16981442e-03 9.51532836e-03 1.58883984e-02\n",
            " 8.87083417e-03 2.19136090e-02 1.25002298e-03 1.36904261e-02\n",
            " 1.37025575e-02 4.45130021e-03 1.52905883e-02 8.58095355e-03\n",
            " 2.05854281e-03 1.99099073e-02 8.24006721e-03 1.53083607e-02\n",
            " 2.23279374e-03 1.95915613e-02 2.30882813e-02 2.41407240e-02\n",
            " 7.85117021e-03 4.25865312e-03 1.23510066e-02 1.67741761e-02\n",
            " 2.32622070e-02 9.07296259e-03 5.99898678e-03 2.07630569e-02\n",
            " 5.98357868e-03 2.09205824e-02 1.89039734e-02 2.37942369e-02\n",
            " 6.86450702e-03 3.07480739e-03 8.85270648e-03 1.38309197e-02\n",
            " 1.34412171e-02 1.02252058e-02 5.51453810e-03 1.12750224e-02\n",
            " 2.21102076e-02 4.50517680e-03 1.14138654e-02 9.91769376e-03\n",
            " 8.25065442e-03 2.36217675e-02 1.30255833e-02 9.73964616e-03\n",
            " 5.84691530e-03 1.16343797e-02 8.36409012e-03 1.28436382e-02\n",
            " 1.92212529e-02 2.64922052e-03 1.42274793e-02 1.86317191e-04\n",
            " 4.41112437e-03 1.71471132e-02 2.04325914e-02 1.13075556e-02\n",
            " 1.87410354e-02 1.17350369e-02 4.27367654e-03 1.06282286e-02\n",
            " 3.51608563e-03 1.48451307e-02 1.90830822e-02 6.46214830e-03\n",
            " 7.92499098e-03 2.48255620e-02 2.01039891e-02 1.08206461e-02\n",
            " 2.49622480e-02 1.91827113e-02 5.88092235e-04 3.43912521e-03\n",
            " 1.19350830e-02 1.64915270e-02 1.57601784e-02 6.32101926e-03\n",
            " 1.39189255e-02 1.73803955e-06 1.20976346e-02 2.40304248e-02\n",
            " 1.07085721e-04 8.86040134e-04 3.18833436e-03 1.31838737e-02\n",
            " 7.06302146e-03 2.18099476e-02 3.19548094e-03 2.32607355e-02\n",
            " 9.91243167e-03 5.40016402e-03 1.96694015e-02 4.57730774e-04\n",
            " 2.49411062e-02 2.42124702e-02 2.27756565e-02 2.11118144e-02\n",
            " 1.53608672e-02 5.61626648e-03 2.40304248e-02 2.10531712e-02\n",
            " 5.93151992e-03 1.33807466e-02 1.33369660e-03 2.27486459e-02\n",
            " 1.41257529e-02 1.13317849e-02 9.34511542e-04 1.82872283e-02\n",
            " 4.76626682e-03 1.30345963e-02 7.17223564e-03 2.41621674e-02\n",
            " 2.49622480e-02 8.89890674e-03 5.72103514e-03 1.57877109e-02\n",
            " 6.45274334e-03 1.51673115e-02 4.85570251e-03 2.12644196e-02\n",
            " 2.40843457e-02 1.95915613e-02 6.00205537e-03 1.85682246e-02\n",
            " 5.69095491e-03 3.64512905e-03 8.16765884e-03 4.50517680e-03\n",
            " 1.70584053e-02 2.37963037e-02 1.05822419e-02 1.82110521e-02\n",
            " 8.51756936e-03 3.97224828e-03 2.47134914e-02 1.79818892e-02\n",
            " 1.33397410e-03 1.64944520e-03 2.08967061e-02 1.73833613e-02\n",
            " 9.61946979e-03 2.49851349e-02 2.36702396e-02 4.48746834e-03\n",
            " 1.06936825e-02 1.25270164e-02 2.10026619e-02 1.72043262e-03\n",
            " 5.56951161e-03 9.81712688e-03 1.80593175e-02 1.07146688e-04\n",
            " 8.49714785e-03 1.78462014e-02 6.33122364e-16 3.31215691e-03\n",
            " 1.67004983e-02 1.55898018e-02 6.38330708e-03 2.42768149e-02\n",
            " 1.34750708e-02 1.98969339e-02 1.13753616e-02 1.91462521e-02\n",
            " 1.48391830e-02 1.19672408e-02 1.75668724e-02 2.73194270e-04\n",
            " 8.64185574e-03 1.99031574e-02 1.08518885e-02 1.66502220e-02\n",
            " 2.39805410e-02 1.06282286e-02 7.66168463e-03 3.10703966e-03\n",
            " 4.29155319e-03 3.32416401e-03 1.25013061e-02 2.22080707e-03\n",
            " 1.69929312e-02 4.07276532e-03 1.30245950e-02 7.29477923e-03\n",
            " 7.66214787e-03 1.83224915e-03 2.89961415e-04 7.42506123e-03\n",
            " 1.36178975e-02 5.06620172e-03 7.15879046e-03 1.30155110e-02\n",
            " 4.47550636e-03 4.63002203e-04 1.51311465e-02 2.32199409e-02\n",
            " 9.07616283e-03 2.26619959e-02 1.91629637e-02 2.16646053e-03\n",
            " 4.61592265e-03 3.77294299e-03 7.53417715e-03 8.13092135e-03\n",
            " 1.99124066e-04 4.82478806e-03 1.55827705e-02 3.85383197e-03\n",
            " 8.73759573e-03 1.49473862e-02 5.03736124e-03 3.44122397e-03\n",
            " 9.66210882e-03 9.80357487e-03 2.34022082e-02 6.99874947e-03\n",
            " 1.43612297e-02 2.49290540e-02 1.75327273e-02 5.18532283e-03\n",
            " 9.85325933e-03 5.73480121e-03 1.01497100e-02 2.08527163e-02\n",
            " 1.49334743e-02 5.18149502e-03 1.06417420e-02 2.46069307e-02\n",
            " 2.20710744e-04 9.77321705e-03 1.23863556e-02 2.11087168e-02\n",
            " 1.85654299e-03 8.80995028e-03 1.05010324e-02 8.38289510e-03\n",
            " 1.97917656e-02 7.32964186e-03 2.41731232e-02 3.89852632e-03\n",
            " 1.45511812e-03 2.49622480e-02 1.99145584e-02 1.27972763e-02\n",
            " 3.30545123e-03 2.05789362e-03 1.59889377e-02 1.53250920e-02\n",
            " 1.48377103e-02 1.32243614e-03 5.17682075e-03 2.03537658e-02\n",
            " 1.61883534e-02 2.01039891e-02 1.91938302e-03 1.86742356e-02\n",
            " 5.84691530e-03 4.18007568e-03 1.68616584e-02 1.35531533e-02\n",
            " 1.68450284e-03 1.23288596e-02 2.40693260e-02 8.05297377e-03\n",
            " 3.30691773e-03 3.27790328e-03 6.76987131e-03 2.39678594e-03\n",
            " 1.55307257e-02 1.93009983e-02 5.85697575e-06 2.26424612e-02\n",
            " 2.25516043e-02 1.27983672e-02 9.19396993e-04 1.58205732e-02\n",
            " 3.98903366e-03 1.34224136e-03 1.14923396e-02 1.11216923e-02\n",
            " 1.26169364e-05 1.13181295e-02 1.16403632e-02 1.53980733e-02\n",
            " 2.30422476e-02 2.48069807e-03 1.93036889e-04 2.40304248e-02\n",
            " 9.44592098e-03 1.43612297e-02 4.00496488e-03 3.32810418e-03\n",
            " 9.71459391e-03 1.94442150e-03 8.34327765e-04 2.29092643e-03\n",
            " 1.52602455e-02 6.98460791e-04 2.13606501e-02 2.21509767e-03\n",
            " 1.19185769e-03 2.01039891e-02 2.35606540e-02 1.62014638e-02\n",
            " 3.95589420e-03 1.61115636e-02 1.49129449e-02 2.39584974e-02\n",
            " 1.15140007e-02 8.16852518e-03 5.84717642e-05 1.41840418e-02\n",
            " 6.51938472e-04 1.15981285e-02 2.37187976e-02 9.87868317e-04\n",
            " 1.29772612e-02 1.10011242e-02 1.91827113e-02 1.34748613e-02\n",
            " 1.08441762e-02 1.32391118e-02 1.44132473e-02 1.45464282e-02\n",
            " 9.92396931e-03 9.94009507e-03 2.29562333e-02 5.68317640e-03\n",
            " 2.01037808e-02 1.91419166e-02 2.27026642e-02 8.80529260e-03\n",
            " 9.14787652e-03 8.41758842e-03 1.04087096e-02 1.94442150e-03\n",
            " 1.61909858e-02 2.13682725e-02 2.02209324e-02 1.21080044e-02\n",
            " 1.10897341e-02 1.83074770e-02 2.31233691e-03 1.27277172e-02\n",
            " 3.49819035e-03 2.20901820e-02 1.03841739e-02 2.25475927e-02\n",
            " 1.80044413e-02 5.09983747e-03 1.99864929e-02 1.11400380e-02\n",
            " 2.00194547e-03 1.36074815e-02 4.46183078e-03 1.23641664e-02\n",
            " 1.73883740e-02 1.62610761e-02 8.03113217e-03 2.08252199e-02\n",
            " 1.30311836e-02 1.32747835e-02 4.79105079e-03 9.54862975e-03\n",
            " 5.90753322e-04 3.12201266e-03 9.85688970e-03 4.15053018e-03\n",
            " 1.84059978e-02 8.47304374e-03 1.78600370e-02 8.34565602e-03\n",
            " 2.20710744e-04 4.94573955e-03 2.35309949e-02 1.86917058e-02\n",
            " 1.14482046e-02 3.09145948e-03 1.56461085e-02 2.26112761e-02\n",
            " 4.18453480e-03 1.75902599e-02 1.08763515e-02 8.41730437e-03\n",
            " 2.01861063e-02 2.43900928e-02 4.71548116e-03 6.88050016e-04\n",
            " 1.51155897e-03 1.34524497e-02 2.23339539e-02 1.22280330e-03\n",
            " 1.93787489e-02 1.67547758e-02 7.83710953e-03 5.34682364e-03\n",
            " 1.68169597e-02 7.21832233e-04 2.29933787e-02 4.85446855e-03\n",
            " 1.47892448e-02 1.97601028e-02 1.94547123e-02 1.22570490e-02\n",
            " 3.41898106e-04 7.85921668e-03 2.34209332e-02 1.94442150e-03\n",
            " 7.96259188e-03 2.22281399e-02 1.45140935e-02 1.18583474e-02\n",
            " 1.35078399e-02 5.94240133e-03 7.74661889e-03 8.89167680e-03\n",
            " 1.18005599e-02 1.54665525e-02 2.08346896e-02 1.06178411e-02\n",
            " 2.40463664e-03 1.35951304e-02 3.83893003e-03 2.04470821e-02\n",
            " 1.27064153e-03 7.75531107e-03 2.19103432e-02 1.97385547e-02\n",
            " 8.50925597e-03 9.32528307e-03 2.61940343e-04 1.15248830e-02\n",
            " 3.89852632e-03 1.70198272e-02 6.38775084e-03 3.98903366e-03\n",
            " 9.63313067e-03 1.90422608e-02 4.15460377e-04 2.86248087e-03\n",
            " 1.53917582e-02 2.40005568e-02 2.10349111e-02 1.63998462e-02\n",
            " 2.30568981e-02 2.02510666e-02 5.52493879e-04 8.57609195e-03\n",
            " 2.34834083e-02 9.89646264e-03 2.06220424e-03 4.96739344e-03\n",
            " 1.62390956e-03 1.03775342e-02 1.95230827e-02 1.78454072e-02\n",
            " 1.58805554e-02 1.23776846e-02 1.06608304e-02 1.50174844e-02\n",
            " 7.11391205e-03 1.00807666e-02 1.09098166e-02 1.38919818e-04\n",
            " 7.38463752e-03 2.43378533e-03 2.09515796e-02 2.32866725e-02\n",
            " 3.44176027e-03 1.44661704e-02 1.75327273e-02 3.33505127e-03\n",
            " 4.81805916e-03 9.04163122e-03 1.90129554e-02 1.24921099e-02\n",
            " 4.49709464e-03 1.73071064e-02 6.61772991e-03 2.84190081e-03\n",
            " 1.92677740e-02 1.13555739e-02 9.98435429e-03 2.03495728e-03\n",
            " 6.29190458e-04 1.99619536e-02 2.87681579e-03 1.43396519e-02\n",
            " 1.46350684e-02 1.71400594e-02 1.79818892e-02 1.96417466e-02\n",
            " 4.44133761e-03 1.03446273e-02 1.48451307e-02 1.45923709e-02\n",
            " 1.90641745e-02 8.16352559e-03 2.07806446e-02 4.27824859e-03\n",
            " 2.13509072e-02 1.63248980e-02 6.67315839e-04 1.72881435e-02\n",
            " 1.75219767e-02 3.62367492e-03 2.37721312e-02 6.67836123e-03\n",
            " 5.56609188e-03 8.31926867e-03 5.17113621e-03 1.64915270e-02\n",
            " 1.69065498e-02 1.66506467e-02 2.07522307e-02 3.55497301e-04\n",
            " 2.87355550e-03 2.35569926e-02 3.17642868e-03 8.43227698e-03\n",
            " 1.39650994e-02 1.48229354e-02 8.66193087e-03 2.31233691e-03\n",
            " 1.46293483e-02 1.74216603e-02 2.46802981e-02 1.47726320e-03\n",
            " 1.18677951e-02 1.61559223e-02 2.51790565e-03 2.20109967e-02\n",
            " 6.30766230e-03 1.10889644e-02 1.45465452e-02 1.19524178e-02\n",
            " 4.07633522e-03 1.46551964e-02 1.98220280e-02 1.17301522e-02\n",
            " 5.61602301e-03 9.42981550e-04 1.10452688e-02 6.99726338e-03\n",
            " 4.49868161e-03 1.60715362e-02 5.26087783e-03 3.95659412e-03\n",
            " 2.22395067e-02 7.43191239e-03 5.31151289e-03 4.75338841e-03\n",
            " 2.92184271e-03 6.82724396e-03 1.88178456e-02 1.86280217e-02\n",
            " 1.10019200e-02 2.46840359e-02 2.28748262e-02 1.19498570e-03\n",
            " 6.89286733e-04 2.31720328e-02 6.19556568e-03 1.38452290e-02\n",
            " 1.07647729e-03 2.20850083e-04 1.20804220e-02 1.03879190e-02\n",
            " 1.12231828e-02 1.39459915e-03 1.97525814e-02 1.66529938e-02\n",
            " 1.49934885e-03 2.19166336e-03 2.91778555e-03 8.60560452e-05\n",
            " 1.55743323e-02 2.36605517e-02 4.00287536e-03 2.13606501e-02\n",
            " 1.85021134e-02 5.57784436e-03 5.44077088e-03 2.65302100e-06\n",
            " 1.27265460e-02 2.33854448e-02 7.14310104e-04 2.43833103e-02\n",
            " 6.39442059e-07 2.03710301e-02 1.15881475e-02 2.05145074e-02\n",
            " 1.97900464e-02 2.58142947e-05 1.77361219e-02 4.14767650e-05\n",
            " 2.26946801e-02 1.39052106e-02 1.74521273e-02 1.07318011e-02\n",
            " 1.12906868e-02 1.61492791e-03 2.49447855e-02 8.92285410e-04\n",
            " 1.19646815e-02 2.23054389e-02 1.69275580e-02 4.73846166e-03\n",
            " 2.20555217e-02 1.72218343e-02 1.61522634e-02 3.91756317e-03\n",
            " 1.46540695e-02 5.11518162e-03 1.11713710e-02 5.11518162e-03\n",
            " 7.64437200e-03 1.99472622e-02 1.91124058e-02 1.06848268e-03\n",
            " 2.33503046e-02 7.52575904e-03 2.00409046e-03 1.83931437e-02\n",
            " 4.31734064e-03 3.46362203e-04 2.32478910e-02 1.56861210e-02\n",
            " 4.27694436e-04 1.09961767e-02 1.44454903e-02 3.28688598e-03\n",
            " 1.43495843e-02 5.17108943e-03 2.38239295e-02 1.84068234e-02\n",
            " 2.07353826e-02 2.12320416e-02 4.54700275e-03 2.70183618e-04\n",
            " 5.40177803e-03 2.48751741e-02 2.29862384e-02 6.48989560e-03\n",
            " 1.86831714e-02 6.82825546e-03 1.35173833e-02 1.63519824e-02\n",
            " 5.83914491e-03 1.73801407e-02 4.74121249e-03 5.03736124e-03\n",
            " 7.67022997e-03 1.98780860e-02 1.20918368e-02 3.15908220e-03\n",
            " 1.37647726e-02 1.54631593e-02 1.77811604e-02 1.14784969e-02\n",
            " 1.51592068e-02 2.03911546e-02 5.75858218e-03 1.75681563e-02\n",
            " 6.12916953e-03 1.33192698e-02 1.95791462e-02 2.15851879e-02\n",
            " 1.87319105e-02 1.98031285e-02 2.24035133e-02 5.11261303e-03\n",
            " 3.91756317e-03 1.38004930e-02 2.07775438e-02 1.45459010e-02\n",
            " 8.26295628e-03 1.10949278e-02 1.53316674e-03 1.32628514e-03\n",
            " 3.96121464e-03 1.63166943e-02 5.46953571e-03 2.06180773e-02\n",
            " 4.15798678e-03 7.72302469e-04 1.80688100e-02 9.43398024e-03\n",
            " 1.13051552e-02 8.82459242e-03 5.89117955e-03 2.50482918e-03\n",
            " 8.33626714e-04 9.72913918e-03 1.96486797e-02 7.47722703e-03\n",
            " 7.89313328e-03 9.42792902e-03 2.00476141e-02 1.16398468e-02\n",
            " 1.01634850e-02 3.10982993e-03 1.60794615e-03 1.38170822e-03\n",
            " 2.06954895e-02 1.49988268e-02 6.73411447e-03 1.02905833e-02\n",
            " 1.12334280e-02 7.60468871e-03 1.78903033e-02 9.10770639e-03\n",
            " 1.41182744e-02 4.43037326e-03 2.20570650e-02 1.42864641e-02\n",
            " 8.39219143e-03 3.98309954e-03 9.40351915e-03 2.29386387e-02\n",
            " 1.39912457e-02 1.89330274e-02 1.91525168e-02 1.98121749e-02\n",
            " 1.33495577e-02 3.39601500e-03 1.57415373e-02 1.40226452e-02\n",
            " 3.38815743e-03 9.41721548e-03 5.16318053e-04 9.59059323e-04\n",
            " 9.21705158e-03 1.44661704e-02 8.87454249e-03 2.81580676e-03\n",
            " 9.92396931e-03 6.20453048e-03 8.54680422e-03 2.18990116e-02\n",
            " 1.70623790e-02 4.37220453e-04 5.70549556e-03 1.49938490e-02\n",
            " 7.80886297e-03 3.93411648e-03 1.08050764e-02 7.10661976e-03\n",
            " 3.62801715e-03 8.13640923e-03 1.55876623e-02 9.97220744e-03\n",
            " 1.02403269e-02 7.51138133e-03 1.81675405e-02 4.93561233e-03\n",
            " 2.33555386e-02 5.98481889e-03 7.06965415e-03 9.19396993e-04\n",
            " 4.20614656e-03]\n",
            "3200 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.13656457e-03 4.57227651e-03 1.74870459e-02 2.26326836e-02\n",
            " 1.74441405e-02 4.89498723e-03 4.32525530e-03 1.98804968e-02\n",
            " 1.53829953e-02 2.43602133e-02 7.20812862e-04 1.30401097e-02\n",
            " 9.98833318e-03 4.28024702e-03 6.97879416e-03 1.31215382e-02\n",
            " 8.81451832e-03 1.63581207e-02 2.39550176e-02 1.87451562e-02\n",
            " 1.20967927e-02 2.09241172e-02 2.37036143e-02 2.29881619e-02\n",
            " 2.08786063e-02 8.67352466e-03 2.13655479e-02 1.08248870e-02\n",
            " 1.11832307e-02 1.24103889e-02 6.78212243e-03 1.48900460e-02\n",
            " 6.06399876e-03 1.90726947e-02 7.77725377e-03 5.72507129e-03\n",
            " 8.70404779e-03 1.52985357e-03 1.00825612e-02 5.20921817e-03\n",
            " 5.70348625e-03 1.90726947e-02 3.90858989e-03 1.57333134e-05\n",
            " 2.42260368e-02 2.40024430e-02 6.16553926e-03 1.31357367e-02\n",
            " 1.45574341e-02 1.56061053e-02 3.01804607e-03 1.13801021e-02\n",
            " 1.43096009e-02 2.07909250e-02 1.84925418e-02 1.20465955e-04\n",
            " 1.01952678e-02 1.31357367e-02 1.34274040e-02 2.10532652e-03\n",
            " 7.68865728e-09 3.09064435e-03 2.33767498e-05 6.96586053e-03\n",
            " 1.33455863e-02 8.96784049e-03 4.88911237e-04 2.46437716e-07\n",
            " 1.20753548e-02 8.33766821e-03 7.66585132e-03 2.91166461e-03\n",
            " 7.90818430e-03 1.11606936e-02 9.93268372e-03 1.77858967e-02\n",
            " 5.88947155e-03 2.45119547e-02 9.45693738e-03 2.28308260e-03\n",
            " 1.21426096e-02 1.91211978e-02 2.28081528e-02 1.45120988e-02\n",
            " 9.73768965e-03 1.69576166e-02 1.93098143e-02 2.34224649e-02\n",
            " 2.28191848e-02 2.07651585e-02 2.42362854e-02 1.41100256e-02\n",
            " 2.17095909e-02 1.96974081e-02 1.19356916e-02 1.16632308e-02\n",
            " 1.78640391e-02 1.16028119e-03 2.43477989e-02 7.65749489e-03\n",
            " 1.95822783e-02 3.25616418e-03 2.23033234e-02 1.67819092e-02\n",
            " 4.31714706e-04 1.77941877e-02 1.24241458e-03 1.53858886e-02\n",
            " 2.45119547e-02 8.92255117e-03 3.58747409e-03 1.06940669e-02\n",
            " 1.87127363e-02 1.88207267e-02 1.91351325e-02 1.44864649e-02\n",
            " 9.93268372e-03 1.30358239e-02 4.33820626e-04 1.46070668e-02\n",
            " 7.83341961e-03 5.72927191e-03 2.23557349e-02 5.32316158e-03\n",
            " 2.20470839e-02 2.07773189e-02 1.98804968e-02 1.23124006e-02\n",
            " 5.41896452e-04 2.21466692e-02 1.16596946e-02 1.07248703e-02\n",
            " 4.47678647e-03 4.66953871e-03 1.27091024e-03 1.66578133e-02\n",
            " 6.14216202e-03 2.45119547e-02 1.14437271e-02 1.94481590e-02\n",
            " 6.48973927e-04 1.13445348e-03 2.43514961e-02 1.08800903e-02\n",
            " 2.09411428e-02 5.79750886e-03 7.40816142e-05 3.90038625e-03\n",
            " 1.35718814e-02 2.18025268e-02 1.85909937e-02 1.02240991e-02\n",
            " 1.14499161e-02 1.15706576e-02 2.04043020e-02 1.93623980e-03\n",
            " 8.05644870e-03 2.00487347e-02 9.10864706e-03 7.55619100e-04\n",
            " 1.54673591e-02 2.19683121e-03 1.52364873e-02 1.13347579e-02\n",
            " 2.27234058e-02 2.43316530e-02 1.03855435e-02 2.04086538e-02\n",
            " 1.49327884e-02 8.17049280e-03 2.23910989e-02 1.77597338e-02\n",
            " 9.75013936e-03 2.25508031e-02 1.95197718e-02 5.38325497e-03\n",
            " 1.34274040e-02 3.81288982e-03 8.00971784e-05 1.69637758e-02\n",
            " 2.37508839e-02 9.51535629e-03 1.43277162e-02 4.50753513e-03\n",
            " 1.51328971e-02 1.93178788e-02 1.69439514e-02 3.81288982e-03\n",
            " 1.26640235e-02 1.27400085e-02 9.31029467e-03 1.51378637e-02\n",
            " 7.11762277e-03 1.04789574e-03 1.31138942e-02 1.57472033e-02\n",
            " 1.98437409e-02 9.96076819e-03 7.79156427e-03 1.25347671e-02\n",
            " 1.61025336e-03 2.28460083e-02 1.85567165e-02 1.75252475e-02\n",
            " 1.32992324e-02 5.25232670e-05 1.76583349e-02 9.46487725e-03\n",
            " 1.51848338e-02 2.43645843e-02 1.65491170e-02 4.82833045e-03\n",
            " 3.35019853e-03 1.08520296e-02 7.47539637e-03 1.77941877e-02\n",
            " 9.67239268e-03 5.01055922e-03 9.53650252e-03 1.11903520e-02\n",
            " 1.00666568e-02 1.05990167e-02 2.37239907e-02 7.68865728e-09\n",
            " 2.43811375e-02 4.14492543e-03 9.43211596e-03 1.58576633e-02\n",
            " 8.85752577e-03 2.18854591e-02 1.23599879e-03 1.36238928e-02\n",
            " 1.36670840e-02 4.44959282e-03 1.52410631e-02 8.57859126e-03\n",
            " 2.05854812e-03 1.99223541e-02 8.14528335e-03 1.52545096e-02\n",
            " 2.21975709e-03 1.95513576e-02 2.31328214e-02 2.41111115e-02\n",
            " 7.85003578e-03 4.24709398e-03 1.23263229e-02 1.67483436e-02\n",
            " 2.32507433e-02 9.08271697e-03 5.98722319e-03 2.07425755e-02\n",
            " 5.93270801e-03 2.09324762e-02 1.88101490e-02 2.37405399e-02\n",
            " 6.85912423e-03 3.07247842e-03 8.81451832e-03 1.38066749e-02\n",
            " 1.34232877e-02 1.02228380e-02 5.49377569e-03 1.12295962e-02\n",
            " 2.20964451e-02 4.47678647e-03 1.13801021e-02 9.92097064e-03\n",
            " 8.21102788e-03 2.35831853e-02 1.29606984e-02 9.74322480e-03\n",
            " 5.83792877e-03 1.16217310e-02 8.38044680e-03 1.28258694e-02\n",
            " 1.91466864e-02 2.65457503e-03 1.41616345e-02 1.83745920e-04\n",
            " 4.41206445e-03 1.71429618e-02 2.03772548e-02 1.12930658e-02\n",
            " 1.87193574e-02 1.17273752e-02 4.25466248e-03 1.06326099e-02\n",
            " 3.50235488e-03 1.48417987e-02 1.90605435e-02 6.42817018e-03\n",
            " 7.93100750e-03 1.99772752e-02 1.07386796e-02 1.91389760e-02\n",
            " 5.75800466e-04 3.43213111e-03 1.19295534e-02 1.65491170e-02\n",
            " 1.57675652e-02 6.30081343e-03 1.38740922e-02 1.71847569e-06\n",
            " 1.20559714e-02 2.40455406e-02 1.06491678e-04 8.86731773e-04\n",
            " 3.18009224e-03 1.31677155e-02 7.06380085e-03 2.17180067e-02\n",
            " 3.19000116e-03 2.32287255e-02 9.81938539e-03 5.37291235e-03\n",
            " 1.96848363e-02 4.53465725e-04 2.42049312e-02 2.27403648e-02\n",
            " 2.10509265e-02 1.52825873e-02 5.58743288e-03 2.40455406e-02\n",
            " 2.10160108e-02 5.93474519e-03 1.33695963e-02 1.33566890e-03\n",
            " 2.27330850e-02 1.41246757e-02 1.13439779e-02 9.34721858e-04\n",
            " 1.81708437e-02 4.76889550e-03 1.30401097e-02 7.16171108e-03\n",
            " 2.41454490e-02 8.91014035e-03 5.69398045e-03 1.58423356e-02\n",
            " 6.44213845e-03 1.51607856e-02 4.84841094e-03 2.13228667e-02\n",
            " 2.40557334e-02 1.95513576e-02 5.99670970e-03 1.84934804e-02\n",
            " 5.68535961e-03 3.64400515e-03 8.15470888e-03 4.47678647e-03\n",
            " 1.70412384e-02 2.37955805e-02 1.05508840e-02 1.81768510e-02\n",
            " 8.50376629e-03 3.96064958e-03 1.79249668e-02 1.33211300e-03\n",
            " 1.63563976e-03 2.09200979e-02 1.72970384e-02 9.59121819e-03\n",
            " 2.36755390e-02 4.45567253e-03 1.06587418e-02 1.25114010e-02\n",
            " 2.09937434e-02 1.70259737e-03 5.55614205e-03 9.81438742e-03\n",
            " 1.80488298e-02 1.06329599e-04 8.44314374e-03 1.78482423e-02\n",
            " 6.30952798e-16 3.29558823e-03 1.66507243e-02 1.55913859e-02\n",
            " 6.36676797e-03 2.42149798e-02 1.34266614e-02 1.99014638e-02\n",
            " 1.13727916e-02 1.91377087e-02 1.47923929e-02 1.19599714e-02\n",
            " 1.74885033e-02 2.72156898e-04 8.61720591e-03 1.98819506e-02\n",
            " 1.08631566e-02 1.66275972e-02 2.39565100e-02 1.06326099e-02\n",
            " 7.65749489e-03 3.10970980e-03 4.29634508e-03 3.31135043e-03\n",
            " 1.25347671e-02 2.21104185e-03 1.69863117e-02 4.07486398e-03\n",
            " 1.29856081e-02 7.31269421e-03 7.64740291e-03 1.81831043e-03\n",
            " 2.88279417e-04 7.39765661e-03 1.36300751e-02 5.08105043e-03\n",
            " 7.14392574e-03 1.29993818e-02 4.47185352e-03 4.61364952e-04\n",
            " 1.50909997e-02 2.31931508e-02 9.05657092e-03 2.26204820e-02\n",
            " 1.91303493e-02 2.15873994e-03 4.59297179e-03 3.76471456e-03\n",
            " 7.47884287e-03 8.11433952e-03 1.99252560e-04 4.80938688e-03\n",
            " 1.55808846e-02 3.83375531e-03 8.71287816e-03 1.49356179e-02\n",
            " 5.02785486e-03 3.44098287e-03 9.67949904e-03 9.78894137e-03\n",
            " 2.33548936e-02 6.98956216e-03 1.43015878e-02 1.74613445e-02\n",
            " 5.16791708e-03 9.82828451e-03 5.72507129e-03 1.01173292e-02\n",
            " 2.07795151e-02 1.49087705e-02 5.18192594e-03 1.05221590e-02\n",
            " 2.45837574e-02 2.20889188e-04 9.77923517e-03 1.23780326e-02\n",
            " 2.10971576e-02 1.83813698e-03 8.80185624e-03 1.05105236e-02\n",
            " 8.37377176e-03 1.97657278e-02 7.32319836e-03 2.41402556e-02\n",
            " 3.90038625e-03 1.45217657e-03 1.98383350e-02 1.28270182e-02\n",
            " 3.29770253e-03 2.05124809e-03 1.59905008e-02 1.52276800e-02\n",
            " 1.48463298e-02 1.32079235e-03 5.16969550e-03 2.03612895e-02\n",
            " 1.61154696e-02 1.99772752e-02 1.91544734e-03 1.86879500e-02\n",
            " 5.83792877e-03 4.17866380e-03 1.68693098e-02 1.35672483e-02\n",
            " 1.67629813e-03 1.22156672e-02 2.40110598e-02 8.03711863e-03\n",
            " 3.26806748e-03 3.26128844e-03 6.76798867e-03 2.38950279e-03\n",
            " 1.55542486e-02 1.92294310e-02 5.84388127e-06 2.26329991e-02\n",
            " 2.24255549e-02 1.28025935e-02 9.12619783e-04 1.57862915e-02\n",
            " 3.98884776e-03 1.33877235e-03 1.14677167e-02 1.10480309e-02\n",
            " 1.23743088e-05 1.12910422e-02 1.15876664e-02 1.53749764e-02\n",
            " 2.30426052e-02 2.47838976e-03 1.92432352e-04 2.40455406e-02\n",
            " 9.38608573e-03 1.43015878e-02 3.99188565e-03 3.29627172e-03\n",
            " 9.69818170e-03 1.94328744e-03 8.26935969e-04 2.29120478e-03\n",
            " 1.52116332e-02 6.87631782e-04 2.13891501e-02 2.20375492e-03\n",
            " 1.18154653e-03 1.99772752e-02 2.35467996e-02 1.61224453e-02\n",
            " 3.91313041e-03 1.61191480e-02 1.48196155e-02 2.39477692e-02\n",
            " 1.14752253e-02 8.15214459e-03 5.81572114e-05 1.41242735e-02\n",
            " 6.48616740e-04 1.15873928e-02 2.36650859e-02 9.84224952e-04\n",
            " 1.29967543e-02 1.09954332e-02 1.91389760e-02 1.34701904e-02\n",
            " 1.08524667e-02 1.32012442e-02 1.43350472e-02 1.44957057e-02\n",
            " 9.93268372e-03 9.89276480e-03 2.29414973e-02 5.68070754e-03\n",
            " 2.00975851e-02 1.90169868e-02 2.26619957e-02 8.79679287e-03\n",
            " 9.08536179e-03 8.41493346e-03 1.03076156e-02 1.94328744e-03\n",
            " 1.60966301e-02 2.13788716e-02 2.02520454e-02 1.20026983e-02\n",
            " 1.10637886e-02 1.82291631e-02 2.32143191e-03 1.26771098e-02\n",
            " 3.50407262e-03 2.20129849e-02 1.03825202e-02 2.25406317e-02\n",
            " 1.79948519e-02 5.09709480e-03 1.99899924e-02 1.11083895e-02\n",
            " 1.99393732e-03 1.35962017e-02 4.42986464e-03 1.23618913e-02\n",
            " 1.73173330e-02 1.62069984e-02 7.99810783e-03 2.08088856e-02\n",
            " 1.30284850e-02 1.32312090e-02 4.77211667e-03 9.49605945e-03\n",
            " 5.88935959e-04 3.11366006e-03 9.83259267e-03 4.13669886e-03\n",
            " 1.83766083e-02 8.47655349e-03 1.77741996e-02 8.27033624e-03\n",
            " 2.20889188e-04 4.91551318e-03 2.35398089e-02 1.86696328e-02\n",
            " 1.13829203e-02 3.06653241e-03 1.56703152e-02 2.25371965e-02\n",
            " 4.17518690e-03 1.75910136e-02 1.08765767e-02 8.40195044e-03\n",
            " 2.01012224e-02 2.43571159e-02 4.71925282e-03 6.86012716e-04\n",
            " 1.50800393e-03 1.34043550e-02 2.23510774e-02 1.22028650e-03\n",
            " 1.92918732e-02 1.67512904e-02 7.80458159e-03 5.32774452e-03\n",
            " 1.68314038e-02 7.20812862e-04 2.29315503e-02 4.87239635e-03\n",
            " 1.47505728e-02 1.97330131e-02 1.94211225e-02 1.22172743e-02\n",
            " 3.40430518e-04 7.86046675e-03 2.33833855e-02 1.94328744e-03\n",
            " 7.94676694e-03 2.22286124e-02 1.44669288e-02 1.18563823e-02\n",
            " 1.34905661e-02 5.95206457e-03 7.75328517e-03 8.84377098e-03\n",
            " 1.18092829e-02 1.54074905e-02 2.07909250e-02 1.06114683e-02\n",
            " 2.38412166e-03 1.35990895e-02 3.83098032e-03 2.04673762e-02\n",
            " 1.25856172e-03 7.76381584e-03 2.18455296e-02 1.97209178e-02\n",
            " 8.49359674e-03 9.27845758e-03 2.61122168e-04 1.15623845e-02\n",
            " 3.90038625e-03 1.69616790e-02 6.34165826e-03 3.98884776e-03\n",
            " 9.59961940e-03 1.90388814e-02 4.15698562e-04 2.80918503e-03\n",
            " 1.53653963e-02 2.39437866e-02 2.09829415e-02 1.64259001e-02\n",
            " 2.30544594e-02 2.02133961e-02 5.43034054e-04 8.56444955e-03\n",
            " 2.34139576e-02 9.89694917e-03 2.06467799e-03 4.94256441e-03\n",
            " 1.61471952e-03 1.03422765e-02 1.95004897e-02 1.78471707e-02\n",
            " 1.58708402e-02 1.23939737e-02 1.06628522e-02 1.49704625e-02\n",
            " 7.10653842e-03 1.00605536e-02 1.08973830e-02 1.38501372e-04\n",
            " 7.35870881e-03 2.41296924e-03 2.07470624e-02 2.32386310e-02\n",
            " 3.44062516e-03 1.44447501e-02 1.74613445e-02 3.30990826e-03\n",
            " 4.82833045e-03 9.02260464e-03 1.89185983e-02 1.24914291e-02\n",
            " 4.50753513e-03 1.73287200e-02 6.57193941e-03 2.81829342e-03\n",
            " 1.92743364e-02 1.12076894e-02 9.98865465e-03 2.02770326e-03\n",
            " 6.27701803e-04 1.99698930e-02 2.86904514e-03 1.42525888e-02\n",
            " 1.45509339e-02 1.70701083e-02 1.79249668e-02 1.96476851e-02\n",
            " 4.42507166e-03 1.03517329e-02 1.48417987e-02 1.46078247e-02\n",
            " 1.89571262e-02 8.12457898e-03 2.07668219e-02 4.25149869e-03\n",
            " 2.12614401e-02 1.63005288e-02 6.62267534e-04 1.72825233e-02\n",
            " 1.74206220e-02 3.62444618e-03 2.36959565e-02 6.68418837e-03\n",
            " 5.56024636e-03 8.31515650e-03 5.13246413e-03 1.65491170e-02\n",
            " 1.69011167e-02 1.65729919e-02 2.07503448e-02 3.53901037e-04\n",
            " 2.87029067e-03 2.35221150e-02 3.16309957e-03 8.44803995e-03\n",
            " 1.39472267e-02 1.48088053e-02 8.62693617e-03 2.32143191e-03\n",
            " 1.45549447e-02 1.74359144e-02 2.45857409e-02 1.46036080e-03\n",
            " 1.18690265e-02 1.61060017e-02 2.50882376e-03 2.20262539e-02\n",
            " 6.26456607e-03 1.10962514e-02 1.44087246e-02 1.18432810e-02\n",
            " 4.06927269e-03 1.46419748e-02 1.97839705e-02 1.17677046e-02\n",
            " 5.62723781e-03 9.38224033e-04 1.09551812e-02 6.99092655e-03\n",
            " 4.49539098e-03 1.59509249e-02 5.22370640e-03 3.96431397e-03\n",
            " 2.22639071e-02 7.42357805e-03 5.29692327e-03 4.76539407e-03\n",
            " 2.91592365e-03 6.80607035e-03 1.87768141e-02 1.85750908e-02\n",
            " 1.10085163e-02 2.46719158e-02 2.28504229e-02 1.19819105e-03\n",
            " 6.87366744e-04 2.31850372e-02 6.16553926e-03 1.37856678e-02\n",
            " 1.07604588e-03 2.20290713e-04 1.20154809e-02 1.02531117e-02\n",
            " 1.12133631e-02 1.39421435e-03 1.96835132e-02 1.66575222e-02\n",
            " 1.49730878e-03 2.18660187e-03 2.91166461e-03 8.59233816e-05\n",
            " 1.55500500e-02 2.37239907e-02 3.97523740e-03 2.13891501e-02\n",
            " 1.85253931e-02 5.59601272e-03 5.45338928e-03 2.62399828e-06\n",
            " 1.25813798e-02 2.33178376e-02 7.09666598e-04 2.43396172e-02\n",
            " 6.20628542e-07 2.03621469e-02 1.15050765e-02 2.04597486e-02\n",
            " 1.97948464e-02 2.54555466e-05 1.77246970e-02 4.09918188e-05\n",
            " 2.26725693e-02 1.38540193e-02 1.74103079e-02 1.07062502e-02\n",
            " 1.12945377e-02 1.61375021e-03 8.92066701e-04 1.19535495e-02\n",
            " 2.22299820e-02 1.69488280e-02 4.69221500e-03 2.20247378e-02\n",
            " 1.72127853e-02 1.61223678e-02 3.90858989e-03 1.46042636e-02\n",
            " 5.09891611e-03 1.11068839e-02 5.09891611e-03 7.61813395e-03\n",
            " 1.99769957e-02 1.91298790e-02 1.06425335e-03 2.32304676e-02\n",
            " 7.51245686e-03 1.98797706e-03 1.83479645e-02 4.30144503e-03\n",
            " 3.47101579e-04 2.32902795e-02 1.56436953e-02 4.24915879e-04\n",
            " 1.09103095e-02 1.44483821e-02 3.27225608e-03 1.43317966e-02\n",
            " 5.16814344e-03 2.38126436e-02 1.84057410e-02 2.07477438e-02\n",
            " 2.11664329e-02 4.55343162e-03 2.70619788e-04 5.38388979e-03\n",
            " 2.29058800e-02 6.46044208e-03 1.86524587e-02 6.78523578e-03\n",
            " 1.34751335e-02 1.63187009e-02 5.84488539e-03 1.73070401e-02\n",
            " 4.73073227e-03 5.02785486e-03 7.45104658e-03 1.98804968e-02\n",
            " 1.20613860e-02 3.15888472e-03 1.37272743e-02 1.53952348e-02\n",
            " 1.77566529e-02 1.14717616e-02 1.51290920e-02 2.03473386e-02\n",
            " 5.75545749e-03 1.75452024e-02 6.12366484e-03 1.33069924e-02\n",
            " 1.95575920e-02 2.16030905e-02 1.87369274e-02 1.98143757e-02\n",
            " 2.23723065e-02 5.07366209e-03 3.90858989e-03 1.37864833e-02\n",
            " 2.06533997e-02 1.44077731e-02 8.28122074e-03 1.10456553e-02\n",
            " 1.52671823e-03 1.32349297e-03 3.95327664e-03 1.62626674e-02\n",
            " 5.47015968e-03 2.06235439e-02 4.17160029e-03 7.69969875e-04\n",
            " 1.79502400e-02 9.44139749e-03 1.12906438e-02 8.80833829e-03\n",
            " 5.88664241e-03 2.50291650e-03 8.25696422e-04 9.69208787e-03\n",
            " 1.95650122e-02 7.42182042e-03 7.86067946e-03 9.40071713e-03\n",
            " 2.00467155e-02 1.16232572e-02 1.00864733e-02 3.09846474e-03\n",
            " 1.60540093e-03 1.37038241e-03 2.06434387e-02 1.49501827e-02\n",
            " 6.71696768e-03 1.02977817e-02 1.12003466e-02 7.60287094e-03\n",
            " 1.78557279e-02 9.01473616e-03 1.40758951e-02 4.41798158e-03\n",
            " 2.20101044e-02 1.42617832e-02 8.35867182e-03 3.95909808e-03\n",
            " 9.40881122e-03 2.28911862e-02 1.38153909e-02 1.87451562e-02\n",
            " 1.90776668e-02 1.98109214e-02 1.33493777e-02 3.39010346e-03\n",
            " 1.57251766e-02 1.40299214e-02 3.38441268e-03 9.37391508e-03\n",
            " 5.13844375e-04 9.58803632e-04 9.20401802e-03 1.44447501e-02\n",
            " 8.82997351e-03 2.80992790e-03 9.93268372e-03 6.21241951e-03\n",
            " 8.53005618e-03 2.18262870e-02 1.70264672e-02 4.34931879e-04\n",
            " 5.71539890e-03 1.49788483e-02 7.81813445e-03 3.90688806e-03\n",
            " 1.07885538e-02 7.08148681e-03 3.62861767e-03 8.09528960e-03\n",
            " 1.56061053e-02 9.97942274e-03 1.02379253e-02 7.52250928e-03\n",
            " 1.81706641e-02 4.91894441e-03 2.33111807e-02 5.96298988e-03\n",
            " 7.05279513e-03 9.12619783e-04 4.19270890e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3210 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.11661470e-03 4.56741305e-03 1.74821352e-02 2.25974077e-02\n",
            " 1.74105753e-02 4.90519988e-03 4.30579865e-03 1.96321669e-02\n",
            " 1.53566858e-02 7.19948441e-04 1.30469023e-02 9.94481198e-03\n",
            " 4.26231994e-03 6.97460720e-03 1.30889388e-02 8.79627465e-03\n",
            " 1.63355892e-02 2.39808707e-02 1.87427799e-02 1.20631514e-02\n",
            " 2.09294412e-02 2.37597869e-02 2.29502902e-02 2.08181732e-02\n",
            " 8.68587856e-03 2.13515573e-02 1.07899020e-02 1.11948148e-02\n",
            " 1.23291784e-02 6.77398534e-03 1.48903538e-02 6.08456094e-03\n",
            " 1.90083600e-02 7.69570875e-03 5.72428570e-03 8.67573987e-03\n",
            " 1.53120564e-03 1.00689069e-02 5.18264481e-03 5.68906044e-03\n",
            " 1.90083600e-02 3.90742419e-03 1.57050157e-05 2.42051226e-02\n",
            " 2.40065736e-02 6.16466106e-03 1.31175217e-02 1.45328579e-02\n",
            " 1.56304048e-02 3.02041853e-03 1.13544047e-02 1.43292398e-02\n",
            " 2.07707027e-02 1.85280096e-02 1.19381001e-04 1.02083086e-02\n",
            " 1.31175217e-02 1.33548179e-02 2.09495709e-03 7.59647905e-09\n",
            " 3.10430824e-03 2.30154034e-05 6.93811902e-03 1.32698209e-02\n",
            " 8.97635815e-03 4.87706312e-04 2.48242245e-07 1.20504421e-02\n",
            " 8.29694101e-03 7.65605556e-03 2.91134483e-03 7.90851429e-03\n",
            " 1.11184038e-02 9.94266454e-03 1.77425817e-02 5.88643201e-03\n",
            " 9.40282917e-03 2.28031000e-03 1.20602542e-02 1.90768738e-02\n",
            " 2.28050127e-02 1.44771451e-02 9.75021582e-03 1.68725689e-02\n",
            " 1.92523288e-02 2.33806429e-02 2.27583152e-02 2.07698930e-02\n",
            " 2.42389204e-02 1.40568313e-02 2.17112395e-02 1.96426965e-02\n",
            " 1.18807220e-02 1.16552497e-02 1.78247344e-02 1.14625366e-03\n",
            " 2.42759712e-02 7.63742609e-03 1.95877319e-02 3.23909269e-03\n",
            " 2.22685261e-02 1.67705924e-02 4.31219652e-04 1.77641417e-02\n",
            " 1.23303630e-03 1.53754950e-02 8.82855568e-03 3.54236622e-03\n",
            " 1.06661648e-02 1.86540489e-02 1.87611727e-02 1.90923595e-02\n",
            " 1.45137558e-02 9.94266454e-03 1.29927196e-02 4.35202733e-04\n",
            " 1.45927544e-02 7.80373485e-03 5.73688871e-03 2.23879502e-02\n",
            " 5.29853432e-03 2.20214871e-02 2.07172849e-02 1.96321669e-02\n",
            " 1.23060604e-02 5.39710773e-04 2.21115816e-02 1.16051989e-02\n",
            " 1.06916236e-02 4.44307736e-03 4.64759410e-03 1.26460310e-03\n",
            " 1.66029680e-02 6.11803818e-03 1.14138855e-02 1.94171233e-02\n",
            " 6.46117778e-04 1.13135859e-03 2.43432872e-02 1.08534193e-02\n",
            " 2.09029262e-02 5.75470109e-03 7.39276099e-05 3.90069835e-03\n",
            " 1.35760037e-02 2.16970106e-02 1.85875019e-02 1.01989899e-02\n",
            " 1.14248331e-02 1.15548450e-02 2.04159330e-02 1.93452274e-03\n",
            " 8.04890707e-03 2.00234709e-02 9.03896167e-03 7.51548638e-04\n",
            " 1.54403018e-02 2.17692902e-03 1.52290345e-02 1.12724633e-02\n",
            " 2.27224794e-02 2.43100293e-02 1.03688632e-02 2.04085113e-02\n",
            " 1.49423199e-02 8.16626136e-03 2.24059808e-02 1.77076604e-02\n",
            " 9.71324087e-03 2.25294622e-02 1.95458335e-02 5.37782447e-03\n",
            " 1.33548179e-02 3.78286362e-03 7.91499849e-05 1.69759907e-02\n",
            " 2.37252497e-02 9.45909859e-03 1.43007198e-02 4.49057328e-03\n",
            " 1.51452999e-02 1.93124824e-02 1.69356042e-02 3.78286362e-03\n",
            " 1.25766790e-02 1.27330792e-02 9.29758152e-03 1.51204473e-02\n",
            " 7.10633413e-03 1.04671335e-03 1.30652674e-02 1.57242088e-02\n",
            " 1.97983704e-02 9.91106160e-03 7.80267476e-03 1.23429591e-02\n",
            " 1.60721733e-03 2.28833810e-02 1.85590861e-02 1.74746458e-02\n",
            " 1.32768662e-02 5.21656106e-05 1.76182559e-02 9.44328994e-03\n",
            " 1.51698386e-02 1.64499900e-02 4.82511705e-03 3.34281629e-03\n",
            " 1.08093442e-02 7.46120258e-03 1.77641417e-02 9.66059037e-03\n",
            " 4.97682513e-03 9.51879349e-03 1.11796647e-02 1.00188474e-02\n",
            " 1.06132908e-02 2.36806625e-02 7.59647905e-09 4.10447648e-03\n",
            " 9.41404340e-03 1.58230827e-02 8.85783572e-03 2.19086131e-02\n",
            " 1.22817370e-03 1.35343988e-02 1.36509200e-02 4.40383683e-03\n",
            " 1.52300287e-02 8.54794071e-03 2.04010119e-03 1.99237545e-02\n",
            " 8.13526433e-03 1.51758513e-02 2.21564997e-03 1.94169485e-02\n",
            " 2.30361293e-02 2.41365545e-02 7.83880460e-03 4.23731706e-03\n",
            " 1.23079927e-02 1.67213047e-02 2.32071942e-02 9.07994774e-03\n",
            " 5.96959397e-03 2.07316978e-02 5.90811854e-03 2.08870188e-02\n",
            " 1.88150361e-02 2.37350690e-02 6.85101606e-03 3.07170000e-03\n",
            " 8.79627465e-03 1.37546058e-02 1.34454805e-02 1.02037199e-02\n",
            " 5.46403606e-03 1.11917225e-02 2.20505513e-02 4.44307736e-03\n",
            " 1.13544047e-02 9.90803602e-03 8.19483849e-03 2.35901104e-02\n",
            " 1.29214092e-02 9.71977400e-03 5.83611934e-03 1.16519928e-02\n",
            " 8.36387227e-03 1.27818893e-02 1.91598455e-02 2.60920568e-03\n",
            " 1.41112518e-02 1.81919783e-04 4.39078451e-03 1.71100246e-02\n",
            " 2.01908892e-02 1.12341230e-02 1.86809183e-02 1.17217478e-02\n",
            " 4.24696295e-03 1.06143640e-02 3.49931293e-03 1.48657555e-02\n",
            " 1.89980457e-02 6.38236220e-03 7.90407029e-03 1.99524491e-02\n",
            " 1.06661567e-02 1.91276059e-02 5.71912650e-04 3.41919159e-03\n",
            " 1.19250703e-02 1.64499900e-02 1.57546362e-02 6.29267300e-03\n",
            " 1.38495962e-02 1.65399467e-06 1.19869524e-02 2.40328768e-02\n",
            " 1.05502653e-04 8.86948356e-04 3.17698879e-03 1.30928820e-02\n",
            " 7.01010970e-03 2.17203596e-02 3.18078365e-03 2.30525318e-02\n",
            " 9.82479209e-03 5.35899269e-03 1.96922945e-02 4.52437439e-04\n",
            " 2.41545028e-02 2.26919311e-02 2.10737575e-02 1.52659715e-02\n",
            " 5.58946695e-03 2.40328768e-02 2.09443749e-02 5.93365232e-03\n",
            " 1.33410373e-02 1.33101096e-03 2.27268518e-02 1.41103795e-02\n",
            " 1.13106573e-02 9.30045219e-04 1.81281870e-02 4.76858545e-03\n",
            " 1.30469023e-02 7.14054796e-03 2.40253948e-02 8.90855909e-03\n",
            " 5.67677556e-03 1.58552836e-02 6.43700157e-03 1.51217698e-02\n",
            " 4.83721144e-03 2.12161411e-02 2.40247371e-02 1.94169485e-02\n",
            " 5.99726013e-03 1.85146879e-02 5.68178655e-03 3.63650834e-03\n",
            " 8.13379396e-03 4.44307736e-03 1.69811178e-02 2.37605809e-02\n",
            " 1.05223880e-02 1.81532902e-02 8.48518137e-03 3.94787318e-03\n",
            " 1.78437733e-02 1.33061601e-03 1.62407737e-03 2.08619039e-02\n",
            " 1.72513856e-02 9.57186073e-03 2.36377921e-02 4.43299723e-03\n",
            " 1.06487874e-02 1.24906879e-02 2.09562376e-02 1.69627533e-03\n",
            " 5.54193916e-03 9.75064936e-03 1.79849201e-02 1.05088664e-04\n",
            " 8.41883939e-03 1.78697041e-02 6.04270346e-16 3.27906847e-03\n",
            " 1.66071090e-02 1.55000332e-02 6.35656441e-03 2.41311816e-02\n",
            " 1.34049459e-02 1.98378423e-02 1.12927047e-02 1.91256595e-02\n",
            " 1.47405857e-02 1.19448650e-02 1.74780333e-02 2.71014894e-04\n",
            " 8.56422980e-03 1.97842726e-02 1.08408409e-02 1.65988703e-02\n",
            " 2.39407267e-02 1.06143640e-02 7.63742609e-03 3.08568776e-03\n",
            " 4.30050927e-03 3.32112517e-03 1.23429591e-02 2.20897081e-03\n",
            " 1.69964448e-02 4.05734052e-03 1.30000094e-02 7.30004372e-03\n",
            " 7.64149898e-03 1.81887797e-03 2.85674591e-04 7.39125586e-03\n",
            " 1.36059362e-02 5.05459136e-03 7.12893708e-03 1.29626812e-02\n",
            " 4.45178203e-03 4.58779235e-04 1.50834930e-02 2.31398847e-02\n",
            " 9.01791826e-03 2.26629554e-02 1.90698862e-02 2.15476608e-03\n",
            " 4.59257255e-03 3.75142518e-03 7.41873722e-03 8.08107455e-03\n",
            " 1.98402920e-04 4.76831542e-03 1.55573263e-02 3.82382538e-03\n",
            " 8.72008012e-03 1.49333809e-02 5.02114061e-03 3.43721629e-03\n",
            " 9.68741083e-03 9.78881033e-03 2.32150811e-02 7.00402525e-03\n",
            " 1.42515976e-02 1.74383768e-02 5.13351647e-03 9.80852321e-03\n",
            " 5.72428570e-03 1.01048979e-02 2.07273039e-02 1.48965211e-02\n",
            " 5.15650203e-03 1.05087855e-02 2.21161305e-04 9.77075515e-03\n",
            " 1.22977140e-02 2.10233677e-02 1.82813844e-03 8.77536394e-03\n",
            " 1.05170531e-02 8.36974641e-03 1.96744381e-02 7.30168355e-03\n",
            " 2.40404829e-02 3.90069835e-03 1.44199990e-03 1.98339716e-02\n",
            " 1.28230418e-02 3.29112568e-03 2.05234797e-03 1.59234036e-02\n",
            " 1.52070390e-02 1.48106403e-02 1.32034261e-03 5.13652333e-03\n",
            " 2.03384231e-02 1.61380416e-02 1.99524491e-02 1.90388385e-03\n",
            " 1.86834583e-02 5.83611934e-03 4.15910324e-03 1.68633362e-02\n",
            " 1.35592225e-02 1.67371026e-03 1.21522599e-02 2.39800865e-02\n",
            " 8.01218030e-03 3.26800393e-03 3.24972474e-03 6.76912572e-03\n",
            " 2.37491728e-03 1.55155133e-02 1.92328690e-02 5.77240420e-06\n",
            " 2.26516562e-02 2.22877150e-02 1.28084320e-02 9.08356012e-04\n",
            " 1.57271948e-02 3.99648825e-03 1.33617831e-03 1.14384803e-02\n",
            " 1.09264211e-02 1.23526942e-05 1.12344518e-02 1.15409255e-02\n",
            " 1.53210614e-02 2.30499057e-02 2.47518967e-03 1.91977365e-04\n",
            " 2.40328768e-02 9.34289157e-03 1.42515976e-02 3.98762958e-03\n",
            " 3.29695224e-03 9.64844079e-03 1.93721837e-03 8.22157478e-04\n",
            " 2.28742173e-03 1.51827713e-02 6.86151471e-04 2.13252125e-02\n",
            " 2.20296089e-03 1.17915971e-03 1.99524491e-02 2.34773308e-02\n",
            " 1.60594831e-02 3.90448672e-03 1.60856936e-02 1.48436852e-02\n",
            " 2.39172067e-02 1.14577501e-02 8.13065859e-03 5.81296274e-05\n",
            " 1.41145844e-02 6.48150189e-04 1.15816874e-02 2.35598131e-02\n",
            " 9.80876434e-04 1.29749066e-02 1.09916347e-02 1.91276059e-02\n",
            " 1.33378756e-02 1.08361113e-02 1.32104632e-02 1.43066158e-02\n",
            " 1.44674070e-02 9.94266454e-03 9.89714266e-03 2.29060358e-02\n",
            " 5.67056303e-03 1.99842080e-02 1.89988540e-02 2.26930941e-02\n",
            " 8.77486945e-03 9.07207699e-03 8.42097582e-03 1.02640068e-02\n",
            " 1.93721837e-03 1.60362544e-02 2.13047396e-02 2.02386667e-02\n",
            " 1.19695977e-02 1.10465784e-02 1.82111405e-02 2.31599133e-03\n",
            " 1.26212228e-02 3.49466929e-03 2.19683073e-02 1.03650951e-02\n",
            " 2.25174823e-02 1.79615379e-02 5.06807021e-03 1.99804968e-02\n",
            " 1.10901927e-02 1.98574518e-03 1.35615232e-02 4.39040126e-03\n",
            " 1.23460758e-02 1.72785323e-02 1.62729740e-02 8.01657736e-03\n",
            " 2.07921235e-02 1.30154343e-02 1.31485466e-02 4.76093246e-03\n",
            " 9.51397724e-03 5.87734450e-04 3.12191311e-03 9.80722653e-03\n",
            " 4.13517492e-03 1.83136816e-02 8.40661120e-03 1.77805976e-02\n",
            " 8.19313517e-03 2.21161305e-04 4.88455941e-03 2.35092350e-02\n",
            " 1.85771422e-02 1.14009840e-02 3.07181325e-03 1.56323902e-02\n",
            " 2.24824023e-02 4.16858789e-03 1.75907802e-02 1.08517156e-02\n",
            " 8.39477976e-03 2.00574912e-02 4.70786956e-03 6.79310112e-04\n",
            " 1.50376125e-03 1.33551595e-02 2.23551398e-02 1.21914801e-03\n",
            " 1.93172216e-02 1.67222536e-02 7.77983776e-03 5.31262895e-03\n",
            " 1.67400378e-02 7.19948441e-04 2.28783253e-02 4.87658933e-03\n",
            " 1.47460219e-02 1.96827828e-02 1.94359115e-02 1.21309466e-02\n",
            " 3.37863835e-04 7.89404389e-03 2.33760133e-02 1.93721837e-03\n",
            " 7.91068825e-03 2.21645077e-02 1.44126428e-02 1.18068995e-02\n",
            " 1.34449827e-02 5.95962456e-03 7.73862332e-03 8.78898554e-03\n",
            " 1.17957178e-02 1.53854241e-02 2.07707027e-02 1.05918375e-02\n",
            " 2.37654019e-03 1.35653008e-02 3.82267685e-03 2.03646962e-02\n",
            " 1.25248819e-03 7.72322293e-03 2.17499459e-02 1.97284541e-02\n",
            " 8.50900940e-03 9.23209490e-03 2.60535638e-04 1.15960845e-02\n",
            " 3.90069835e-03 1.68857074e-02 6.32149104e-03 3.99648825e-03\n",
            " 9.56307923e-03 1.90408604e-02 4.15183173e-04 2.79849915e-03\n",
            " 1.53117604e-02 2.38138429e-02 2.10044713e-02 1.64044447e-02\n",
            " 2.30392297e-02 2.02073680e-02 5.42972866e-04 8.58194589e-03\n",
            " 2.34055086e-02 9.86721569e-03 2.06754122e-03 4.91761061e-03\n",
            " 1.61623912e-03 1.03030700e-02 1.94144643e-02 1.78481328e-02\n",
            " 1.57760610e-02 1.23853218e-02 1.06524580e-02 1.48699651e-02\n",
            " 7.10478616e-03 1.00583980e-02 1.08576363e-02 1.38423960e-04\n",
            " 7.36995454e-03 2.39175784e-03 2.07000211e-02 2.32171645e-02\n",
            " 3.42681524e-03 1.44376179e-02 1.74383768e-02 3.30365226e-03\n",
            " 4.82511705e-03 9.02238729e-03 1.89768178e-02 1.25024996e-02\n",
            " 4.49057328e-03 1.73515477e-02 6.55192399e-03 2.79610571e-03\n",
            " 1.92627428e-02 1.12252020e-02 9.97601604e-03 2.02432218e-03\n",
            " 6.24509223e-04 2.00057941e-02 2.86561625e-03 1.42073371e-02\n",
            " 1.44641733e-02 1.70578597e-02 1.78437733e-02 1.96296636e-02\n",
            " 4.41870369e-03 1.03626873e-02 1.48657555e-02 1.46297608e-02\n",
            " 1.89484992e-02 8.10769995e-03 2.07203107e-02 4.20827554e-03\n",
            " 2.12814665e-02 1.63259469e-02 6.61144667e-04 1.72452566e-02\n",
            " 1.74454113e-02 3.60410007e-03 2.36768223e-02 6.66129640e-03\n",
            " 5.54773695e-03 8.30797412e-03 5.09993547e-03 1.64499900e-02\n",
            " 1.68905654e-02 1.65635341e-02 2.07028484e-02 3.53959828e-04\n",
            " 2.85928145e-03 2.34851971e-02 3.15931883e-03 8.41319104e-03\n",
            " 1.39198566e-02 1.47566996e-02 8.59496392e-03 2.31599133e-03\n",
            " 1.45318416e-02 1.74480410e-02 1.45744815e-03 1.17845223e-02\n",
            " 1.60965058e-02 2.50601481e-03 2.20204336e-02 6.25504509e-03\n",
            " 1.10652680e-02 1.43844150e-02 1.18657529e-02 4.07490695e-03\n",
            " 1.45954914e-02 1.97855693e-02 1.17523236e-02 5.63192141e-03\n",
            " 9.33552951e-04 1.09427440e-02 6.97516858e-03 4.45925562e-03\n",
            " 1.58491743e-02 5.22793992e-03 3.96020363e-03 2.22256648e-02\n",
            " 7.42839688e-03 5.28583762e-03 4.74873566e-03 2.91418504e-03\n",
            " 6.79568959e-03 1.87774340e-02 1.84994226e-02 1.10248568e-02\n",
            " 2.28714198e-02 1.19279137e-03 6.86494206e-04 2.31710079e-02\n",
            " 6.16466106e-03 1.37709826e-02 1.06969451e-03 2.19322812e-04\n",
            " 1.19173017e-02 1.01475455e-02 1.11964580e-02 1.38988612e-03\n",
            " 1.96675827e-02 1.66257038e-02 1.50087677e-03 2.18107240e-03\n",
            " 2.91134483e-03 8.52857966e-05 1.54897007e-02 2.36806625e-02\n",
            " 3.97522571e-03 2.13252125e-02 1.85242310e-02 5.53258586e-03\n",
            " 5.42184067e-03 2.57311948e-06 1.25615150e-02 2.32705752e-02\n",
            " 7.09263854e-04 2.42551107e-02 5.76265169e-07 2.02833162e-02\n",
            " 1.14172535e-02 2.04527299e-02 1.97218582e-02 2.52702322e-05\n",
            " 1.77351013e-02 4.05584907e-05 2.25735535e-02 1.38446562e-02\n",
            " 1.73876494e-02 1.06945338e-02 1.12878173e-02 1.61330116e-03\n",
            " 8.91816795e-04 1.19148112e-02 2.22055966e-02 1.69322602e-02\n",
            " 4.70059809e-03 2.20054348e-02 1.71405042e-02 1.61155149e-02\n",
            " 3.90742419e-03 1.45937276e-02 5.09973001e-03 1.11097020e-02\n",
            " 5.09973001e-03 7.63526972e-03 1.99311070e-02 1.91052980e-02\n",
            " 1.06210793e-03 2.31630891e-02 7.49126159e-03 1.98674827e-03\n",
            " 1.83044044e-02 4.28704868e-03 3.44017540e-04 2.33460003e-02\n",
            " 1.55921995e-02 4.23547672e-04 1.08820930e-02 1.44673346e-02\n",
            " 3.26431927e-03 1.43140941e-02 5.17863687e-03 2.37693986e-02\n",
            " 1.83180607e-02 2.07796893e-02 2.11479402e-02 4.52190405e-03\n",
            " 2.69610690e-04 5.37958676e-03 2.28715363e-02 6.40547253e-03\n",
            " 1.86416635e-02 6.75743352e-03 1.34423408e-02 1.62056822e-02\n",
            " 5.84196125e-03 1.73441188e-02 4.72862827e-03 5.02114061e-03\n",
            " 7.44743279e-03 1.96321669e-02 1.20370213e-02 3.15276619e-03\n",
            " 1.36822277e-02 1.53707401e-02 1.77342338e-02 1.13847889e-02\n",
            " 1.51046300e-02 2.03548297e-02 5.74838700e-03 1.75354944e-02\n",
            " 6.12182834e-03 1.32853495e-02 1.95550928e-02 2.15801208e-02\n",
            " 1.87349270e-02 1.97578856e-02 2.23706193e-02 5.04598579e-03\n",
            " 3.90742419e-03 1.37859800e-02 2.05888465e-02 1.43421400e-02\n",
            " 8.29228993e-03 1.09659953e-02 1.51812442e-03 1.31025216e-03\n",
            " 3.93981203e-03 1.62411580e-02 5.46606720e-03 2.05970634e-02\n",
            " 4.15767717e-03 7.66843808e-04 1.78783996e-02 9.44712389e-03\n",
            " 1.12361410e-02 8.79519736e-03 5.85928068e-03 2.49857892e-03\n",
            " 8.16361688e-04 9.70957600e-03 1.95858174e-02 7.35054247e-03\n",
            " 7.85728044e-03 9.39581991e-03 2.00033971e-02 1.15790706e-02\n",
            " 1.00875491e-02 3.09477430e-03 1.60111442e-03 1.37230873e-03\n",
            " 2.05617848e-02 1.48786941e-02 6.72521007e-03 1.02807911e-02\n",
            " 1.12047468e-02 7.57445233e-03 1.78446682e-02 8.91637953e-03\n",
            " 1.40038286e-02 4.41690440e-03 2.19857608e-02 1.42654552e-02\n",
            " 8.32609533e-03 3.96227444e-03 9.37422159e-03 2.28299061e-02\n",
            " 1.38216142e-02 1.87427799e-02 1.90529866e-02 1.98329861e-02\n",
            " 1.33232148e-02 3.38284175e-03 1.56623009e-02 1.39954662e-02\n",
            " 3.38321712e-03 9.33727264e-03 5.14041868e-04 9.58468013e-04\n",
            " 9.17203989e-03 1.44376179e-02 8.84265301e-03 2.80837521e-03\n",
            " 9.94266454e-03 6.20820460e-03 8.52422119e-03 2.17947209e-02\n",
            " 1.70330151e-02 4.31250916e-04 5.71048626e-03 1.49319889e-02\n",
            " 7.82573088e-03 3.89417355e-03 1.07897739e-02 7.07009137e-03\n",
            " 3.64664491e-03 8.07737934e-03 1.56304048e-02 9.88800409e-03\n",
            " 1.02145273e-02 7.51304999e-03 1.81254083e-02 4.91944001e-03\n",
            " 2.33069451e-02 5.95662880e-03 7.03530725e-03 9.08356012e-04\n",
            " 4.19385030e-03]\n",
            "3220 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.10510820e-03 4.55897977e-03 1.74353156e-02 2.24985502e-02\n",
            " 1.74184090e-02 4.90405483e-03 4.29802969e-03 1.95572063e-02\n",
            " 1.53638095e-02 7.17404758e-04 1.30052154e-02 9.91250334e-03\n",
            " 4.24797482e-03 6.95024669e-03 1.30471694e-02 8.79072512e-03\n",
            " 1.63117175e-02 2.39277706e-02 1.87416702e-02 1.20596119e-02\n",
            " 2.07940440e-02 2.37356545e-02 2.28605070e-02 2.08583488e-02\n",
            " 8.68197313e-03 2.13157910e-02 1.07640362e-02 1.11848080e-02\n",
            " 1.23146016e-02 6.77661352e-03 1.48530944e-02 6.07470857e-03\n",
            " 1.89323684e-02 7.70777289e-03 5.72528695e-03 8.64250449e-03\n",
            " 1.53325522e-03 1.00716039e-02 5.15782500e-03 5.67233279e-03\n",
            " 1.89323684e-02 3.91118047e-03 1.56798299e-05 2.39559158e-02\n",
            " 6.13475292e-03 1.30866210e-02 1.45089760e-02 1.55991393e-02\n",
            " 3.01441236e-03 1.13719972e-02 1.43074214e-02 2.07712019e-02\n",
            " 1.85513796e-02 1.18777762e-04 1.02098698e-02 1.30866210e-02\n",
            " 1.33608046e-02 2.08524811e-03 7.59860952e-09 3.10001838e-03\n",
            " 2.31420258e-05 6.93361799e-03 1.31910186e-02 8.99079650e-03\n",
            " 4.85027943e-04 2.47959765e-07 1.20157960e-02 8.24548860e-03\n",
            " 7.65266965e-03 2.91313760e-03 7.88746620e-03 1.10562678e-02\n",
            " 9.94188116e-03 1.77159165e-02 5.87729782e-03 9.39280748e-03\n",
            " 2.27183022e-03 1.19855322e-02 1.90633661e-02 2.28134444e-02\n",
            " 1.44552009e-02 9.71328903e-03 1.68537934e-02 1.92193000e-02\n",
            " 2.33122962e-02 2.27029819e-02 2.07177861e-02 1.40397357e-02\n",
            " 2.17108780e-02 1.96235529e-02 1.18825299e-02 1.16601063e-02\n",
            " 1.77261765e-02 1.14573935e-03 7.64409206e-03 1.95770328e-02\n",
            " 3.22764441e-03 2.22155236e-02 1.67360921e-02 4.29870144e-04\n",
            " 1.77439060e-02 1.21920952e-03 1.53342001e-02 8.78911256e-03\n",
            " 3.53050494e-03 1.06442974e-02 1.86365772e-02 1.87021152e-02\n",
            " 1.90980398e-02 1.45029765e-02 9.94188116e-03 1.29266764e-02\n",
            " 4.34068142e-04 1.45875246e-02 7.78590891e-03 5.68916465e-03\n",
            " 2.23678955e-02 5.29493170e-03 2.19921586e-02 2.07270156e-02\n",
            " 1.95572063e-02 1.22735042e-02 5.39459177e-04 2.21017473e-02\n",
            " 1.15877500e-02 1.06547718e-02 4.43978800e-03 4.64263981e-03\n",
            " 1.26328878e-03 1.65944040e-02 6.11578866e-03 1.13877357e-02\n",
            " 1.92874205e-02 6.43696372e-04 1.12961826e-03 1.08281794e-02\n",
            " 2.08555544e-02 5.73930014e-03 7.39236581e-05 3.89585097e-03\n",
            " 1.35555742e-02 2.16798821e-02 1.85656177e-02 1.01864677e-02\n",
            " 1.14174242e-02 1.15244209e-02 2.03812052e-02 1.92353464e-03\n",
            " 8.02566194e-03 2.00189577e-02 9.01025220e-03 7.44345131e-04\n",
            " 1.54158540e-02 2.17910961e-03 1.52075450e-02 1.12328545e-02\n",
            " 2.26905940e-02 1.03441048e-02 2.03172623e-02 1.48618797e-02\n",
            " 8.11176298e-03 2.23818358e-02 1.77088578e-02 9.70504914e-03\n",
            " 2.25184835e-02 1.95428697e-02 5.37244733e-03 1.33608046e-02\n",
            " 3.78178400e-03 7.87720476e-05 1.69716743e-02 2.36743498e-02\n",
            " 9.44194284e-03 1.42404752e-02 4.49007716e-03 1.51649967e-02\n",
            " 1.92393918e-02 1.69413197e-02 3.78178400e-03 1.25850496e-02\n",
            " 1.27048448e-02 9.29195567e-03 1.51026904e-02 7.09554025e-03\n",
            " 1.04449725e-03 1.30393723e-02 1.56921995e-02 1.97938531e-02\n",
            " 9.89452049e-03 7.78776720e-03 1.23549191e-02 1.60136282e-03\n",
            " 2.28744281e-02 1.85103359e-02 1.74684567e-02 1.32690306e-02\n",
            " 5.20047083e-05 1.75777568e-02 9.42908803e-03 1.51317358e-02\n",
            " 1.63821915e-02 4.81168785e-03 3.33973205e-03 1.07764436e-02\n",
            " 7.45353729e-03 1.77439060e-02 9.60959650e-03 4.97518439e-03\n",
            " 9.50188990e-03 1.11475058e-02 1.00020549e-02 1.06128181e-02\n",
            " 2.37039469e-02 7.59860952e-09 4.09788557e-03 9.41262877e-03\n",
            " 1.57791814e-02 8.83185789e-03 2.19014210e-02 1.21918373e-03\n",
            " 1.35306262e-02 1.36614233e-02 4.40141018e-03 1.52167147e-02\n",
            " 8.55229784e-03 2.02947061e-03 1.99045190e-02 8.12013940e-03\n",
            " 1.51189819e-02 2.21321516e-03 1.94262618e-02 2.29920710e-02\n",
            " 7.81991995e-03 4.23591800e-03 1.22798240e-02 1.67098881e-02\n",
            " 2.31908421e-02 9.07715734e-03 5.95179744e-03 2.06791383e-02\n",
            " 5.88526313e-03 2.08674000e-02 1.88245577e-02 2.36532342e-02\n",
            " 6.84401100e-03 3.07105352e-03 8.79072512e-03 1.36688939e-02\n",
            " 1.34287218e-02 1.02053498e-02 5.46823571e-03 1.11861279e-02\n",
            " 2.19720998e-02 4.43978800e-03 1.13719972e-02 9.90594078e-03\n",
            " 8.15845874e-03 2.35625795e-02 1.29212453e-02 9.72066573e-03\n",
            " 5.82618224e-03 1.16284119e-02 8.37138050e-03 1.27591152e-02\n",
            " 1.91319868e-02 2.61034074e-03 1.40689210e-02 1.81422249e-04\n",
            " 4.37552267e-03 1.71234993e-02 2.01625059e-02 1.12289356e-02\n",
            " 1.86634320e-02 1.16677708e-02 4.23674148e-03 1.06063834e-02\n",
            " 3.48942564e-03 1.48333836e-02 1.89976245e-02 6.40019396e-03\n",
            " 7.86043738e-03 1.98918418e-02 1.06111575e-02 1.90930177e-02\n",
            " 5.71685831e-04 3.40479076e-03 1.18960683e-02 1.63821915e-02\n",
            " 1.57614165e-02 6.28473196e-03 1.37950871e-02 1.62590472e-06\n",
            " 1.19705918e-02 2.40089589e-02 1.05387787e-04 8.77508694e-04\n",
            " 3.15393364e-03 1.30608139e-02 6.98074019e-03 2.17009846e-02\n",
            " 3.16327577e-03 2.30356943e-02 9.81479869e-03 5.34265663e-03\n",
            " 1.96404934e-02 4.52598256e-04 2.26579075e-02 2.10695062e-02\n",
            " 1.52321398e-02 5.58931993e-03 2.40089589e-02 2.08922031e-02\n",
            " 5.93020261e-03 1.33132962e-02 1.32379166e-03 2.26218291e-02\n",
            " 1.40780946e-02 1.12887501e-02 9.28773626e-04 1.80929837e-02\n",
            " 4.76611785e-03 1.30052154e-02 7.12328207e-03 2.40017015e-02\n",
            " 8.87669285e-03 5.69293311e-03 1.58639679e-02 6.37114659e-03\n",
            " 1.50980204e-02 4.82802669e-03 2.11948314e-02 2.39754556e-02\n",
            " 1.94262618e-02 5.98358625e-03 1.85188728e-02 5.66865964e-03\n",
            " 3.63141707e-03 8.12833503e-03 4.43978800e-03 1.69713060e-02\n",
            " 2.37146749e-02 1.05114730e-02 1.81319813e-02 8.43276788e-03\n",
            " 3.93818986e-03 1.78371903e-02 1.32773647e-03 1.61865348e-03\n",
            " 2.08484935e-02 1.72172685e-02 9.57791473e-03 2.36155532e-02\n",
            " 4.43184943e-03 1.06326305e-02 1.24584584e-02 2.09458097e-02\n",
            " 1.69525867e-03 5.52833701e-03 9.72372533e-03 1.79747637e-02\n",
            " 1.04695901e-04 8.39278361e-03 1.78539946e-02 6.01996690e-16\n",
            " 3.26888266e-03 1.65949195e-02 1.55001914e-02 6.35405606e-03\n",
            " 1.33427832e-02 1.98337817e-02 1.12664617e-02 1.90814934e-02\n",
            " 1.47175971e-02 1.19136152e-02 1.73913983e-02 2.69874545e-04\n",
            " 8.49845597e-03 1.97728516e-02 1.08302466e-02 1.65494412e-02\n",
            " 2.39292364e-02 1.06063834e-02 7.64409206e-03 3.07614120e-03\n",
            " 4.29468229e-03 3.31399182e-03 1.23549191e-02 2.20156016e-03\n",
            " 1.69468118e-02 4.04129831e-03 1.29708946e-02 7.28142491e-03\n",
            " 7.64827431e-03 1.81049214e-03 2.83980349e-04 7.37700071e-03\n",
            " 1.35772515e-02 5.05994189e-03 7.09861566e-03 1.29539833e-02\n",
            " 4.45007233e-03 4.56698530e-04 1.50025925e-02 2.31371947e-02\n",
            " 9.01496948e-03 2.26516074e-02 1.90581364e-02 2.15244320e-03\n",
            " 4.60517873e-03 3.74853573e-03 7.39824279e-03 8.09118975e-03\n",
            " 1.96869087e-04 4.75485842e-03 1.55382133e-02 3.79438427e-03\n",
            " 8.70252506e-03 1.49129613e-02 5.02355045e-03 3.43708516e-03\n",
            " 9.65126681e-03 9.74349555e-03 2.31733369e-02 7.00004563e-03\n",
            " 1.42751024e-02 1.74113340e-02 5.10477511e-03 9.79052591e-03\n",
            " 5.72528695e-03 1.01083128e-02 2.07215751e-02 1.48484481e-02\n",
            " 5.15649131e-03 1.04532682e-02 2.21367877e-04 9.74154806e-03\n",
            " 1.22349606e-02 2.09909765e-02 1.81499252e-03 8.77215228e-03\n",
            " 1.04872308e-02 8.33986155e-03 1.96775695e-02 7.28111501e-03\n",
            " 3.89585097e-03 1.44209242e-03 1.98294567e-02 1.28049066e-02\n",
            " 3.27374466e-03 2.04687893e-03 1.58849438e-02 1.51770912e-02\n",
            " 1.47827013e-02 1.32014967e-03 5.11114293e-03 2.02753844e-02\n",
            " 1.61334493e-02 1.98918418e-02 1.89313827e-03 1.86569873e-02\n",
            " 5.82618224e-03 4.15244162e-03 1.68474302e-02 1.35442966e-02\n",
            " 1.66912373e-03 1.21127412e-02 2.39644157e-02 7.94743508e-03\n",
            " 3.26254838e-03 3.23724634e-03 6.74576868e-03 2.37028808e-03\n",
            " 1.54826715e-02 1.91735570e-02 5.74343283e-06 2.26625306e-02\n",
            " 2.22594800e-02 1.28020854e-02 9.09992055e-04 1.57174342e-02\n",
            " 3.99785520e-03 1.33250067e-03 1.14159246e-02 1.08961641e-02\n",
            " 1.23570659e-05 1.12265484e-02 1.15109315e-02 1.52989111e-02\n",
            " 2.30165112e-02 2.46345518e-03 1.91364297e-04 2.40089589e-02\n",
            " 9.29277317e-03 1.42751024e-02 3.96916262e-03 3.29612290e-03\n",
            " 9.62785756e-03 1.93681351e-03 8.15437100e-04 2.27690902e-03\n",
            " 1.51661548e-02 6.83768022e-04 2.12873075e-02 2.20117999e-03\n",
            " 1.17618902e-03 1.98918418e-02 2.34385694e-02 1.60315228e-02\n",
            " 3.90008107e-03 1.60559146e-02 1.48407235e-02 2.38966101e-02\n",
            " 1.14485040e-02 8.09281521e-03 5.78477734e-05 1.40751649e-02\n",
            " 6.44127183e-04 1.15652807e-02 2.35546325e-02 9.77859771e-04\n",
            " 1.28891417e-02 1.09872152e-02 1.90930177e-02 1.32707477e-02\n",
            " 1.07880916e-02 1.32102356e-02 1.42630673e-02 1.44637670e-02\n",
            " 9.94188116e-03 9.88328227e-03 2.27904183e-02 5.63937969e-03\n",
            " 1.99280655e-02 1.89404168e-02 2.26537325e-02 8.75145747e-03\n",
            " 9.05622596e-03 8.42005975e-03 1.02490789e-02 1.93681351e-03\n",
            " 1.60589046e-02 2.12499634e-02 2.02293036e-02 1.19057554e-02\n",
            " 1.10098166e-02 1.81945010e-02 2.31287307e-03 1.25778798e-02\n",
            " 3.47758404e-03 2.18975903e-02 1.03563415e-02 2.24982165e-02\n",
            " 1.79098697e-02 5.05844461e-03 1.99210674e-02 1.10631323e-02\n",
            " 1.98333413e-03 1.35458983e-02 4.37787152e-03 1.23390795e-02\n",
            " 1.71968512e-02 1.62919207e-02 8.00895189e-03 2.08043938e-02\n",
            " 1.29801312e-02 1.31194909e-02 4.75754773e-03 9.48920350e-03\n",
            " 5.83742650e-04 3.11508156e-03 9.78106660e-03 4.12174804e-03\n",
            " 1.82880092e-02 8.34141523e-03 1.77816432e-02 8.17923223e-03\n",
            " 2.21367877e-04 4.87292170e-03 2.34761660e-02 1.85291560e-02\n",
            " 1.13950272e-02 3.06500541e-03 1.55233372e-02 2.24042005e-02\n",
            " 4.17105316e-03 1.75704832e-02 1.08292948e-02 8.38818659e-03\n",
            " 2.00884500e-02 4.69834604e-03 6.74834828e-04 1.49711393e-03\n",
            " 1.33373823e-02 2.23287586e-02 1.21691570e-03 1.93104660e-02\n",
            " 1.66420998e-02 7.76285354e-03 5.29232150e-03 1.66968974e-02\n",
            " 7.17404758e-04 2.28270705e-02 4.87469043e-03 1.46927479e-02\n",
            " 1.96167461e-02 1.94112482e-02 1.21296774e-02 3.37955292e-04\n",
            " 7.88404346e-03 2.33675789e-02 1.93681351e-03 7.90813873e-03\n",
            " 2.20931138e-02 1.43443045e-02 1.17709431e-02 1.34624354e-02\n",
            " 5.97247594e-03 7.73685013e-03 8.78495648e-03 1.17543731e-02\n",
            " 1.53214660e-02 2.07712019e-02 1.05834691e-02 2.37660814e-03\n",
            " 1.35593618e-02 3.82017693e-03 2.02898800e-02 1.25187035e-03\n",
            " 7.70548219e-03 2.17279754e-02 1.96842702e-02 8.50835070e-03\n",
            " 9.20249110e-03 2.60402096e-04 1.15910218e-02 3.89585097e-03\n",
            " 1.68814208e-02 6.31231987e-03 3.99785520e-03 9.55040778e-03\n",
            " 1.90380335e-02 4.11118788e-04 2.78648419e-03 1.53046225e-02\n",
            " 2.37652531e-02 2.09728249e-02 1.64022535e-02 2.30307636e-02\n",
            " 2.02011140e-02 5.41948053e-04 8.54387810e-03 2.33352426e-02\n",
            " 9.82118797e-03 2.05354035e-03 4.88240098e-03 1.61315530e-03\n",
            " 1.02699360e-02 1.92944972e-02 1.78398968e-02 1.57409772e-02\n",
            " 1.23883667e-02 1.06100804e-02 1.48425856e-02 7.11052523e-03\n",
            " 1.00483681e-02 1.08382433e-02 1.37958328e-04 7.36281966e-03\n",
            " 2.38771191e-03 2.06660985e-02 2.32121596e-02 3.41201188e-03\n",
            " 1.44089727e-02 1.74113340e-02 3.29460512e-03 4.81168785e-03\n",
            " 8.99474482e-03 1.89527504e-02 1.24810930e-02 4.49007716e-03\n",
            " 1.73201288e-02 6.55432899e-03 2.79928557e-03 1.92639372e-02\n",
            " 1.11758122e-02 9.97636463e-03 2.02040620e-03 6.24108716e-04\n",
            " 1.99605656e-02 2.86062418e-03 1.41974405e-02 1.44275753e-02\n",
            " 1.70412448e-02 1.78371903e-02 1.95807149e-02 4.41158691e-03\n",
            " 1.03461867e-02 1.48333836e-02 1.46168638e-02 1.89344509e-02\n",
            " 8.06782228e-03 2.06339870e-02 4.18625232e-03 2.12893009e-02\n",
            " 1.62987238e-02 6.59130822e-04 1.72059801e-02 1.73834765e-02\n",
            " 3.59489789e-03 2.36290590e-02 6.63145821e-03 5.55083265e-03\n",
            " 8.30406869e-03 5.09432804e-03 1.63821915e-02 1.68291541e-02\n",
            " 1.65608337e-02 2.06678953e-02 3.51964223e-04 2.84086139e-03\n",
            " 2.34727081e-02 3.16044744e-03 8.41151350e-03 1.38907939e-02\n",
            " 1.47403211e-02 8.58049644e-03 2.31287307e-03 1.44749647e-02\n",
            " 1.74071072e-02 1.44982646e-03 1.17809235e-02 1.60955284e-02\n",
            " 2.51368933e-03 2.20007865e-02 6.24797249e-03 1.10693044e-02\n",
            " 1.43650342e-02 1.18307847e-02 4.07586128e-03 1.45519764e-02\n",
            " 1.97766952e-02 1.17238525e-02 5.60459848e-03 9.26583919e-04\n",
            " 1.08694897e-02 6.95493165e-03 4.44313207e-03 1.57976383e-02\n",
            " 5.22599578e-03 3.96046146e-03 2.22169572e-02 7.43200079e-03\n",
            " 5.26426539e-03 4.74131995e-03 2.90887404e-03 6.78323572e-03\n",
            " 1.87676262e-02 1.84827794e-02 1.09814630e-02 2.28001548e-02\n",
            " 1.18902569e-03 6.83951982e-04 2.31051163e-02 6.13475292e-03\n",
            " 1.37458168e-02 1.06946765e-03 2.17886864e-04 1.19104230e-02\n",
            " 1.01440145e-02 1.11561357e-02 1.37927342e-03 1.95891009e-02\n",
            " 1.66066328e-02 1.49806576e-03 2.16830614e-03 2.91313760e-03\n",
            " 8.50678012e-05 1.54468212e-02 2.37039469e-02 3.95423750e-03\n",
            " 2.12873075e-02 1.84995101e-02 5.53699637e-03 5.42387944e-03\n",
            " 2.51968737e-06 1.25397884e-02 2.32422283e-02 7.07834965e-04\n",
            " 5.80044412e-07 2.02710609e-02 1.13996500e-02 2.04156384e-02\n",
            " 1.97321291e-02 2.50175620e-05 1.76681990e-02 4.05418267e-05\n",
            " 2.25770491e-02 1.38244166e-02 1.73798210e-02 1.06806035e-02\n",
            " 1.12724236e-02 1.61455327e-03 8.90412796e-04 1.18955308e-02\n",
            " 2.22147626e-02 1.68993416e-02 4.69973776e-03 2.19677989e-02\n",
            " 1.71065099e-02 1.60691356e-02 3.91118047e-03 1.45719894e-02\n",
            " 5.09702455e-03 1.10801714e-02 5.09702455e-03 7.61065749e-03\n",
            " 1.98865883e-02 1.90617307e-02 1.06146988e-03 2.30424756e-02\n",
            " 7.45626535e-03 1.98422522e-03 1.82676264e-02 4.26726973e-03\n",
            " 3.43965327e-04 2.33089291e-02 1.55846303e-02 4.22382167e-04\n",
            " 1.09060515e-02 1.44471356e-02 3.24367536e-03 1.42987096e-02\n",
            " 5.17080001e-03 2.37546453e-02 1.82885262e-02 2.07497543e-02\n",
            " 2.11434018e-02 4.50986357e-03 2.67545528e-04 5.36796870e-03\n",
            " 2.28332113e-02 6.38468099e-03 1.85885682e-02 6.73705886e-03\n",
            " 1.34283431e-02 1.61760229e-02 5.83036357e-03 1.73459330e-02\n",
            " 4.71484043e-03 5.02355045e-03 7.44574333e-03 1.95572063e-02\n",
            " 1.20148910e-02 3.14597347e-03 1.36267039e-02 1.53627041e-02\n",
            " 1.76509204e-02 1.13612018e-02 1.50671668e-02 2.03113388e-02\n",
            " 5.73450971e-03 1.75262168e-02 6.10664247e-03 1.32781976e-02\n",
            " 1.95134972e-02 2.15886441e-02 1.86915398e-02 1.96744082e-02\n",
            " 2.23948762e-02 5.03027972e-03 3.91118047e-03 1.37797170e-02\n",
            " 2.05853705e-02 1.43237088e-02 8.29376865e-03 1.09459757e-02\n",
            " 1.50344062e-03 1.30393610e-03 3.92337331e-03 1.62449372e-02\n",
            " 5.46582456e-03 2.05618503e-02 4.14476641e-03 7.64401945e-04\n",
            " 1.79693506e-02 9.41880397e-03 1.12028173e-02 8.75865064e-03\n",
            " 5.83946480e-03 2.49403258e-03 8.12420020e-04 9.68322879e-03\n",
            " 1.95717807e-02 7.33860941e-03 7.84009088e-03 9.41188816e-03\n",
            " 1.99963178e-02 1.15876154e-02 1.00752750e-02 3.09050742e-03\n",
            " 1.59117664e-03 1.36372627e-03 2.05560348e-02 1.48603097e-02\n",
            " 6.69280832e-03 1.02002427e-02 1.11816452e-02 7.56163464e-03\n",
            " 1.78427147e-02 8.92482300e-03 1.39687976e-02 4.39668773e-03\n",
            " 2.19850551e-02 1.42769227e-02 8.32459542e-03 3.96138068e-03\n",
            " 9.36523201e-03 2.27529002e-02 1.38526387e-02 1.87416702e-02\n",
            " 1.90236933e-02 1.98003125e-02 1.33247494e-02 3.37511389e-03\n",
            " 1.56342960e-02 1.39512827e-02 3.38228948e-03 9.31197052e-03\n",
            " 5.11629852e-04 9.56871337e-04 9.16734868e-03 1.44089727e-02\n",
            " 8.80748508e-03 2.80648932e-03 9.94188116e-03 6.19979560e-03\n",
            " 8.50017297e-03 2.18142115e-02 1.70327878e-02 4.30722340e-04\n",
            " 5.72407656e-03 1.48617695e-02 7.82106465e-03 3.88018043e-03\n",
            " 1.07901063e-02 7.06238858e-03 3.64249993e-03 8.07657949e-03\n",
            " 1.55991393e-02 9.87275749e-03 1.01992105e-02 7.45486243e-03\n",
            " 1.80260605e-02 4.90477562e-03 2.32819662e-02 5.94984807e-03\n",
            " 7.02630329e-03 9.09992055e-04 4.17734332e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3230 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.08054931e-03 4.54556689e-03 1.74215583e-02 2.24365123e-02\n",
            " 1.74043285e-02 4.89294089e-03 4.28270150e-03 1.94896445e-02\n",
            " 1.53506899e-02 7.14746503e-04 1.29751040e-02 9.89151562e-03\n",
            " 4.21775450e-03 6.94699173e-03 1.30251004e-02 8.78063700e-03\n",
            " 1.62866948e-02 1.87321314e-02 1.20597732e-02 2.06953023e-02\n",
            " 2.37089082e-02 2.27833719e-02 2.06294464e-02 8.62396868e-03\n",
            " 2.12951118e-02 1.07302309e-02 1.11656024e-02 1.23121279e-02\n",
            " 6.76250957e-03 1.48055207e-02 6.07349057e-03 1.88569060e-02\n",
            " 7.68399047e-03 5.71268536e-03 8.62168920e-03 1.52987180e-03\n",
            " 1.00421646e-02 5.12474884e-03 5.65488026e-03 1.88569060e-02\n",
            " 3.90687723e-03 1.55365837e-05 6.11207190e-03 1.30733205e-02\n",
            " 1.45078263e-02 1.55409162e-02 3.01552147e-03 1.13609915e-02\n",
            " 1.42560767e-02 2.06391577e-02 1.85298973e-02 1.16607814e-04\n",
            " 1.01251599e-02 1.30733205e-02 1.33429337e-02 2.08856814e-03\n",
            " 7.51335483e-09 3.10098475e-03 2.30815676e-05 6.89047598e-03\n",
            " 1.31321735e-02 8.91831814e-03 4.88233219e-04 2.44466733e-07\n",
            " 1.19829196e-02 8.19632736e-03 7.65764571e-03 2.91079053e-03\n",
            " 7.85135719e-03 1.10331967e-02 9.93496306e-03 1.76781530e-02\n",
            " 5.86692026e-03 9.38970942e-03 2.27019374e-03 1.19379402e-02\n",
            " 1.90430287e-02 2.28216269e-02 1.44526316e-02 9.70843364e-03\n",
            " 1.67768152e-02 1.91898397e-02 2.32750449e-02 2.27213801e-02\n",
            " 2.07117128e-02 1.39897841e-02 2.16402040e-02 1.96044308e-02\n",
            " 1.18735007e-02 1.16353066e-02 1.76801166e-02 1.13961974e-03\n",
            " 7.63438054e-03 1.95304546e-02 3.19995331e-03 2.21629317e-02\n",
            " 1.67606779e-02 4.29573946e-04 1.74722622e-02 1.21263839e-03\n",
            " 1.52750540e-02 8.75272887e-03 3.53598519e-03 1.06435931e-02\n",
            " 1.86020399e-02 1.86655487e-02 1.90660009e-02 1.44782543e-02\n",
            " 9.93496306e-03 1.29203608e-02 4.34146271e-04 1.45714948e-02\n",
            " 7.78808463e-03 5.68957035e-03 2.23786560e-02 5.27066036e-03\n",
            " 2.19478147e-02 2.06889302e-02 1.94896445e-02 1.22443476e-02\n",
            " 5.36036432e-04 2.20873320e-02 1.15532144e-02 1.06164489e-02\n",
            " 4.43507411e-03 4.61661967e-03 1.26394573e-03 1.65751592e-02\n",
            " 6.10966803e-03 1.13770105e-02 1.92868250e-02 6.40665289e-04\n",
            " 1.12824723e-03 1.08497535e-02 2.08684727e-02 5.71227836e-03\n",
            " 7.33670223e-05 3.88921133e-03 1.35106883e-02 2.16797549e-02\n",
            " 1.85696573e-02 1.01884184e-02 1.13874835e-02 1.14986234e-02\n",
            " 2.03383190e-02 1.91664461e-03 7.99988047e-03 1.99382123e-02\n",
            " 8.98368027e-03 7.45628574e-04 1.54246498e-02 2.17797451e-03\n",
            " 1.52135753e-02 1.11856566e-02 2.26675153e-02 1.03110719e-02\n",
            " 2.02498738e-02 1.48682730e-02 8.10508619e-03 2.22870999e-02\n",
            " 1.76757531e-02 9.68589605e-03 2.25039333e-02 1.95159570e-02\n",
            " 5.35754988e-03 1.33429337e-02 3.77790339e-03 7.85975582e-05\n",
            " 1.69537607e-02 2.36248191e-02 9.44469484e-03 1.42471450e-02\n",
            " 4.48444435e-03 1.51450953e-02 1.91925051e-02 1.69472835e-02\n",
            " 3.77790339e-03 1.24458942e-02 1.26609706e-02 9.29944712e-03\n",
            " 1.50857461e-02 7.07362260e-03 1.04293230e-03 1.30372290e-02\n",
            " 1.56928289e-02 1.97342534e-02 9.89260039e-03 7.78919227e-03\n",
            " 1.23609237e-02 1.59459374e-03 2.28096058e-02 1.84969683e-02\n",
            " 1.74048445e-02 1.32288701e-02 5.19763351e-05 1.75926629e-02\n",
            " 9.42679501e-03 1.51361387e-02 1.63872400e-02 4.80218868e-03\n",
            " 3.33998669e-03 1.07314814e-02 7.47253737e-03 1.74722622e-02\n",
            " 9.53931042e-03 4.97308967e-03 9.48820181e-03 1.11312686e-02\n",
            " 9.97411419e-03 1.05860291e-02 2.36863143e-02 7.51335483e-09\n",
            " 4.10089498e-03 9.41470933e-03 1.57511342e-02 8.83280051e-03\n",
            " 2.18698897e-02 1.20999796e-03 1.34902648e-02 1.36864117e-02\n",
            " 4.39493555e-03 1.51756821e-02 8.54014649e-03 2.01677280e-03\n",
            " 1.98849221e-02 8.11572808e-03 1.51142832e-02 2.20688621e-03\n",
            " 1.94100321e-02 2.29120873e-02 7.79643778e-03 4.22366926e-03\n",
            " 1.22372777e-02 1.66470385e-02 2.31845752e-02 9.07046703e-03\n",
            " 5.93075880e-03 2.06348892e-02 5.88774294e-03 2.08322830e-02\n",
            " 1.86719942e-02 2.35753682e-02 6.81621879e-03 3.06872949e-03\n",
            " 8.78063700e-03 1.36167820e-02 1.34240203e-02 1.01596006e-02\n",
            " 5.46741669e-03 1.11544179e-02 2.18948200e-02 4.43507411e-03\n",
            " 1.13609915e-02 9.90619697e-03 8.11323638e-03 2.35018824e-02\n",
            " 1.29131669e-02 9.63078923e-03 5.82192519e-03 1.15949147e-02\n",
            " 8.28827898e-03 1.27413048e-02 1.90984207e-02 2.61578240e-03\n",
            " 1.40233402e-02 1.80765214e-04 4.35693872e-03 1.70807505e-02\n",
            " 2.00969357e-02 1.11783238e-02 1.86329848e-02 1.16280279e-02\n",
            " 4.23590068e-03 1.05324922e-02 3.48065420e-03 1.48379740e-02\n",
            " 1.88942082e-02 6.40759200e-03 7.85951632e-03 1.98325531e-02\n",
            " 1.06300532e-02 1.90729270e-02 5.68200366e-04 3.38114885e-03\n",
            " 1.18779998e-02 1.63872400e-02 1.57508335e-02 6.27947333e-03\n",
            " 1.37473280e-02 1.61107289e-06 1.19640623e-02 1.04946929e-04\n",
            " 8.74515444e-04 3.12500925e-03 1.30494071e-02 6.97559708e-03\n",
            " 2.16858188e-02 3.16042850e-03 2.30735713e-02 9.79525205e-03\n",
            " 5.33741314e-03 1.96220427e-02 4.52372349e-04 2.25904659e-02\n",
            " 2.10624682e-02 1.52047643e-02 5.57903604e-03 2.08864400e-02\n",
            " 5.89489021e-03 1.32922870e-02 1.31262909e-03 2.25810551e-02\n",
            " 1.40400336e-02 1.12525255e-02 9.20660214e-04 1.80711461e-02\n",
            " 4.76136496e-03 1.29751040e-02 7.12028474e-03 8.82712307e-03\n",
            " 5.69630439e-03 1.58839103e-02 6.36249033e-03 1.51084723e-02\n",
            " 4.81449492e-03 2.10467571e-02 1.94100321e-02 5.97946363e-03\n",
            " 1.84730144e-02 5.65627852e-03 3.59291067e-03 8.12564662e-03\n",
            " 4.43507411e-03 1.68893513e-02 2.37101238e-02 1.04999470e-02\n",
            " 1.81307910e-02 8.44001082e-03 3.93420751e-03 1.78231950e-02\n",
            " 1.32648938e-03 1.60800408e-03 2.07536820e-02 1.71875692e-02\n",
            " 9.58060835e-03 2.35767530e-02 4.40615743e-03 1.05673572e-02\n",
            " 1.24459829e-02 2.09399644e-02 1.68666763e-03 5.50684572e-03\n",
            " 9.70414934e-03 1.79108774e-02 1.04495851e-04 8.39142776e-03\n",
            " 1.78282818e-02 6.03266741e-16 3.25938540e-03 1.65479001e-02\n",
            " 1.54847334e-02 6.34238029e-03 1.33349912e-02 1.98487530e-02\n",
            " 1.12337399e-02 1.90461941e-02 1.47033601e-02 1.18794500e-02\n",
            " 1.73330897e-02 2.68047387e-04 8.45277977e-03 1.97797520e-02\n",
            " 1.08100604e-02 1.65243008e-02 1.05324922e-02 7.63438054e-03\n",
            " 3.03614393e-03 4.28699478e-03 3.31665788e-03 1.23609237e-02\n",
            " 2.19875814e-03 1.69172120e-02 4.03662460e-03 1.29571188e-02\n",
            " 7.25434687e-03 7.62446146e-03 1.81120144e-03 2.80837027e-04\n",
            " 7.36822484e-03 1.35119166e-02 5.03382678e-03 7.07288697e-03\n",
            " 1.29101537e-02 4.45376373e-03 4.53362684e-04 1.49444382e-02\n",
            " 2.29046003e-02 8.99014200e-03 2.26558518e-02 1.90308653e-02\n",
            " 2.13911477e-03 4.58631410e-03 3.75163297e-03 7.38404056e-03\n",
            " 8.06189165e-03 1.95900060e-04 4.74386645e-03 1.55170655e-02\n",
            " 3.76578533e-03 8.70493570e-03 1.48668338e-02 5.00624769e-03\n",
            " 3.43820358e-03 9.64756473e-03 9.74002475e-03 2.31232607e-02\n",
            " 7.00369977e-03 1.42659700e-02 1.73773589e-02 5.10677420e-03\n",
            " 9.78110527e-03 5.71268536e-03 1.00544420e-02 2.07073347e-02\n",
            " 1.48617018e-02 5.15609913e-03 1.04255075e-02 2.20283566e-04\n",
            " 9.71330139e-03 1.22243704e-02 2.09620706e-02 1.81134681e-03\n",
            " 8.75373700e-03 1.04830868e-02 8.30888954e-03 1.96677931e-02\n",
            " 7.26076919e-03 3.88921133e-03 1.43691984e-03 1.98061869e-02\n",
            " 1.28025687e-02 3.26553001e-03 2.04030363e-03 1.58795763e-02\n",
            " 1.51356139e-02 1.46990199e-02 1.31992846e-03 5.09171962e-03\n",
            " 2.02374593e-02 1.60962553e-02 1.98325531e-02 1.90394649e-03\n",
            " 1.86504290e-02 5.82192519e-03 4.14726021e-03 1.68168579e-02\n",
            " 1.35678380e-02 1.65808115e-03 1.21041785e-02 7.93099628e-03\n",
            " 3.25071675e-03 3.23091752e-03 6.73585908e-03 2.36724218e-03\n",
            " 1.54828224e-02 1.91558715e-02 5.69478035e-06 2.25951792e-02\n",
            " 2.22473557e-02 1.27819284e-02 9.05784881e-04 1.57157869e-02\n",
            " 3.98294311e-03 1.32914173e-03 1.13567036e-02 1.08577248e-02\n",
            " 1.22741664e-05 1.11992365e-02 1.14541096e-02 1.52421906e-02\n",
            " 2.29897272e-02 2.44693769e-03 1.91020895e-04 9.25831635e-03\n",
            " 1.42659700e-02 3.96378985e-03 3.28131756e-03 9.61762310e-03\n",
            " 1.93271274e-03 8.12553403e-04 2.27197885e-03 1.51337579e-02\n",
            " 6.82529448e-04 2.13179902e-02 2.20091033e-03 1.17300609e-03\n",
            " 1.98325531e-02 2.34008625e-02 1.60335854e-02 3.88707597e-03\n",
            " 1.60119362e-02 1.47520209e-02 1.14374630e-02 8.08440701e-03\n",
            " 5.76888478e-05 1.40501384e-02 6.39671318e-04 1.15553983e-02\n",
            " 2.34910496e-02 9.77131007e-04 1.28664682e-02 1.09598481e-02\n",
            " 1.90729270e-02 1.31704557e-02 1.07672991e-02 1.31833165e-02\n",
            " 1.42693937e-02 1.44571497e-02 9.93496306e-03 9.88311729e-03\n",
            " 2.27174797e-02 5.59637009e-03 1.99041491e-02 1.88722344e-02\n",
            " 2.26527252e-02 8.73283286e-03 9.06877833e-03 8.41945585e-03\n",
            " 1.02313049e-02 1.93271274e-03 1.59465482e-02 2.11476410e-02\n",
            " 2.01716365e-02 1.19204334e-02 1.09185599e-02 1.81177205e-02\n",
            " 2.30534542e-03 1.25682852e-02 3.46606618e-03 2.17866277e-02\n",
            " 1.03511341e-02 2.25051756e-02 1.79009477e-02 5.04646003e-03\n",
            " 1.98646192e-02 1.10682044e-02 1.97972643e-03 1.34561199e-02\n",
            " 4.36654938e-03 1.23134246e-02 1.71064874e-02 1.62542300e-02\n",
            " 7.99393547e-03 2.07860523e-02 1.29393378e-02 1.30906660e-02\n",
            " 4.76305713e-03 9.47996586e-03 5.80577616e-04 3.12322571e-03\n",
            " 9.74257456e-03 4.11305666e-03 1.82021964e-02 8.32128895e-03\n",
            " 1.77712867e-02 8.18819574e-03 2.20283566e-04 4.86762139e-03\n",
            " 2.34426025e-02 1.84643677e-02 1.14147481e-02 3.03660397e-03\n",
            " 1.55271060e-02 2.23873521e-02 4.14546067e-03 1.75780003e-02\n",
            " 1.07893929e-02 8.36384066e-03 2.01084054e-02 4.68290594e-03\n",
            " 6.68130106e-04 1.49184269e-03 1.33202167e-02 2.23236313e-02\n",
            " 1.21339168e-03 1.92369566e-02 1.66100318e-02 7.69939233e-03\n",
            " 5.27312911e-03 1.66876180e-02 7.14746503e-04 2.28331062e-02\n",
            " 4.85724461e-03 1.46713329e-02 1.95711470e-02 1.94254912e-02\n",
            " 1.21271886e-02 3.35201284e-04 7.88133862e-03 2.33438343e-02\n",
            " 1.93271274e-03 7.88010677e-03 2.20581134e-02 1.43322082e-02\n",
            " 1.17655477e-02 1.34279456e-02 5.91740558e-03 7.73398201e-03\n",
            " 8.79638017e-03 1.17195025e-02 1.52889357e-02 2.06391577e-02\n",
            " 1.05738560e-02 2.37035066e-03 1.34861647e-02 3.81197892e-03\n",
            " 2.02717956e-02 1.25445652e-03 7.69608743e-03 2.17314167e-02\n",
            " 1.95289532e-02 8.48657421e-03 9.17100347e-03 2.59779750e-04\n",
            " 1.15713083e-02 3.88921133e-03 1.68820880e-02 6.29581754e-03\n",
            " 3.98294311e-03 9.55574653e-03 1.90116839e-02 4.12496435e-04\n",
            " 2.78783718e-03 1.53080345e-02 2.37758312e-02 2.09645947e-02\n",
            " 1.63496088e-02 2.29868686e-02 2.01547369e-02 5.39942913e-04\n",
            " 8.51642594e-03 2.33565166e-02 9.79075032e-03 2.05738720e-03\n",
            " 4.87502170e-03 1.61009935e-03 1.01624201e-02 1.92794286e-02\n",
            " 1.78337239e-02 1.57132639e-02 1.23642879e-02 1.05678886e-02\n",
            " 1.48258442e-02 7.09534183e-03 1.00214596e-02 1.08234799e-02\n",
            " 1.37843450e-04 7.33732242e-03 2.38862933e-03 2.06925628e-02\n",
            " 2.31936617e-02 3.40822579e-03 1.44047284e-02 1.73773589e-02\n",
            " 3.27388324e-03 4.80218868e-03 8.98463203e-03 1.89445532e-02\n",
            " 1.24940609e-02 4.48444435e-03 1.72350009e-02 6.54647516e-03\n",
            " 2.79293289e-03 1.92691632e-02 1.11489110e-02 9.95294811e-03\n",
            " 2.01753842e-03 6.23579727e-04 1.97391862e-02 2.85378942e-03\n",
            " 1.41840281e-02 1.44152688e-02 1.70170560e-02 1.78231950e-02\n",
            " 1.95263367e-02 4.40274555e-03 1.03453215e-02 1.48379740e-02\n",
            " 1.45654379e-02 1.89102949e-02 8.05719118e-03 2.05837794e-02\n",
            " 4.14548792e-03 2.12910547e-02 1.63527431e-02 6.62119997e-04\n",
            " 1.71704285e-02 1.74061101e-02 3.59141547e-03 2.36037987e-02\n",
            " 6.59315393e-03 5.54142119e-03 8.30001936e-03 5.05889003e-03\n",
            " 1.63872400e-02 1.68294476e-02 1.65646996e-02 2.06524797e-02\n",
            " 3.52104705e-04 2.83165519e-03 2.33007633e-02 3.14881822e-03\n",
            " 8.36886272e-03 1.38429287e-02 1.47249445e-02 8.55653599e-03\n",
            " 2.30534542e-03 1.44553387e-02 1.73927035e-02 1.44501651e-03\n",
            " 1.17423082e-02 1.60363409e-02 2.51057467e-03 2.19680202e-02\n",
            " 6.23229802e-03 1.10242686e-02 1.43561414e-02 1.18154410e-02\n",
            " 4.07184273e-03 1.44812207e-02 1.97725763e-02 1.17398234e-02\n",
            " 5.58609336e-03 9.16634502e-04 1.08525116e-02 6.93785067e-03\n",
            " 4.41951086e-03 1.57561012e-02 5.20924813e-03 3.92823264e-03\n",
            " 2.21487227e-02 7.38803341e-03 5.25551086e-03 4.73943627e-03\n",
            " 2.90543484e-03 6.77607455e-03 1.87956809e-02 1.83932159e-02\n",
            " 1.09600822e-02 2.27644304e-02 1.18397323e-03 6.83984358e-04\n",
            " 2.30933188e-02 6.11207190e-03 1.37052544e-02 1.06769562e-03\n",
            " 2.17118208e-04 1.18921766e-02 1.01372120e-02 1.11527445e-02\n",
            " 1.37504801e-03 1.94662108e-02 1.65815477e-02 1.49425358e-03\n",
            " 2.16432010e-03 2.91079053e-03 8.50263902e-05 1.54102530e-02\n",
            " 2.36863143e-02 3.94527240e-03 2.13179902e-02 1.85128132e-02\n",
            " 5.54087834e-03 5.39984388e-03 2.49905421e-06 1.25300332e-02\n",
            " 2.32018535e-02 7.07459701e-04 5.79582501e-07 2.01975269e-02\n",
            " 1.13545074e-02 2.03728550e-02 1.97363894e-02 2.47959513e-05\n",
            " 1.76128221e-02 4.05694621e-05 2.25209813e-02 1.38105336e-02\n",
            " 1.71927118e-02 1.06680547e-02 1.12459781e-02 1.60101713e-03\n",
            " 8.88451000e-04 1.18609764e-02 2.21796374e-02 1.68524047e-02\n",
            " 4.69866678e-03 2.19395489e-02 1.69551256e-02 1.60666696e-02\n",
            " 3.90687723e-03 1.45630177e-02 5.08932196e-03 1.10456456e-02\n",
            " 5.08932196e-03 7.60919416e-03 1.98477802e-02 1.90250591e-02\n",
            " 1.05792678e-03 2.30347074e-02 7.44173303e-03 1.97229994e-03\n",
            " 1.82979683e-02 4.25544586e-03 3.44404437e-04 2.33106923e-02\n",
            " 1.55399430e-02 4.20471764e-04 1.09383269e-02 1.44448361e-02\n",
            " 3.22471551e-03 1.41800796e-02 5.13640240e-03 2.37482636e-02\n",
            " 1.82337533e-02 2.07606796e-02 2.11583963e-02 4.50921125e-03\n",
            " 2.67426391e-04 5.35063030e-03 2.28418418e-02 6.37909430e-03\n",
            " 1.85722630e-02 6.72400641e-03 1.33973334e-02 1.61711944e-02\n",
            " 5.82249587e-03 1.72734526e-02 4.71756244e-03 5.00624769e-03\n",
            " 7.42360508e-03 1.94896445e-02 1.20078379e-02 3.14133559e-03\n",
            " 1.35680613e-02 1.53172697e-02 1.76290386e-02 1.13098545e-02\n",
            " 1.50172519e-02 2.03153705e-02 5.73331371e-03 1.75285870e-02\n",
            " 6.08695873e-03 1.32436056e-02 1.94573314e-02 2.15196010e-02\n",
            " 1.85888935e-02 1.96468721e-02 2.23390810e-02 5.02668583e-03\n",
            " 3.90687723e-03 1.37716412e-02 2.05235280e-02 1.42791796e-02\n",
            " 8.24164182e-03 1.09333870e-02 1.49553668e-03 1.29827256e-03\n",
            " 3.90623366e-03 1.61729588e-02 5.45032248e-03 2.04752634e-02\n",
            " 4.09566905e-03 7.67303352e-04 1.79838826e-02 9.41782777e-03\n",
            " 1.11687384e-02 8.74364748e-03 5.79553406e-03 2.50030692e-03\n",
            " 8.06328553e-04 9.60922536e-03 1.94721463e-02 7.33745331e-03\n",
            " 7.81974588e-03 9.35377191e-03 1.99633220e-02 1.15747572e-02\n",
            " 1.00717626e-02 3.07471035e-03 1.58954390e-03 1.36251101e-03\n",
            " 2.05615935e-02 1.48263255e-02 6.69841263e-03 1.01572466e-02\n",
            " 1.11551059e-02 7.52570646e-03 1.78207769e-02 8.88649723e-03\n",
            " 1.39439625e-02 4.39815364e-03 2.18461907e-02 1.42429875e-02\n",
            " 8.28584932e-03 3.95989679e-03 9.33695051e-03 2.27013097e-02\n",
            " 1.38322157e-02 1.87321314e-02 1.90087447e-02 1.97692988e-02\n",
            " 1.33108865e-02 3.36474140e-03 1.55734300e-02 1.38832185e-02\n",
            " 3.38003184e-03 9.28724089e-03 5.08612608e-04 9.54658213e-04\n",
            " 9.15925725e-03 1.44047284e-02 8.73522097e-03 2.79956146e-03\n",
            " 9.93496306e-03 6.19121391e-03 8.46368872e-03 2.17508799e-02\n",
            " 1.69933614e-02 4.30678950e-04 5.73292533e-03 1.48080027e-02\n",
            " 7.79488315e-03 3.85987307e-03 1.07673528e-02 7.04177936e-03\n",
            " 3.63284999e-03 8.05538868e-03 1.55409162e-02 9.82962797e-03\n",
            " 1.01747419e-02 7.47866091e-03 1.80043794e-02 4.90348737e-03\n",
            " 2.32878426e-02 5.93659533e-03 7.00433718e-03 9.05784881e-04\n",
            " 4.17349091e-03]\n",
            "3240 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.04424094e-03 4.53655872e-03 1.73712182e-02 2.22837988e-02\n",
            " 1.74274856e-02 4.88754579e-03 4.26881508e-03 1.95202640e-02\n",
            " 1.53067830e-02 7.12399150e-04 1.29392963e-02 9.85789280e-03\n",
            " 4.19864726e-03 6.90790813e-03 1.29218184e-02 8.74523824e-03\n",
            " 1.62594257e-02 1.86826076e-02 1.20316344e-02 2.06211682e-02\n",
            " 2.26194724e-02 2.05543735e-02 8.60204125e-03 2.12780299e-02\n",
            " 1.06809623e-02 1.10944602e-02 1.23222471e-02 6.73291714e-03\n",
            " 1.48157689e-02 6.07051478e-03 1.88196449e-02 7.68055163e-03\n",
            " 5.69539026e-03 8.60742764e-03 1.52960421e-03 1.00092374e-02\n",
            " 5.12625820e-03 5.64081901e-03 1.88196449e-02 3.89484481e-03\n",
            " 1.54491376e-05 6.11692618e-03 1.30984854e-02 1.44728126e-02\n",
            " 1.55527118e-02 2.99675503e-03 1.13151919e-02 1.41076348e-02\n",
            " 2.06047572e-02 1.85045207e-02 1.15114987e-04 1.01222707e-02\n",
            " 1.30984854e-02 1.33322220e-02 2.07793039e-03 7.29845182e-09\n",
            " 3.09494302e-03 2.28301393e-05 6.86195997e-03 1.30299065e-02\n",
            " 8.93501812e-03 4.82721620e-04 2.29314810e-07 1.18778957e-02\n",
            " 8.13467480e-03 7.63938131e-03 2.90048883e-03 7.85331043e-03\n",
            " 1.10271812e-02 9.92232716e-03 1.76426698e-02 5.79784584e-03\n",
            " 9.36505922e-03 2.26486994e-03 1.19519919e-02 1.89981458e-02\n",
            " 2.28134022e-02 1.44235586e-02 9.70319161e-03 1.68106260e-02\n",
            " 1.89953252e-02 2.31535068e-02 2.25362984e-02 2.06294750e-02\n",
            " 1.39084547e-02 2.15973621e-02 1.94529955e-02 1.17495895e-02\n",
            " 1.16336018e-02 1.76824298e-02 1.13439217e-03 7.59967467e-03\n",
            " 1.95351113e-02 3.17108383e-03 2.21424609e-02 1.66865553e-02\n",
            " 4.23308635e-04 1.74726978e-02 1.20148545e-03 1.52449375e-02\n",
            " 8.72023771e-03 3.51528361e-03 1.06016972e-02 1.85679928e-02\n",
            " 1.86318999e-02 1.90745526e-02 1.44930917e-02 9.92232716e-03\n",
            " 1.29096247e-02 4.31483346e-04 1.45171037e-02 7.76959935e-03\n",
            " 5.64868585e-03 2.23495495e-02 5.26125795e-03 2.18912157e-02\n",
            " 2.06085793e-02 1.95202640e-02 1.21546275e-02 5.34998305e-04\n",
            " 2.20458889e-02 1.15314574e-02 1.05877637e-02 4.41916141e-03\n",
            " 4.58146460e-03 1.25493488e-03 1.65354936e-02 6.10775022e-03\n",
            " 1.13379018e-02 1.93048414e-02 6.38869977e-04 1.11795668e-03\n",
            " 1.08060976e-02 2.07685954e-02 5.71336319e-03 7.30529218e-05\n",
            " 3.87583606e-03 1.34912179e-02 2.17384200e-02 1.85555807e-02\n",
            " 1.01032300e-02 1.12962924e-02 1.14694343e-02 2.03145760e-02\n",
            " 1.91985539e-03 7.95531242e-03 1.98001890e-02 8.97433693e-03\n",
            " 7.47357090e-04 1.53919105e-02 2.18011371e-03 1.52032087e-02\n",
            " 1.11638045e-02 2.26877777e-02 1.03107958e-02 2.02159652e-02\n",
            " 1.48759132e-02 8.09218268e-03 2.22566820e-02 1.75997514e-02\n",
            " 9.66424616e-03 2.23487830e-02 1.92632633e-02 5.33491895e-03\n",
            " 1.33322220e-02 3.76711261e-03 7.85098819e-05 1.69046862e-02\n",
            " 9.44724922e-03 1.41979484e-02 4.44645088e-03 1.51427137e-02\n",
            " 1.91389051e-02 1.69318436e-02 3.76711261e-03 1.24353918e-02\n",
            " 1.26247414e-02 9.30970045e-03 1.50554526e-02 7.05292445e-03\n",
            " 1.03838466e-03 1.30458655e-02 1.55759715e-02 1.97069799e-02\n",
            " 9.84199393e-03 7.75729288e-03 1.23024553e-02 1.59497637e-03\n",
            " 2.28427116e-02 1.84836727e-02 1.73281934e-02 1.32455272e-02\n",
            " 5.16291001e-05 1.75560659e-02 9.41692238e-03 1.51242050e-02\n",
            " 1.64165799e-02 4.79710633e-03 3.32715064e-03 1.07447018e-02\n",
            " 7.41548099e-03 1.74726978e-02 9.54759039e-03 4.95232443e-03\n",
            " 9.47082107e-03 1.11175333e-02 9.95210838e-03 1.04753703e-02\n",
            " 7.29845182e-09 4.11098799e-03 9.40570574e-03 1.56559579e-02\n",
            " 8.84220435e-03 2.18887411e-02 1.20265756e-03 1.34861719e-02\n",
            " 1.36604577e-02 4.36041355e-03 1.51687764e-02 8.51258493e-03\n",
            " 1.97326972e-03 1.98553534e-02 8.14047191e-03 1.50759014e-02\n",
            " 2.20913697e-03 1.93887934e-02 2.29133374e-02 7.77703922e-03\n",
            " 4.22091176e-03 1.22013731e-02 1.66483014e-02 2.31291766e-02\n",
            " 9.00353948e-03 5.91523208e-03 2.06149016e-02 5.84698268e-03\n",
            " 2.07416025e-02 1.86658711e-02 6.83558603e-03 3.06607233e-03\n",
            " 8.74523824e-03 1.35424000e-02 1.34328201e-02 1.01633330e-02\n",
            " 5.47004366e-03 1.11286120e-02 2.18811040e-02 4.41916141e-03\n",
            " 1.13151919e-02 9.89070683e-03 8.10055689e-03 2.34767277e-02\n",
            " 1.29090313e-02 9.55804440e-03 5.81772388e-03 1.15013923e-02\n",
            " 8.22679656e-03 1.26239827e-02 1.90329120e-02 2.57496807e-03\n",
            " 1.40048644e-02 1.79223851e-04 4.34601699e-03 1.70282336e-02\n",
            " 2.00762327e-02 1.11736777e-02 1.86424603e-02 1.16436647e-02\n",
            " 4.23926557e-03 1.05202383e-02 3.47296220e-03 1.48054769e-02\n",
            " 1.87649181e-02 6.36425703e-03 7.84706003e-03 1.98911425e-02\n",
            " 1.06115649e-02 1.90751277e-02 5.68091312e-04 3.37697162e-03\n",
            " 1.18445332e-02 1.64165799e-02 1.57026306e-02 6.25775230e-03\n",
            " 1.37378777e-02 1.56691884e-06 1.19191506e-02 1.04177848e-04\n",
            " 8.73906312e-04 3.11009979e-03 1.30438292e-02 6.96302993e-03\n",
            " 2.16643038e-02 3.15494594e-03 2.30120067e-02 9.80711998e-03\n",
            " 5.34469851e-03 1.95721005e-02 4.49606483e-04 2.25245711e-02\n",
            " 2.10672012e-02 1.50776179e-02 5.56497163e-03 2.08509611e-02\n",
            " 5.88205556e-03 1.32155444e-02 1.29427239e-03 2.25641478e-02\n",
            " 1.40079341e-02 1.12198290e-02 9.17899115e-04 1.80985105e-02\n",
            " 4.74535029e-03 1.29392963e-02 7.05396524e-03 8.81936993e-03\n",
            " 5.71928547e-03 1.56924916e-02 6.34599698e-03 1.51000050e-02\n",
            " 4.80179315e-03 2.10798247e-02 1.93887934e-02 5.93336376e-03\n",
            " 1.84761175e-02 5.64162494e-03 3.57296232e-03 8.10165666e-03\n",
            " 4.41916141e-03 1.68375782e-02 1.04681516e-02 1.80510927e-02\n",
            " 8.37942577e-03 3.87702199e-03 1.78018898e-02 1.32026971e-03\n",
            " 1.61298886e-03 2.06549270e-02 1.71854833e-02 9.55326819e-03\n",
            " 4.37699170e-03 1.05724197e-02 1.23827319e-02 2.08884847e-02\n",
            " 1.67930185e-03 5.49231810e-03 9.57734325e-03 1.78216416e-02\n",
            " 1.04351456e-04 8.40498749e-03 1.77924582e-02 5.81206455e-16\n",
            " 3.24570241e-03 1.65208522e-02 1.54497156e-02 6.31573885e-03\n",
            " 1.33305248e-02 1.97341427e-02 1.11349598e-02 1.89098382e-02\n",
            " 1.47084974e-02 1.18554115e-02 1.73497260e-02 2.67024365e-04\n",
            " 8.43669746e-03 1.97691200e-02 1.07719044e-02 1.64470900e-02\n",
            " 1.05202383e-02 7.59967467e-03 3.02539868e-03 4.26408073e-03\n",
            " 3.31956967e-03 1.23024553e-02 2.19709506e-03 1.68932151e-02\n",
            " 4.00517495e-03 1.29264947e-02 7.19851333e-03 7.61673219e-03\n",
            " 1.79351813e-03 2.80677090e-04 7.36029197e-03 1.35032286e-02\n",
            " 4.99857207e-03 7.02505250e-03 1.28358560e-02 4.42955195e-03\n",
            " 4.51500588e-04 1.48244702e-02 2.29088762e-02 8.98049070e-03\n",
            " 2.26051979e-02 1.90298251e-02 2.14248442e-03 4.58825304e-03\n",
            " 3.71500780e-03 7.37003649e-03 8.04103993e-03 1.94173119e-04\n",
            " 4.71609125e-03 1.55226447e-02 3.77725387e-03 8.63311908e-03\n",
            " 1.48607624e-02 4.99202702e-03 3.42405692e-03 9.59089633e-03\n",
            " 9.67835478e-03 2.29960505e-02 6.98933802e-03 1.42531012e-02\n",
            " 1.73890634e-02 5.06146593e-03 9.75681005e-03 5.69539026e-03\n",
            " 1.00580541e-02 2.06854263e-02 1.48176286e-02 5.11673118e-03\n",
            " 1.03548566e-02 2.18618541e-04 9.68250607e-03 1.21759918e-02\n",
            " 2.09242728e-02 1.80862453e-03 8.67713287e-03 1.04395310e-02\n",
            " 8.30405918e-03 1.96486388e-02 7.23889562e-03 3.87583606e-03\n",
            " 1.43129805e-03 1.97667325e-02 1.27213319e-02 3.23479079e-03\n",
            " 2.03562049e-03 1.58637957e-02 1.50604311e-02 1.46526680e-02\n",
            " 1.31900147e-03 5.06406369e-03 2.01046908e-02 1.61412784e-02\n",
            " 1.98911425e-02 1.89854297e-03 1.85932812e-02 5.81772388e-03\n",
            " 4.13506980e-03 1.67686686e-02 1.35708511e-02 1.64642615e-03\n",
            " 1.21635811e-02 7.91192188e-03 3.26256210e-03 3.22662832e-03\n",
            " 6.68706046e-03 2.35704914e-03 1.53285186e-02 1.89595023e-02\n",
            " 5.58618476e-06 2.25358645e-02 2.22507259e-02 1.27504039e-02\n",
            " 8.99523825e-04 1.55745701e-02 3.97901634e-03 1.31953825e-03\n",
            " 1.13247510e-02 1.08018979e-02 1.21456055e-05 1.11236585e-02\n",
            " 1.14838841e-02 1.52118031e-02 2.29863526e-02 2.44823457e-03\n",
            " 1.90378432e-04 9.27434905e-03 1.42531012e-02 3.95506271e-03\n",
            " 3.24771937e-03 9.57301580e-03 1.91913882e-03 8.10133076e-04\n",
            " 2.26709762e-03 1.51311289e-02 6.83022008e-04 2.11163163e-02\n",
            " 2.19933777e-03 1.16711200e-03 1.98911425e-02 2.34244071e-02\n",
            " 1.60530066e-02 3.88802668e-03 1.58778962e-02 1.47786658e-02\n",
            " 1.14498957e-02 8.07853455e-03 5.75589960e-05 1.40667933e-02\n",
            " 6.35085683e-04 1.15399068e-02 2.35181714e-02 9.76660388e-04\n",
            " 1.27835393e-02 1.09031115e-02 1.90751277e-02 1.31259148e-02\n",
            " 1.06647327e-02 1.31250243e-02 1.42324308e-02 1.44402812e-02\n",
            " 9.92232716e-03 9.86244318e-03 2.26732035e-02 5.59234810e-03\n",
            " 1.98602605e-02 1.87350310e-02 2.26061585e-02 8.71291095e-03\n",
            " 9.07104746e-03 8.36868098e-03 1.02265783e-02 1.91913882e-03\n",
            " 1.59304036e-02 2.11312696e-02 2.01200681e-02 1.18808270e-02\n",
            " 1.09478771e-02 1.79946499e-02 2.29388818e-03 1.25349789e-02\n",
            " 3.43348455e-03 2.17809194e-02 1.02178106e-02 2.24530380e-02\n",
            " 1.78543199e-02 5.05454970e-03 1.98192452e-02 1.10140625e-02\n",
            " 1.98089928e-03 1.34010439e-02 4.31092330e-03 1.22893016e-02\n",
            " 1.70744250e-02 1.61791094e-02 7.94236065e-03 2.07974549e-02\n",
            " 1.29100498e-02 1.30728599e-02 4.73787028e-03 9.45505003e-03\n",
            " 5.80823290e-04 3.10464456e-03 9.70824156e-03 4.06400050e-03\n",
            " 1.81185462e-02 8.23751683e-03 1.77279577e-02 8.20645048e-03\n",
            " 2.18618541e-04 4.84960415e-03 2.33896379e-02 1.83309537e-02\n",
            " 1.13687417e-02 3.03453454e-03 1.53863870e-02 2.23108843e-02\n",
            " 4.12191051e-03 1.75588546e-02 1.07387876e-02 8.35923311e-03\n",
            " 2.01129983e-02 4.67092486e-03 6.64402033e-04 1.48870069e-03\n",
            " 1.33166520e-02 2.22671630e-02 1.21103448e-03 1.91977007e-02\n",
            " 1.65464902e-02 7.67622603e-03 5.26409720e-03 1.66556150e-02\n",
            " 7.12399150e-04 2.28289953e-02 4.82795144e-03 1.46545571e-02\n",
            " 1.95400722e-02 1.94040371e-02 1.21311591e-02 3.34826145e-04\n",
            " 7.88946627e-03 2.33234186e-02 1.91913882e-03 7.87352896e-03\n",
            " 2.19984519e-02 1.43127546e-02 1.17015916e-02 1.33981298e-02\n",
            " 5.86797527e-03 7.64925929e-03 8.77035761e-03 1.16229182e-02\n",
            " 1.52207824e-02 2.06047572e-02 1.05625267e-02 2.35420677e-03\n",
            " 1.33971687e-02 3.79649459e-03 2.01912443e-02 1.23351178e-03\n",
            " 7.69729737e-03 2.17400895e-02 1.94546521e-02 8.48006758e-03\n",
            " 9.17508167e-03 2.58770298e-04 1.15902092e-02 3.87583606e-03\n",
            " 1.68809597e-02 6.27487791e-03 3.97901634e-03 9.55113232e-03\n",
            " 1.89318755e-02 4.12691935e-04 2.79137349e-03 1.52325689e-02\n",
            " 2.09378540e-02 1.62934086e-02 2.29236090e-02 2.01538110e-02\n",
            " 5.39572121e-04 8.50391613e-03 2.33610943e-02 9.71380762e-03\n",
            " 2.05562610e-03 4.85893420e-03 1.60347420e-03 1.01873670e-02\n",
            " 1.91512994e-02 1.77718886e-02 1.56844716e-02 1.23204749e-02\n",
            " 1.05478640e-02 1.47888195e-02 7.08839298e-03 1.00244968e-02\n",
            " 1.08092475e-02 1.37266411e-04 7.29957192e-03 2.37278526e-03\n",
            " 2.07041845e-02 2.31820694e-02 3.39933480e-03 1.44004359e-02\n",
            " 1.73890634e-02 3.25152836e-03 4.79710633e-03 8.85223046e-03\n",
            " 1.89386076e-02 1.24604931e-02 4.44645088e-03 1.71782499e-02\n",
            " 6.54398985e-03 2.76921641e-03 1.92083740e-02 1.11647858e-02\n",
            " 9.95333640e-03 2.00634379e-03 6.19938341e-04 1.96513701e-02\n",
            " 2.84954008e-03 1.41367359e-02 1.44182899e-02 1.70377829e-02\n",
            " 1.78018898e-02 1.95172005e-02 4.38300319e-03 1.03526106e-02\n",
            " 1.48054769e-02 1.44673230e-02 1.88874750e-02 8.02589309e-03\n",
            " 2.05492243e-02 4.11938817e-03 2.12158927e-02 1.63090611e-02\n",
            " 6.58062084e-04 1.70990357e-02 1.73848805e-02 3.55954901e-03\n",
            " 6.58595270e-03 5.51403595e-03 8.26855470e-03 5.05366451e-03\n",
            " 1.64165799e-02 1.67409729e-02 1.65641257e-02 2.05952812e-02\n",
            " 3.49827116e-04 2.80939721e-03 2.31608590e-02 3.12611653e-03\n",
            " 8.26949604e-03 1.37789244e-02 1.46533064e-02 8.52902517e-03\n",
            " 2.29388818e-03 1.44445694e-02 1.72845412e-02 1.43905219e-03\n",
            " 1.16154722e-02 1.59795542e-02 2.49451905e-03 2.18267607e-02\n",
            " 6.19607915e-03 1.10077918e-02 1.43483107e-02 1.17938612e-02\n",
            " 4.06252538e-03 1.44856660e-02 1.97688715e-02 1.17216279e-02\n",
            " 5.58510615e-03 9.08843345e-04 1.08168424e-02 6.91648293e-03\n",
            " 4.40687055e-03 1.56652973e-02 5.21193842e-03 3.89856069e-03\n",
            " 2.20591900e-02 7.37898425e-03 5.24296835e-03 4.71439125e-03\n",
            " 2.89413229e-03 6.70843170e-03 1.87610916e-02 1.83630662e-02\n",
            " 1.08984558e-02 2.27260702e-02 1.16939479e-03 6.82033360e-04\n",
            " 2.29245785e-02 6.11692618e-03 1.36926189e-02 1.05998996e-03\n",
            " 2.16932721e-04 1.16786427e-02 1.00153078e-02 1.11671677e-02\n",
            " 1.36216682e-03 1.94882608e-02 1.65463511e-02 1.48910167e-03\n",
            " 2.16012941e-03 2.90048883e-03 8.37936929e-05 1.53988171e-02\n",
            " 3.93244093e-03 2.11163163e-02 1.84705046e-02 5.54025076e-03\n",
            " 5.38330182e-03 2.48471639e-06 1.25120977e-02 2.30715849e-02\n",
            " 7.04023785e-04 5.80106614e-07 2.00359494e-02 1.12174439e-02\n",
            " 2.03491396e-02 1.96997966e-02 2.45557938e-05 1.75293472e-02\n",
            " 4.03078167e-05 2.23169726e-02 1.37923145e-02 1.71871239e-02\n",
            " 1.06621266e-02 1.12325394e-02 1.59588234e-03 8.86284134e-04\n",
            " 1.18022154e-02 2.21500078e-02 1.67854393e-02 4.66078747e-03\n",
            " 2.18691878e-02 1.69625385e-02 1.60469490e-02 3.89484481e-03\n",
            " 1.45103704e-02 5.07410165e-03 1.10426929e-02 5.07410165e-03\n",
            " 7.60170830e-03 1.97532927e-02 1.89826799e-02 1.05419319e-03\n",
            " 2.29021663e-02 7.42621252e-03 1.96991712e-03 1.82261365e-02\n",
            " 4.22680532e-03 3.41489041e-04 2.32871123e-02 1.55380744e-02\n",
            " 4.17697486e-04 1.09247331e-02 1.44130818e-02 3.22139726e-03\n",
            " 1.41989278e-02 5.12080090e-03 1.82564927e-02 2.07026594e-02\n",
            " 2.10004815e-02 4.48190043e-03 2.64684650e-04 5.35232109e-03\n",
            " 2.27342882e-02 6.37496282e-03 1.85552139e-02 6.69844269e-03\n",
            " 1.33715638e-02 1.62270544e-02 5.76892738e-03 1.72815580e-02\n",
            " 4.70474120e-03 4.99202702e-03 7.41061040e-03 1.95202640e-02\n",
            " 1.19614393e-02 3.12636561e-03 1.35730640e-02 1.53086741e-02\n",
            " 1.75956281e-02 1.13038607e-02 1.49742635e-02 2.02464659e-02\n",
            " 5.73243857e-03 1.75204662e-02 6.04258116e-03 1.31438189e-02\n",
            " 1.94235829e-02 2.15066128e-02 1.85883136e-02 1.96194050e-02\n",
            " 2.23424219e-02 5.03568965e-03 3.89484481e-03 1.37224079e-02\n",
            " 2.03984968e-02 1.42804262e-02 8.17089880e-03 1.09447029e-02\n",
            " 1.49110351e-03 1.29953261e-03 3.90056512e-03 1.61609003e-02\n",
            " 5.44279360e-03 2.04161569e-02 4.10294781e-03 7.62478451e-04\n",
            " 1.77443231e-02 9.40970946e-03 1.11661330e-02 8.67239265e-03\n",
            " 5.76507542e-03 2.48501320e-03 8.00616113e-04 9.59560947e-03\n",
            " 1.94814501e-02 7.33717439e-03 7.78196099e-03 9.29386892e-03\n",
            " 1.99240219e-02 1.15720480e-02 1.00497670e-02 3.06276467e-03\n",
            " 1.58791516e-03 1.35676874e-03 2.05247320e-02 1.47588859e-02\n",
            " 6.65848966e-03 1.00681599e-02 1.11348969e-02 7.52156733e-03\n",
            " 1.78110480e-02 8.89067457e-03 1.38315003e-02 4.37588078e-03\n",
            " 2.18056370e-02 1.41979588e-02 8.27527039e-03 3.95386505e-03\n",
            " 9.32312360e-03 2.25974345e-02 1.37655819e-02 1.86826076e-02\n",
            " 1.89933380e-02 1.97418045e-02 1.32894266e-02 3.34285422e-03\n",
            " 1.55638025e-02 1.37989351e-02 3.37734000e-03 9.25550445e-03\n",
            " 5.08851713e-04 9.52326066e-04 9.10730358e-03 1.44004359e-02\n",
            " 8.74037564e-03 2.79670242e-03 9.92232716e-03 6.18456866e-03\n",
            " 8.46479948e-03 2.15885188e-02 1.69239324e-02 4.30501967e-04\n",
            " 5.74047243e-03 1.47314511e-02 7.76770983e-03 3.86167614e-03\n",
            " 1.07476419e-02 7.04863122e-03 3.62440341e-03 8.02469489e-03\n",
            " 1.55527118e-02 9.74988859e-03 1.01271946e-02 7.47091949e-03\n",
            " 1.79267863e-02 4.90324442e-03 2.32094661e-02 5.90593698e-03\n",
            " 6.95825127e-03 8.99523825e-04 4.16675707e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3250 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.03510746e-03 4.52132919e-03 1.73406460e-02 2.22443326e-02\n",
            " 1.73617652e-02 4.88264215e-03 4.26639896e-03 1.94644845e-02\n",
            " 1.52886972e-02 7.09720718e-04 1.29163651e-02 9.83786639e-03\n",
            " 4.18959190e-03 6.86821700e-03 1.29124279e-02 8.73421644e-03\n",
            " 1.61907794e-02 1.86432346e-02 1.19972436e-02 2.06012448e-02\n",
            " 2.26082274e-02 2.05427496e-02 8.56331854e-03 2.12874590e-02\n",
            " 1.06447153e-02 1.10803231e-02 1.22939981e-02 6.72142321e-03\n",
            " 1.47879855e-02 6.04301444e-03 1.88148142e-02 7.68397252e-03\n",
            " 5.66946123e-03 8.60208396e-03 1.52244932e-03 1.00051598e-02\n",
            " 5.12016738e-03 5.63509291e-03 1.88148142e-02 3.89730923e-03\n",
            " 1.54121317e-05 6.10185856e-03 1.30845219e-02 1.44455595e-02\n",
            " 1.55131786e-02 2.98156455e-03 1.13052516e-02 1.40479387e-02\n",
            " 2.05808065e-02 1.84343828e-02 1.14535122e-04 1.01104573e-02\n",
            " 1.30845219e-02 1.33098735e-02 2.07569605e-03 7.18734221e-09\n",
            " 3.08325449e-03 2.28049883e-05 6.85126227e-03 1.30240747e-02\n",
            " 8.92625540e-03 4.81932485e-04 2.28230379e-07 1.18503083e-02\n",
            " 8.14222912e-03 7.61553250e-03 2.89963236e-03 7.83891127e-03\n",
            " 1.10071752e-02 9.91869709e-03 1.76470492e-02 5.78120106e-03\n",
            " 9.34957520e-03 2.26037291e-03 1.19277734e-02 1.89566461e-02\n",
            " 2.27965556e-02 1.44155922e-02 9.64698792e-03 1.67668899e-02\n",
            " 1.89263088e-02 2.31029155e-02 2.25217868e-02 2.06090285e-02\n",
            " 1.38983657e-02 2.15561714e-02 1.94449932e-02 1.17263204e-02\n",
            " 1.16169786e-02 1.76943211e-02 1.13285351e-03 7.58871416e-03\n",
            " 1.95235240e-02 3.16665743e-03 2.21316725e-02 1.66625601e-02\n",
            " 4.19167946e-04 1.74683496e-02 1.19668545e-03 1.52277977e-02\n",
            " 8.68198796e-03 3.50592492e-03 1.05792830e-02 1.85301751e-02\n",
            " 1.86332090e-02 1.90849758e-02 1.44811844e-02 9.91869709e-03\n",
            " 1.28836426e-02 4.30553111e-04 1.44895526e-02 7.75712938e-03\n",
            " 5.60136939e-03 2.23634515e-02 5.26787753e-03 2.18801028e-02\n",
            " 2.05754964e-02 1.94644845e-02 1.20736544e-02 5.32525588e-04\n",
            " 2.20070012e-02 1.15219444e-02 1.05778372e-02 4.41312946e-03\n",
            " 4.57214137e-03 1.25375792e-03 1.65329274e-02 6.08692203e-03\n",
            " 1.13262161e-02 1.92525385e-02 6.36323625e-04 1.11397675e-03\n",
            " 1.07456349e-02 2.07009444e-02 5.70901233e-03 7.30034026e-05\n",
            " 3.85680418e-03 1.34291308e-02 2.17543066e-02 1.85214474e-02\n",
            " 1.00844121e-02 1.12797163e-02 1.14276283e-02 2.02923645e-02\n",
            " 1.91232834e-03 7.95179165e-03 1.97190065e-02 8.93722683e-03\n",
            " 7.46260586e-04 1.53700044e-02 2.17993395e-03 1.52153702e-02\n",
            " 1.11615439e-02 2.26721262e-02 1.02954188e-02 2.01942137e-02\n",
            " 1.48419411e-02 8.08078716e-03 2.21852656e-02 1.75736171e-02\n",
            " 9.64579349e-03 2.22925293e-02 1.92403575e-02 5.31498764e-03\n",
            " 1.33098735e-02 3.76059182e-03 7.86136967e-05 1.68822443e-02\n",
            " 9.41687089e-03 1.42477398e-02 4.43811047e-03 1.51343301e-02\n",
            " 1.91093979e-02 1.69051988e-02 3.76059182e-03 1.24160442e-02\n",
            " 1.25782986e-02 9.30524885e-03 1.50092094e-02 7.04147656e-03\n",
            " 1.03653682e-03 1.30332308e-02 1.55633646e-02 1.96547723e-02\n",
            " 9.84533583e-03 7.73006094e-03 1.23163245e-02 1.58560487e-03\n",
            " 2.28101966e-02 1.84553923e-02 1.73271012e-02 1.32254407e-02\n",
            " 5.16097634e-05 1.75670662e-02 9.40729091e-03 1.50889930e-02\n",
            " 1.63940338e-02 4.79649878e-03 3.32207487e-03 1.07344485e-02\n",
            " 7.39112437e-03 1.74683496e-02 9.53688025e-03 4.95345058e-03\n",
            " 9.43208838e-03 1.10848645e-02 9.93916865e-03 1.04507293e-02\n",
            " 7.18734221e-09 4.10419090e-03 9.36742044e-03 1.56355656e-02\n",
            " 8.81122717e-03 2.18558226e-02 1.20002827e-03 1.34934126e-02\n",
            " 1.36650755e-02 4.34978516e-03 1.51369725e-02 8.49711227e-03\n",
            " 1.97313275e-03 1.98055407e-02 8.11615023e-03 1.50332406e-02\n",
            " 2.20370580e-03 1.93284272e-02 2.27722309e-02 7.75269372e-03\n",
            " 4.21063577e-03 1.21904946e-02 1.66221869e-02 2.31124502e-02\n",
            " 8.98836837e-03 5.90792928e-03 2.05583986e-02 5.85788043e-03\n",
            " 2.07065523e-02 1.86648513e-02 6.81096214e-03 3.06484958e-03\n",
            " 8.73421644e-03 1.35166906e-02 1.34024951e-02 1.01078737e-02\n",
            " 5.44915116e-03 1.11216654e-02 2.18910862e-02 4.41312946e-03\n",
            " 1.13052516e-02 9.89006129e-03 8.07917312e-03 1.28971063e-02\n",
            " 9.52327751e-03 5.80947230e-03 1.14818437e-02 8.19766753e-03\n",
            " 1.25715138e-02 1.89862754e-02 2.57377447e-03 1.40399674e-02\n",
            " 1.78210357e-04 4.33644842e-03 1.69874292e-02 2.00584249e-02\n",
            " 1.11637712e-02 1.86395779e-02 1.16314323e-02 4.21182310e-03\n",
            " 1.05053748e-02 3.46372550e-03 1.47992889e-02 1.87397375e-02\n",
            " 6.34404841e-03 7.84974651e-03 1.98850793e-02 1.05736802e-02\n",
            " 1.90417674e-02 5.65779629e-04 3.37841672e-03 1.18152412e-02\n",
            " 1.63940338e-02 1.56858104e-02 6.24377191e-03 1.37312282e-02\n",
            " 1.56640091e-06 1.19268964e-02 1.03445091e-04 8.65544526e-04\n",
            " 3.10162205e-03 1.30299577e-02 6.95916479e-03 2.16326267e-02\n",
            " 3.15172970e-03 2.30150722e-02 9.79804548e-03 5.34482168e-03\n",
            " 1.94814024e-02 4.46017434e-04 2.24726884e-02 2.10365952e-02\n",
            " 1.50452281e-02 5.57374702e-03 2.08008191e-02 5.88070460e-03\n",
            " 1.31884244e-02 1.29024642e-03 2.25688368e-02 1.39684306e-02\n",
            " 1.11955805e-02 9.14711675e-04 1.80696922e-02 4.74107875e-03\n",
            " 1.29163651e-02 7.04362318e-03 8.81963020e-03 5.69852028e-03\n",
            " 1.55948634e-02 6.33025356e-03 1.50940091e-02 4.79126450e-03\n",
            " 2.10271012e-02 1.93284272e-02 5.90861946e-03 1.84799584e-02\n",
            " 5.62414504e-03 3.55658156e-03 8.07874880e-03 4.41312946e-03\n",
            " 1.67942993e-02 1.04486631e-02 1.80347304e-02 8.32705167e-03\n",
            " 3.87545351e-03 1.77787409e-02 1.31504728e-03 1.61102953e-03\n",
            " 2.06163620e-02 1.71623056e-02 9.54966492e-03 4.36086428e-03\n",
            " 1.05552504e-02 1.23602414e-02 2.08744834e-02 1.67634593e-03\n",
            " 5.48687246e-03 9.55988308e-03 1.77946367e-02 1.04012319e-04\n",
            " 8.39455339e-03 1.77912672e-02 5.79512438e-16 3.24399831e-03\n",
            " 1.64781843e-02 1.54534797e-02 6.30581929e-03 1.33125724e-02\n",
            " 1.97207579e-02 1.11174807e-02 1.88848703e-02 1.46593236e-02\n",
            " 1.18172608e-02 1.73189185e-02 2.65919778e-04 8.42894782e-03\n",
            " 1.97640721e-02 1.07441955e-02 1.63593195e-02 1.05053748e-02\n",
            " 7.58871416e-03 3.02074974e-03 4.23754275e-03 3.31632367e-03\n",
            " 1.23163245e-02 2.18844597e-03 1.68418718e-02 3.99135203e-03\n",
            " 1.28716428e-02 7.18480937e-03 7.59733055e-03 1.78545153e-03\n",
            " 2.77479759e-04 7.33921082e-03 1.34748730e-02 5.00085711e-03\n",
            " 7.02168472e-03 1.28093796e-02 4.42874474e-03 4.48964460e-04\n",
            " 1.48200367e-02 2.28981858e-02 8.95377094e-03 2.25745749e-02\n",
            " 1.89840478e-02 2.12752557e-03 4.58972503e-03 3.69999534e-03\n",
            " 7.35497453e-03 8.04185967e-03 1.93795095e-04 4.71612470e-03\n",
            " 1.54935285e-02 3.77117730e-03 8.63941819e-03 1.48491563e-02\n",
            " 4.97051598e-03 3.41623217e-03 9.56965615e-03 9.64429415e-03\n",
            " 2.29910798e-02 6.98333664e-03 1.42528028e-02 1.73543713e-02\n",
            " 5.04826753e-03 9.75259678e-03 5.66946123e-03 1.00150976e-02\n",
            " 2.06897294e-02 1.48051351e-02 5.11778432e-03 1.03434493e-02\n",
            " 2.17114565e-04 9.69961859e-03 1.21601179e-02 2.09137360e-02\n",
            " 1.80622213e-03 8.64932346e-03 1.04253731e-02 8.30188652e-03\n",
            " 1.96047857e-02 7.24158929e-03 3.85680418e-03 1.42985180e-03\n",
            " 1.97301964e-02 1.27080733e-02 3.22541309e-03 2.03340346e-03\n",
            " 1.58560849e-02 1.50466874e-02 1.46540602e-02 1.31867705e-03\n",
            " 5.05166804e-03 2.00627198e-02 1.61100827e-02 1.98850793e-02\n",
            " 1.89962972e-03 1.85326785e-02 5.80947230e-03 4.12546521e-03\n",
            " 1.67603969e-02 1.35709945e-02 1.64877730e-03 1.21553633e-02\n",
            " 7.89764877e-03 3.25372143e-03 3.22337428e-03 6.65283173e-03\n",
            " 2.34539851e-03 1.53206802e-02 1.88886371e-02 5.55818635e-06\n",
            " 2.24939660e-02 2.22172441e-02 1.27287140e-02 8.95125315e-04\n",
            " 1.55604744e-02 3.97170396e-03 1.31664353e-03 1.13084159e-02\n",
            " 1.08015217e-02 1.20778578e-05 1.11109816e-02 1.14676040e-02\n",
            " 1.51908419e-02 2.29629925e-02 2.44046902e-03 1.89856626e-04\n",
            " 9.23126366e-03 1.42528028e-02 3.94692126e-03 3.24589712e-03\n",
            " 9.55899232e-03 1.91201388e-03 8.11725871e-04 2.26878240e-03\n",
            " 1.51073628e-02 6.79847893e-04 2.10495129e-02 2.19174660e-03\n",
            " 1.16462209e-03 1.98850793e-02 1.60175059e-02 3.88263257e-03\n",
            " 1.58696411e-02 1.47270637e-02 1.14267548e-02 8.04871754e-03\n",
            " 5.73907736e-05 1.40328737e-02 6.32461045e-04 1.15332656e-02\n",
            " 9.72848594e-04 1.27460533e-02 1.08770292e-02 1.90417674e-02\n",
            " 1.30636876e-02 1.06706325e-02 1.31178636e-02 1.42203928e-02\n",
            " 1.43777542e-02 9.91869709e-03 9.85890375e-03 2.26623041e-02\n",
            " 5.57268587e-03 1.98145536e-02 1.87229039e-02 2.26246497e-02\n",
            " 8.70913620e-03 9.07921093e-03 8.35117320e-03 1.02231269e-02\n",
            " 1.91201388e-03 1.59019629e-02 2.11329118e-02 2.00697502e-02\n",
            " 1.18725677e-02 1.09680593e-02 1.79703765e-02 2.28164737e-03\n",
            " 1.25418229e-02 3.42493538e-03 2.17571072e-02 1.02011934e-02\n",
            " 2.24104402e-02 1.78495859e-02 5.05039187e-03 1.98082640e-02\n",
            " 1.10053233e-02 1.97481092e-03 1.33553348e-02 4.30505365e-03\n",
            " 1.22666750e-02 1.70189274e-02 1.61647884e-02 7.91804491e-03\n",
            " 2.07852514e-02 1.28445056e-02 1.30185362e-02 4.73064273e-03\n",
            " 9.44237190e-03 5.77069621e-04 3.10684194e-03 9.68964186e-03\n",
            " 4.05373788e-03 1.80948155e-02 8.24518734e-03 1.77239600e-02\n",
            " 8.21595843e-03 2.17114565e-04 4.84350476e-03 1.83228283e-02\n",
            " 1.13607280e-02 3.03107685e-03 1.53741418e-02 2.22630728e-02\n",
            " 4.10391084e-03 1.75305375e-02 1.07180697e-02 8.34914726e-03\n",
            " 2.01196489e-02 4.65566824e-03 6.61331373e-04 1.48466301e-03\n",
            " 1.33063663e-02 2.21955655e-02 1.20706124e-03 1.91508720e-02\n",
            " 1.65073674e-02 7.66119360e-03 5.23581392e-03 1.66250475e-02\n",
            " 7.09720718e-04 2.27733855e-02 4.81217142e-03 1.46244738e-02\n",
            " 1.95302553e-02 1.93941074e-02 1.21443469e-02 3.33382326e-04\n",
            " 7.82506926e-03 1.91201388e-03 7.87721559e-03 2.19670916e-02\n",
            " 1.43003308e-02 1.16896623e-02 1.33794772e-02 5.83990925e-03\n",
            " 7.66006841e-03 8.74531931e-03 1.15957162e-02 1.52192125e-02\n",
            " 2.05808065e-02 1.05360301e-02 2.35231128e-03 1.33707329e-02\n",
            " 3.78467789e-03 2.01768389e-02 1.22996214e-03 7.67124978e-03\n",
            " 2.17223044e-02 1.94258615e-02 8.48049879e-03 9.12037538e-03\n",
            " 2.58568793e-04 1.15846215e-02 3.85680418e-03 1.68692768e-02\n",
            " 6.24830597e-03 3.97170396e-03 9.54126341e-03 1.88948825e-02\n",
            " 4.08661985e-04 2.79113115e-03 1.52086155e-02 2.09298237e-02\n",
            " 1.62848198e-02 2.28739409e-02 2.01355089e-02 5.38615368e-04\n",
            " 8.48493434e-03 9.71065948e-03 2.04368319e-03 4.85198654e-03\n",
            " 1.60066372e-03 1.01617285e-02 1.91155932e-02 1.77166451e-02\n",
            " 1.56469802e-02 1.23074304e-02 1.04969374e-02 1.47597974e-02\n",
            " 7.08416699e-03 1.00114802e-02 1.08064232e-02 1.36805632e-04\n",
            " 7.24879675e-03 2.36742741e-03 2.06824417e-02 3.39189872e-03\n",
            " 1.43809866e-02 1.73543713e-02 3.25103804e-03 4.79649878e-03\n",
            " 8.82930077e-03 1.89493600e-02 1.24455634e-02 4.43811047e-03\n",
            " 1.71573323e-02 6.52061503e-03 2.77419514e-03 1.91763828e-02\n",
            " 1.11693562e-02 9.94872369e-03 2.00123525e-03 6.18828387e-04\n",
            " 1.96298689e-02 2.82922777e-03 1.41013600e-02 1.43872621e-02\n",
            " 1.70020906e-02 1.77787409e-02 1.94442509e-02 4.36974854e-03\n",
            " 1.03313414e-02 1.47992889e-02 1.44519746e-02 1.88643753e-02\n",
            " 8.00019265e-03 2.05442241e-02 4.09821424e-03 2.12371376e-02\n",
            " 1.62774775e-02 6.56524470e-04 1.70676782e-02 1.73533833e-02\n",
            " 3.54871356e-03 6.56479296e-03 5.50055547e-03 8.23288740e-03\n",
            " 5.03783819e-03 1.63940338e-02 1.67012228e-02 1.65221959e-02\n",
            " 2.05864197e-02 3.47441225e-04 2.78688986e-03 3.12014851e-03\n",
            " 8.23926703e-03 1.37648450e-02 1.46425240e-02 8.53308311e-03\n",
            " 2.28164737e-03 1.44294709e-02 1.72487829e-02 1.43221544e-03\n",
            " 1.16103033e-02 1.59503740e-02 2.48628480e-03 2.17888641e-02\n",
            " 6.17009710e-03 1.09903413e-02 1.43064036e-02 1.18009414e-02\n",
            " 4.05037121e-03 1.44681436e-02 1.97452936e-02 1.16863181e-02\n",
            " 5.57257820e-03 9.04896122e-04 1.07915491e-02 6.88601021e-03\n",
            " 4.39119939e-03 1.55845976e-02 5.19482672e-03 3.89096811e-03\n",
            " 2.19503476e-02 7.32342012e-03 5.23260705e-03 4.68715791e-03\n",
            " 2.88551311e-03 6.67137813e-03 1.87454121e-02 1.82852414e-02\n",
            " 1.08651315e-02 2.27072665e-02 1.16571474e-03 6.81050583e-04\n",
            " 2.29011882e-02 6.10185856e-03 1.36716600e-02 1.05837155e-03\n",
            " 2.15812232e-04 1.16512059e-02 9.96847773e-03 1.11059432e-02\n",
            " 1.35913174e-03 1.94706119e-02 1.64956772e-02 1.48512824e-03\n",
            " 2.15563119e-03 2.89963236e-03 8.34782855e-05 1.53633130e-02\n",
            " 3.91869164e-03 2.10495129e-02 1.84074547e-02 5.52595815e-03\n",
            " 5.38666888e-03 2.47378595e-06 1.24816828e-02 2.30813486e-02\n",
            " 7.01848647e-04 5.81250573e-07 2.00144548e-02 1.12098611e-02\n",
            " 2.02860444e-02 1.96996435e-02 2.45578933e-05 1.74988493e-02\n",
            " 4.00540919e-05 2.22546975e-02 1.37620283e-02 1.71737812e-02\n",
            " 1.06609672e-02 1.12285934e-02 1.58982633e-03 8.81240967e-04\n",
            " 1.17414118e-02 2.21251650e-02 1.67686657e-02 4.65284785e-03\n",
            " 2.18579082e-02 1.69371274e-02 1.60001557e-02 3.89730923e-03\n",
            " 1.44975052e-02 5.06999146e-03 1.10146990e-02 5.06999146e-03\n",
            " 7.58155530e-03 1.97095915e-02 1.88852410e-02 1.05170712e-03\n",
            " 2.28690164e-02 7.43122875e-03 1.96559452e-03 1.81939129e-02\n",
            " 4.21141717e-03 3.42146517e-04 1.55197428e-02 4.15985071e-04\n",
            " 1.08901537e-02 1.43982228e-02 3.21198685e-03 1.41888660e-02\n",
            " 5.10524410e-03 1.82733833e-02 2.05773819e-02 2.10074105e-02\n",
            " 4.44234309e-03 2.63899786e-04 5.34259808e-03 2.27225112e-02\n",
            " 6.34663418e-03 1.85255900e-02 6.67603349e-03 1.33287417e-02\n",
            " 1.62630907e-02 5.75664940e-03 1.72252720e-02 4.70153275e-03\n",
            " 4.97051598e-03 7.42620463e-03 1.94644845e-02 1.19539143e-02\n",
            " 3.12611010e-03 1.35376445e-02 1.52879428e-02 1.75820790e-02\n",
            " 1.12913005e-02 1.49614128e-02 2.02325288e-02 5.72293926e-03\n",
            " 1.75052951e-02 6.01856075e-03 1.31211182e-02 1.93585606e-02\n",
            " 2.14906452e-02 1.85565927e-02 1.96150465e-02 2.23185890e-02\n",
            " 5.01569305e-03 3.89730923e-03 1.36968499e-02 2.03697929e-02\n",
            " 1.42639296e-02 8.13458355e-03 1.09117646e-02 1.48963734e-03\n",
            " 1.29571393e-03 3.88443456e-03 1.61400551e-02 5.43617060e-03\n",
            " 2.03636159e-02 4.09359725e-03 7.61068294e-04 1.77531435e-02\n",
            " 9.38634327e-03 1.11299563e-02 8.65761197e-03 5.75467952e-03\n",
            " 2.48498730e-03 7.98579039e-04 9.58485261e-03 1.94423063e-02\n",
            " 7.33667240e-03 7.76756006e-03 9.27671528e-03 1.99153269e-02\n",
            " 1.15445181e-02 1.00242815e-02 3.06078475e-03 1.58443424e-03\n",
            " 1.35164541e-03 2.05042598e-02 1.47438211e-02 6.64259019e-03\n",
            " 1.00454994e-02 1.10669714e-02 7.51710344e-03 1.77760865e-02\n",
            " 8.87198668e-03 1.38182771e-02 4.36426911e-03 2.17800920e-02\n",
            " 1.41688536e-02 8.25081638e-03 3.93888155e-03 9.31453684e-03\n",
            " 2.25603101e-02 1.37423983e-02 1.86432346e-02 1.89313907e-02\n",
            " 1.96975161e-02 1.32775589e-02 3.33663023e-03 1.55038875e-02\n",
            " 1.37512647e-02 3.37616868e-03 9.23804094e-03 5.05249578e-04\n",
            " 9.46842789e-04 9.12439861e-03 1.43809866e-02 8.70446125e-03\n",
            " 2.79434549e-03 9.91869709e-03 6.16901094e-03 8.44618563e-03\n",
            " 2.15773618e-02 1.68969211e-02 4.27549806e-04 5.73098164e-03\n",
            " 1.47018498e-02 7.74876048e-03 3.85683762e-03 1.06991187e-02\n",
            " 7.03291342e-03 3.61902465e-03 7.99615265e-03 1.55131786e-02\n",
            " 9.73377104e-03 1.01172368e-02 7.47392439e-03 1.79013323e-02\n",
            " 4.90329642e-03 5.89846839e-03 6.93880953e-03 8.95125315e-04\n",
            " 4.17120887e-03]\n",
            "3260 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.01090585e-03 4.50791412e-03 1.72824737e-02 2.22053481e-02\n",
            " 1.73716039e-02 4.85317454e-03 4.23820936e-03 1.94493202e-02\n",
            " 1.52692111e-02 7.09428838e-04 1.29089638e-02 9.80710995e-03\n",
            " 4.18895119e-03 6.83553147e-03 1.29212538e-02 8.70035003e-03\n",
            " 1.61809845e-02 1.86366281e-02 1.19491282e-02 2.05973940e-02\n",
            " 2.24185481e-02 2.05083830e-02 8.55266408e-03 2.12250415e-02\n",
            " 1.06375740e-02 1.10209569e-02 1.22600245e-02 6.68980563e-03\n",
            " 1.47749946e-02 6.02409676e-03 1.88138370e-02 7.66242253e-03\n",
            " 5.66204182e-03 8.59272589e-03 1.51837192e-03 9.94717848e-03\n",
            " 5.10853004e-03 5.62483223e-03 1.88138370e-02 3.89724450e-03\n",
            " 1.53242130e-05 6.09975910e-03 1.30753742e-02 1.43836864e-02\n",
            " 1.54797762e-02 2.98494668e-03 1.12625434e-02 1.39745488e-02\n",
            " 2.05059049e-02 1.84214326e-02 1.13408152e-04 1.00712070e-02\n",
            " 1.30753742e-02 1.32924503e-02 2.05602876e-03 6.98297303e-09\n",
            " 3.06118837e-03 2.20275955e-05 6.80738829e-03 1.29950542e-02\n",
            " 8.91198273e-03 4.77603848e-04 2.25160825e-07 1.18174429e-02\n",
            " 8.09046609e-03 7.57777532e-03 2.89865802e-03 7.84645283e-03\n",
            " 1.09818242e-02 9.89787709e-03 1.75834926e-02 5.76110848e-03\n",
            " 9.32122798e-03 2.25641527e-03 1.19183153e-02 1.89585774e-02\n",
            " 2.27905318e-02 1.43485195e-02 9.64070570e-03 1.67546829e-02\n",
            " 1.87986376e-02 2.24652672e-02 2.06254920e-02 1.38766868e-02\n",
            " 2.14750365e-02 1.93594953e-02 1.17141072e-02 1.16080198e-02\n",
            " 1.76755808e-02 1.12282885e-03 7.59083825e-03 1.95281296e-02\n",
            " 3.13402708e-03 2.21269983e-02 1.66433916e-02 4.16208888e-04\n",
            " 1.72369801e-02 1.19072318e-03 1.51976879e-02 8.63363178e-03\n",
            " 3.48885907e-03 1.05080533e-02 1.84816863e-02 1.85790988e-02\n",
            " 1.90585654e-02 1.44829978e-02 9.89787709e-03 1.28573729e-02\n",
            " 4.29372283e-04 1.44224709e-02 7.72738934e-03 5.58186985e-03\n",
            " 2.22988268e-02 5.24478909e-03 2.17560725e-02 2.04342341e-02\n",
            " 1.94493202e-02 1.20475029e-02 5.32062458e-04 2.19159722e-02\n",
            " 1.15163689e-02 1.05340062e-02 4.38771317e-03 4.56267474e-03\n",
            " 1.23965330e-03 1.64751294e-02 6.06303249e-03 1.13204077e-02\n",
            " 1.91961968e-02 6.34478789e-04 1.10463989e-03 1.06995356e-02\n",
            " 2.06455309e-02 5.70466034e-03 7.27562434e-05 3.84804502e-03\n",
            " 1.34298061e-02 2.17124744e-02 1.84459403e-02 1.00503128e-02\n",
            " 1.12141553e-02 1.14141062e-02 2.02600508e-02 1.90969460e-03\n",
            " 7.94835196e-03 1.96937436e-02 8.91832579e-03 7.40803483e-04\n",
            " 1.53097897e-02 2.17632681e-03 1.51846188e-02 1.11185187e-02\n",
            " 2.26041278e-02 1.02886858e-02 2.01497946e-02 1.48393246e-02\n",
            " 8.06395820e-03 2.21183709e-02 1.75800326e-02 9.60479649e-03\n",
            " 2.21946586e-02 1.90414089e-02 5.30674423e-03 1.32924503e-02\n",
            " 3.74095862e-03 7.84461737e-05 1.68046601e-02 9.40915619e-03\n",
            " 1.41392602e-02 4.41028501e-03 1.50971667e-02 1.90615574e-02\n",
            " 1.68583899e-02 3.74095862e-03 1.23767765e-02 1.25193228e-02\n",
            " 9.31215585e-03 1.49724862e-02 7.00222924e-03 1.03549889e-03\n",
            " 1.29779993e-02 1.55405735e-02 1.95850523e-02 9.82005647e-03\n",
            " 7.71692622e-03 1.22636217e-02 1.58635671e-03 2.27606927e-02\n",
            " 1.83743522e-02 1.71451184e-02 1.32133475e-02 5.08412759e-05\n",
            " 1.74969231e-02 9.34288509e-03 1.50812600e-02 1.63585636e-02\n",
            " 4.79113088e-03 3.30258919e-03 1.06885144e-02 7.36703447e-03\n",
            " 1.72369801e-02 9.53162951e-03 4.91100401e-03 9.40843023e-03\n",
            " 1.10195714e-02 9.93105691e-03 1.03988055e-02 6.98297303e-09\n",
            " 4.10616109e-03 9.37530537e-03 1.55781656e-02 8.81504157e-03\n",
            " 2.18380641e-02 1.19415285e-03 1.35025753e-02 1.35789639e-02\n",
            " 4.33044149e-03 1.50796270e-02 8.46274499e-03 1.95804191e-03\n",
            " 1.97663942e-02 8.06838166e-03 1.49823970e-02 2.20717014e-03\n",
            " 1.92825821e-02 2.27135851e-02 7.72809381e-03 4.20854071e-03\n",
            " 1.21789608e-02 1.66022864e-02 8.95565557e-03 5.89619603e-03\n",
            " 2.05435380e-02 5.81720269e-03 2.06604945e-02 1.86661382e-02\n",
            " 6.79774770e-03 3.06098307e-03 8.70035003e-03 1.34855070e-02\n",
            " 1.34000646e-02 1.00580112e-02 5.44092278e-03 1.10793932e-02\n",
            " 2.18364781e-02 4.38771317e-03 1.12625434e-02 9.86075954e-03\n",
            " 8.05372598e-03 1.28258084e-02 9.51439543e-03 5.80370863e-03\n",
            " 1.14736289e-02 8.15633668e-03 1.25058088e-02 1.89216079e-02\n",
            " 2.57221641e-03 1.39795776e-02 1.76755988e-04 4.32294400e-03\n",
            " 1.69512051e-02 1.99475021e-02 1.10704865e-02 1.86630243e-02\n",
            " 1.16400401e-02 4.21132997e-03 1.04780403e-02 3.45567446e-03\n",
            " 1.47404256e-02 1.87431187e-02 6.33993010e-03 7.82011636e-03\n",
            " 1.98822240e-02 1.05572725e-02 1.90468484e-02 5.63317761e-04\n",
            " 3.35412000e-03 1.17363652e-02 1.63585636e-02 1.57030849e-02\n",
            " 6.22691555e-03 1.37073662e-02 1.52240215e-06 1.18358749e-02\n",
            " 1.01687274e-04 8.66129055e-04 3.09452994e-03 1.30144081e-02\n",
            " 6.92792466e-03 2.15812815e-02 3.14202074e-03 9.80378609e-03\n",
            " 5.33201470e-03 1.94728245e-02 4.43365550e-04 2.24528086e-02\n",
            " 2.10081750e-02 1.50554290e-02 5.54968297e-03 2.07608206e-02\n",
            " 5.85915805e-03 1.31672771e-02 1.28342335e-03 2.25700254e-02\n",
            " 1.39250139e-02 1.11423224e-02 9.10246945e-04 1.80461392e-02\n",
            " 4.71558985e-03 1.29089638e-02 7.04149351e-03 8.79681225e-03\n",
            " 5.68174758e-03 1.54764370e-02 6.30416300e-03 1.50413675e-02\n",
            " 4.76414211e-03 2.10573038e-02 1.92825821e-02 5.89033860e-03\n",
            " 1.84275263e-02 5.60696368e-03 3.55410623e-03 8.07349842e-03\n",
            " 4.38771317e-03 1.67449226e-02 1.04279483e-02 1.80012688e-02\n",
            " 8.27966930e-03 3.85585153e-03 1.77471720e-02 1.30862726e-03\n",
            " 1.60694131e-03 2.05254267e-02 1.71501954e-02 9.50581873e-03\n",
            " 4.35197151e-03 1.05414183e-02 1.23484861e-02 2.07845285e-02\n",
            " 1.65949459e-03 5.46049388e-03 9.52163405e-03 1.77348082e-02\n",
            " 1.03553090e-04 8.38053986e-03 1.76910240e-02 5.35909135e-16\n",
            " 3.23084432e-03 1.63677055e-02 1.54005426e-02 6.29827781e-03\n",
            " 1.32450455e-02 1.96533770e-02 1.10811489e-02 1.88727474e-02\n",
            " 1.46309841e-02 1.17858251e-02 1.73143777e-02 2.63567592e-04\n",
            " 8.43135615e-03 1.96750843e-02 1.06982001e-02 1.62987761e-02\n",
            " 1.04780403e-02 7.59083825e-03 3.00644002e-03 4.22654757e-03\n",
            " 3.30566253e-03 1.22636217e-02 2.18636175e-03 1.67952758e-02\n",
            " 3.95120336e-03 1.28821942e-02 7.13414392e-03 7.58038112e-03\n",
            " 1.77392684e-03 2.76739911e-04 7.33630732e-03 1.34365024e-02\n",
            " 4.98182837e-03 7.00351245e-03 1.27508133e-02 4.36697726e-03\n",
            " 4.44744366e-04 1.47534338e-02 8.90453059e-03 2.25853211e-02\n",
            " 1.89820398e-02 2.11203693e-03 4.59006819e-03 3.66199524e-03\n",
            " 7.29717957e-03 8.06161744e-03 1.92489529e-04 4.69819113e-03\n",
            " 1.55083179e-02 3.77307807e-03 8.63795258e-03 1.48299881e-02\n",
            " 4.96143553e-03 3.39191796e-03 9.52943105e-03 9.59063311e-03\n",
            " 6.96404679e-03 1.42126014e-02 1.73404814e-02 5.01163351e-03\n",
            " 9.74100116e-03 5.66204182e-03 1.00178240e-02 2.06664773e-02\n",
            " 1.47939927e-02 5.08022510e-03 1.03389355e-02 2.14945012e-04\n",
            " 9.66339339e-03 1.21986209e-02 2.08649477e-02 1.80116214e-03\n",
            " 8.65284397e-03 1.03903920e-02 8.25893897e-03 1.95861334e-02\n",
            " 7.20201980e-03 3.84804502e-03 1.42101440e-03 1.97309611e-02\n",
            " 1.26995745e-02 3.19822317e-03 2.03195419e-03 1.58194883e-02\n",
            " 1.50105880e-02 1.46060629e-02 1.31741854e-03 5.01919894e-03\n",
            " 2.00581513e-02 1.61237232e-02 1.98822240e-02 1.88290578e-03\n",
            " 1.84770817e-02 5.80370863e-03 4.11283060e-03 1.67962566e-02\n",
            " 1.35712194e-02 1.63192677e-03 1.21317033e-02 7.85258235e-03\n",
            " 3.24950122e-03 3.21226669e-03 6.64870907e-03 2.32907262e-03\n",
            " 1.51120536e-02 1.88495893e-02 5.41315399e-06 2.24376629e-02\n",
            " 2.22013969e-02 1.26893708e-02 8.91809681e-04 1.54711567e-02\n",
            " 3.97173185e-03 1.31135684e-03 1.13005734e-02 1.07696601e-02\n",
            " 1.19653433e-05 1.10499496e-02 1.14192534e-02 1.51410671e-02\n",
            " 2.44112078e-03 1.89321832e-04 9.23390744e-03 1.42126014e-02\n",
            " 3.92971532e-03 3.23739936e-03 9.49093614e-03 1.89502069e-03\n",
            " 8.06911653e-04 2.25059423e-03 1.50906940e-02 6.77658622e-04\n",
            " 2.09917830e-02 2.18492756e-03 1.15496761e-03 1.98822240e-02\n",
            " 1.59943667e-02 3.86215626e-03 1.58210589e-02 1.46998108e-02\n",
            " 1.13964785e-02 8.03913382e-03 5.72531776e-05 1.39418096e-02\n",
            " 6.27499146e-04 1.14630740e-02 9.58996946e-04 1.27075892e-02\n",
            " 1.08525952e-02 1.90468484e-02 1.30705517e-02 1.05547038e-02\n",
            " 1.30575026e-02 1.41889533e-02 1.43582880e-02 9.89787709e-03\n",
            " 9.82725392e-03 2.26253032e-02 5.56912436e-03 1.97845817e-02\n",
            " 1.87222089e-02 2.26012949e-02 8.67611005e-03 8.98572380e-03\n",
            " 8.34916760e-03 1.01982726e-02 1.89502069e-03 1.58739938e-02\n",
            " 2.10952615e-02 1.99585310e-02 1.18281388e-02 1.09359487e-02\n",
            " 1.77997100e-02 2.26663728e-03 1.24758301e-02 3.41828149e-03\n",
            " 2.17787655e-02 1.01897527e-02 2.23902575e-02 1.77730017e-02\n",
            " 5.03825462e-03 1.97187384e-02 1.09248467e-02 1.96192725e-03\n",
            " 1.33032664e-02 4.23305237e-03 1.22016622e-02 1.70369918e-02\n",
            " 1.61780997e-02 7.90987753e-03 2.07204968e-02 1.27876748e-02\n",
            " 1.30142926e-02 4.69574448e-03 9.43054917e-03 5.75707338e-04\n",
            " 3.07010848e-03 9.66903404e-03 4.01828047e-03 1.80581832e-02\n",
            " 8.17186719e-03 1.76557082e-02 8.21075734e-03 2.14945012e-04\n",
            " 4.83548542e-03 1.82601441e-02 1.13304553e-02 3.02590814e-03\n",
            " 1.52964852e-02 2.22305625e-02 4.09271693e-03 1.74480024e-02\n",
            " 1.06799172e-02 8.33090600e-03 2.00724329e-02 4.64278867e-03\n",
            " 6.53758615e-04 1.47958226e-03 1.32816608e-02 2.21934016e-02\n",
            " 1.20605311e-03 1.91312665e-02 1.64554887e-02 7.60945521e-03\n",
            " 5.22344564e-03 1.65431348e-02 7.09428838e-04 2.26885371e-02\n",
            " 4.76701772e-03 1.46133946e-02 1.94897921e-02 1.93862846e-02\n",
            " 1.21163242e-02 3.33130079e-04 7.82666496e-03 1.89502069e-03\n",
            " 7.84252370e-03 2.18847019e-02 1.42785081e-02 1.16174626e-02\n",
            " 1.33605774e-02 5.80216121e-03 7.65744200e-03 8.72668117e-03\n",
            " 1.15571274e-02 1.51810145e-02 2.05059049e-02 1.05288566e-02\n",
            " 2.33740851e-03 1.33399178e-02 3.77019748e-03 2.00787808e-02\n",
            " 1.22492062e-03 7.67478894e-03 2.16463485e-02 1.94139358e-02\n",
            " 8.47918167e-03 9.10641301e-03 2.57876859e-04 1.15761484e-02\n",
            " 3.84804502e-03 1.68640474e-02 6.23799351e-03 3.97173185e-03\n",
            " 9.51622150e-03 1.88481391e-02 4.09534350e-04 2.78536435e-03\n",
            " 1.51602676e-02 2.08285689e-02 1.62359697e-02 2.01012584e-02\n",
            " 5.39433239e-04 8.50500872e-03 9.67534226e-03 2.04453637e-03\n",
            " 4.84224251e-03 1.60021618e-03 1.01845841e-02 1.90539078e-02\n",
            " 1.76718225e-02 1.56951801e-02 1.22492011e-02 1.04734930e-02\n",
            " 1.47347214e-02 7.08724082e-03 1.00097222e-02 1.07649915e-02\n",
            " 1.36989712e-04 7.22517940e-03 2.34459110e-03 2.07045613e-02\n",
            " 3.37638785e-03 1.43641930e-02 1.73404814e-02 3.24427468e-03\n",
            " 4.79113088e-03 8.80661781e-03 1.88986930e-02 1.23913563e-02\n",
            " 4.41028501e-03 1.71147148e-02 6.52508094e-03 2.75101510e-03\n",
            " 1.90746168e-02 1.11957579e-02 9.91197653e-03 1.99730674e-03\n",
            " 6.10477757e-04 1.95650170e-02 2.81723810e-03 1.40939263e-02\n",
            " 1.43747638e-02 1.70192942e-02 1.77471720e-02 1.93963002e-02\n",
            " 4.36107953e-03 1.03134940e-02 1.47404256e-02 1.44198653e-02\n",
            " 1.88712589e-02 7.98078219e-03 2.04215661e-02 4.08862086e-03\n",
            " 2.11469964e-02 1.63121420e-02 6.52808716e-04 1.69793410e-02\n",
            " 1.73633777e-02 3.53182151e-03 6.57361221e-03 5.48494092e-03\n",
            " 8.21348379e-03 5.02135112e-03 1.63585636e-02 1.66955533e-02\n",
            " 1.65233613e-02 2.05134307e-02 3.46462876e-04 2.78224800e-03\n",
            " 3.11225676e-03 8.22570537e-03 1.36786867e-02 1.45611681e-02\n",
            " 8.51341688e-03 2.26663728e-03 1.43917219e-02 1.72371295e-02\n",
            " 1.42510411e-03 1.15297214e-02 1.59174285e-02 2.48703560e-03\n",
            " 2.17527628e-02 6.15688742e-03 1.09543612e-02 1.42591505e-02\n",
            " 1.17206526e-02 4.04875176e-03 1.44633150e-02 1.97573032e-02\n",
            " 1.16859953e-02 5.52605882e-03 9.03582282e-04 1.07363509e-02\n",
            " 6.88169608e-03 4.38514113e-03 1.55610840e-02 5.18354410e-03\n",
            " 3.89458668e-03 2.19260029e-02 7.31555705e-03 5.21886948e-03\n",
            " 4.68319223e-03 2.87885383e-03 6.63365007e-03 1.86971743e-02\n",
            " 1.82432463e-02 1.08359288e-02 2.27272368e-02 1.15479671e-03\n",
            " 6.78449070e-04 6.09975910e-03 1.36280192e-02 1.04343486e-03\n",
            " 2.14543248e-04 1.16178409e-02 9.91279260e-03 1.11143069e-02\n",
            " 1.34934071e-03 1.94392647e-02 1.64324929e-02 1.48260699e-03\n",
            " 2.15007672e-03 2.89865802e-03 8.23113807e-05 1.53049123e-02\n",
            " 3.90095554e-03 2.09917830e-02 1.83700500e-02 5.50851663e-03\n",
            " 5.35059171e-03 2.46123692e-06 1.24578070e-02 6.97603301e-04\n",
            " 5.77060655e-07 1.98871856e-02 1.11544466e-02 2.02525859e-02\n",
            " 1.96931958e-02 2.42603281e-05 1.74738817e-02 4.00897794e-05\n",
            " 2.22323111e-02 1.37623809e-02 1.71188367e-02 1.06435567e-02\n",
            " 1.12278329e-02 1.57982437e-03 8.78632975e-04 1.17112176e-02\n",
            " 2.21216064e-02 1.65975251e-02 4.62335188e-03 2.18367984e-02\n",
            " 1.69672916e-02 1.59496129e-02 3.89724450e-03 1.45006626e-02\n",
            " 5.06224041e-03 1.09924852e-02 5.06224041e-03 7.59757729e-03\n",
            " 1.96770009e-02 1.87991953e-02 1.05032186e-03 7.43542965e-03\n",
            " 1.95799507e-03 1.81496080e-02 4.17451396e-03 3.35674215e-04\n",
            " 1.55259363e-02 4.11993674e-04 1.08332835e-02 1.44094464e-02\n",
            " 3.20239670e-03 1.41513879e-02 5.09148769e-03 1.82769074e-02\n",
            " 2.05426030e-02 2.07990007e-02 4.41086145e-03 2.59585672e-04\n",
            " 5.33449061e-03 2.26078322e-02 6.34019362e-03 1.85094324e-02\n",
            " 6.67584083e-03 1.33055161e-02 1.61769174e-02 5.72175626e-03\n",
            " 1.72018352e-02 4.68822294e-03 4.96143553e-03 7.42100695e-03\n",
            " 1.94493202e-02 1.19519766e-02 3.11331388e-03 1.34939651e-02\n",
            " 1.52738895e-02 1.75594597e-02 1.12299975e-02 1.49473799e-02\n",
            " 2.02512463e-02 5.70667251e-03 1.74483263e-02 6.00466769e-03\n",
            " 1.30676991e-02 1.93455891e-02 2.13740648e-02 1.85600534e-02\n",
            " 1.95846926e-02 2.22980217e-02 4.98742027e-03 3.89724450e-03\n",
            " 1.36453231e-02 2.02984415e-02 1.42553172e-02 8.11880716e-03\n",
            " 1.09409054e-02 1.47718553e-03 1.29124366e-03 3.88501574e-03\n",
            " 1.60871339e-02 5.41791243e-03 2.02769286e-02 4.10049413e-03\n",
            " 7.49684533e-04 1.75653516e-02 9.36993295e-03 1.11013803e-02\n",
            " 8.62830026e-03 5.73744940e-03 2.45059435e-03 7.90769968e-04\n",
            " 9.58085560e-03 1.94246277e-02 7.32952804e-03 7.75076509e-03\n",
            " 9.20930093e-03 1.98357140e-02 1.15574683e-02 1.00113460e-02\n",
            " 3.04242556e-03 1.57715583e-03 1.35307206e-03 2.04296322e-02\n",
            " 1.47119551e-02 6.60429708e-03 1.00231652e-02 1.10613062e-02\n",
            " 7.48949494e-03 1.77831473e-02 8.85214258e-03 1.37918019e-02\n",
            " 4.35748745e-03 2.16945444e-02 1.41099969e-02 8.22051534e-03\n",
            " 3.92448682e-03 9.27293734e-03 2.24519501e-02 1.36942972e-02\n",
            " 1.86366281e-02 1.89039026e-02 1.96537721e-02 1.32632553e-02\n",
            " 3.31779498e-03 1.54651136e-02 1.36972651e-02 3.37178528e-03\n",
            " 9.21083723e-03 5.04187539e-04 9.43998260e-04 9.07408027e-03\n",
            " 1.43641930e-02 8.67553875e-03 2.78401231e-03 9.89787709e-03\n",
            " 6.17100707e-03 8.42529968e-03 2.15255118e-02 1.68909217e-02\n",
            " 4.22748046e-04 5.72130932e-03 1.46609331e-02 7.73102305e-03\n",
            " 3.86170773e-03 1.06874359e-02 7.02294713e-03 3.61724422e-03\n",
            " 7.96524548e-03 1.54797762e-02 9.68890488e-03 1.00501774e-02\n",
            " 7.45297623e-03 1.77516310e-02 4.89309723e-03 5.83888507e-03\n",
            " 6.92056075e-03 8.91809681e-04 4.14829283e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3270 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.99767594e-03 4.50558441e-03 1.72316149e-02 2.21767405e-02\n",
            " 1.73922089e-02 4.81756694e-03 4.23645209e-03 1.94176086e-02\n",
            " 1.53105058e-02 7.09528830e-04 1.28896411e-02 9.78661144e-03\n",
            " 4.17242133e-03 6.82860296e-03 1.29034502e-02 8.68503760e-03\n",
            " 1.61702928e-02 1.85770400e-02 1.19255431e-02 2.05382474e-02\n",
            " 2.23910365e-02 2.04579463e-02 8.51265064e-03 2.12350123e-02\n",
            " 1.06009980e-02 1.10251138e-02 1.22356555e-02 6.66142549e-03\n",
            " 1.47440790e-02 5.99485598e-03 1.87964660e-02 7.65613900e-03\n",
            " 5.65141461e-03 8.58132865e-03 1.51017715e-03 9.94156153e-03\n",
            " 5.07810008e-03 5.61346233e-03 1.87964660e-02 3.90060434e-03\n",
            " 1.51862659e-05 6.06539679e-03 1.30598155e-02 1.43612941e-02\n",
            " 1.54567318e-02 2.98318791e-03 1.12486552e-02 1.39237527e-02\n",
            " 2.05170221e-02 1.83019737e-02 1.12680388e-04 1.00120013e-02\n",
            " 1.30598155e-02 1.32562917e-02 2.05329603e-03 6.97298528e-09\n",
            " 3.05678510e-03 2.19292136e-05 6.80167218e-03 1.29766528e-02\n",
            " 8.87179696e-03 4.72519013e-04 2.23402058e-07 1.17964256e-02\n",
            " 8.09753856e-03 7.53913278e-03 2.90117455e-03 7.81963949e-03\n",
            " 1.09862664e-02 9.88864541e-03 1.75758444e-02 5.74070503e-03\n",
            " 9.28220525e-03 2.25250060e-03 1.19106617e-02 1.89075209e-02\n",
            " 1.43333277e-02 9.60435346e-03 1.67224571e-02 1.87321484e-02\n",
            " 2.24378164e-02 2.06541870e-02 1.38846927e-02 2.14278813e-02\n",
            " 1.93269137e-02 1.17223876e-02 1.15956177e-02 1.76769637e-02\n",
            " 1.11425920e-03 7.58771308e-03 1.95468077e-02 3.12015878e-03\n",
            " 2.20791402e-02 1.66297466e-02 4.13455683e-04 1.72448328e-02\n",
            " 1.17937774e-03 1.51783072e-02 8.60859897e-03 3.48335162e-03\n",
            " 1.04917106e-02 1.84776388e-02 1.85877243e-02 1.90785999e-02\n",
            " 1.43777868e-02 9.88864541e-03 1.28488273e-02 4.29493522e-04\n",
            " 1.44236958e-02 7.69082216e-03 5.55958365e-03 2.23121500e-02\n",
            " 5.24919224e-03 2.17594430e-02 2.03647335e-02 1.94176086e-02\n",
            " 1.19724929e-02 5.29023686e-04 2.18831965e-02 1.14896663e-02\n",
            " 1.05025370e-02 4.39333073e-03 4.53320087e-03 1.24147065e-03\n",
            " 1.64657041e-02 6.01698788e-03 1.13245037e-02 1.91894085e-02\n",
            " 6.31800703e-04 1.10137364e-03 1.06434107e-02 2.06203115e-02\n",
            " 5.68482019e-03 7.21435855e-05 3.83822582e-03 1.33587409e-02\n",
            " 2.16857259e-02 1.83928623e-02 1.00397374e-02 1.12008414e-02\n",
            " 1.13749405e-02 2.02370240e-02 1.90669302e-03 7.93455649e-03\n",
            " 1.96523406e-02 8.89918736e-03 7.38277253e-04 1.52508125e-02\n",
            " 2.16762579e-03 1.51294442e-02 1.11197288e-02 1.02613198e-02\n",
            " 2.01148364e-02 1.48330674e-02 8.04566718e-03 2.21073674e-02\n",
            " 1.76156218e-02 9.60549615e-03 2.21311509e-02 1.89944951e-02\n",
            " 5.28502990e-03 1.32562917e-02 3.74720559e-03 7.75471308e-05\n",
            " 1.67301496e-02 9.37861038e-03 1.41371484e-02 4.41604298e-03\n",
            " 1.50949707e-02 1.90039025e-02 1.68290984e-02 3.74720559e-03\n",
            " 1.23154952e-02 1.24459568e-02 9.29227440e-03 1.49709679e-02\n",
            " 6.99336574e-03 1.03400117e-03 1.29112283e-02 1.55155016e-02\n",
            " 1.95764446e-02 9.80694735e-03 7.70297585e-03 1.22723818e-02\n",
            " 1.58182516e-03 1.83479699e-02 1.70772331e-02 1.31650617e-02\n",
            " 5.07573341e-05 1.75073565e-02 9.31475990e-03 1.50523341e-02\n",
            " 1.63641312e-02 4.78632323e-03 3.30111449e-03 1.06938144e-02\n",
            " 7.33504383e-03 1.72448328e-02 9.48572247e-03 4.90261698e-03\n",
            " 9.39588321e-03 1.09990669e-02 9.93349711e-03 1.03555950e-02\n",
            " 6.97298528e-09 4.10329814e-03 9.36711842e-03 1.55503864e-02\n",
            " 8.80535635e-03 2.17695764e-02 1.18211763e-03 1.34341529e-02\n",
            " 1.35990774e-02 4.33414236e-03 1.50124392e-02 8.45403332e-03\n",
            " 1.94329483e-03 1.97364624e-02 8.03761098e-03 1.49072046e-02\n",
            " 2.21357777e-03 1.92825143e-02 7.72203741e-03 4.20216297e-03\n",
            " 1.21592505e-02 1.65800941e-02 8.95358754e-03 5.88360533e-03\n",
            " 2.04967776e-02 5.78603823e-03 2.06234266e-02 1.86559219e-02\n",
            " 6.76910615e-03 3.05845678e-03 8.68503760e-03 1.34528005e-02\n",
            " 1.33354962e-02 1.00491102e-02 5.42597859e-03 1.10497209e-02\n",
            " 2.18333675e-02 4.39333073e-03 1.12486552e-02 9.86168039e-03\n",
            " 8.01621355e-03 1.27966733e-02 9.51862113e-03 5.79411414e-03\n",
            " 1.13744334e-02 8.16836840e-03 1.25087587e-02 1.89205174e-02\n",
            " 2.57351827e-03 1.39311981e-02 1.74892830e-04 4.30332931e-03\n",
            " 1.68697179e-02 1.99111590e-02 1.10386409e-02 1.86026294e-02\n",
            " 1.15959256e-02 4.21316795e-03 1.04660698e-02 3.45311625e-03\n",
            " 1.46793305e-02 1.87390306e-02 6.32409949e-03 7.80695547e-03\n",
            " 1.98832015e-02 1.05184319e-02 1.90382056e-02 5.62086653e-04\n",
            " 3.34786375e-03 1.17217804e-02 1.63641312e-02 1.56382214e-02\n",
            " 6.21875828e-03 1.36218829e-02 1.51863717e-06 1.18247795e-02\n",
            " 1.01287131e-04 8.64021089e-04 3.07622045e-03 1.30237967e-02\n",
            " 6.93235629e-03 2.15811610e-02 3.13726348e-03 9.76088631e-03\n",
            " 5.33220642e-03 1.93635568e-02 4.43065999e-04 2.24335327e-02\n",
            " 2.09102904e-02 1.50329381e-02 5.52943114e-03 2.07124113e-02\n",
            " 5.84501483e-03 1.31520605e-02 1.27047193e-03 2.25642824e-02\n",
            " 1.39189558e-02 1.11222361e-02 9.06894040e-04 1.79748555e-02\n",
            " 4.71592672e-03 1.28896411e-02 7.02342115e-03 8.78811311e-03\n",
            " 5.65041899e-03 1.54452385e-02 6.29368203e-03 1.50184611e-02\n",
            " 4.75239881e-03 2.10485717e-02 1.92825143e-02 5.88421862e-03\n",
            " 1.83715265e-02 5.59680720e-03 3.54570362e-03 8.04504264e-03\n",
            " 4.39333073e-03 1.67485767e-02 1.03978746e-02 1.79221328e-02\n",
            " 8.25401896e-03 3.85455499e-03 1.77410417e-02 1.30819670e-03\n",
            " 1.60484606e-03 2.04937000e-02 1.71261660e-02 9.49242125e-03\n",
            " 4.34071394e-03 1.05055089e-02 1.23493998e-02 2.07758238e-02\n",
            " 1.64740902e-03 5.45500087e-03 9.49014236e-03 1.76984658e-02\n",
            " 1.03092368e-04 8.37432267e-03 1.76885839e-02 5.31707588e-16\n",
            " 3.22942632e-03 1.63333477e-02 1.53939728e-02 6.28579534e-03\n",
            " 1.32331250e-02 1.96514311e-02 1.10832428e-02 1.88483801e-02\n",
            " 1.46096352e-02 1.17674561e-02 1.72250839e-02 2.62459725e-04\n",
            " 8.41891740e-03 1.96328721e-02 1.06760695e-02 1.62823390e-02\n",
            " 1.04660698e-02 7.58771308e-03 2.98784782e-03 4.22377070e-03\n",
            " 3.29569048e-03 1.22723818e-02 2.18355176e-03 1.67440193e-02\n",
            " 3.94567762e-03 1.28347541e-02 7.14023799e-03 7.56277329e-03\n",
            " 1.77355842e-03 2.74368219e-04 7.32959093e-03 1.34076831e-02\n",
            " 4.99075565e-03 6.97351240e-03 1.27430332e-02 4.36569708e-03\n",
            " 4.40317289e-04 1.47278895e-02 8.90043934e-03 1.89666694e-02\n",
            " 2.10495385e-03 4.57756872e-03 3.64111649e-03 7.29349591e-03\n",
            " 8.05772791e-03 1.91740689e-04 4.68541871e-03 1.54978014e-02\n",
            " 3.76254025e-03 8.61503654e-03 1.47713046e-02 4.95036937e-03\n",
            " 3.37716657e-03 9.50652098e-03 9.58029319e-03 6.97039690e-03\n",
            " 1.42302914e-02 1.73251669e-02 4.98152727e-03 9.71740495e-03\n",
            " 5.65141461e-03 1.00001967e-02 2.05795857e-02 1.47438041e-02\n",
            " 5.08337453e-03 1.03316324e-02 2.15123647e-04 9.65963972e-03\n",
            " 1.22023944e-02 2.08700416e-02 1.79458526e-03 8.61850508e-03\n",
            " 1.03953776e-02 8.25137983e-03 1.95980329e-02 7.19323646e-03\n",
            " 3.83822582e-03 1.42184469e-03 1.97123109e-02 1.26812394e-02\n",
            " 3.18932854e-03 2.02790215e-03 1.58249517e-02 1.49955181e-02\n",
            " 1.45996401e-02 1.31869358e-03 5.01837129e-03 1.99909702e-02\n",
            " 1.61085422e-02 1.98832015e-02 1.87926347e-03 1.84384101e-02\n",
            " 5.79411414e-03 4.10767478e-03 1.67318019e-02 1.35760249e-02\n",
            " 1.62617510e-03 1.20185120e-02 7.81964019e-03 3.23509474e-03\n",
            " 3.19635305e-03 6.63693374e-03 2.31616905e-03 1.50781435e-02\n",
            " 1.88343746e-02 5.39084156e-06 2.23666536e-02 2.21770007e-02\n",
            " 1.26987913e-02 8.91298548e-04 1.54759874e-02 3.94809745e-03\n",
            " 1.30210115e-03 1.12786017e-02 1.07493957e-02 1.18924585e-05\n",
            " 1.10470343e-02 1.13793248e-02 1.50719896e-02 2.43295014e-03\n",
            " 1.88711587e-04 9.22467089e-03 1.42302914e-02 3.92977037e-03\n",
            " 3.23023559e-03 9.47901170e-03 1.88279432e-03 7.99119641e-04\n",
            " 2.24359305e-03 1.50538950e-02 6.73462935e-04 2.09022329e-02\n",
            " 2.16330019e-03 1.15150042e-03 1.98832015e-02 1.59909417e-02\n",
            " 3.84510799e-03 1.57969200e-02 1.46533375e-02 1.13292985e-02\n",
            " 8.01088735e-03 5.70355519e-05 1.39157442e-02 6.24557828e-04\n",
            " 1.14553918e-02 9.50683966e-04 1.26118754e-02 1.08499180e-02\n",
            " 1.90382056e-02 1.30606144e-02 1.04916972e-02 1.29807720e-02\n",
            " 1.41642940e-02 1.43466068e-02 9.88864541e-03 9.80489602e-03\n",
            " 5.55141310e-03 1.97774231e-02 1.86198874e-02 8.66690894e-03\n",
            " 8.95798829e-03 8.34721157e-03 1.01443372e-02 1.88279432e-03\n",
            " 1.58769631e-02 2.10605840e-02 1.98897478e-02 1.17974358e-02\n",
            " 1.09523511e-02 1.77202980e-02 2.26950358e-03 1.24355168e-02\n",
            " 3.40517270e-03 2.17385885e-02 1.01412255e-02 2.23272684e-02\n",
            " 1.77571033e-02 5.01805011e-03 1.96694911e-02 1.09211322e-02\n",
            " 1.95873652e-03 1.32818389e-02 4.22755130e-03 1.21702514e-02\n",
            " 1.70316872e-02 1.61983690e-02 7.90224192e-03 2.06175408e-02\n",
            " 1.27620657e-02 1.29713309e-02 4.68992492e-03 9.42944415e-03\n",
            " 5.74216649e-04 3.05557989e-03 9.62817680e-03 3.99995492e-03\n",
            " 1.80194733e-02 8.16621367e-03 1.76361750e-02 8.20409107e-03\n",
            " 2.15123647e-04 4.82648756e-03 1.82744953e-02 1.12962423e-02\n",
            " 3.02357873e-03 1.52779027e-02 2.22430413e-02 4.08601608e-03\n",
            " 1.73424927e-02 1.06568670e-02 8.32472068e-03 2.00831161e-02\n",
            " 4.62480930e-03 6.49553536e-04 1.47616795e-03 1.32694368e-02\n",
            " 2.21465444e-02 1.20491977e-03 1.90672957e-02 1.63931624e-02\n",
            " 7.57381188e-03 5.19335856e-03 1.65547620e-02 7.09528830e-04\n",
            " 4.77336045e-03 1.45697680e-02 1.94722440e-02 1.93819213e-02\n",
            " 1.21130435e-02 3.33823435e-04 7.82783572e-03 1.88279432e-03\n",
            " 7.84985242e-03 2.18879287e-02 1.42500548e-02 1.16029809e-02\n",
            " 1.33786117e-02 5.78423665e-03 7.63638389e-03 8.70971144e-03\n",
            " 1.14904618e-02 1.51490909e-02 2.05170221e-02 1.05092446e-02\n",
            " 2.32291216e-03 1.33396620e-02 3.75616708e-03 2.00280565e-02\n",
            " 1.21954188e-03 7.63965680e-03 2.16517750e-02 1.93906055e-02\n",
            " 8.46315690e-03 9.08050233e-03 2.57665960e-04 1.15724582e-02\n",
            " 3.83822582e-03 1.68698697e-02 6.20636271e-03 3.94809745e-03\n",
            " 9.49380432e-03 1.88225029e-02 4.09075899e-04 2.75996881e-03\n",
            " 1.51397943e-02 2.08282738e-02 1.61865229e-02 2.00829510e-02\n",
            " 5.37556245e-04 8.47535895e-03 9.62073262e-03 2.03921184e-03\n",
            " 4.82283271e-03 1.59073696e-03 1.01590299e-02 1.90176451e-02\n",
            " 1.76595344e-02 1.56959730e-02 1.22079419e-02 1.04272219e-02\n",
            " 1.47152890e-02 7.06752063e-03 9.99179434e-03 1.07601822e-02\n",
            " 1.36843906e-04 7.21083973e-03 2.34582944e-03 2.06770109e-02\n",
            " 3.35979210e-03 1.43782081e-02 1.73251669e-02 3.23306455e-03\n",
            " 4.78632323e-03 8.78693046e-03 1.88599855e-02 1.23841924e-02\n",
            " 4.41604298e-03 1.70357016e-02 6.52656562e-03 2.75708271e-03\n",
            " 1.90385681e-02 1.11839210e-02 9.90618736e-03 1.99416482e-03\n",
            " 6.08823520e-04 1.95454527e-02 2.80626313e-03 1.40509815e-02\n",
            " 1.43441131e-02 1.69810746e-02 1.77410417e-02 1.92105604e-02\n",
            " 4.34646440e-03 1.02933824e-02 1.46793305e-02 1.43930299e-02\n",
            " 1.88580607e-02 7.94835164e-03 2.03451568e-02 4.05156348e-03\n",
            " 2.10804344e-02 1.62300745e-02 6.51614724e-04 1.69360971e-02\n",
            " 1.73475610e-02 3.52057028e-03 6.56678265e-03 5.46519683e-03\n",
            " 8.21256880e-03 5.02253558e-03 1.63641312e-02 1.66366148e-02\n",
            " 1.65235459e-02 2.05042170e-02 3.45525606e-04 2.77439613e-03\n",
            " 3.10293071e-03 8.19553212e-03 1.36396913e-02 1.45614105e-02\n",
            " 8.50503322e-03 2.26950358e-03 1.43943600e-02 1.72065935e-02\n",
            " 1.41947427e-03 1.15229588e-02 1.58631462e-02 2.48026857e-03\n",
            " 2.17078161e-02 6.12814774e-03 1.09609950e-02 1.41947504e-02\n",
            " 1.16579880e-02 4.04239705e-03 1.44014097e-02 1.97311302e-02\n",
            " 1.16326183e-02 5.50816912e-03 8.95830025e-04 1.07091425e-02\n",
            " 6.86636781e-03 4.34716214e-03 1.55300705e-02 5.16602069e-03\n",
            " 3.89065263e-03 2.19480328e-02 7.27894992e-03 5.20959020e-03\n",
            " 4.68261137e-03 2.87313149e-03 6.62476496e-03 1.87041490e-02\n",
            " 1.82129250e-02 1.07875814e-02 1.15628800e-03 6.77191371e-04\n",
            " 6.06539679e-03 1.36392395e-02 1.04438084e-03 2.12809347e-04\n",
            " 1.15775995e-02 9.90279960e-03 1.11046741e-02 1.34957732e-03\n",
            " 1.94055448e-02 1.64314359e-02 1.47897025e-03 2.14093502e-03\n",
            " 2.90117455e-03 8.22678352e-05 1.52559421e-02 3.89863516e-03\n",
            " 2.09022329e-02 1.83243887e-02 5.49907574e-03 5.36330913e-03\n",
            " 2.42796920e-06 1.24316558e-02 6.92598470e-04 5.77896260e-07\n",
            " 1.98463139e-02 1.11765773e-02 2.01498515e-02 1.96937831e-02\n",
            " 2.40011682e-05 1.74674732e-02 4.00894238e-05 2.21893742e-02\n",
            " 1.37434578e-02 1.70642589e-02 1.06065063e-02 1.12655084e-02\n",
            " 1.57182101e-03 8.76026431e-04 1.16585477e-02 2.21054435e-02\n",
            " 1.65842070e-02 4.61045839e-03 2.18288116e-02 1.69480214e-02\n",
            " 1.58892659e-02 3.90060434e-03 1.45049128e-02 5.05935788e-03\n",
            " 1.09381665e-02 5.05935788e-03 7.58577183e-03 1.96364945e-02\n",
            " 1.87848409e-02 1.04683395e-03 7.41321136e-03 1.95308808e-03\n",
            " 1.80888694e-02 4.14512304e-03 3.35895457e-04 1.54998115e-02\n",
            " 4.09361523e-04 1.07999487e-02 1.43961381e-02 3.19435582e-03\n",
            " 1.41402155e-02 5.06353937e-03 1.82816468e-02 2.05038226e-02\n",
            " 2.07794493e-02 4.40170682e-03 2.58959830e-04 5.31439090e-03\n",
            " 6.32246261e-03 1.84316196e-02 6.63836340e-03 1.32865137e-02\n",
            " 1.61546142e-02 5.71530296e-03 1.71418474e-02 4.67950514e-03\n",
            " 4.95036937e-03 7.40881287e-03 1.94176086e-02 1.19369020e-02\n",
            " 3.10969276e-03 1.34686524e-02 1.52461470e-02 1.75244275e-02\n",
            " 1.12295471e-02 1.49222910e-02 2.02464425e-02 5.69308362e-03\n",
            " 1.73582730e-02 5.95119266e-03 1.30519292e-02 1.92849215e-02\n",
            " 2.13388670e-02 1.85601731e-02 1.95554626e-02 2.23045764e-02\n",
            " 4.95870460e-03 3.90060434e-03 1.36393371e-02 2.02747362e-02\n",
            " 1.42406762e-02 8.09994360e-03 1.09273282e-02 1.47144440e-03\n",
            " 1.28690410e-03 3.87757154e-03 1.60766827e-02 5.40552983e-03\n",
            " 2.02818031e-02 4.08705878e-03 7.47436236e-04 1.74889993e-02\n",
            " 9.36430248e-03 1.11046252e-02 8.59795085e-03 5.73632638e-03\n",
            " 2.44703186e-03 7.89147476e-04 9.57594084e-03 1.93784023e-02\n",
            " 7.30185566e-03 7.72141883e-03 9.14985618e-03 1.98348105e-02\n",
            " 1.15476896e-02 1.00010314e-02 3.03420880e-03 1.57210294e-03\n",
            " 1.34037147e-03 2.04065948e-02 1.46910798e-02 6.56636964e-03\n",
            " 1.00160474e-02 1.10248284e-02 7.48509798e-03 1.77791083e-02\n",
            " 8.84995638e-03 1.38000317e-02 4.34513751e-03 2.17060421e-02\n",
            " 1.40807835e-02 8.19811586e-03 3.91493191e-03 9.26899200e-03\n",
            " 2.24402592e-02 1.36391725e-02 1.85770400e-02 1.88888047e-02\n",
            " 1.96282045e-02 1.32597983e-02 3.30701713e-03 1.53815134e-02\n",
            " 1.36379588e-02 3.37506794e-03 9.19370658e-03 5.00943916e-04\n",
            " 9.41169264e-04 9.04210273e-03 1.43782081e-02 8.64776787e-03\n",
            " 2.78341841e-03 9.88864541e-03 6.16675537e-03 8.41862319e-03\n",
            " 2.14776926e-02 1.68962374e-02 4.21135259e-04 5.71574032e-03\n",
            " 1.46406127e-02 7.69652259e-03 3.85627995e-03 1.06663346e-02\n",
            " 7.01811537e-03 3.61167663e-03 7.95990446e-03 1.54567318e-02\n",
            " 9.65250907e-03 1.00426564e-02 7.44536921e-03 1.76311829e-02\n",
            " 4.88472641e-03 5.81639416e-03 6.90063715e-03 8.91298548e-04\n",
            " 4.12714763e-03]\n",
            "3280 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.98094940e-03 4.49851049e-03 1.71814534e-02 2.21261618e-02\n",
            " 1.73223100e-02 4.78604276e-03 4.22974309e-03 1.94114908e-02\n",
            " 1.53076648e-02 7.08659128e-04 1.28417354e-02 9.73129620e-03\n",
            " 4.17013838e-03 6.80755661e-03 1.29062808e-02 8.66520725e-03\n",
            " 1.61347473e-02 1.85854743e-02 1.19241699e-02 2.04231329e-02\n",
            " 2.03559446e-02 8.50994804e-03 2.12203562e-02 1.05486055e-02\n",
            " 1.09765125e-02 1.22304315e-02 6.66488385e-03 1.47295181e-02\n",
            " 5.99141135e-03 1.87933567e-02 7.64750561e-03 5.64761319e-03\n",
            " 8.55215050e-03 1.51392744e-03 9.88387410e-03 5.07532492e-03\n",
            " 5.60952556e-03 1.87933567e-02 3.89552675e-03 1.51718327e-05\n",
            " 6.04819996e-03 1.30495989e-02 1.43594385e-02 1.54534920e-02\n",
            " 2.97519680e-03 1.11466734e-02 1.39297174e-02 2.05032834e-02\n",
            " 1.83050662e-02 1.12029406e-04 9.94114670e-03 1.30495989e-02\n",
            " 1.32319650e-02 2.04914923e-03 6.76724898e-09 3.05575909e-03\n",
            " 2.18634815e-05 6.76293821e-03 1.28869320e-02 8.86001170e-03\n",
            " 4.73144424e-04 2.22323044e-07 1.17684002e-02 8.05984971e-03\n",
            " 7.51254009e-03 2.89762434e-03 7.80142631e-03 1.09860129e-02\n",
            " 9.90183178e-03 1.75721347e-02 5.72101811e-03 9.27745292e-03\n",
            " 2.24935237e-03 1.18884578e-02 1.88901567e-02 1.42920072e-02\n",
            " 9.60288964e-03 1.66739116e-02 1.87168246e-02 2.06157349e-02\n",
            " 1.38128795e-02 2.13561569e-02 1.93004185e-02 1.16853445e-02\n",
            " 1.15460943e-02 1.76314466e-02 1.11586164e-03 7.59304648e-03\n",
            " 1.94814380e-02 3.11814272e-03 2.20455077e-02 1.66386664e-02\n",
            " 4.09065102e-04 1.72344249e-02 1.17187539e-03 1.51281322e-02\n",
            " 8.56727104e-03 3.45456440e-03 1.04501968e-02 1.84021225e-02\n",
            " 1.85412304e-02 1.90530479e-02 1.43863042e-02 9.90183178e-03\n",
            " 1.28348178e-02 4.28675515e-04 1.43790092e-02 7.66028602e-03\n",
            " 5.52321652e-03 5.23720129e-03 2.16076256e-02 2.03019521e-02\n",
            " 1.94114908e-02 1.19374093e-02 5.25922065e-04 2.18342495e-02\n",
            " 1.14784628e-02 1.04803371e-02 4.37786560e-03 4.53087943e-03\n",
            " 1.23028513e-03 1.64695194e-02 5.98868824e-03 1.12497545e-02\n",
            " 1.91695980e-02 6.28763298e-04 1.09760492e-03 1.06033358e-02\n",
            " 2.05279552e-02 5.65691272e-03 7.21231384e-05 3.83301159e-03\n",
            " 1.33156983e-02 2.16807209e-02 1.83491462e-02 9.98263112e-03\n",
            " 1.11392291e-02 1.13791747e-02 2.01825113e-02 1.90682163e-03\n",
            " 7.93172233e-03 1.95550862e-02 8.86942557e-03 7.35641730e-04\n",
            " 1.52467242e-02 2.15960433e-03 1.51094774e-02 1.10982461e-02\n",
            " 1.02349635e-02 2.00419089e-02 1.48387952e-02 8.01312293e-03\n",
            " 2.20185582e-02 1.75979346e-02 9.57657737e-03 2.20277199e-02\n",
            " 1.89302862e-02 5.27506032e-03 1.32319650e-02 3.73402028e-03\n",
            " 7.68154107e-05 1.66915798e-02 9.38581627e-03 1.41222689e-02\n",
            " 4.40205660e-03 1.50919597e-02 1.90038331e-02 1.68224250e-02\n",
            " 3.73402028e-03 1.23137308e-02 1.24029236e-02 9.30061443e-03\n",
            " 1.48995031e-02 6.94877579e-03 1.03258555e-03 1.29017310e-02\n",
            " 1.54564386e-02 1.95936879e-02 9.80006092e-03 7.67381799e-03\n",
            " 1.22312947e-02 1.57240025e-03 1.83188847e-02 1.70890055e-02\n",
            " 1.31810538e-02 5.07811826e-05 1.74927131e-02 9.32241776e-03\n",
            " 1.50378959e-02 1.63937555e-02 4.77243512e-03 3.30083834e-03\n",
            " 1.06660835e-02 7.31417580e-03 1.72344249e-02 9.47412847e-03\n",
            " 4.89542609e-03 9.37569443e-03 1.09351755e-02 9.92538816e-03\n",
            " 1.03249288e-02 6.76724898e-09 4.10092902e-03 9.34560133e-03\n",
            " 1.55483875e-02 8.79731700e-03 2.17124786e-02 1.17498083e-03\n",
            " 1.34197403e-02 1.35509488e-02 4.32201027e-03 1.49950127e-02\n",
            " 8.35701945e-03 1.92963899e-03 1.96911358e-02 8.00069265e-03\n",
            " 1.48712416e-02 2.19961639e-03 1.91412354e-02 7.70709377e-03\n",
            " 4.19546927e-03 1.21361664e-02 1.65653827e-02 8.97351440e-03\n",
            " 5.87669685e-03 2.04788730e-02 5.78337226e-03 2.05257430e-02\n",
            " 1.86170774e-02 6.77033429e-03 3.05919464e-03 8.66520725e-03\n",
            " 1.34436656e-02 1.32844090e-02 9.99447375e-03 5.42609385e-03\n",
            " 1.10591583e-02 2.17688118e-02 4.37786560e-03 1.11466734e-02\n",
            " 9.86688886e-03 8.03483013e-03 1.27720714e-02 9.53218521e-03\n",
            " 5.79446986e-03 1.13488377e-02 8.15869832e-03 1.24257566e-02\n",
            " 1.88404170e-02 2.55842368e-03 1.39159627e-02 1.74010711e-04\n",
            " 4.28579254e-03 1.68622552e-02 1.98548628e-02 1.10378332e-02\n",
            " 1.85703697e-02 1.15854405e-02 4.19832407e-03 1.04480317e-02\n",
            " 3.44937407e-03 1.46175592e-02 1.86842911e-02 6.29233036e-03\n",
            " 7.77811098e-03 1.98824844e-02 1.05108422e-02 1.90297645e-02\n",
            " 5.59763716e-04 3.33598512e-03 1.16884373e-02 1.63937555e-02\n",
            " 1.56476930e-02 6.21967914e-03 1.36089877e-02 1.49188590e-06\n",
            " 1.18206933e-02 1.00974751e-04 8.56979055e-04 3.05834102e-03\n",
            " 1.29534613e-02 6.88280498e-03 2.15496133e-02 3.11770212e-03\n",
            " 9.75399238e-03 5.34961495e-03 1.93160382e-02 4.42385552e-04\n",
            " 2.08851435e-02 1.50409740e-02 5.50957077e-03 2.07145377e-02\n",
            " 5.80935804e-03 1.31401881e-02 1.27786229e-03 1.38943033e-02\n",
            " 1.10829368e-02 9.05078949e-04 1.79607799e-02 4.70777959e-03\n",
            " 1.28417354e-02 7.00028137e-03 8.72834206e-03 5.64067165e-03\n",
            " 1.53991122e-02 6.28364302e-03 1.50093777e-02 4.74904544e-03\n",
            " 2.10592433e-02 1.91412354e-02 5.86488844e-03 1.83724787e-02\n",
            " 5.57903910e-03 3.52508853e-03 8.01762407e-03 4.37786560e-03\n",
            " 1.67056313e-02 1.03776943e-02 1.79071658e-02 8.21074136e-03\n",
            " 3.83908891e-03 1.76811145e-02 1.30113802e-03 1.58613118e-03\n",
            " 2.04880598e-02 1.70806646e-02 9.46836662e-03 4.30053246e-03\n",
            " 1.04877965e-02 1.23678421e-02 2.07676151e-02 1.64285775e-03\n",
            " 5.44944975e-03 9.44271207e-03 1.76431836e-02 1.03299232e-04\n",
            " 8.37307581e-03 1.76032005e-02 5.31197912e-16 3.22316965e-03\n",
            " 1.63253420e-02 1.53787879e-02 6.26892888e-03 1.32051204e-02\n",
            " 1.96463885e-02 1.10112381e-02 1.88483055e-02 1.45996369e-02\n",
            " 1.17553391e-02 1.71822031e-02 2.61406008e-04 8.39259025e-03\n",
            " 1.96255693e-02 1.06736126e-02 1.62178788e-02 1.04480317e-02\n",
            " 7.59304648e-03 2.97381743e-03 4.20105059e-03 3.29017651e-03\n",
            " 1.22312947e-02 2.18108924e-03 1.66940541e-02 3.90112949e-03\n",
            " 1.28156621e-02 7.08369107e-03 7.54120755e-03 1.75415628e-03\n",
            " 2.73968841e-04 7.29495782e-03 1.34046497e-02 4.95067098e-03\n",
            " 6.96237632e-03 1.27108257e-02 4.36439476e-03 4.38881746e-04\n",
            " 1.46818674e-02 8.88942851e-03 1.89799901e-02 2.09768947e-03\n",
            " 4.58413287e-03 3.63018801e-03 7.26867519e-03 8.03818780e-03\n",
            " 1.90474067e-04 4.66653983e-03 1.54971270e-02 3.75260690e-03\n",
            " 8.61672130e-03 1.47099045e-02 4.94660711e-03 3.37617968e-03\n",
            " 9.47467048e-03 9.44083699e-03 6.96106872e-03 1.42456975e-02\n",
            " 1.72888527e-02 4.96088977e-03 9.68888081e-03 5.64761319e-03\n",
            " 1.00054225e-02 2.05950964e-02 1.46976797e-02 5.07254722e-03\n",
            " 1.03125571e-02 2.12870961e-04 9.57055224e-03 1.21622322e-02\n",
            " 2.07872704e-02 1.78414231e-03 8.60981009e-03 1.02997618e-02\n",
            " 8.22933662e-03 1.95843076e-02 7.17233056e-03 3.83301159e-03\n",
            " 1.41438911e-03 1.97633621e-02 1.26728743e-02 3.14678688e-03\n",
            " 2.02615704e-03 1.58049308e-02 1.49519469e-02 1.45838926e-02\n",
            " 1.31933989e-03 4.98599406e-03 1.99540439e-02 1.60699751e-02\n",
            " 1.98824844e-02 1.87617935e-03 1.83836802e-02 5.79446986e-03\n",
            " 4.09509104e-03 1.67078293e-02 1.35030806e-02 1.62469981e-03\n",
            " 1.20341548e-02 7.77297104e-03 3.23859990e-03 3.19110543e-03\n",
            " 6.62156434e-03 2.31938967e-03 1.50255528e-02 1.87981683e-02\n",
            " 5.33250542e-06 2.21914483e-02 1.26242226e-02 8.85982844e-04\n",
            " 1.54162721e-02 3.94467403e-03 1.29856562e-03 1.12288772e-02\n",
            " 1.07206691e-02 1.18358237e-05 1.10301089e-02 1.14179347e-02\n",
            " 1.50445399e-02 2.43833360e-03 1.88490960e-04 9.21040369e-03\n",
            " 1.42456975e-02 3.91335234e-03 3.22464580e-03 9.44403321e-03\n",
            " 1.87707676e-03 7.91938561e-04 2.23841140e-03 1.50217357e-02\n",
            " 6.72569300e-04 2.08393178e-02 2.16121232e-03 1.14790835e-03\n",
            " 1.98824844e-02 1.59798511e-02 3.83834055e-03 1.58063387e-02\n",
            " 1.46290297e-02 1.13011754e-02 8.00379141e-03 5.67978399e-05\n",
            " 1.38570509e-02 6.17311452e-04 1.14476288e-02 9.50174568e-04\n",
            " 1.25508692e-02 1.07797709e-02 1.90297645e-02 1.30110260e-02\n",
            " 1.04382580e-02 1.29496540e-02 1.41495011e-02 1.43556312e-02\n",
            " 9.90183178e-03 9.79291283e-03 5.54327125e-03 1.98031231e-02\n",
            " 1.86756704e-02 8.65818654e-03 8.94812642e-03 8.31687107e-03\n",
            " 1.01279069e-02 1.87707676e-03 1.58674924e-02 2.09909801e-02\n",
            " 1.98810560e-02 1.17270300e-02 1.09281013e-02 1.76650059e-02\n",
            " 2.25475811e-03 1.23884181e-02 3.38751413e-03 2.17251507e-02\n",
            " 1.01666053e-02 1.77630063e-02 5.01817195e-03 1.95864042e-02\n",
            " 1.08467314e-02 1.95544372e-03 1.32652139e-02 4.20327355e-03\n",
            " 1.21696349e-02 1.69814946e-02 1.62026678e-02 7.88898894e-03\n",
            " 2.05870964e-02 1.27654549e-02 1.29798177e-02 4.68807931e-03\n",
            " 9.39848242e-03 5.70015717e-04 3.05546976e-03 9.64316178e-03\n",
            " 3.97885235e-03 1.79291214e-02 8.06545658e-03 1.76351955e-02\n",
            " 8.18636211e-03 2.12870961e-04 4.80539954e-03 1.81943547e-02\n",
            " 1.12505880e-02 3.02775619e-03 1.51637761e-02 4.06803413e-03\n",
            " 1.72868698e-02 1.06063347e-02 8.31711440e-03 2.01109471e-02\n",
            " 4.59091510e-03 6.41193567e-04 1.47331190e-03 1.32666715e-02\n",
            " 2.21002086e-02 1.20308936e-03 1.90657879e-02 1.63443463e-02\n",
            " 7.55478924e-03 5.17178356e-03 1.65206991e-02 7.08659128e-04\n",
            " 4.74366224e-03 1.45761062e-02 1.94427490e-02 1.93773233e-02\n",
            " 1.21364809e-02 3.30858514e-04 7.78902222e-03 1.87707676e-03\n",
            " 7.84205794e-03 2.17538937e-02 1.41887658e-02 1.15138594e-02\n",
            " 1.32738790e-02 5.77197756e-03 7.62528135e-03 8.65300370e-03\n",
            " 1.14727436e-02 1.50999222e-02 2.05032834e-02 1.05112730e-02\n",
            " 2.31904277e-03 1.32840379e-02 3.74959138e-03 2.00414812e-02\n",
            " 1.21636421e-03 7.63795727e-03 2.16391704e-02 1.92773289e-02\n",
            " 8.46428535e-03 9.04643166e-03 2.57082252e-04 1.15019891e-02\n",
            " 3.83301159e-03 1.68878493e-02 6.20779447e-03 3.94467403e-03\n",
            " 9.50584263e-03 1.87347433e-02 4.09560832e-04 2.75294656e-03\n",
            " 1.51030419e-02 2.08535563e-02 1.61574631e-02 2.00755079e-02\n",
            " 5.36882223e-04 8.44996003e-03 9.60024020e-03 2.03899546e-03\n",
            " 4.82580484e-03 1.59224138e-03 1.01572419e-02 1.89722585e-02\n",
            " 1.76273906e-02 1.56674342e-02 1.21671613e-02 1.03791989e-02\n",
            " 1.46837575e-02 7.05876227e-03 9.98211040e-03 1.07564668e-02\n",
            " 1.36685109e-04 7.18128809e-03 2.33378965e-03 2.06891304e-02\n",
            " 3.34906766e-03 1.43603183e-02 1.72888527e-02 3.21726852e-03\n",
            " 4.77243512e-03 8.76258250e-03 1.87812726e-02 1.22876323e-02\n",
            " 4.40205660e-03 1.69899390e-02 6.50674961e-03 2.74784436e-03\n",
            " 1.89787906e-02 1.12008073e-02 9.87610102e-03 1.98961880e-03\n",
            " 6.08784195e-04 1.94549093e-02 2.79820911e-03 1.40313646e-02\n",
            " 1.43728823e-02 1.69759098e-02 1.76811145e-02 1.92307618e-02\n",
            " 4.33294983e-03 1.02916034e-02 1.46175592e-02 1.43480669e-02\n",
            " 1.88633892e-02 7.94152040e-03 2.02723161e-02 4.04985221e-03\n",
            " 2.10726067e-02 1.62021148e-02 6.50265233e-04 1.68963255e-02\n",
            " 1.73043499e-02 3.50285680e-03 6.51041705e-03 5.46940725e-03\n",
            " 8.14866159e-03 5.00061817e-03 1.63937555e-02 1.66381375e-02\n",
            " 1.64942006e-02 2.04362616e-02 3.43092244e-04 2.75482545e-03\n",
            " 3.08915527e-03 8.18372275e-03 1.35434510e-02 1.45338133e-02\n",
            " 8.48839587e-03 2.25475811e-03 1.43509231e-02 1.72163190e-02\n",
            " 1.41914406e-03 1.14385470e-02 1.58538047e-02 2.47566591e-03\n",
            " 2.16627389e-02 6.11742866e-03 1.09540465e-02 1.41421248e-02\n",
            " 1.16820359e-02 4.04287483e-03 1.43207039e-02 1.97378254e-02\n",
            " 1.16021753e-02 5.47450779e-03 8.91215299e-04 1.06788546e-02\n",
            " 6.85385533e-03 4.33764137e-03 1.55033855e-02 5.15984779e-03\n",
            " 3.86658225e-03 2.18538198e-02 7.25991030e-03 5.19632184e-03\n",
            " 4.64942045e-03 2.87194494e-03 6.58220663e-03 1.86758079e-02\n",
            " 1.81708946e-02 1.07373374e-02 1.14317148e-03 6.75080785e-04\n",
            " 6.04819996e-03 1.36146986e-02 1.04219595e-03 2.12094839e-04\n",
            " 1.15387098e-02 9.84202969e-03 1.11145032e-02 1.33475549e-03\n",
            " 1.94291086e-02 1.64199131e-02 1.47921353e-03 2.13601937e-03\n",
            " 2.89762434e-03 8.21654129e-05 1.51559155e-02 3.87431844e-03\n",
            " 2.08393178e-02 1.83052732e-02 5.48722401e-03 5.36403160e-03\n",
            " 2.41123491e-06 1.24667104e-02 6.87882790e-04 5.79246330e-07\n",
            " 1.98018684e-02 1.11256157e-02 2.01569656e-02 1.95541951e-02\n",
            " 2.39335363e-05 1.74090800e-02 3.99284090e-05 2.21759528e-02\n",
            " 1.37204967e-02 1.70408263e-02 1.05934691e-02 1.12399707e-02\n",
            " 1.56913714e-03 8.74251035e-04 1.16264969e-02 2.21016707e-02\n",
            " 1.65198896e-02 4.61016315e-03 2.17909591e-02 1.69503834e-02\n",
            " 1.58473528e-02 3.89552675e-03 1.45000326e-02 5.06074482e-03\n",
            " 1.09116254e-02 5.06074482e-03 7.54885000e-03 1.95591147e-02\n",
            " 1.86910169e-02 1.04314077e-03 7.39544690e-03 1.94787831e-03\n",
            " 1.79986153e-02 4.12743147e-03 3.36029451e-04 1.54937404e-02\n",
            " 4.07320780e-04 1.08059183e-02 1.43811827e-02 3.19158672e-03\n",
            " 1.41380565e-02 5.04443133e-03 1.82649723e-02 2.04811158e-02\n",
            " 2.05429206e-02 4.38132515e-03 2.56562308e-04 5.32695545e-03\n",
            " 6.30867621e-03 1.84473542e-02 6.65388125e-03 1.32692915e-02\n",
            " 1.60992862e-02 5.68394524e-03 1.71372578e-02 4.66910524e-03\n",
            " 4.94660711e-03 7.41352915e-03 1.94114908e-02 1.19165296e-02\n",
            " 3.11095173e-03 1.33950925e-02 1.52543337e-02 1.74827941e-02\n",
            " 1.12121554e-02 1.48961436e-02 2.01998972e-02 5.66462812e-03\n",
            " 1.73447931e-02 5.92335981e-03 1.30131806e-02 1.92463558e-02\n",
            " 2.13237972e-02 1.85310776e-02 1.95566275e-02 4.93517090e-03\n",
            " 3.89552675e-03 1.35892918e-02 2.02147067e-02 1.42018901e-02\n",
            " 8.05923010e-03 1.08710129e-02 1.46335463e-03 1.28118951e-03\n",
            " 3.86471855e-03 1.60104447e-02 5.39103737e-03 2.02642582e-02\n",
            " 4.07342499e-03 7.47992918e-04 1.75245665e-02 9.36241168e-03\n",
            " 1.10735189e-02 8.58550361e-03 5.70504618e-03 2.44453592e-03\n",
            " 7.85646268e-04 9.56697489e-03 1.93778730e-02 7.26555587e-03\n",
            " 7.71669864e-03 9.14337104e-03 1.98213628e-02 1.15692843e-02\n",
            " 9.94591862e-03 3.02981304e-03 1.56644103e-03 1.33674263e-03\n",
            " 2.04106946e-02 1.46463139e-02 6.50747572e-03 1.00047164e-02\n",
            " 1.09928645e-02 7.48074869e-03 1.77735463e-02 8.78885376e-03\n",
            " 1.37481739e-02 4.32773893e-03 2.16902052e-02 1.40352478e-02\n",
            " 8.17698703e-03 3.89451734e-03 9.26439452e-03 1.36381674e-02\n",
            " 1.85854743e-02 1.88853383e-02 1.95902481e-02 1.32186180e-02\n",
            " 3.28513020e-03 1.53402925e-02 1.35335011e-02 3.37638839e-03\n",
            " 9.17645864e-03 4.98520846e-04 9.39270633e-04 9.03785568e-03\n",
            " 1.43603183e-02 8.60094899e-03 2.78381553e-03 9.90183178e-03\n",
            " 6.16525686e-03 8.41881199e-03 2.14570365e-02 1.68326430e-02\n",
            " 4.20022134e-04 5.73189827e-03 1.46012592e-02 7.66516476e-03\n",
            " 3.85651737e-03 1.06593536e-02 7.03489684e-03 3.60403298e-03\n",
            " 7.94884060e-03 1.54534920e-02 9.59861376e-03 9.95403736e-03\n",
            " 7.40768833e-03 1.75800143e-02 4.87358798e-03 5.80154445e-03\n",
            " 6.88365731e-03 8.85982844e-04 4.11600576e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3290 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.95763693e-03 4.47309145e-03 1.71499600e-02 1.72101084e-02\n",
            " 4.78325241e-03 4.21655178e-03 1.94114074e-02 1.52962179e-02\n",
            " 7.07271971e-04 1.28177429e-02 9.71714611e-03 4.17237900e-03\n",
            " 6.79906166e-03 1.28620916e-02 8.65996018e-03 1.60610255e-02\n",
            " 1.85050063e-02 1.19107836e-02 2.03611443e-02 2.02181324e-02\n",
            " 8.50562963e-03 2.11803659e-02 1.05513014e-02 1.09689593e-02\n",
            " 1.22087307e-02 6.65625764e-03 1.46883634e-02 5.95851282e-03\n",
            " 1.87689746e-02 7.63852022e-03 5.64116887e-03 8.52762175e-03\n",
            " 1.50945879e-03 9.87421688e-03 5.08557303e-03 5.60450654e-03\n",
            " 1.87689746e-02 3.89239812e-03 1.50066804e-05 6.05178064e-03\n",
            " 1.30441218e-02 1.43530494e-02 1.54467051e-02 2.94098532e-03\n",
            " 1.10951098e-02 1.38189930e-02 2.04355484e-02 1.83083420e-02\n",
            " 1.10939997e-04 9.90790846e-03 1.30441218e-02 1.31068728e-02\n",
            " 2.04630859e-03 6.56999329e-09 3.04791474e-03 2.19012432e-05\n",
            " 6.73640075e-03 1.28682468e-02 8.83958150e-03 4.68974026e-04\n",
            " 2.17290249e-07 1.17075292e-02 8.04141284e-03 7.50444926e-03\n",
            " 2.89513110e-03 7.80150508e-03 1.09957541e-02 9.90077626e-03\n",
            " 1.75771030e-02 5.65823876e-03 9.22131246e-03 2.24378579e-03\n",
            " 1.18655571e-02 1.88594152e-02 1.42851181e-02 9.60577269e-03\n",
            " 1.66115326e-02 1.87298851e-02 2.06239659e-02 1.37715071e-02\n",
            " 2.13091670e-02 1.92851092e-02 1.15692539e-02 1.14642356e-02\n",
            " 1.76267125e-02 1.10759269e-03 7.58362201e-03 1.94779127e-02\n",
            " 3.12084226e-03 1.66304737e-02 4.04285998e-04 1.72286769e-02\n",
            " 1.16071411e-03 1.51050340e-02 8.49353217e-03 3.43533767e-03\n",
            " 1.04278340e-02 1.83719290e-02 1.85049938e-02 1.90298909e-02\n",
            " 1.43853538e-02 9.90077626e-03 1.28276862e-02 4.28139049e-04\n",
            " 1.43696094e-02 7.65820888e-03 5.50642269e-03 5.22727336e-03\n",
            " 2.15502510e-02 2.02176478e-02 1.94114074e-02 1.19399968e-02\n",
            " 5.20607873e-04 1.14679115e-02 1.04564792e-02 4.36696472e-03\n",
            " 4.53120307e-03 1.22383583e-03 1.64586967e-02 5.95808963e-03\n",
            " 1.12044164e-02 1.91212919e-02 6.25688764e-04 1.09121258e-03\n",
            " 1.06015594e-02 2.04989697e-02 5.61815640e-03 7.14026593e-05\n",
            " 3.82675966e-03 1.33230097e-02 2.16057434e-02 1.83239361e-02\n",
            " 9.93139981e-03 1.11091239e-02 1.13773353e-02 2.01498176e-02\n",
            " 1.90238791e-03 7.91605222e-03 1.93410575e-02 8.84603061e-03\n",
            " 7.36479829e-04 1.52276709e-02 2.15252343e-03 1.51005159e-02\n",
            " 1.10996413e-02 1.02178513e-02 2.00059149e-02 1.48178628e-02\n",
            " 8.00532441e-03 1.75449894e-02 9.56964637e-03 1.88759885e-02\n",
            " 5.25784087e-03 1.31068728e-02 3.72473228e-03 7.61882853e-05\n",
            " 1.66906373e-02 9.35612612e-03 1.41254061e-02 4.39417417e-03\n",
            " 1.50760666e-02 1.90020800e-02 1.68130438e-02 3.72473228e-03\n",
            " 1.23459642e-02 1.23779372e-02 9.25941288e-03 1.48631230e-02\n",
            " 6.93451503e-03 1.03144370e-03 1.29069008e-02 1.53911950e-02\n",
            " 1.95705585e-02 9.77259798e-03 7.64795716e-03 1.21815668e-02\n",
            " 1.56804624e-03 1.82523389e-02 1.70491016e-02 1.31522987e-02\n",
            " 5.07921995e-05 1.75009201e-02 9.28626738e-03 1.50269678e-02\n",
            " 1.64136865e-02 4.76882244e-03 3.29078081e-03 1.06397729e-02\n",
            " 7.29970281e-03 1.72286769e-02 9.45312598e-03 4.89368416e-03\n",
            " 9.31344557e-03 1.09092397e-02 9.91030117e-03 1.02786602e-02\n",
            " 6.56999329e-09 4.10270134e-03 9.29461970e-03 1.54588481e-02\n",
            " 8.79113408e-03 2.17161433e-02 1.16523150e-03 1.33074412e-02\n",
            " 1.35638717e-02 4.30703789e-03 1.49954354e-02 8.30805455e-03\n",
            " 1.90666540e-03 1.96353849e-02 7.99330412e-03 1.48636617e-02\n",
            " 2.19874208e-03 1.90821120e-02 7.69392652e-03 4.18990273e-03\n",
            " 1.21261477e-02 1.65480987e-02 8.96829799e-03 5.86982125e-03\n",
            " 2.04830737e-02 5.78699855e-03 2.04787831e-02 1.85844189e-02\n",
            " 6.76963842e-03 3.05904691e-03 8.65996018e-03 1.33986846e-02\n",
            " 1.32868998e-02 9.91283509e-03 5.37947814e-03 1.10558744e-02\n",
            " 2.17631253e-02 4.36696472e-03 1.10951098e-02 9.87206917e-03\n",
            " 7.99911432e-03 1.27534871e-02 9.54757882e-03 5.78995246e-03\n",
            " 1.13299556e-02 8.12758571e-03 1.24062144e-02 1.87805943e-02\n",
            " 2.53744178e-03 1.38828746e-02 1.72900709e-04 4.27555212e-03\n",
            " 1.68663165e-02 1.98478476e-02 1.10295597e-02 1.84733689e-02\n",
            " 1.15984816e-02 4.18245643e-03 1.04244354e-02 3.44648524e-03\n",
            " 1.45924189e-02 1.85646948e-02 6.25167611e-03 7.73538343e-03\n",
            " 1.98858495e-02 1.04815444e-02 1.90141804e-02 5.57021133e-04\n",
            " 3.33191922e-03 1.16691422e-02 1.64136865e-02 1.55211314e-02\n",
            " 6.21177643e-03 1.35737922e-02 1.48523097e-06 1.18014827e-02\n",
            " 1.00889191e-04 8.46188687e-04 3.04219533e-03 1.29436793e-02\n",
            " 6.88496404e-03 2.15352596e-02 3.11290690e-03 9.73911515e-03\n",
            " 5.34364450e-03 1.92882593e-02 4.42021435e-04 2.08848694e-02\n",
            " 1.49861854e-02 5.48771845e-03 2.07055821e-02 5.79585356e-03\n",
            " 1.31001362e-02 1.27283029e-03 1.38703707e-02 1.10114852e-02\n",
            " 9.01308558e-04 1.79363369e-02 4.70454691e-03 1.28177429e-02\n",
            " 6.98130905e-03 8.70908369e-03 5.66215750e-03 1.53408176e-02\n",
            " 6.26254893e-03 1.49509918e-02 4.73369830e-03 2.10798604e-02\n",
            " 1.90821120e-02 5.85387547e-03 1.83790095e-02 5.55671165e-03\n",
            " 3.49042529e-03 7.95920151e-03 4.36696472e-03 1.66338414e-02\n",
            " 1.03634058e-02 1.79063468e-02 8.19863407e-03 3.81186368e-03\n",
            " 1.76452963e-02 1.29679578e-03 1.57527455e-03 2.04674330e-02\n",
            " 1.70237313e-02 9.44516447e-03 4.28307149e-03 1.04666272e-02\n",
            " 1.22772903e-02 2.07541311e-02 1.63276809e-03 5.44539480e-03\n",
            " 9.44030195e-03 1.75658764e-02 1.03349500e-04 8.35413146e-03\n",
            " 1.76021201e-02 5.32850652e-16 3.22380640e-03 1.62949601e-02\n",
            " 1.53661432e-02 6.26112649e-03 1.31917854e-02 1.96277669e-02\n",
            " 1.10035147e-02 1.88205646e-02 1.45528977e-02 1.17390931e-02\n",
            " 1.71933717e-02 2.59867094e-04 8.39121536e-03 1.96078411e-02\n",
            " 1.06598081e-02 1.61788802e-02 1.04244354e-02 7.58362201e-03\n",
            " 2.96505470e-03 4.17474954e-03 3.29245506e-03 1.21815668e-02\n",
            " 2.17460913e-03 1.66837628e-02 3.87237189e-03 1.27699831e-02\n",
            " 7.01949739e-03 7.53618547e-03 1.73779486e-03 2.71243382e-04\n",
            " 7.28158139e-03 1.34090092e-02 4.91737217e-03 6.93117002e-03\n",
            " 1.27236282e-02 4.36642068e-03 4.36443107e-04 1.45728856e-02\n",
            " 8.88699497e-03 1.89296191e-02 2.09373063e-03 4.57474977e-03\n",
            " 3.62127187e-03 7.24382954e-03 8.03443652e-03 1.89352844e-04\n",
            " 4.63859942e-03 1.54813550e-02 3.73137829e-03 8.60061724e-03\n",
            " 1.47067096e-02 4.93955166e-03 3.37549544e-03 9.43992676e-03\n",
            " 9.39678243e-03 6.95826071e-03 1.42392650e-02 1.72242541e-02\n",
            " 4.95816910e-03 9.69004342e-03 5.64116887e-03 9.99039620e-03\n",
            " 2.05453928e-02 1.46998031e-02 5.05748998e-03 1.02893071e-02\n",
            " 2.11247493e-04 9.55707211e-03 1.21499043e-02 2.07484603e-02\n",
            " 1.77609291e-03 8.51631268e-03 1.02708055e-02 8.23781901e-03\n",
            " 1.95562807e-02 7.16989666e-03 3.82675966e-03 1.41060343e-03\n",
            " 1.97622206e-02 1.25984417e-02 3.12149831e-03 2.02696411e-03\n",
            " 1.58058417e-02 1.49305196e-02 1.45732876e-02 1.31933152e-03\n",
            " 4.97237158e-03 1.99355243e-02 1.60924706e-02 1.98858495e-02\n",
            " 1.87177396e-03 1.83204604e-02 5.78995246e-03 4.08397712e-03\n",
            " 1.67091712e-02 1.34964829e-02 1.62438639e-03 1.19646118e-02\n",
            " 7.76184927e-03 3.21865180e-03 3.18872520e-03 6.57582024e-03\n",
            " 2.31280100e-03 1.50037900e-02 1.86119769e-02 5.30713280e-06\n",
            " 1.26053255e-02 8.77859390e-04 1.53838082e-02 3.93859348e-03\n",
            " 1.29828135e-03 1.12119974e-02 1.07079317e-02 1.17389372e-05\n",
            " 1.10039624e-02 1.14007046e-02 1.50417531e-02 2.43876675e-03\n",
            " 1.88181111e-04 9.21110084e-03 1.42392650e-02 3.90437393e-03\n",
            " 3.20300611e-03 9.42040105e-03 1.87327384e-03 7.90378653e-04\n",
            " 2.22180298e-03 1.50006670e-02 6.68947548e-04 2.07477031e-02\n",
            " 2.16576388e-03 1.14462258e-03 1.98858495e-02 1.59386402e-02\n",
            " 3.81549902e-03 1.57900505e-02 1.44701686e-02 1.12754922e-02\n",
            " 7.99878823e-03 5.67191936e-05 1.38399984e-02 6.15449373e-04\n",
            " 1.14519894e-02 9.45322732e-04 1.24488927e-02 1.07038318e-02\n",
            " 1.90141804e-02 1.29768397e-02 1.04136654e-02 1.29372062e-02\n",
            " 1.41211155e-02 1.43181236e-02 9.90077626e-03 9.75810263e-03\n",
            " 5.53864490e-03 1.97849218e-02 1.86410197e-02 8.65585057e-03\n",
            " 8.94779432e-03 8.20273907e-03 1.00984436e-02 1.87327384e-03\n",
            " 1.58185677e-02 2.09449926e-02 1.98325053e-02 1.16804567e-02\n",
            " 1.08957494e-02 1.76111866e-02 2.24929070e-03 1.23395662e-02\n",
            " 3.37580379e-03 2.17095513e-02 1.01385921e-02 1.77415939e-02\n",
            " 5.01501579e-03 1.95563039e-02 1.08397304e-02 1.95013826e-03\n",
            " 1.32557099e-02 4.19627407e-03 1.21633634e-02 1.69620528e-02\n",
            " 1.61474058e-02 7.87727549e-03 2.05765450e-02 1.27650770e-02\n",
            " 1.29112006e-02 4.68622210e-03 9.38906753e-03 5.69404589e-04\n",
            " 3.04887683e-03 9.62924591e-03 3.95948759e-03 1.78468442e-02\n",
            " 8.01543858e-03 1.76261240e-02 8.16058401e-03 2.11247493e-04\n",
            " 4.80594565e-03 1.81355278e-02 1.12276563e-02 3.03145792e-03\n",
            " 1.51246559e-02 4.01547766e-03 1.72782198e-02 1.05816954e-02\n",
            " 8.31803164e-03 2.00962681e-02 4.55840511e-03 6.35967270e-04\n",
            " 1.47018217e-03 1.32343779e-02 1.20093249e-03 1.90085464e-02\n",
            " 1.63379461e-02 7.54147807e-03 5.16391266e-03 1.64649200e-02\n",
            " 7.07271971e-04 4.73605093e-03 1.45478403e-02 1.94175877e-02\n",
            " 1.93806972e-02 1.21517768e-02 3.29006990e-04 7.77036550e-03\n",
            " 1.87327384e-03 7.83432938e-03 2.17266332e-02 1.41841786e-02\n",
            " 1.14879573e-02 1.32199867e-02 5.78177627e-03 7.53212548e-03\n",
            " 8.61598602e-03 1.13621730e-02 1.50868675e-02 2.04355484e-02\n",
            " 1.05074353e-02 2.30446229e-03 1.31921024e-02 3.73230903e-03\n",
            " 1.99996370e-02 1.21020896e-03 7.63243859e-03 2.16034008e-02\n",
            " 1.91262941e-02 8.45990530e-03 9.00067997e-03 2.56452991e-04\n",
            " 1.15120623e-02 3.82675966e-03 1.68590043e-02 6.18725775e-03\n",
            " 3.93859348e-03 9.48457215e-03 1.86832132e-02 4.09044533e-04\n",
            " 2.74412444e-03 1.50343873e-02 2.08402377e-02 1.61304296e-02\n",
            " 2.00835642e-02 5.33388833e-04 8.40017781e-03 9.55686131e-03\n",
            " 2.03527032e-03 4.80486827e-03 1.58393626e-03 1.01031878e-02\n",
            " 1.89792092e-02 1.76251478e-02 1.56522572e-02 1.21368137e-02\n",
            " 1.03272338e-02 1.45802425e-02 7.05493650e-03 9.94495616e-03\n",
            " 1.07460698e-02 1.36463266e-04 7.15564340e-03 2.33520001e-03\n",
            " 2.06661274e-02 3.35235788e-03 1.43489936e-02 1.72242541e-02\n",
            " 3.21024718e-03 4.76882244e-03 8.68429572e-03 1.87197239e-02\n",
            " 1.22644579e-02 4.39417417e-03 1.69603842e-02 6.50407170e-03\n",
            " 2.75115301e-03 1.89394953e-02 1.11947685e-02 9.85575850e-03\n",
            " 1.98543992e-03 6.08598245e-04 1.93808205e-02 2.79097420e-03\n",
            " 1.40170058e-02 1.43644975e-02 1.68756532e-02 1.76452963e-02\n",
            " 1.92023256e-02 4.32839858e-03 1.02921417e-02 1.45924189e-02\n",
            " 1.43052622e-02 1.88146112e-02 7.92710759e-03 2.02590268e-02\n",
            " 4.04238890e-03 2.10585845e-02 1.61815713e-02 6.48152607e-04\n",
            " 1.68319742e-02 1.72904901e-02 3.48389472e-03 6.50812520e-03\n",
            " 5.46211256e-03 8.13143600e-03 5.00153397e-03 1.64136865e-02\n",
            " 1.65833849e-02 1.64899565e-02 2.03998556e-02 3.39379520e-04\n",
            " 2.74982933e-03 3.03412377e-03 8.09054797e-03 1.34801880e-02\n",
            " 1.45274572e-02 8.47712572e-03 2.24929070e-03 1.43446826e-02\n",
            " 1.71600093e-02 1.41587723e-03 1.13862144e-02 1.58600565e-02\n",
            " 2.46993229e-03 2.15899535e-02 6.09100642e-03 1.09070337e-02\n",
            " 1.41042580e-02 1.16132873e-02 4.04648190e-03 1.42502332e-02\n",
            " 1.97224019e-02 1.15772513e-02 5.46135315e-03 8.89010708e-04\n",
            " 1.06771155e-02 6.85272241e-03 4.33854297e-03 1.54199257e-02\n",
            " 5.12526603e-03 3.84233185e-03 7.18606851e-03 5.18643662e-03\n",
            " 4.57205044e-03 2.86726285e-03 6.55131209e-03 1.87097113e-02\n",
            " 1.81758111e-02 1.07153439e-02 1.12765731e-03 6.73659440e-04\n",
            " 6.05178064e-03 1.35953895e-02 1.04161596e-03 2.10430363e-04\n",
            " 1.14722273e-02 9.81533631e-03 1.10525967e-02 1.32127260e-03\n",
            " 1.93674226e-02 1.64171777e-02 1.47666685e-03 2.13434826e-03\n",
            " 2.89513110e-03 8.18362620e-05 1.51432931e-02 3.85472243e-03\n",
            " 2.07477031e-02 1.82841640e-02 5.47987645e-03 5.37234809e-03\n",
            " 2.40156327e-06 1.24515695e-02 6.85269946e-04 5.81705013e-07\n",
            " 1.97632656e-02 1.11264282e-02 2.01491123e-02 1.95505822e-02\n",
            " 2.38755627e-05 1.74083299e-02 3.98973743e-05 1.37030429e-02\n",
            " 1.70222220e-02 1.05857049e-02 1.12238956e-02 1.56783118e-03\n",
            " 8.72557261e-04 1.15510347e-02 1.64859171e-02 4.58656288e-03\n",
            " 2.17736452e-02 1.69124323e-02 1.58400726e-02 3.89239812e-03\n",
            " 1.44922375e-02 5.06282287e-03 1.08735258e-02 5.06282287e-03\n",
            " 7.54775480e-03 1.95533579e-02 1.86691163e-02 1.04155674e-03\n",
            " 7.38847091e-03 1.93404605e-03 1.79937414e-02 4.12242748e-03\n",
            " 3.36076808e-04 1.54841930e-02 4.06092099e-04 1.07815681e-02\n",
            " 1.43710773e-02 3.18140128e-03 1.40905319e-02 5.02185316e-03\n",
            " 1.82577158e-02 2.03583894e-02 2.05130260e-02 4.35062726e-03\n",
            " 2.54805377e-04 5.31857735e-03 6.29756012e-03 1.84233711e-02\n",
            " 6.64776834e-03 1.32494523e-02 1.59923642e-02 5.65255678e-03\n",
            " 1.71109270e-02 4.66489054e-03 4.93955166e-03 7.42095541e-03\n",
            " 1.94114074e-02 1.19145065e-02 3.11027959e-03 1.33347801e-02\n",
            " 1.52259031e-02 1.74247488e-02 1.11989852e-02 1.48844754e-02\n",
            " 2.02225262e-02 5.65677071e-03 1.73390075e-02 5.92265425e-03\n",
            " 1.29698371e-02 1.92429067e-02 2.13082136e-02 1.85063128e-02\n",
            " 1.95466027e-02 4.90925546e-03 3.89239812e-03 1.35767402e-02\n",
            " 2.02228009e-02 1.41928271e-02 8.02367320e-03 1.08765702e-02\n",
            " 1.45254952e-03 1.27632582e-03 3.86685893e-03 1.59677173e-02\n",
            " 5.38575661e-03 2.02655016e-02 4.07214047e-03 7.45217451e-04\n",
            " 1.74714629e-02 9.34780905e-03 1.10727378e-02 8.50720095e-03\n",
            " 5.69904530e-03 2.43663663e-03 7.87097598e-04 9.54833729e-03\n",
            " 1.93150505e-02 7.26668298e-03 7.68593478e-03 9.13690161e-03\n",
            " 1.98003568e-02 1.15349971e-02 9.92897667e-03 3.02724861e-03\n",
            " 1.55775093e-03 1.32852006e-03 2.03808613e-02 1.46327913e-02\n",
            " 6.45317308e-03 9.96961823e-03 1.09538986e-02 7.46669530e-03\n",
            " 1.77446810e-02 8.78234162e-03 1.36949438e-02 4.29566046e-03\n",
            " 2.16169832e-02 1.39831297e-02 8.16385263e-03 3.88388503e-03\n",
            " 9.25895670e-03 1.36258621e-02 1.85050063e-02 1.88773280e-02\n",
            " 1.95710277e-02 1.32054810e-02 3.27258027e-03 1.53249322e-02\n",
            " 1.35070918e-02 3.37600002e-03 9.11588596e-03 4.93150910e-04\n",
            " 9.37412672e-04 9.02299972e-03 1.43489936e-02 8.52057979e-03\n",
            " 2.77223929e-03 9.90077626e-03 6.15671706e-03 8.40069902e-03\n",
            " 2.13782372e-02 1.68297696e-02 4.17203378e-04 5.71528670e-03\n",
            " 1.45974957e-02 7.64475170e-03 3.85027956e-03 1.06476540e-02\n",
            " 6.99615552e-03 3.60302548e-03 7.93843522e-03 1.54467051e-02\n",
            " 9.57573137e-03 9.91459822e-03 7.39047926e-03 1.75181459e-02\n",
            " 4.86809399e-03 5.77422240e-03 6.79490482e-03 8.77859390e-04\n",
            " 4.10455476e-03]\n",
            "3300 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.94433635e-03 4.46408111e-03 1.71270355e-02 1.71802119e-02\n",
            " 4.77765937e-03 4.19357555e-03 1.93933259e-02 1.52831041e-02\n",
            " 7.07320331e-04 1.27811048e-02 9.70482694e-03 4.16015260e-03\n",
            " 6.78668632e-03 1.28334555e-02 8.64294984e-03 1.60458002e-02\n",
            " 1.85459438e-02 1.18665356e-02 2.03051903e-02 2.01559279e-02\n",
            " 8.45494352e-03 2.11673337e-02 1.05099773e-02 1.09721091e-02\n",
            " 1.22033430e-02 6.64460912e-03 1.46662885e-02 5.92280108e-03\n",
            " 1.87214716e-02 7.60354337e-03 5.61600737e-03 8.46832867e-03\n",
            " 1.50476362e-03 9.82501599e-03 5.08324799e-03 5.59179905e-03\n",
            " 1.87214716e-02 3.89052460e-03 1.48528190e-05 6.03459481e-03\n",
            " 1.30430068e-02 1.43208188e-02 1.54389064e-02 2.92842238e-03\n",
            " 1.10743492e-02 1.37785344e-02 2.02740795e-02 1.82702469e-02\n",
            " 1.10209457e-04 9.85077852e-03 1.30430068e-02 1.30899217e-02\n",
            " 2.03455265e-03 6.42675400e-09 3.04626602e-03 2.15042922e-05\n",
            " 6.68600953e-03 1.28513410e-02 8.83668824e-03 4.66208478e-04\n",
            " 2.14012959e-07 1.16462695e-02 8.01911349e-03 7.41418843e-03\n",
            " 2.89110553e-03 7.78069063e-03 1.09286176e-02 9.87913100e-03\n",
            " 1.75143224e-02 5.65910313e-03 9.17872593e-03 2.24055526e-03\n",
            " 1.18497486e-02 1.88286595e-02 1.42555588e-02 9.61029266e-03\n",
            " 1.66053025e-02 1.87035709e-02 2.05802522e-02 1.37309398e-02\n",
            " 2.12723366e-02 1.92795106e-02 1.15631892e-02 1.14526707e-02\n",
            " 1.75795660e-02 1.09591843e-03 7.57685826e-03 1.94234716e-02\n",
            " 3.11446235e-03 1.66361591e-02 4.00976281e-04 1.72207475e-02\n",
            " 1.16092783e-03 1.50202777e-02 8.46956832e-03 3.42063756e-03\n",
            " 1.03892852e-02 1.83472393e-02 1.84594614e-02 1.89883300e-02\n",
            " 1.43864981e-02 9.87913100e-03 1.28089987e-02 4.26683686e-04\n",
            " 1.43033750e-02 7.62870165e-03 5.50492968e-03 5.20686779e-03\n",
            " 2.01338646e-02 1.93933259e-02 1.19595251e-02 5.17776002e-04\n",
            " 1.14446492e-02 1.04386781e-02 4.34813881e-03 4.51194484e-03\n",
            " 1.21689054e-03 1.64103562e-02 5.96474608e-03 1.12052728e-02\n",
            " 1.90452670e-02 6.22958403e-04 1.08738024e-03 1.05753112e-02\n",
            " 2.04605684e-02 5.61109217e-03 7.07327583e-05 3.82168898e-03\n",
            " 1.33006599e-02 1.83548978e-02 9.93205979e-03 1.10829232e-02\n",
            " 1.13316454e-02 2.01323342e-02 1.89665337e-03 7.91295151e-03\n",
            " 1.93186019e-02 8.83549477e-03 7.31923630e-04 1.51969506e-02\n",
            " 2.15027119e-03 1.50966688e-02 1.10690700e-02 1.01909905e-02\n",
            " 1.99614558e-02 1.47883337e-02 8.00475287e-03 1.75679996e-02\n",
            " 9.53655526e-03 1.88439338e-02 5.23777229e-03 1.30899217e-02\n",
            " 3.70872911e-03 7.55779318e-05 1.66471444e-02 9.34526023e-03\n",
            " 1.40606720e-02 4.37540216e-03 1.50542520e-02 1.89380939e-02\n",
            " 1.67946969e-02 3.70872911e-03 1.23004564e-02 1.23209112e-02\n",
            " 9.24941411e-03 1.48293600e-02 6.91653220e-03 1.02951348e-03\n",
            " 1.28601814e-02 1.53773831e-02 1.95319687e-02 9.76147365e-03\n",
            " 7.64513795e-03 1.21585964e-02 1.56138692e-03 1.82086573e-02\n",
            " 1.69462092e-02 1.31511139e-02 5.01670761e-05 1.74842996e-02\n",
            " 9.24153206e-03 1.50272613e-02 1.64372968e-02 4.76047507e-03\n",
            " 3.27754988e-03 1.05862155e-02 7.27943893e-03 1.72207475e-02\n",
            " 9.40854318e-03 4.87164888e-03 9.29929346e-03 1.08822779e-02\n",
            " 9.91602868e-03 1.02677315e-02 6.42675400e-09 4.10082296e-03\n",
            " 9.29378293e-03 1.54100560e-02 8.80253500e-03 1.15708947e-03\n",
            " 1.32507610e-02 1.35099573e-02 4.30280734e-03 1.49449555e-02\n",
            " 8.29299841e-03 1.89899746e-03 1.96231317e-02 7.96874364e-03\n",
            " 1.48735418e-02 2.18990627e-03 1.90613881e-02 7.67732724e-03\n",
            " 4.18525502e-03 1.19345059e-02 1.65205488e-02 8.95032598e-03\n",
            " 5.85582897e-03 2.04493856e-02 5.75201030e-03 2.04114448e-02\n",
            " 1.85424681e-02 6.76544745e-03 3.05007614e-03 8.64294984e-03\n",
            " 1.33526371e-02 1.32553747e-02 9.89030659e-03 5.38507716e-03\n",
            " 1.10107335e-02 4.34813881e-03 1.10743492e-02 9.85765288e-03\n",
            " 7.99859803e-03 1.27112590e-02 9.49416576e-03 5.79301862e-03\n",
            " 1.13490358e-02 8.09516172e-03 1.23892928e-02 1.87271207e-02\n",
            " 2.53825452e-03 1.38445003e-02 1.72169703e-04 4.26194659e-03\n",
            " 1.68262938e-02 1.97914148e-02 1.10129150e-02 1.84504096e-02\n",
            " 1.15493826e-02 4.17931274e-03 1.03927990e-02 3.44120456e-03\n",
            " 1.45394022e-02 1.85683860e-02 6.24418390e-03 7.72999385e-03\n",
            " 1.98863840e-02 1.05023530e-02 1.89900855e-02 5.55003309e-04\n",
            " 3.31618751e-03 1.16240223e-02 1.64372968e-02 1.54799855e-02\n",
            " 6.19384726e-03 1.35279231e-02 1.47392438e-06 1.17948959e-02\n",
            " 1.00285162e-04 8.46560113e-04 3.03062304e-03 1.29379380e-02\n",
            " 6.87643618e-03 2.14748166e-02 3.10083896e-03 9.73750334e-03\n",
            " 5.34406952e-03 1.92973188e-02 4.41334042e-04 2.08470272e-02\n",
            " 1.49752645e-02 5.44126666e-03 2.07116181e-02 5.78053854e-03\n",
            " 1.30980856e-02 1.26428528e-03 1.38465115e-02 1.09886368e-02\n",
            " 8.97301464e-04 1.79335153e-02 4.68511502e-03 1.27811048e-02\n",
            " 6.95695234e-03 8.63973996e-03 5.66171835e-03 1.52989213e-02\n",
            " 6.24386298e-03 1.49022288e-02 4.70312534e-03 2.11071059e-02\n",
            " 1.90613881e-02 5.83122290e-03 1.83327019e-02 5.53389547e-03\n",
            " 3.47809945e-03 7.96237339e-03 4.34813881e-03 1.65931241e-02\n",
            " 1.03146608e-02 1.79167369e-02 8.18328273e-03 3.79904755e-03\n",
            " 1.76057344e-02 1.28944468e-03 1.57136460e-03 2.04054132e-02\n",
            " 1.69730178e-02 9.40344099e-03 4.27321965e-03 1.04278420e-02\n",
            " 1.22750137e-02 2.07078295e-02 1.63069539e-03 5.42128306e-03\n",
            " 9.45375890e-03 1.75416486e-02 1.03120005e-04 8.33106310e-03\n",
            " 1.75450633e-02 5.10977545e-16 3.20285315e-03 1.62389835e-02\n",
            " 1.53376649e-02 6.24785757e-03 1.31683398e-02 1.96042792e-02\n",
            " 1.09336579e-02 1.87845741e-02 1.45472587e-02 1.17286899e-02\n",
            " 1.71547861e-02 2.58088923e-04 8.35295908e-03 1.95560947e-02\n",
            " 1.06407993e-02 1.61390989e-02 1.03927990e-02 7.57685826e-03\n",
            " 2.96190795e-03 4.16624891e-03 3.28956140e-03 1.21585964e-02\n",
            " 2.17087557e-03 1.66750743e-02 3.85101805e-03 1.27803568e-02\n",
            " 6.99773856e-03 7.51673725e-03 1.73429012e-03 2.71294138e-04\n",
            " 7.27204428e-03 1.33975744e-02 4.88427940e-03 6.90899730e-03\n",
            " 1.26572193e-02 4.34417005e-03 4.36382320e-04 1.45608007e-02\n",
            " 8.86483734e-03 1.89159371e-02 2.09676688e-03 4.55560954e-03\n",
            " 3.61250026e-03 7.21291732e-03 7.99540378e-03 1.87906886e-04\n",
            " 4.61339605e-03 1.54828646e-02 3.71708284e-03 8.59321281e-03\n",
            " 1.46784750e-02 4.91892089e-03 3.36994842e-03 9.40071455e-03\n",
            " 9.31526823e-03 6.93664749e-03 1.42215074e-02 1.71930995e-02\n",
            " 4.94383764e-03 9.62797791e-03 5.61600737e-03 9.97911836e-03\n",
            " 2.04548869e-02 1.46710688e-02 5.05008827e-03 1.02466726e-02\n",
            " 2.09922174e-04 9.54468992e-03 1.21393877e-02 2.06994183e-02\n",
            " 1.76837781e-03 8.51429607e-03 1.02170568e-02 8.21492377e-03\n",
            " 1.94207528e-02 7.14489690e-03 3.82168898e-03 1.40773372e-03\n",
            " 1.97563818e-02 1.25661179e-02 3.10635603e-03 2.02608211e-03\n",
            " 1.58033997e-02 1.49093175e-02 1.44749005e-02 1.31529449e-03\n",
            " 4.96634645e-03 1.98795848e-02 1.60356353e-02 1.98863840e-02\n",
            " 1.85878953e-03 1.82035764e-02 5.79301862e-03 4.06930173e-03\n",
            " 1.66946586e-02 1.35033608e-02 1.61720324e-03 1.19094667e-02\n",
            " 7.77423189e-03 3.20822452e-03 3.17892753e-03 6.55761497e-03\n",
            " 2.30323661e-03 1.48967997e-02 1.85883225e-02 5.23875640e-06\n",
            " 1.25525629e-02 8.73088541e-04 1.53449622e-02 3.92351577e-03\n",
            " 1.29673089e-03 1.11576093e-02 1.05998355e-02 1.16966652e-05\n",
            " 1.09665239e-02 1.13397658e-02 1.50058756e-02 2.43744948e-03\n",
            " 1.87657540e-04 9.20240070e-03 1.42215074e-02 3.88937374e-03\n",
            " 3.19838729e-03 9.39365232e-03 1.86137550e-03 7.87176759e-04\n",
            " 2.20947079e-03 1.49799502e-02 6.64483410e-04 2.06551495e-02\n",
            " 2.15569796e-03 1.14002450e-03 1.98863840e-02 1.59090231e-02\n",
            " 3.80583781e-03 1.57452015e-02 1.44637228e-02 1.12519521e-02\n",
            " 7.98687617e-03 5.64765350e-05 1.37584663e-02 6.11753753e-04\n",
            " 1.14068276e-02 9.39316438e-04 1.24547915e-02 1.06768649e-02\n",
            " 1.89900855e-02 1.29665601e-02 1.04117292e-02 1.29172061e-02\n",
            " 1.40949138e-02 1.42864324e-02 9.87913100e-03 9.72868879e-03\n",
            " 5.53113434e-03 1.97628589e-02 1.86358903e-02 8.62229569e-03\n",
            " 8.94068824e-03 8.20837756e-03 1.00602883e-02 1.86137550e-03\n",
            " 1.57536785e-02 2.08820216e-02 1.97852200e-02 1.16426625e-02\n",
            " 1.08697728e-02 1.75868926e-02 2.23989855e-03 1.22879360e-02\n",
            " 3.36597435e-03 1.01019895e-02 1.76950840e-02 5.01677148e-03\n",
            " 1.95203098e-02 1.08037147e-02 1.94085090e-03 1.32067691e-02\n",
            " 4.19248871e-03 1.21312020e-02 1.69120903e-02 1.61051503e-02\n",
            " 7.86552815e-03 2.05463671e-02 1.27215729e-02 1.28533494e-02\n",
            " 4.67036706e-03 9.38055976e-03 5.69378334e-04 3.03233767e-03\n",
            " 9.61081142e-03 3.92913708e-03 1.78158456e-02 7.95943292e-03\n",
            " 1.76506434e-02 8.13924982e-03 2.09922174e-04 4.81151034e-03\n",
            " 1.80617094e-02 1.12448453e-02 3.01032022e-03 1.50375286e-02\n",
            " 4.01172085e-03 1.72780946e-02 1.05562727e-02 8.29676747e-03\n",
            " 2.00672120e-02 4.54671608e-03 6.29571689e-04 1.46575908e-03\n",
            " 1.32202382e-02 1.19756764e-03 1.89936834e-02 1.62850878e-02\n",
            " 7.50549213e-03 5.15205157e-03 1.63839804e-02 7.07320331e-04\n",
            " 4.68238323e-03 1.45134829e-02 1.93747311e-02 1.93508108e-02\n",
            " 1.20881718e-02 3.26539423e-04 7.73795666e-03 1.86137550e-03\n",
            " 7.80701173e-03 1.41743788e-02 1.14664746e-02 1.31612524e-02\n",
            " 5.75308141e-03 7.51067213e-03 8.60036275e-03 1.13533221e-02\n",
            " 1.50784949e-02 2.02740795e-02 1.04949003e-02 2.29873198e-03\n",
            " 1.31358402e-02 3.72921442e-03 1.99369943e-02 1.20954874e-03\n",
            " 7.63546633e-03 1.90999655e-02 8.41974858e-03 8.98305004e-03\n",
            " 2.55900319e-04 1.14412587e-02 3.82168898e-03 1.68345504e-02\n",
            " 6.16144875e-03 3.92351577e-03 9.44684066e-03 1.86391593e-02\n",
            " 4.08209275e-04 2.72252648e-03 1.50440944e-02 2.08354534e-02\n",
            " 1.61175582e-02 2.00392603e-02 5.32363341e-04 8.39072651e-03\n",
            " 9.51838351e-03 2.03268531e-03 4.79953341e-03 1.58530205e-03\n",
            " 1.00736351e-02 1.89846670e-02 1.75365826e-02 1.55644990e-02\n",
            " 1.20683373e-02 1.02987119e-02 1.45656042e-02 7.04441554e-03\n",
            " 9.92212104e-03 1.07165933e-02 1.36288585e-04 7.13689460e-03\n",
            " 2.31718066e-03 2.05722812e-02 3.34823234e-03 1.43336581e-02\n",
            " 1.71930995e-02 3.20990130e-03 4.76047507e-03 8.68019031e-03\n",
            " 1.86261436e-02 1.22357513e-02 4.37540216e-03 1.69579449e-02\n",
            " 6.48102953e-03 2.74360476e-03 1.89073977e-02 1.11759584e-02\n",
            " 9.82845268e-03 1.97999269e-03 6.04206570e-04 1.93499163e-02\n",
            " 2.78337002e-03 1.39930104e-02 1.43389116e-02 1.68644202e-02\n",
            " 1.76057344e-02 1.91711503e-02 4.31354127e-03 1.02731976e-02\n",
            " 1.45394022e-02 1.42875245e-02 1.87777496e-02 7.91567650e-03\n",
            " 2.02196036e-02 4.03376049e-03 2.10883344e-02 1.61275659e-02\n",
            " 6.42313961e-04 1.67925655e-02 1.72444999e-02 3.46530114e-03\n",
            " 6.48655892e-03 5.46299633e-03 8.08794404e-03 4.98337471e-03\n",
            " 1.64372968e-02 1.65381414e-02 1.64423845e-02 2.03697550e-02\n",
            " 3.37563412e-04 2.73933679e-03 3.03919126e-03 8.08615473e-03\n",
            " 1.34104888e-02 1.45004092e-02 8.43177928e-03 2.23989855e-03\n",
            " 1.42742848e-02 1.71555201e-02 1.41608285e-03 1.13751938e-02\n",
            " 1.58188815e-02 2.46107461e-03 6.08149821e-03 1.08838524e-02\n",
            " 1.40744135e-02 1.16052926e-02 4.04025161e-03 1.42498620e-02\n",
            " 1.97050147e-02 1.15484359e-02 5.43565503e-03 8.85368196e-04\n",
            " 1.06490395e-02 6.85021566e-03 4.32089626e-03 1.53856606e-02\n",
            " 5.10469154e-03 3.84131776e-03 7.16727340e-03 5.19165320e-03\n",
            " 4.56594151e-03 2.86348394e-03 6.52479306e-03 1.86791343e-02\n",
            " 1.81207304e-02 1.07185106e-02 1.12130281e-03 6.71615050e-04\n",
            " 6.03459481e-03 1.35832426e-02 1.03079992e-03 2.10006200e-04\n",
            " 1.14519705e-02 9.79168077e-03 1.10310064e-02 1.31514179e-03\n",
            " 1.92762240e-02 1.63881900e-02 1.47133381e-03 2.12363266e-03\n",
            " 2.89110553e-03 8.13489847e-05 1.51117518e-02 3.85196977e-03\n",
            " 2.06551495e-02 1.82703070e-02 5.47460867e-03 5.35999851e-03\n",
            " 2.38848084e-06 1.24444897e-02 6.79151052e-04 5.80632219e-07\n",
            " 1.97702897e-02 1.11406394e-02 2.01105707e-02 1.95643224e-02\n",
            " 2.37992697e-05 1.73445365e-02 3.98130787e-05 1.36483905e-02\n",
            " 1.69765078e-02 1.05669619e-02 1.11676508e-02 1.56094078e-03\n",
            " 8.70874274e-04 1.15359706e-02 1.64201377e-02 4.58548441e-03\n",
            " 1.68481890e-02 1.58306729e-02 3.89052460e-03 1.44823433e-02\n",
            " 5.04434945e-03 1.08393230e-02 5.04434945e-03 7.53958444e-03\n",
            " 1.95270143e-02 1.85943834e-02 1.03992218e-03 7.37441299e-03\n",
            " 1.92770465e-03 1.79696777e-02 4.10821806e-03 3.32116876e-04\n",
            " 1.54658277e-02 4.03782210e-04 1.07949456e-02 1.43202732e-02\n",
            " 3.16468012e-03 1.40440218e-02 5.01736768e-03 1.82194824e-02\n",
            " 2.03169400e-02 2.05039100e-02 4.35048018e-03 2.53145257e-04\n",
            " 5.30709845e-03 6.29736349e-03 1.83733757e-02 6.64530742e-03\n",
            " 1.32526568e-02 1.59626637e-02 5.64570517e-03 1.70897262e-02\n",
            " 4.65266882e-03 4.91892089e-03 7.41323575e-03 1.93933259e-02\n",
            " 1.18486187e-02 3.10498691e-03 1.33110104e-02 1.52096953e-02\n",
            " 1.74315450e-02 1.11520347e-02 1.46510330e-02 2.01734577e-02\n",
            " 5.63548494e-03 1.73175554e-02 5.92103725e-03 1.29368850e-02\n",
            " 1.92437014e-02 2.12725991e-02 1.84736302e-02 1.95427977e-02\n",
            " 4.89465967e-03 3.89052460e-03 1.35475738e-02 2.01740621e-02\n",
            " 1.41565789e-02 8.01290446e-03 1.08760897e-02 1.44519134e-03\n",
            " 1.27054516e-03 3.84517336e-03 1.59358830e-02 5.38578254e-03\n",
            " 2.01943815e-02 4.05416953e-03 7.38415834e-04 1.74771734e-02\n",
            " 9.31574837e-03 1.10326473e-02 8.48686123e-03 5.66139026e-03\n",
            " 2.41447865e-03 7.77011395e-04 9.50997058e-03 1.92903238e-02\n",
            " 7.19760089e-03 7.68082607e-03 9.09315101e-03 1.96931294e-02\n",
            " 1.15108396e-02 9.89623647e-03 3.00093141e-03 1.55400641e-03\n",
            " 1.32492687e-03 2.03616903e-02 1.45844637e-02 6.41412248e-03\n",
            " 9.96365369e-03 1.09052363e-02 7.44883635e-03 1.77335878e-02\n",
            " 8.74572247e-03 1.36603524e-02 4.27710190e-03 1.39529213e-02\n",
            " 8.14590067e-03 3.86954111e-03 9.23996917e-03 1.36586091e-02\n",
            " 1.85459438e-02 1.88271103e-02 1.95224746e-02 1.31507293e-02\n",
            " 3.24383788e-03 1.52859935e-02 1.35007124e-02 3.36594398e-03\n",
            " 9.07931679e-03 4.92842358e-04 9.35605595e-04 9.02184454e-03\n",
            " 1.43336581e-02 8.50635885e-03 2.76292435e-03 9.87913100e-03\n",
            " 6.15964791e-03 8.38192580e-03 2.13709943e-02 1.67804088e-02\n",
            " 4.15284538e-04 5.71969872e-03 1.45985093e-02 7.62996439e-03\n",
            " 3.83846689e-03 1.06010376e-02 6.98571615e-03 3.60242353e-03\n",
            " 7.94536044e-03 1.54389064e-02 9.53666901e-03 9.87648511e-03\n",
            " 7.39158959e-03 1.74279110e-02 4.85581167e-03 5.76794882e-03\n",
            " 6.78014621e-03 8.73088541e-04 4.07975950e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3310 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.94030053e-03 4.46608431e-03 1.70975224e-02 1.71946899e-02\n",
            " 4.77437109e-03 4.16437641e-03 1.93519228e-02 1.52668371e-02\n",
            " 7.05769151e-04 1.28066499e-02 9.66976997e-03 4.13587655e-03\n",
            " 6.78831424e-03 1.28110247e-02 8.59941190e-03 1.60566336e-02\n",
            " 1.84679782e-02 1.18244903e-02 2.03073564e-02 2.01747697e-02\n",
            " 8.44315053e-03 1.05063876e-02 1.09283315e-02 1.21899637e-02\n",
            " 6.62237069e-03 1.45887225e-02 5.90370759e-03 1.86989777e-02\n",
            " 7.58121927e-03 5.60613768e-03 8.44502812e-03 1.50445044e-03\n",
            " 9.76969263e-03 5.08067699e-03 5.58931994e-03 1.86989777e-02\n",
            " 3.88822911e-03 1.47919191e-05 6.03607760e-03 1.30163715e-02\n",
            " 1.42658136e-02 1.53730937e-02 2.93202829e-03 1.10813216e-02\n",
            " 1.37350417e-02 2.01754521e-02 1.82451131e-02 1.09432943e-04\n",
            " 9.80342002e-03 1.30163715e-02 1.30163351e-02 2.02557889e-03\n",
            " 6.36642674e-09 3.04262847e-03 2.09836612e-05 6.67262966e-03\n",
            " 1.28383130e-02 8.81742048e-03 4.62340651e-04 2.12091162e-07\n",
            " 1.16243727e-02 7.94277378e-03 7.39784451e-03 2.88996634e-03\n",
            " 7.76159507e-03 1.09369013e-02 9.85735288e-03 1.74424181e-02\n",
            " 5.64070334e-03 9.16498667e-03 2.24219779e-03 1.18165588e-02\n",
            " 1.88365312e-02 1.41941378e-02 9.59493846e-03 1.65637701e-02\n",
            " 1.86318610e-02 2.06106472e-02 1.36977957e-02 1.91760615e-02\n",
            " 1.15379939e-02 1.14416049e-02 1.75743559e-02 1.08965487e-03\n",
            " 7.59774395e-03 1.93316218e-02 3.08187516e-03 1.66498502e-02\n",
            " 4.01223179e-04 1.72194550e-02 1.16043624e-03 1.49786361e-02\n",
            " 8.46824400e-03 3.42086460e-03 1.03481930e-02 1.82686214e-02\n",
            " 1.84358835e-02 1.89356603e-02 1.42801083e-02 9.85735288e-03\n",
            " 1.28184402e-02 4.25452260e-04 1.42474448e-02 7.61065724e-03\n",
            " 5.48394984e-03 5.17299418e-03 2.00475163e-02 1.93519228e-02\n",
            " 1.19554893e-02 5.14361397e-04 1.14317364e-02 1.04115895e-02\n",
            " 4.34547923e-03 4.49941684e-03 1.21153826e-03 1.63466604e-02\n",
            " 5.94515481e-03 1.12213846e-02 1.90583474e-02 6.20959377e-04\n",
            " 1.08665468e-03 1.05810854e-02 2.04491081e-02 5.61249951e-03\n",
            " 7.04704795e-05 3.81966439e-03 1.32761759e-02 1.82959872e-02\n",
            " 9.91952386e-03 1.10587050e-02 1.13542395e-02 2.01138437e-02\n",
            " 1.89391904e-03 7.88597997e-03 1.93149987e-02 8.81876627e-03\n",
            " 7.27941284e-04 1.51442288e-02 2.13953716e-03 1.50871189e-02\n",
            " 1.10294453e-02 1.01734793e-02 1.99389007e-02 1.47747445e-02\n",
            " 7.98959608e-03 1.75720968e-02 9.44591551e-03 1.88464606e-02\n",
            " 5.23540309e-03 1.30163351e-02 3.70546127e-03 7.52568321e-05\n",
            " 1.66061040e-02 9.34258774e-03 1.39386461e-02 4.34040232e-03\n",
            " 1.50131727e-02 1.89300006e-02 1.67300482e-02 3.70546127e-03\n",
            " 1.22459886e-02 1.22887878e-02 9.23660939e-03 1.48157653e-02\n",
            " 6.90809831e-03 1.02705631e-03 1.28316872e-02 1.53773293e-02\n",
            " 1.94671329e-02 9.73392392e-03 7.63420912e-03 1.21401485e-02\n",
            " 1.55758537e-03 1.81706976e-02 1.68062185e-02 1.31399570e-02\n",
            " 4.91780344e-05 1.74224671e-02 9.19698323e-03 1.50218501e-02\n",
            " 1.63919674e-02 4.76277042e-03 3.26407880e-03 1.05636972e-02\n",
            " 7.25851647e-03 1.72194550e-02 9.40019102e-03 4.82930243e-03\n",
            " 9.32462380e-03 1.08569321e-02 9.91749343e-03 1.02401313e-02\n",
            " 6.36642674e-09 4.09965267e-03 9.23155421e-03 1.53758377e-02\n",
            " 8.79335433e-03 1.15171798e-03 1.32428933e-02 1.35126594e-02\n",
            " 4.30229189e-03 1.49327232e-02 8.27962363e-03 1.88805467e-03\n",
            " 1.95606841e-02 7.95574326e-03 1.48296536e-02 2.18727910e-03\n",
            " 1.90162242e-02 7.67501991e-03 4.18602236e-03 1.19453175e-02\n",
            " 1.65153981e-02 8.95086794e-03 5.85243228e-03 2.04371321e-02\n",
            " 5.71794224e-03 2.03932966e-02 1.84301579e-02 6.75071589e-03\n",
            " 3.03859171e-03 8.59941190e-03 1.33512803e-02 1.32640865e-02\n",
            " 9.87637925e-03 5.37879939e-03 1.09443234e-02 4.34547923e-03\n",
            " 1.10813216e-02 9.82316726e-03 7.99978247e-03 1.26666586e-02\n",
            " 9.51515826e-03 5.80573375e-03 1.12759568e-02 8.04437051e-03\n",
            " 1.23438535e-02 1.86226597e-02 2.53370022e-03 1.38233422e-02\n",
            " 1.70801682e-04 4.24034377e-03 1.67973986e-02 1.97331672e-02\n",
            " 1.09261522e-02 1.84547382e-02 1.15273591e-02 4.17943126e-03\n",
            " 1.03613641e-02 3.43239752e-03 1.44216170e-02 1.85687517e-02\n",
            " 6.24687774e-03 7.72723710e-03 1.98094661e-02 1.04936860e-02\n",
            " 1.90073653e-02 5.54752556e-04 3.29907503e-03 1.15830923e-02\n",
            " 1.63919674e-02 1.54676569e-02 6.19444708e-03 1.35158166e-02\n",
            " 1.47035260e-06 1.17462837e-02 9.92514812e-05 8.48294991e-04\n",
            " 3.02733907e-03 1.29486758e-02 6.84425264e-03 3.09506049e-03\n",
            " 9.70212303e-03 5.30719061e-03 1.93111361e-02 4.40600123e-04\n",
            " 1.49760448e-02 5.42957924e-03 2.06826157e-02 5.73146099e-03\n",
            " 1.30831584e-02 1.25760343e-03 1.38447557e-02 1.09532987e-02\n",
            " 8.95158194e-04 1.78897518e-02 4.67460738e-03 1.28066499e-02\n",
            " 6.96823746e-03 8.60824710e-03 5.64513120e-03 1.53221066e-02\n",
            " 6.22197507e-03 1.49128664e-02 4.66771369e-03 1.90162242e-02\n",
            " 5.80529318e-03 1.83473442e-02 5.51097995e-03 3.47701718e-03\n",
            " 7.95848807e-03 4.34547923e-03 1.65941195e-02 1.03098162e-02\n",
            " 1.78844735e-02 8.16049865e-03 3.79498980e-03 1.75644497e-02\n",
            " 1.28686045e-03 1.56519736e-03 2.03269521e-02 1.69462968e-02\n",
            " 9.37166491e-03 4.25942096e-03 1.03733290e-02 1.22543041e-02\n",
            " 2.06299916e-02 1.62419268e-03 5.39425942e-03 9.44488776e-03\n",
            " 1.74921803e-02 1.02672224e-04 8.30501669e-03 1.75185841e-02\n",
            " 4.74560418e-16 3.20918518e-03 1.61562916e-02 1.52491280e-02\n",
            " 6.24005137e-03 1.31791643e-02 1.95849843e-02 1.09017511e-02\n",
            " 1.87749992e-02 1.45234452e-02 1.17172310e-02 1.71605699e-02\n",
            " 2.55799104e-04 8.34870903e-03 1.94955196e-02 1.05896205e-02\n",
            " 1.61157773e-02 1.03613641e-02 7.59774395e-03 2.95206089e-03\n",
            " 4.16259210e-03 3.27469721e-03 1.21401485e-02 2.16970094e-03\n",
            " 1.66282159e-02 3.84144237e-03 1.27453725e-02 6.98285919e-03\n",
            " 7.50527206e-03 1.73179486e-03 2.68482462e-04 7.27613265e-03\n",
            " 1.34075058e-02 4.87110433e-03 6.89040022e-03 1.25774076e-02\n",
            " 4.29641485e-03 4.35760781e-04 1.45381520e-02 8.81805189e-03\n",
            " 1.89032328e-02 2.09496939e-03 4.54724611e-03 3.60101473e-03\n",
            " 7.19054823e-03 7.98196076e-03 1.87446768e-04 4.60428056e-03\n",
            " 1.54878918e-02 3.70101969e-03 8.58930558e-03 1.46125186e-02\n",
            " 4.91037914e-03 3.34978242e-03 9.39979925e-03 9.31958248e-03\n",
            " 6.92303310e-03 1.41644691e-02 1.71715853e-02 4.89784742e-03\n",
            " 9.62088196e-03 5.60613768e-03 9.95954456e-03 2.04081186e-02\n",
            " 1.46854856e-02 5.02869468e-03 1.02037597e-02 2.09486058e-04\n",
            " 9.54053879e-03 1.21447153e-02 2.06413256e-02 1.76287267e-03\n",
            " 8.50456489e-03 1.02073845e-02 8.19935274e-03 1.93773046e-02\n",
            " 7.09601130e-03 3.81966439e-03 1.39911920e-03 1.97376171e-02\n",
            " 1.25685359e-02 3.09065141e-03 2.02721454e-03 1.58021342e-02\n",
            " 1.48392872e-02 1.43784083e-02 1.31051560e-03 4.93900496e-03\n",
            " 1.98727142e-02 1.60128871e-02 1.98094661e-02 1.85066594e-03\n",
            " 1.81690224e-02 5.80573375e-03 4.06385218e-03 1.67237217e-02\n",
            " 1.35136164e-02 1.60087985e-03 1.19077404e-02 7.77935154e-03\n",
            " 3.20165106e-03 3.17215712e-03 6.56642216e-03 2.29950597e-03\n",
            " 1.48051875e-02 1.85926765e-02 5.16502470e-06 1.25330052e-02\n",
            " 8.71152827e-04 1.52879642e-02 3.91216916e-03 1.29064131e-03\n",
            " 1.11038587e-02 1.06184662e-02 1.15369318e-05 1.08960227e-02\n",
            " 1.12763231e-02 1.49906094e-02 2.42494604e-03 1.87257145e-04\n",
            " 9.20319628e-03 1.41644691e-02 3.88980839e-03 3.17578896e-03\n",
            " 9.32352829e-03 1.84327347e-03 7.85943324e-04 2.20375556e-03\n",
            " 1.49284225e-02 6.64285374e-04 2.06445582e-02 2.15096359e-03\n",
            " 1.13526810e-03 1.98094661e-02 1.58950704e-02 3.79588247e-03\n",
            " 1.56778928e-02 1.44560598e-02 1.12265405e-02 7.98283253e-03\n",
            " 5.64229890e-05 1.37794337e-02 6.08090924e-04 1.13458818e-02\n",
            " 9.29431312e-04 1.24567518e-02 1.06696634e-02 1.90073653e-02\n",
            " 1.29440891e-02 1.03747472e-02 1.28348546e-02 1.40795567e-02\n",
            " 1.42795191e-02 9.85735288e-03 9.72124441e-03 5.51266366e-03\n",
            " 1.97692682e-02 1.86171570e-02 8.58406344e-03 8.88646853e-03\n",
            " 8.19299775e-03 1.00269783e-02 1.84327347e-03 1.56978127e-02\n",
            " 1.97754705e-02 1.16551021e-02 1.08453595e-02 1.75502861e-02\n",
            " 2.22299573e-03 1.22764364e-02 3.35355324e-03 1.01123572e-02\n",
            " 1.76035223e-02 5.00500834e-03 1.94202375e-02 1.07993389e-02\n",
            " 1.93310805e-03 1.31443666e-02 4.17076789e-03 1.20550767e-02\n",
            " 1.69027430e-02 1.60495671e-02 7.84647058e-03 2.04495422e-02\n",
            " 1.26662994e-02 1.28580703e-02 4.63713352e-03 9.36873935e-03\n",
            " 5.70424850e-04 3.02520694e-03 9.58046390e-03 3.91889076e-03\n",
            " 1.77968881e-02 7.94838672e-03 1.76300048e-02 8.13817799e-03\n",
            " 2.09486058e-04 4.78934140e-03 1.80428865e-02 1.11857143e-02\n",
            " 3.00209963e-03 1.50354956e-02 3.99803956e-03 1.72254241e-02\n",
            " 1.05031618e-02 8.28257586e-03 2.00578450e-02 4.54724442e-03\n",
            " 6.27597458e-04 1.46496989e-03 1.31876224e-02 1.19683047e-03\n",
            " 1.90036550e-02 1.62440688e-02 7.48780608e-03 5.13759341e-03\n",
            " 1.63719159e-02 7.05769151e-04 4.64431045e-03 1.44769028e-02\n",
            " 1.93692438e-02 1.93423520e-02 1.20870342e-02 3.24666637e-04\n",
            " 7.72593021e-03 1.84327347e-03 7.76060009e-03 1.41657909e-02\n",
            " 1.14562877e-02 1.31454425e-02 5.73762615e-03 7.49598171e-03\n",
            " 8.60867801e-03 1.13110858e-02 1.50440012e-02 2.01754521e-02\n",
            " 1.04811961e-02 2.30031678e-03 1.31136892e-02 3.70253388e-03\n",
            " 1.98531401e-02 1.20049025e-03 7.61779700e-03 1.91176585e-02\n",
            " 8.40242175e-03 8.97869438e-03 2.55098608e-04 1.13911414e-02\n",
            " 3.81966439e-03 1.68262669e-02 6.15130847e-03 3.91216916e-03\n",
            " 9.44988931e-03 1.86369936e-02 4.08578850e-04 2.71356144e-03\n",
            " 1.50127084e-02 1.60306794e-02 2.00065313e-02 5.28276159e-04\n",
            " 8.38205236e-03 9.49854731e-03 2.03388788e-03 4.78509523e-03\n",
            " 1.58408318e-03 1.00193209e-02 1.89886754e-02 1.75325808e-02\n",
            " 1.55368276e-02 1.20362908e-02 1.02861361e-02 1.45761100e-02\n",
            " 7.05162978e-03 9.90765222e-03 1.06717379e-02 1.35987127e-04\n",
            " 7.13721956e-03 2.30510187e-03 2.05619844e-02 3.34384644e-03\n",
            " 1.43082776e-02 1.71715853e-02 3.20974584e-03 4.76277042e-03\n",
            " 8.66031616e-03 1.85679109e-02 1.22419614e-02 4.34040232e-03\n",
            " 1.69783424e-02 6.48428579e-03 2.71208683e-03 1.88343732e-02\n",
            " 1.11183987e-02 9.79070686e-03 1.97789062e-03 5.96697787e-04\n",
            " 1.92802270e-02 2.78141406e-03 1.39604188e-02 1.43001465e-02\n",
            " 1.68196243e-02 1.75644497e-02 1.91762869e-02 4.30769350e-03\n",
            " 1.02571608e-02 1.44216170e-02 1.42615746e-02 1.87051245e-02\n",
            " 7.89772351e-03 2.01829582e-02 4.00704994e-03 1.61329012e-02\n",
            " 6.38934558e-04 1.67975942e-02 1.71351704e-02 3.46218380e-03\n",
            " 6.48822764e-03 5.41983358e-03 8.08691375e-03 4.97002034e-03\n",
            " 1.63919674e-02 1.65356028e-02 1.64434832e-02 2.03557028e-02\n",
            " 3.36035906e-04 2.74425394e-03 3.02615223e-03 8.08333567e-03\n",
            " 1.34013336e-02 1.44358838e-02 8.39612864e-03 2.22299573e-03\n",
            " 1.42634675e-02 1.71488480e-02 1.41364151e-03 1.13555419e-02\n",
            " 1.57988361e-02 2.46580635e-03 6.06117376e-03 1.08074796e-02\n",
            " 1.40392030e-02 1.15733492e-02 4.03589518e-03 1.41654126e-02\n",
            " 1.97023547e-02 1.15335890e-02 5.41534400e-03 8.80522580e-04\n",
            " 1.06237373e-02 6.83848989e-03 4.32053841e-03 1.53549926e-02\n",
            " 5.07182429e-03 3.83672018e-03 7.16463814e-03 5.18519617e-03\n",
            " 4.56753284e-03 2.85797507e-03 6.50743738e-03 1.86962083e-02\n",
            " 1.81333693e-02 1.06906653e-02 1.11812307e-03 6.70450928e-04\n",
            " 6.03607760e-03 1.35561340e-02 1.01706908e-03 2.09373266e-04\n",
            " 1.14520346e-02 9.75654161e-03 1.10127355e-02 1.31101698e-03\n",
            " 1.92751265e-02 1.63319060e-02 1.46957617e-03 2.11783517e-03\n",
            " 2.88996634e-03 8.02101872e-05 1.50711638e-02 3.83812488e-03\n",
            " 2.06445582e-02 1.82979613e-02 5.48534378e-03 5.33987534e-03\n",
            " 2.36368033e-06 1.23913788e-02 6.76894958e-04 5.73248482e-07\n",
            " 1.97124379e-02 1.10945682e-02 2.00892746e-02 1.95434687e-02\n",
            " 2.35950408e-05 1.73397697e-02 3.96369963e-05 1.36257365e-02\n",
            " 1.69419017e-02 1.05671651e-02 1.11641662e-02 1.54861788e-03\n",
            " 8.68875803e-04 1.15352898e-02 1.63583748e-02 4.56101364e-03\n",
            " 1.68510631e-02 1.57948498e-02 3.88822911e-03 1.44602766e-02\n",
            " 5.03008350e-03 1.08372426e-02 5.03008350e-03 7.53756771e-03\n",
            " 1.95497656e-02 1.85790389e-02 1.03809308e-03 7.37251895e-03\n",
            " 1.92364029e-03 1.79706421e-02 4.07878418e-03 3.26110439e-04\n",
            " 1.54465220e-02 3.99928665e-04 1.07654719e-02 1.43264690e-02\n",
            " 3.15738266e-03 1.39927195e-02 4.97897723e-03 1.81763301e-02\n",
            " 2.03067976e-02 2.04209638e-02 4.35012248e-03 2.52419634e-04\n",
            " 5.27760023e-03 6.29341474e-03 1.83509662e-02 6.64524872e-03\n",
            " 1.32215239e-02 1.59202627e-02 5.60893789e-03 1.70731444e-02\n",
            " 4.64650666e-03 4.91037914e-03 7.38810382e-03 1.93519228e-02\n",
            " 1.18480419e-02 3.08474834e-03 1.32547392e-02 1.52016593e-02\n",
            " 1.74347313e-02 1.11130096e-02 1.46652056e-02 2.01616622e-02\n",
            " 5.60863903e-03 1.72547214e-02 5.89399270e-03 1.29328947e-02\n",
            " 1.92271555e-02 1.84493889e-02 1.95371080e-02 4.87112890e-03\n",
            " 3.88822911e-03 1.35500763e-02 2.02084141e-02 1.41657214e-02\n",
            " 8.00830071e-03 1.08470669e-02 1.43719230e-03 1.27079877e-03\n",
            " 3.84004110e-03 1.59248379e-02 5.37135029e-03 2.00785141e-02\n",
            " 4.04194545e-03 7.29629226e-04 1.74470749e-02 9.30251253e-03\n",
            " 1.10313949e-02 8.47291986e-03 5.65003124e-03 2.39603917e-03\n",
            " 7.70856574e-04 9.46383983e-03 1.92215609e-02 7.18210973e-03\n",
            " 7.67502976e-03 9.02804168e-03 1.95965561e-02 1.15110800e-02\n",
            " 9.89392968e-03 2.97989329e-03 1.55340060e-03 1.32380158e-03\n",
            " 2.03685715e-02 1.45896071e-02 6.40338192e-03 9.95508921e-03\n",
            " 1.09395574e-02 7.38275424e-03 1.77229734e-02 8.74184741e-03\n",
            " 1.36421008e-02 4.28149216e-03 1.39471250e-02 8.10768171e-03\n",
            " 3.86033537e-03 9.17286425e-03 1.34740117e-02 1.84679782e-02\n",
            " 1.88216539e-02 1.94704346e-02 1.31481483e-02 3.23509611e-03\n",
            " 1.52794730e-02 1.34598605e-02 3.35331139e-03 9.05273221e-03\n",
            " 4.92983825e-04 9.33454513e-04 8.96448181e-03 1.43082776e-02\n",
            " 8.49638771e-03 2.74768736e-03 9.85735288e-03 6.13618614e-03\n",
            " 8.37253797e-03 1.67702723e-02 4.12267312e-04 5.72982927e-03\n",
            " 1.45661672e-02 7.61190880e-03 3.81707836e-03 1.05827623e-02\n",
            " 6.95097152e-03 3.60100065e-03 7.91403937e-03 1.53730937e-02\n",
            " 9.54052846e-03 9.85287945e-03 7.39043387e-03 1.74041271e-02\n",
            " 4.84958809e-03 5.77724319e-03 6.77541788e-03 8.71152827e-04\n",
            " 4.06569325e-03]\n",
            "3320 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.92772544e-03 4.46304304e-03 1.70774467e-02 1.71896795e-02\n",
            " 4.75744665e-03 4.14434138e-03 1.93467344e-02 1.53123660e-02\n",
            " 7.05009773e-04 1.27816145e-02 9.65728659e-03 4.13638755e-03\n",
            " 6.78536474e-03 1.27760937e-02 8.58958740e-03 1.60517237e-02\n",
            " 1.84952573e-02 1.18009758e-02 2.02849666e-02 2.00884912e-02\n",
            " 8.43983291e-03 1.04455245e-02 1.09359869e-02 1.21541363e-02\n",
            " 6.61306643e-03 1.45900830e-02 5.89541771e-03 1.86500301e-02\n",
            " 7.59411304e-03 5.59142257e-03 8.44397212e-03 1.49936489e-03\n",
            " 9.75633697e-03 5.07890312e-03 5.57330919e-03 1.86500301e-02\n",
            " 3.88673074e-03 1.47793505e-05 6.02090725e-03 1.30051730e-02\n",
            " 1.42364356e-02 1.53849176e-02 2.93488035e-03 1.10738320e-02\n",
            " 1.37549295e-02 2.01459470e-02 1.82402847e-02 1.09033209e-04\n",
            " 9.77775861e-03 1.30051730e-02 1.29998521e-02 2.01741295e-03\n",
            " 6.25171718e-09 3.03883154e-03 2.07995288e-05 6.65692171e-03\n",
            " 1.28146444e-02 8.81276328e-03 4.60996570e-04 2.08450793e-07\n",
            " 1.15481240e-02 7.91927648e-03 7.36360512e-03 2.88826962e-03\n",
            " 7.75962204e-03 1.09079525e-02 9.84665568e-03 1.73986873e-02\n",
            " 5.61768485e-03 9.12133775e-03 2.24477436e-03 1.18235773e-02\n",
            " 1.88275788e-02 1.41604530e-02 9.59826156e-03 1.65612423e-02\n",
            " 1.86409636e-02 1.36554858e-02 1.91367104e-02 1.14778990e-02\n",
            " 1.14363313e-02 1.75407523e-02 1.08101261e-03 7.60282673e-03\n",
            " 1.92926067e-02 3.07685872e-03 1.66250025e-02 3.96116788e-04\n",
            " 1.72323157e-02 1.15679199e-03 1.49573703e-02 8.42640542e-03\n",
            " 3.41615644e-03 1.03185536e-02 1.82060759e-02 1.84411442e-02\n",
            " 1.89153511e-02 1.42794029e-02 9.84665568e-03 1.27818425e-02\n",
            " 4.24638147e-04 1.42410859e-02 7.59698542e-03 5.47114251e-03\n",
            " 5.16286816e-03 2.00420698e-02 1.93467344e-02 1.19449077e-02\n",
            " 5.13396764e-04 1.13664151e-02 1.03883581e-02 4.33362454e-03\n",
            " 4.46890599e-03 1.20776368e-03 1.62792335e-02 5.93421849e-03\n",
            " 1.12217570e-02 1.90386361e-02 6.16642063e-04 1.08392471e-03\n",
            " 1.05698711e-02 5.61040118e-03 7.05225030e-05 3.80922449e-03\n",
            " 1.32641755e-02 1.82877960e-02 9.89870482e-03 1.10514207e-02\n",
            " 1.12870048e-02 2.00973199e-02 1.89410845e-03 7.87393546e-03\n",
            " 1.92110965e-02 8.81721011e-03 7.24268690e-04 1.51116818e-02\n",
            " 2.13504018e-03 1.50597244e-02 1.10160712e-02 1.01524407e-02\n",
            " 1.99086816e-02 1.47397479e-02 7.97647310e-03 1.75502578e-02\n",
            " 9.41187435e-03 1.88220515e-02 5.21750463e-03 1.29998521e-02\n",
            " 3.69633767e-03 7.49679570e-05 1.65758216e-02 9.31315880e-03\n",
            " 1.38799932e-02 4.30808505e-03 1.49801461e-02 1.88516580e-02\n",
            " 1.66912145e-02 3.69633767e-03 1.22734031e-02 1.22252300e-02\n",
            " 9.22935373e-03 1.47877516e-02 6.90466899e-03 1.01767990e-03\n",
            " 1.27911375e-02 1.52646083e-02 1.94422501e-02 9.71602711e-03\n",
            " 7.62813375e-03 1.21185612e-02 1.55536305e-03 1.81639174e-02\n",
            " 1.67679917e-02 1.31379083e-02 4.88836121e-05 1.73811572e-02\n",
            " 9.17164208e-03 1.50234345e-02 1.63986476e-02 4.76163204e-03\n",
            " 3.25308602e-03 1.05641091e-02 7.23110895e-03 1.72323157e-02\n",
            " 9.37513196e-03 4.81158295e-03 9.28727597e-03 1.08381932e-02\n",
            " 9.89493783e-03 1.02226979e-02 6.25171718e-09 4.08780234e-03\n",
            " 9.18582847e-03 1.53280468e-02 8.78143723e-03 1.14672985e-03\n",
            " 1.32438756e-02 1.35084392e-02 4.29371722e-03 1.49151438e-02\n",
            " 8.25534284e-03 1.87245898e-03 1.95520033e-02 7.94433383e-03\n",
            " 1.47474382e-02 2.17097217e-03 1.89924178e-02 7.65916800e-03\n",
            " 4.18744353e-03 1.19136838e-02 1.65202373e-02 8.93896487e-03\n",
            " 5.83497114e-03 5.69285042e-03 2.02585539e-02 1.84371415e-02\n",
            " 6.76144542e-03 3.03103367e-03 8.58958740e-03 1.32906526e-02\n",
            " 1.32671964e-02 9.85197466e-03 5.38119853e-03 1.09038349e-02\n",
            " 4.33362454e-03 1.10738320e-02 9.80968896e-03 7.98425631e-03\n",
            " 1.26332912e-02 9.52809696e-03 5.80388768e-03 1.12648376e-02\n",
            " 8.03016008e-03 1.23211216e-02 1.85869260e-02 2.52248130e-03\n",
            " 1.38124248e-02 1.70065429e-04 4.23189417e-03 1.68122099e-02\n",
            " 1.97016385e-02 1.08999560e-02 1.84113628e-02 1.15078996e-02\n",
            " 4.17848893e-03 1.03460269e-02 3.42510518e-03 1.43860231e-02\n",
            " 1.85571322e-02 6.27022395e-03 7.70574622e-03 1.97931075e-02\n",
            " 1.04742121e-02 1.89765203e-02 5.53875530e-04 3.28866343e-03\n",
            " 1.15436679e-02 1.63986476e-02 1.54479846e-02 6.18582364e-03\n",
            " 1.34555038e-02 1.45396247e-06 1.17573376e-02 9.88096384e-05\n",
            " 8.47898160e-04 3.01251379e-03 1.29438948e-02 6.80886000e-03\n",
            " 3.09182921e-03 9.70192571e-03 5.29031860e-03 1.92463660e-02\n",
            " 4.38120585e-04 1.49682493e-02 5.40870737e-03 5.72073282e-03\n",
            " 1.30444916e-02 1.26006050e-03 1.38216017e-02 1.09503977e-02\n",
            " 8.92279471e-04 1.78875216e-02 4.66133986e-03 1.27816145e-02\n",
            " 6.91098863e-03 8.59986089e-03 5.62714459e-03 1.53008298e-02\n",
            " 6.20482204e-03 1.49073671e-02 4.65595990e-03 1.89924178e-02\n",
            " 5.80028060e-03 1.83437226e-02 5.50761190e-03 3.46721773e-03\n",
            " 7.96289511e-03 4.33362454e-03 1.65959635e-02 1.02434187e-02\n",
            " 1.78288807e-02 8.15026765e-03 3.77938412e-03 1.75441002e-02\n",
            " 1.28145566e-03 1.56133241e-03 2.02152511e-02 1.69133959e-02\n",
            " 9.35656218e-03 4.25329495e-03 1.03364581e-02 1.22396336e-02\n",
            " 1.61963637e-03 5.37561795e-03 9.44639348e-03 1.74611899e-02\n",
            " 1.02303917e-04 8.28496640e-03 1.75237154e-02 4.59121070e-16\n",
            " 3.19545667e-03 1.61141503e-02 1.52223823e-02 6.22973994e-03\n",
            " 1.31535266e-02 1.95537072e-02 1.08789172e-02 1.87366884e-02\n",
            " 1.45154949e-02 1.16991500e-02 1.71272930e-02 2.54316572e-04\n",
            " 8.32271463e-03 1.94598000e-02 1.05675536e-02 1.60365673e-02\n",
            " 1.03460269e-02 7.60282673e-03 2.95500866e-03 4.16167726e-03\n",
            " 3.27204955e-03 1.21185612e-02 2.16907681e-03 1.66092400e-02\n",
            " 3.82736029e-03 1.27428691e-02 6.95661250e-03 7.48619971e-03\n",
            " 1.72171977e-03 2.68851367e-04 7.26611217e-03 1.33680465e-02\n",
            " 4.87368210e-03 6.85312764e-03 1.25176777e-02 4.27564988e-03\n",
            " 4.32490194e-04 1.45237787e-02 8.80664400e-03 1.88938163e-02\n",
            " 2.08622652e-03 4.54819168e-03 3.59141552e-03 7.19589325e-03\n",
            " 7.95046685e-03 1.86966387e-04 4.58608833e-03 1.54861764e-02\n",
            " 3.68631640e-03 8.57981671e-03 1.45582140e-02 4.89730272e-03\n",
            " 3.33792875e-03 9.37913754e-03 9.29831347e-03 6.92002033e-03\n",
            " 1.40644629e-02 1.71742523e-02 4.87797643e-03 9.58860082e-03\n",
            " 5.59142257e-03 9.94851105e-03 2.04075783e-02 1.46099954e-02\n",
            " 5.00295425e-03 1.01614338e-02 2.08266864e-04 9.53531866e-03\n",
            " 1.21456371e-02 1.75688338e-03 8.47764685e-03 1.01809678e-02\n",
            " 8.19881281e-03 1.93543153e-02 7.06049540e-03 3.80922449e-03\n",
            " 1.39539050e-03 1.97145871e-02 1.25734355e-02 3.07935123e-03\n",
            " 2.02309876e-03 1.57976074e-02 1.47947472e-02 1.43536549e-02\n",
            " 1.30748634e-03 4.93260876e-03 1.97600812e-02 1.59662688e-02\n",
            " 1.97931075e-02 1.83622236e-03 1.80413540e-02 5.80388768e-03\n",
            " 4.05200759e-03 1.67182594e-02 1.34918964e-02 1.59639581e-03\n",
            " 1.18994285e-02 7.76075046e-03 3.19661796e-03 3.16206701e-03\n",
            " 6.52781098e-03 2.29260633e-03 1.47824009e-02 1.85824631e-02\n",
            " 5.12503323e-06 1.25229075e-02 8.66401076e-04 1.52330568e-02\n",
            " 3.90560830e-03 1.28301512e-03 1.10944417e-02 1.05586016e-02\n",
            " 1.14795434e-05 1.08502190e-02 1.12166328e-02 1.49941026e-02\n",
            " 2.42102138e-03 1.86531863e-04 9.17763187e-03 1.40644629e-02\n",
            " 3.86980843e-03 3.17087451e-03 9.31504039e-03 1.83192338e-03\n",
            " 7.83217056e-04 2.19996425e-03 1.48878057e-02 6.59568425e-04\n",
            " 2.15496438e-03 1.13259625e-03 1.97931075e-02 1.58657201e-02\n",
            " 3.79289184e-03 1.56580514e-02 1.44749792e-02 1.12064975e-02\n",
            " 7.95213834e-03 5.61704115e-05 1.37159305e-02 6.05936196e-04\n",
            " 1.13227080e-02 9.27064441e-04 1.24175598e-02 1.06582216e-02\n",
            " 1.89765203e-02 1.28956189e-02 1.03512454e-02 1.28188581e-02\n",
            " 1.40515222e-02 1.42537176e-02 9.84665568e-03 9.70054095e-03\n",
            " 5.49715244e-03 1.97424754e-02 1.85696842e-02 8.56080241e-03\n",
            " 8.88246503e-03 8.18119320e-03 1.00018119e-02 1.83192338e-03\n",
            " 1.56853793e-02 1.96304108e-02 1.16288245e-02 1.08675197e-02\n",
            " 1.74433846e-02 2.22334473e-03 1.22578559e-02 3.32810138e-03\n",
            " 1.00444874e-02 1.75624895e-02 4.99620754e-03 1.94117517e-02\n",
            " 1.07699031e-02 1.92915505e-03 1.31454082e-02 4.15898161e-03\n",
            " 1.20372965e-02 1.68906638e-02 1.60300410e-02 7.82484509e-03\n",
            " 1.26447725e-02 1.27344749e-02 4.61915745e-03 9.35417802e-03\n",
            " 5.70168578e-04 3.00847699e-03 9.57292522e-03 3.90411653e-03\n",
            " 1.77432939e-02 7.89693186e-03 1.76435332e-02 8.10457416e-03\n",
            " 2.08266864e-04 4.78153721e-03 1.79829679e-02 1.11842979e-02\n",
            " 2.99533982e-03 1.49235517e-02 3.99298181e-03 1.71637675e-02\n",
            " 1.05074997e-02 8.27010180e-03 2.00024430e-02 4.54125828e-03\n",
            " 6.23549743e-04 1.45914690e-03 1.31681536e-02 1.19322299e-03\n",
            " 1.90009715e-02 1.62372997e-02 7.47375696e-03 5.12259784e-03\n",
            " 1.63384401e-02 7.05009773e-04 4.63833418e-03 1.44110482e-02\n",
            " 1.93204149e-02 1.93212544e-02 1.20816628e-02 3.21902188e-04\n",
            " 7.72477516e-03 1.83192338e-03 7.74891818e-03 1.41634513e-02\n",
            " 1.14357424e-02 1.31290122e-02 5.75598096e-03 7.48689267e-03\n",
            " 8.60538631e-03 1.12667081e-02 1.50284869e-02 2.01459470e-02\n",
            " 1.04667430e-02 2.29531034e-03 1.30992336e-02 3.69931142e-03\n",
            " 1.97933189e-02 1.19260121e-03 7.62083699e-03 1.91264653e-02\n",
            " 8.37046836e-03 8.97296879e-03 2.54334027e-04 1.13907137e-02\n",
            " 3.80922449e-03 1.68037920e-02 6.13177354e-03 3.90560830e-03\n",
            " 9.43860379e-03 1.86328776e-02 4.07296662e-04 2.69848308e-03\n",
            " 1.49357145e-02 1.60178885e-02 1.99877324e-02 5.28021886e-04\n",
            " 8.37458367e-03 9.41175817e-03 2.03077924e-03 4.77456786e-03\n",
            " 1.58555089e-03 1.00142867e-02 1.89600982e-02 1.74599531e-02\n",
            " 1.54819955e-02 1.19769607e-02 1.02569199e-02 1.45073112e-02\n",
            " 7.03551341e-03 9.91225066e-03 1.06437026e-02 1.35811646e-04\n",
            " 7.12561709e-03 2.29262310e-03 3.33148570e-03 1.42848622e-02\n",
            " 1.71742523e-02 3.20477614e-03 4.76163204e-03 8.64550396e-03\n",
            " 1.85570679e-02 1.22146585e-02 4.30808505e-03 1.69553161e-02\n",
            " 6.47654684e-03 2.70113256e-03 1.87935782e-02 1.10936993e-02\n",
            " 9.78758896e-03 1.97262026e-03 5.93352539e-04 1.92751104e-02\n",
            " 2.76825270e-03 1.39404268e-02 1.42759704e-02 1.68437305e-02\n",
            " 1.75441002e-02 1.91784278e-02 4.28549573e-03 1.02530790e-02\n",
            " 1.43860231e-02 1.42459807e-02 1.86791217e-02 7.89428384e-03\n",
            " 2.01663280e-02 3.99419287e-03 1.60301014e-02 6.35774161e-04\n",
            " 1.67127197e-02 1.70759407e-02 3.45326465e-03 6.47924638e-03\n",
            " 5.41019566e-03 8.07999033e-03 4.94438380e-03 1.63986476e-02\n",
            " 1.64264223e-02 1.64255782e-02 2.03323848e-02 3.34323185e-04\n",
            " 2.72074503e-03 3.03019146e-03 8.05305374e-03 1.33522818e-02\n",
            " 1.44080563e-02 8.36397293e-03 2.22334473e-03 1.42486310e-02\n",
            " 1.71643049e-02 1.41377438e-03 1.13342633e-02 1.58034099e-02\n",
            " 2.45523864e-03 6.05342238e-03 1.07774787e-02 1.40085010e-02\n",
            " 1.15802004e-02 4.03110217e-03 1.40971794e-02 1.96847723e-02\n",
            " 1.14960079e-02 5.40331412e-03 8.78934907e-04 1.06150897e-02\n",
            " 6.81533804e-03 4.30408661e-03 1.53156229e-02 5.05342635e-03\n",
            " 3.83371331e-03 7.17130192e-03 5.17824757e-03 4.56494226e-03\n",
            " 2.85020331e-03 6.48971666e-03 1.86853847e-02 1.81399435e-02\n",
            " 1.06950371e-02 1.11306676e-03 6.70790659e-04 6.02090725e-03\n",
            " 1.35411562e-02 1.01266865e-03 2.09369895e-04 1.13772181e-02\n",
            " 9.73912343e-03 1.09944858e-02 1.30568563e-03 1.92404829e-02\n",
            " 1.63048773e-02 1.46628976e-03 2.11242986e-03 2.88826962e-03\n",
            " 7.96198163e-05 1.50489998e-02 3.83298896e-03 1.82103881e-02\n",
            " 5.47981119e-03 5.33107942e-03 2.35059381e-06 1.23609848e-02\n",
            " 6.74534666e-04 5.68965671e-07 1.96840150e-02 1.11187280e-02\n",
            " 2.00561870e-02 1.95472605e-02 2.34441483e-05 1.73376094e-02\n",
            " 3.95390718e-05 1.35686742e-02 1.69276801e-02 1.05389958e-02\n",
            " 1.11786494e-02 1.54401017e-03 8.66273188e-04 1.14731331e-02\n",
            " 1.63202499e-02 4.55782174e-03 1.68263048e-02 1.57795248e-02\n",
            " 3.88673074e-03 1.44588851e-02 5.01971994e-03 1.08300316e-02\n",
            " 5.01971994e-03 7.53254724e-03 1.95099587e-02 1.85387978e-02\n",
            " 1.03492875e-03 7.35245437e-03 1.92014949e-03 1.78880822e-02\n",
            " 4.06936804e-03 3.23160339e-04 1.54387002e-02 3.98401376e-04\n",
            " 1.07542453e-02 1.43152229e-02 3.14850890e-03 1.39704113e-02\n",
            " 4.97709972e-03 1.81609645e-02 2.02541257e-02 2.03770393e-02\n",
            " 4.34749887e-03 2.50882113e-04 5.27517214e-03 6.27896100e-03\n",
            " 1.83111113e-02 6.63665521e-03 1.32109510e-02 1.59308114e-02\n",
            " 5.59422148e-03 1.70842808e-02 4.64753347e-03 4.89730272e-03\n",
            " 7.36106798e-03 1.93467344e-02 1.18241746e-02 3.07616928e-03\n",
            " 1.32419171e-02 1.51853429e-02 1.74236879e-02 1.10896259e-02\n",
            " 1.46273049e-02 2.01275963e-02 5.57794475e-03 1.72244640e-02\n",
            " 5.88657622e-03 1.29080866e-02 1.91827575e-02 1.84612768e-02\n",
            " 1.95284009e-02 4.87310966e-03 3.88673074e-03 1.35223056e-02\n",
            " 2.02167535e-02 1.41461056e-02 7.99490914e-03 1.08432993e-02\n",
            " 1.43224823e-03 1.26963557e-03 3.81510757e-03 1.58992592e-02\n",
            " 5.36861676e-03 2.00635239e-02 4.02706647e-03 7.25087922e-04\n",
            " 1.74292495e-02 9.25939309e-03 1.10378658e-02 8.41637082e-03\n",
            " 5.63084454e-03 2.38621042e-03 7.67893294e-04 9.46830383e-03\n",
            " 1.92287754e-02 7.16984662e-03 7.61894724e-03 9.00831770e-03\n",
            " 1.95542416e-02 1.14608721e-02 9.87591862e-03 2.97665674e-03\n",
            " 1.54806071e-03 1.31993263e-03 2.03720331e-02 1.45179430e-02\n",
            " 6.36977234e-03 9.92513109e-03 1.09397269e-02 7.37020530e-03\n",
            " 1.77142150e-02 8.72527252e-03 1.36188108e-02 4.26253746e-03\n",
            " 1.39533885e-02 8.10480495e-03 3.84676038e-03 9.14581881e-03\n",
            " 1.34818596e-02 1.84952573e-02 1.87927467e-02 1.94300249e-02\n",
            " 1.30676910e-02 3.21221319e-03 1.52317058e-02 1.34426361e-02\n",
            " 3.34475164e-03 9.01897923e-03 4.93194891e-04 9.30601763e-04\n",
            " 8.94439979e-03 1.42848622e-02 8.50352946e-03 2.74174799e-03\n",
            " 9.84665568e-03 6.13428279e-03 8.36836396e-03 1.67483250e-02\n",
            " 4.11995014e-04 5.73509114e-03 1.45837666e-02 7.59771742e-03\n",
            " 3.80006972e-03 1.05556309e-02 6.94844516e-03 3.58874899e-03\n",
            " 7.92018287e-03 1.53849176e-02 9.51597407e-03 9.78564561e-03\n",
            " 7.38990363e-03 1.73079529e-02 4.83837351e-03 5.77232028e-03\n",
            " 6.73856346e-03 8.66401076e-04 4.04430876e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3330 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.92136750e-03 4.46088127e-03 1.70115901e-02 1.72176213e-02\n",
            " 4.73820560e-03 4.12322436e-03 1.93749419e-02 1.52935879e-02\n",
            " 7.05477775e-04 1.27386217e-02 9.56064077e-03 4.12930327e-03\n",
            " 6.78753020e-03 1.27668004e-02 8.57412980e-03 1.60704606e-02\n",
            " 1.84766186e-02 1.17767902e-02 2.00629280e-02 8.41836552e-03\n",
            " 1.04176868e-02 1.08525258e-02 1.21571616e-02 6.58435685e-03\n",
            " 1.45591141e-02 5.86813486e-03 1.86256864e-02 7.58863259e-03\n",
            " 5.61117073e-03 8.41315880e-03 1.49452246e-03 9.70440749e-03\n",
            " 5.07480757e-03 5.56559410e-03 1.86256864e-02 3.88853537e-03\n",
            " 1.45746589e-05 6.01431447e-03 1.30054249e-02 1.41903041e-02\n",
            " 1.54041237e-02 2.92855988e-03 1.10396054e-02 1.36874922e-02\n",
            " 2.01252475e-02 1.82365671e-02 1.07075984e-04 9.73791428e-03\n",
            " 1.30054249e-02 1.27977130e-02 2.00675037e-03 5.94213911e-09\n",
            " 3.03289292e-03 2.04859944e-05 6.60793392e-03 1.27928432e-02\n",
            " 8.80586712e-03 4.54393173e-04 2.00148556e-07 1.15144297e-02\n",
            " 7.91793640e-03 7.32161501e-03 2.88896224e-03 7.76348069e-03\n",
            " 1.09268882e-02 9.84292592e-03 1.73428015e-02 5.61905017e-03\n",
            " 9.08312694e-03 2.23742971e-03 1.18034866e-02 1.87865540e-02\n",
            " 1.41239186e-02 9.60445839e-03 1.65108104e-02 1.85548452e-02\n",
            " 1.36608118e-02 1.90986334e-02 1.14865196e-02 1.14358143e-02\n",
            " 1.75186072e-02 1.07175922e-03 7.58606253e-03 1.93250580e-02\n",
            " 3.05969590e-03 1.66157385e-02 3.93168870e-04 1.72351707e-02\n",
            " 1.15130144e-03 1.49177013e-02 8.40272792e-03 3.38730419e-03\n",
            " 1.02686514e-02 1.81636184e-02 1.84161665e-02 1.89021801e-02\n",
            " 1.43131302e-02 9.84292592e-03 1.27532171e-02 4.23967555e-04\n",
            " 1.41868718e-02 7.58588663e-03 5.42567656e-03 5.15971703e-03\n",
            " 1.99685653e-02 1.93749419e-02 1.19385786e-02 5.11610571e-04\n",
            " 1.13431409e-02 1.03148800e-02 4.31952749e-03 4.44589775e-03\n",
            " 1.19859056e-03 1.62313566e-02 5.89185546e-03 1.12508351e-02\n",
            " 1.90502794e-02 6.15262694e-04 1.07493293e-03 1.05567675e-02\n",
            " 5.59065863e-03 6.95993175e-05 3.80409920e-03 1.32049712e-02\n",
            " 1.82445576e-02 9.86756182e-03 1.10088643e-02 1.12651893e-02\n",
            " 2.00822465e-02 1.89016119e-03 7.82910341e-03 1.91852933e-02\n",
            " 8.77080441e-03 7.21824562e-04 1.50919022e-02 2.13924848e-03\n",
            " 1.50440563e-02 1.10051783e-02 1.01573614e-02 1.98680085e-02\n",
            " 1.47524492e-02 7.96983698e-03 1.75579041e-02 9.41255505e-03\n",
            " 1.86591412e-02 5.21251813e-03 1.27977130e-02 3.68823996e-03\n",
            " 7.40935089e-05 1.65341377e-02 9.28706151e-03 1.38538573e-02\n",
            " 4.26476414e-03 1.49976141e-02 1.88068208e-02 1.66719551e-02\n",
            " 3.68823996e-03 1.22762425e-02 1.21620781e-02 9.19716782e-03\n",
            " 1.47278632e-02 6.87934002e-03 1.01594492e-03 1.27522799e-02\n",
            " 1.52397645e-02 1.94061040e-02 9.72211005e-03 7.61330130e-03\n",
            " 1.20329516e-02 1.55897243e-03 1.81301324e-02 1.66496972e-02\n",
            " 1.31442466e-02 4.85244807e-05 1.73355057e-02 9.13000355e-03\n",
            " 1.50123180e-02 1.63650538e-02 4.76126219e-03 3.23788967e-03\n",
            " 1.04933107e-02 7.20124066e-03 1.72351707e-02 9.37553008e-03\n",
            " 4.79569830e-03 9.29003835e-03 1.08125554e-02 9.85725045e-03\n",
            " 1.01814049e-02 5.94213911e-09 4.06881775e-03 9.19606608e-03\n",
            " 1.52928488e-02 8.77387124e-03 1.13447656e-03 1.32739681e-02\n",
            " 1.34032854e-02 4.27531430e-03 1.49084526e-02 8.22677976e-03\n",
            " 1.86939558e-03 1.95118798e-02 7.88362341e-03 1.47323022e-02\n",
            " 2.16534862e-03 1.88936230e-02 7.65570853e-03 4.18332224e-03\n",
            " 1.19059734e-02 1.65185706e-02 8.90549257e-03 5.82457534e-03\n",
            " 5.64313765e-03 1.84077068e-02 6.73803972e-03 3.03039663e-03\n",
            " 8.57412980e-03 1.32506037e-02 1.32736909e-02 9.81376353e-03\n",
            " 5.36282266e-03 1.08692138e-02 4.31952749e-03 1.10396054e-02\n",
            " 9.80259887e-03 7.95777984e-03 1.26001261e-02 9.50092875e-03\n",
            " 5.77997432e-03 1.12490523e-02 8.00512688e-03 1.22458279e-02\n",
            " 1.85039808e-02 2.52772031e-03 1.37479646e-02 1.69259013e-04\n",
            " 4.22379152e-03 1.68094941e-02 1.96389205e-02 1.08471560e-02\n",
            " 1.84184637e-02 1.14739097e-02 4.17491232e-03 1.03307276e-02\n",
            " 3.42321489e-03 1.43231115e-02 1.85368149e-02 6.25695422e-03\n",
            " 7.66258520e-03 1.97203158e-02 1.04615319e-02 1.89298802e-02\n",
            " 5.51295256e-04 3.28192701e-03 1.14860943e-02 1.63650538e-02\n",
            " 1.54133952e-02 6.17070052e-03 1.34190793e-02 1.41639706e-06\n",
            " 1.17755708e-02 9.74181819e-05 8.45585853e-04 2.99767433e-03\n",
            " 1.29104632e-02 6.79062986e-03 3.08530120e-03 9.67605826e-03\n",
            " 5.28131702e-03 1.92543885e-02 4.37905644e-04 1.49402841e-02\n",
            " 5.36864369e-03 5.69381046e-03 1.30194930e-02 1.24238627e-03\n",
            " 1.38233317e-02 1.09288310e-02 8.91121574e-04 1.77827127e-02\n",
            " 4.65334520e-03 1.27386217e-02 6.91500895e-03 8.57619904e-03\n",
            " 5.61537248e-03 1.50840870e-02 6.16583173e-03 1.48146700e-02\n",
            " 4.63885724e-03 1.88936230e-02 5.77533100e-03 1.83096375e-02\n",
            " 5.48705114e-03 3.46209511e-03 7.95140096e-03 4.31952749e-03\n",
            " 1.65817632e-02 1.02244969e-02 1.78238959e-02 8.12085936e-03\n",
            " 3.76997259e-03 1.75054313e-02 1.27211067e-03 1.55963877e-03\n",
            " 1.69016212e-02 9.34107233e-03 4.21648296e-03 1.03065790e-02\n",
            " 1.22406166e-02 1.60731028e-03 5.36455607e-03 9.40375993e-03\n",
            " 1.74236457e-02 1.02073701e-04 8.27073318e-03 1.74865634e-02\n",
            " 4.43361030e-16 3.18399201e-03 1.60696549e-02 1.51861423e-02\n",
            " 6.21864669e-03 1.31084965e-02 1.94819672e-02 1.08235719e-02\n",
            " 1.87078791e-02 1.45347061e-02 1.17001654e-02 1.70979808e-02\n",
            " 2.52777295e-04 8.30547672e-03 1.93926148e-02 1.05616845e-02\n",
            " 1.59639853e-02 1.03307276e-02 7.58606253e-03 2.94983549e-03\n",
            " 4.16596422e-03 3.25877657e-03 1.20329516e-02 2.16831791e-03\n",
            " 1.65666371e-02 3.77596718e-03 1.27099665e-02 6.91522915e-03\n",
            " 7.48530390e-03 1.71420408e-03 2.67622297e-04 7.26411171e-03\n",
            " 1.33373370e-02 4.85458968e-03 6.84657804e-03 1.24390415e-02\n",
            " 4.25299462e-03 4.29442977e-04 1.44988167e-02 8.80187061e-03\n",
            " 1.88539007e-02 2.08577762e-03 4.54666070e-03 3.56324114e-03\n",
            " 7.16269655e-03 7.94005303e-03 1.85990669e-04 4.57550432e-03\n",
            " 1.54855014e-02 3.68395770e-03 8.57032420e-03 1.45183113e-02\n",
            " 4.90255942e-03 3.33498133e-03 9.34169672e-03 9.21126057e-03\n",
            " 6.91324761e-03 1.40180170e-02 1.71788167e-02 4.87268459e-03\n",
            " 9.55361783e-03 5.61117073e-03 9.94843437e-03 1.45759981e-02\n",
            " 4.99791216e-03 1.01456731e-02 2.05048520e-04 9.48536886e-03\n",
            " 1.21799466e-02 1.75125222e-03 8.48964055e-03 1.01331640e-02\n",
            " 8.15852944e-03 1.93306389e-02 7.03664605e-03 3.80409920e-03\n",
            " 1.39499462e-03 1.97678040e-02 1.25423081e-02 3.03806711e-03\n",
            " 2.02250339e-03 1.57555131e-02 1.47428873e-02 1.43335511e-02\n",
            " 1.30718216e-03 4.91263945e-03 1.97371332e-02 1.60195795e-02\n",
            " 1.97203158e-02 1.82866488e-03 1.79721637e-02 5.77997432e-03\n",
            " 4.04352433e-03 1.67156307e-02 1.34769115e-02 1.58256480e-03\n",
            " 1.18916725e-02 7.76262189e-03 3.18868019e-03 3.16143187e-03\n",
            " 6.52239382e-03 2.27743259e-03 1.45950287e-02 1.85628953e-02\n",
            " 5.03559497e-06 1.24683854e-02 8.55639098e-04 1.51852027e-02\n",
            " 3.90382104e-03 1.28006991e-03 1.10852427e-02 1.05033008e-02\n",
            " 1.13476460e-05 1.08261884e-02 1.11747608e-02 1.49900300e-02\n",
            " 2.41239368e-03 1.86471291e-04 9.15823368e-03 1.40180170e-02\n",
            " 3.85477938e-03 3.15580228e-03 9.26001816e-03 1.81646848e-03\n",
            " 7.79532675e-04 2.18133846e-03 1.48864632e-02 6.56602239e-04\n",
            " 2.14940714e-03 1.12730627e-03 1.97203158e-02 1.58362441e-02\n",
            " 3.76555771e-03 1.56160721e-02 1.44513294e-02 1.12102894e-02\n",
            " 7.92405274e-03 5.61022124e-05 1.36764172e-02 5.97108782e-04\n",
            " 1.13127656e-02 9.18135543e-04 1.24203231e-02 1.06879068e-02\n",
            " 1.89298802e-02 1.29190171e-02 1.02138319e-02 1.28069502e-02\n",
            " 1.39879825e-02 1.42086990e-02 9.84292592e-03 9.66542468e-03\n",
            " 5.48899546e-03 1.97461195e-02 1.85800948e-02 8.53477425e-03\n",
            " 8.82379965e-03 8.18972786e-03 1.00074964e-02 1.81646848e-03\n",
            " 1.56779315e-02 1.95898125e-02 1.14576765e-02 1.08484231e-02\n",
            " 1.73531075e-02 2.20910119e-03 1.21570292e-02 3.32514300e-03\n",
            " 1.00178359e-02 1.75239341e-02 4.99690016e-03 1.93224706e-02\n",
            " 1.07298107e-02 1.92832702e-03 1.31078700e-02 4.10790637e-03\n",
            " 1.20151980e-02 1.68021680e-02 1.60093145e-02 7.81203174e-03\n",
            " 1.26154230e-02 1.27016844e-02 4.60098810e-03 9.33879351e-03\n",
            " 5.70629567e-04 2.98196009e-03 9.55265780e-03 3.87167972e-03\n",
            " 1.76965308e-02 7.82310955e-03 1.76267867e-02 8.08114634e-03\n",
            " 2.05048520e-04 4.74979963e-03 1.79210035e-02 1.11582733e-02\n",
            " 2.97770948e-03 1.48716402e-02 3.98278501e-03 1.71158036e-02\n",
            " 1.04820934e-02 8.26751015e-03 1.99064597e-02 4.52894979e-03\n",
            " 6.14445091e-04 1.45937792e-03 1.31495368e-02 1.19148162e-03\n",
            " 1.89888043e-02 1.62123404e-02 7.41373792e-03 5.10765237e-03\n",
            " 1.63027778e-02 7.05477775e-04 4.59788201e-03 1.43701317e-02\n",
            " 1.92905486e-02 1.92610491e-02 1.20065905e-02 3.19587809e-04\n",
            " 7.71302229e-03 1.81646848e-03 7.73793441e-03 1.41802674e-02\n",
            " 1.13566581e-02 1.31104952e-02 5.73794392e-03 7.46514997e-03\n",
            " 8.58317348e-03 1.12716680e-02 1.49974666e-02 2.01252475e-02\n",
            " 1.04567033e-02 2.27725544e-03 1.30939704e-02 3.67858691e-03\n",
            " 1.97198096e-02 1.18506447e-03 7.62979022e-03 1.91266920e-02\n",
            " 8.33234346e-03 8.98039834e-03 2.53492185e-04 1.13872014e-02\n",
            " 3.80409920e-03 1.67637204e-02 6.10826139e-03 3.90382104e-03\n",
            " 9.40820206e-03 1.85764558e-02 4.08333291e-04 2.68119577e-03\n",
            " 1.49382629e-02 1.60452328e-02 1.99891623e-02 5.25357866e-04\n",
            " 8.39077646e-03 9.39131883e-03 2.03387846e-03 4.75145460e-03\n",
            " 1.57687538e-03 1.00091644e-02 1.88133827e-02 1.74153457e-02\n",
            " 1.55087608e-02 1.19081444e-02 1.02230057e-02 1.44913796e-02\n",
            " 7.03512453e-03 9.89345555e-03 1.06010940e-02 1.35405989e-04\n",
            " 7.11608217e-03 2.28127242e-03 3.32294431e-03 1.42719849e-02\n",
            " 1.71788167e-02 3.19748630e-03 4.76126219e-03 8.65333283e-03\n",
            " 1.85247237e-02 1.22025214e-02 4.26476414e-03 1.69343509e-02\n",
            " 6.47027360e-03 2.68734902e-03 1.86943287e-02 1.10377207e-02\n",
            " 9.77090240e-03 1.96635565e-03 5.90036850e-04 1.92249086e-02\n",
            " 2.75240452e-03 1.39366992e-02 1.42504986e-02 1.68114525e-02\n",
            " 1.75054313e-02 1.91587047e-02 4.27759477e-03 1.02690013e-02\n",
            " 1.43231115e-02 1.41879302e-02 1.86812724e-02 7.86813193e-03\n",
            " 3.98687070e-03 1.60103484e-02 6.31295813e-04 1.66871612e-02\n",
            " 1.70480883e-02 3.43101169e-03 6.48272488e-03 5.38006466e-03\n",
            " 8.06173299e-03 4.91223089e-03 1.63650538e-02 1.63993222e-02\n",
            " 1.63660234e-02 3.32080949e-04 2.71472254e-03 3.01941787e-03\n",
            " 8.04463306e-03 1.32482208e-02 1.43783562e-02 8.34445188e-03\n",
            " 2.20910119e-03 1.42845916e-02 1.71094032e-02 1.40597236e-03\n",
            " 1.12926095e-02 1.57682462e-02 2.45236135e-03 6.01532136e-03\n",
            " 1.07577079e-02 1.39773677e-02 1.15717089e-02 4.03720887e-03\n",
            " 1.40933846e-02 1.96108277e-02 1.15077150e-02 5.37443475e-03\n",
            " 8.76579352e-04 1.05907195e-02 6.81776060e-03 4.30474467e-03\n",
            " 1.53264598e-02 5.03344537e-03 3.81854039e-03 7.13634967e-03\n",
            " 5.16557422e-03 4.55333290e-03 2.84686391e-03 6.44423659e-03\n",
            " 1.87039627e-02 1.80725727e-02 1.06953718e-02 1.10496224e-03\n",
            " 6.69620413e-04 6.01431447e-03 1.35591707e-02 1.00630671e-03\n",
            " 2.07753595e-04 1.13853366e-02 9.70213399e-03 1.10055513e-02\n",
            " 1.29649282e-03 1.91699776e-02 1.62882296e-02 1.46233047e-03\n",
            " 2.10484433e-03 2.88896224e-03 7.88074242e-05 1.49721759e-02\n",
            " 3.78345957e-03 1.82086958e-02 5.48065021e-03 5.32804473e-03\n",
            " 2.29302492e-06 1.22940395e-02 6.69687112e-04 5.66659727e-07\n",
            " 1.96368513e-02 1.11450911e-02 2.00469014e-02 1.95467485e-02\n",
            " 2.32466093e-05 1.72522282e-02 3.96220391e-05 1.35616636e-02\n",
            " 1.69092105e-02 1.05289482e-02 1.11243145e-02 1.54254334e-03\n",
            " 8.65510852e-04 1.14450820e-02 1.62298837e-02 4.52204759e-03\n",
            " 1.67452200e-02 1.57289831e-02 3.88853537e-03 1.44743740e-02\n",
            " 5.01842300e-03 1.08047693e-02 5.01842300e-03 7.50717569e-03\n",
            " 1.94257135e-02 1.84617508e-02 1.03436502e-03 7.31935199e-03\n",
            " 1.91045720e-03 1.78569216e-02 4.04888204e-03 3.20932331e-04\n",
            " 1.54578116e-02 3.95580691e-04 1.07598473e-02 1.43221605e-02\n",
            " 3.13099807e-03 1.39683779e-02 4.95072316e-03 1.80945711e-02\n",
            " 4.31671396e-03 2.46984486e-04 5.25764193e-03 6.24832712e-03\n",
            " 1.82904615e-02 6.61557057e-03 1.32117525e-02 1.57933985e-02\n",
            " 5.56389158e-03 1.70611696e-02 4.64498171e-03 4.90255942e-03\n",
            " 7.34189931e-03 1.93749419e-02 1.17942315e-02 3.07471953e-03\n",
            " 1.31846395e-02 1.51493532e-02 1.74023404e-02 1.10716150e-02\n",
            " 1.46158698e-02 2.01059272e-02 5.54562564e-03 1.72028658e-02\n",
            " 5.88807701e-03 1.28343110e-02 1.91837130e-02 1.84370380e-02\n",
            " 1.95078452e-02 4.84430882e-03 3.88853537e-03 1.34889934e-02\n",
            " 1.41414734e-02 7.94229323e-03 1.07954075e-02 1.42414821e-03\n",
            " 1.26326719e-03 3.80379395e-03 1.58507943e-02 5.37304402e-03\n",
            " 2.00526784e-02 4.02922463e-03 7.16908672e-04 1.73917312e-02\n",
            " 9.25259314e-03 1.10396915e-02 8.40165070e-03 5.60502961e-03\n",
            " 2.37198873e-03 7.61913018e-04 9.43833093e-03 1.92094609e-02\n",
            " 7.15089888e-03 7.57495874e-03 8.93913932e-03 1.95357074e-02\n",
            " 1.14569966e-02 9.85515814e-03 2.96654490e-03 1.54008318e-03\n",
            " 1.31419239e-03 1.44679287e-02 6.32118383e-03 9.92696743e-03\n",
            " 1.09388801e-02 7.35557128e-03 1.77014594e-02 8.69032342e-03\n",
            " 1.36160631e-02 4.24611623e-03 1.39252133e-02 8.06170369e-03\n",
            " 3.82966704e-03 9.11644638e-03 1.34739632e-02 1.84766186e-02\n",
            " 1.87803775e-02 1.93377518e-02 1.30432443e-02 3.17867092e-03\n",
            " 1.51482665e-02 1.33813002e-02 3.34361715e-03 8.97887685e-03\n",
            " 4.93225121e-04 9.29782822e-04 8.95189109e-03 1.42719849e-02\n",
            " 8.49024807e-03 2.73800484e-03 9.84292592e-03 6.12813511e-03\n",
            " 8.34946047e-03 1.67416627e-02 4.08761224e-04 5.71764848e-03\n",
            " 1.45411135e-02 7.58428317e-03 3.79784923e-03 1.05923411e-02\n",
            " 6.94534310e-03 3.58399471e-03 7.88875401e-03 1.54041237e-02\n",
            " 9.45905981e-03 9.70841346e-03 7.36791913e-03 1.71640196e-02\n",
            " 4.83945848e-03 5.70559001e-03 6.72133804e-03 8.55639098e-04\n",
            " 4.00743820e-03]\n",
            "3340 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.91453176e-03 4.45306463e-03 1.70133554e-02 1.71665775e-02\n",
            " 4.73400394e-03 4.09738384e-03 1.93903632e-02 1.53006671e-02\n",
            " 7.04240233e-04 1.27227463e-02 9.54650534e-03 4.12552124e-03\n",
            " 6.76537582e-03 1.27834725e-02 8.50502371e-03 1.60297755e-02\n",
            " 1.84914685e-02 1.16839167e-02 8.36021966e-03 1.04110048e-02\n",
            " 1.08395119e-02 1.21693433e-02 6.54001691e-03 1.45293231e-02\n",
            " 5.84062501e-03 1.86446020e-02 7.58600407e-03 5.59144517e-03\n",
            " 8.41902331e-03 1.48435871e-03 9.64001360e-03 5.06275661e-03\n",
            " 5.54602619e-03 1.86446020e-02 3.88122953e-03 1.44413985e-05\n",
            " 6.01394941e-03 1.30049058e-02 1.40968026e-02 1.53948488e-02\n",
            " 2.92654865e-03 1.10430898e-02 1.36625891e-02 1.81869190e-02\n",
            " 1.06521198e-04 9.73479392e-03 1.30049058e-02 1.28328344e-02\n",
            " 1.98715614e-03 5.92175554e-09 3.03029855e-03 1.95972394e-05\n",
            " 6.60386864e-03 1.27607054e-02 8.78533365e-03 4.51795331e-04\n",
            " 1.98598304e-07 1.15083720e-02 7.90886546e-03 7.31583939e-03\n",
            " 2.88252578e-03 7.74726485e-03 1.08813634e-02 9.82488816e-03\n",
            " 1.72372382e-02 5.60356885e-03 9.07030908e-03 2.22768078e-03\n",
            " 1.18113143e-02 1.87716981e-02 1.40485052e-02 9.57905430e-03\n",
            " 1.65150855e-02 1.85313591e-02 1.36398945e-02 1.89310246e-02\n",
            " 1.14690959e-02 1.13616793e-02 1.75307046e-02 1.05711635e-03\n",
            " 7.58365549e-03 1.92428142e-02 3.01776232e-03 1.66462106e-02\n",
            " 3.90652495e-04 1.72178134e-02 1.14267747e-03 1.49261549e-02\n",
            " 8.37114359e-03 3.39102823e-03 1.02077093e-02 1.81704675e-02\n",
            " 1.83923612e-02 1.88532102e-02 1.42912432e-02 9.82488816e-03\n",
            " 1.27553884e-02 4.22708033e-04 1.40812995e-02 7.53436045e-03\n",
            " 5.40810897e-03 5.11847432e-03 1.93903632e-02 1.19421031e-02\n",
            " 5.08390741e-04 1.13296502e-02 1.03267684e-02 4.31023543e-03\n",
            " 4.40426035e-03 1.18967785e-03 1.61390668e-02 5.90593098e-03\n",
            " 1.12533344e-02 1.90159148e-02 6.12297414e-04 1.07186440e-03\n",
            " 1.05164536e-02 5.57733158e-03 6.89477094e-05 3.79445509e-03\n",
            " 1.31860626e-02 1.82545961e-02 9.84231861e-03 1.09887048e-02\n",
            " 1.12491429e-02 1.88989475e-03 7.81743148e-03 1.91284739e-02\n",
            " 8.76004486e-03 7.17576661e-04 1.49916123e-02 2.13605608e-03\n",
            " 1.50339968e-02 1.09747486e-02 1.01754704e-02 1.98941221e-02\n",
            " 1.47430832e-02 7.96621885e-03 1.74751996e-02 9.33267572e-03\n",
            " 1.86530405e-02 5.21621227e-03 1.28328344e-02 3.68029654e-03\n",
            " 7.39130921e-05 1.65358933e-02 9.28720259e-03 1.36834404e-02\n",
            " 4.17435114e-03 1.49486289e-02 1.87702946e-02 1.66056128e-02\n",
            " 3.68029654e-03 1.22219885e-02 1.21160727e-02 9.18012724e-03\n",
            " 1.47150376e-02 6.86495041e-03 1.01461553e-03 1.27438178e-02\n",
            " 1.52313065e-02 1.92904287e-02 9.70075514e-03 7.59138926e-03\n",
            " 1.20702940e-02 1.55492850e-03 1.81088256e-02 1.64114577e-02\n",
            " 1.31224633e-02 4.72310698e-05 1.72033703e-02 9.06719734e-03\n",
            " 1.49997256e-02 1.63353808e-02 4.75816816e-03 3.20673958e-03\n",
            " 1.04238716e-02 7.20432109e-03 1.72178134e-02 9.32599754e-03\n",
            " 4.72507976e-03 9.26356768e-03 1.08119752e-02 9.84874053e-03\n",
            " 1.01589317e-02 5.92175554e-09 4.06668573e-03 9.17171447e-03\n",
            " 1.52963656e-02 8.77220339e-03 1.12756050e-03 1.32273934e-02\n",
            " 1.33812318e-02 4.28535240e-03 1.49139822e-02 8.22108576e-03\n",
            " 1.86910278e-03 1.95189059e-02 7.87080711e-03 1.47147806e-02\n",
            " 2.15742416e-03 1.89156755e-02 7.65370644e-03 4.17776484e-03\n",
            " 1.18741610e-02 1.64921617e-02 8.89941963e-03 5.80857828e-03\n",
            " 5.59562911e-03 1.83076832e-02 6.71941096e-03 3.02648404e-03\n",
            " 8.50502371e-03 1.32113390e-02 1.32625359e-02 9.79491213e-03\n",
            " 5.33081359e-03 1.07922072e-02 4.31023543e-03 1.10430898e-02\n",
            " 9.74197710e-03 7.94660485e-03 1.25116252e-02 9.44779002e-03\n",
            " 5.79019989e-03 1.12435532e-02 7.91031629e-03 1.22360708e-02\n",
            " 1.84883681e-02 2.53328914e-03 1.37498682e-02 1.68585040e-04\n",
            " 4.22495214e-03 1.67541178e-02 1.96730159e-02 1.07543901e-02\n",
            " 1.83900523e-02 1.14904142e-02 4.16623591e-03 1.03002079e-02\n",
            " 3.41453624e-03 1.42705575e-02 1.85385882e-02 6.26870884e-03\n",
            " 7.65735362e-03 1.97251226e-02 1.04390583e-02 1.89197183e-02\n",
            " 5.49068914e-04 3.25253460e-03 1.14118825e-02 1.63353808e-02\n",
            " 1.53940818e-02 6.15775297e-03 1.34163201e-02 1.41301964e-06\n",
            " 1.17967621e-02 9.57437177e-05 8.42548354e-04 2.99236955e-03\n",
            " 1.28538883e-02 6.74174132e-03 3.07365857e-03 9.68143260e-03\n",
            " 5.25273484e-03 1.92404192e-02 4.35923558e-04 1.49056929e-02\n",
            " 5.36462354e-03 5.67443147e-03 1.30273763e-02 1.23687969e-03\n",
            " 1.38168808e-02 1.09161570e-02 8.84808569e-04 1.77826906e-02\n",
            " 4.61675158e-03 1.27227463e-02 6.91428617e-03 8.56963107e-03\n",
            " 5.62616468e-03 1.50992902e-02 6.15971413e-03 1.47835247e-02\n",
            " 4.60296962e-03 1.89156755e-02 5.77391972e-03 1.83138607e-02\n",
            " 5.48290492e-03 3.42873991e-03 7.93023473e-03 4.31023543e-03\n",
            " 1.65673894e-02 1.01886246e-02 1.78151767e-02 8.09138162e-03\n",
            " 3.76063046e-03 1.75310031e-02 1.27153525e-03 1.55083690e-03\n",
            " 1.68872838e-02 9.26491777e-03 4.21732083e-03 1.02821116e-02\n",
            " 1.22464558e-02 1.60610924e-03 5.31366140e-03 9.39067186e-03\n",
            " 1.73904383e-02 1.01719391e-04 8.25891353e-03 1.74853169e-02\n",
            " 3.90392006e-16 3.17761305e-03 1.59510386e-02 1.50790760e-02\n",
            " 6.20382300e-03 1.30833725e-02 1.93965612e-02 1.08164545e-02\n",
            " 1.86975197e-02 1.45144606e-02 1.16955617e-02 1.71102362e-02\n",
            " 2.49177310e-04 8.30325385e-03 1.92879965e-02 1.04960091e-02\n",
            " 1.59737733e-02 1.03002079e-02 7.58365549e-03 2.93650518e-03\n",
            " 4.14491779e-03 3.25998444e-03 1.20702940e-02 2.16028880e-03\n",
            " 1.65832749e-02 3.78298456e-03 1.27169724e-02 6.90871008e-03\n",
            " 7.42565042e-03 1.70737154e-03 2.66854829e-04 7.24229142e-03\n",
            " 1.33296609e-02 4.83739993e-03 6.84304440e-03 1.23451030e-02\n",
            " 4.16834168e-03 4.26647509e-04 1.44637177e-02 8.71960664e-03\n",
            " 1.88505691e-02 2.07863480e-03 4.54448825e-03 3.54519028e-03\n",
            " 7.14336677e-03 7.91833081e-03 1.84722281e-04 4.57534311e-03\n",
            " 1.54880822e-02 3.66827329e-03 8.57097026e-03 1.45236919e-02\n",
            " 4.88365827e-03 3.30987408e-03 9.34926000e-03 9.21379142e-03\n",
            " 6.89980097e-03 1.39484386e-02 1.71398448e-02 4.84533647e-03\n",
            " 9.52855202e-03 5.59144517e-03 9.93170493e-03 1.45366196e-02\n",
            " 4.96286040e-03 1.01182070e-02 2.05033750e-04 9.48032605e-03\n",
            " 1.21298129e-02 1.74285729e-03 8.45414585e-03 1.01088117e-02\n",
            " 8.16709566e-03 1.92583157e-02 6.98243517e-03 3.79445509e-03\n",
            " 1.38181375e-03 1.97256739e-02 1.25462851e-02 3.03265964e-03\n",
            " 2.02009691e-03 1.57293244e-02 1.47382835e-02 1.41999161e-02\n",
            " 1.30519944e-03 4.90562552e-03 1.97088332e-02 1.59690013e-02\n",
            " 1.97251226e-02 1.79698308e-03 1.79582295e-02 5.79019989e-03\n",
            " 4.03843798e-03 1.67047507e-02 1.35026915e-02 1.55894095e-03\n",
            " 1.18721798e-02 7.74561570e-03 3.17500295e-03 3.14384508e-03\n",
            " 6.49843147e-03 2.26664747e-03 1.44696790e-02 1.85017726e-02\n",
            " 4.92145547e-06 1.24664248e-02 8.52004654e-04 1.50925948e-02\n",
            " 3.90130749e-03 1.27856943e-03 1.10701005e-02 1.04788861e-02\n",
            " 1.12976082e-05 1.07412113e-02 1.11557414e-02 1.49358779e-02\n",
            " 2.41066518e-03 1.85908286e-04 9.15521259e-03 1.39484386e-02\n",
            " 3.85190046e-03 3.13262553e-03 9.20644758e-03 1.78939249e-03\n",
            " 7.76050404e-04 2.18034855e-03 1.48859069e-02 6.53116702e-04\n",
            " 2.14324213e-03 1.12366946e-03 1.97251226e-02 1.57990781e-02\n",
            " 3.75484855e-03 1.55208407e-02 1.43793229e-02 1.12035602e-02\n",
            " 7.90255744e-03 5.60244766e-05 1.36805383e-02 5.95630563e-04\n",
            " 1.12283943e-02 9.03076111e-04 1.23968542e-02 1.06574725e-02\n",
            " 1.89197183e-02 1.28945754e-02 1.02187005e-02 1.28092667e-02\n",
            " 1.39887467e-02 1.42067746e-02 9.82488816e-03 9.65809809e-03\n",
            " 5.48171490e-03 1.97639353e-02 1.85363618e-02 8.48044984e-03\n",
            " 8.76836670e-03 8.16352559e-03 9.96910657e-03 1.78939249e-03\n",
            " 1.56429059e-02 1.94716272e-02 1.14644144e-02 1.08211841e-02\n",
            " 1.73306892e-02 2.20257059e-03 1.21571197e-02 3.33082631e-03\n",
            " 9.96228623e-03 1.73678685e-02 5.00019262e-03 1.93429949e-02\n",
            " 1.07088881e-02 1.91890018e-03 1.30577521e-02 4.11037605e-03\n",
            " 1.19183498e-02 1.67701205e-02 1.59931676e-02 7.79179506e-03\n",
            " 1.25376840e-02 1.26172291e-02 4.54575750e-03 9.32973417e-03\n",
            " 5.71145328e-04 2.94925286e-03 9.52458694e-03 3.86553425e-03\n",
            " 1.76887543e-02 7.84091960e-03 1.76303838e-02 8.08813459e-03\n",
            " 2.05033750e-04 4.73420745e-03 1.78987160e-02 1.10930744e-02\n",
            " 2.94292400e-03 1.48465450e-02 3.96363044e-03 1.71236884e-02\n",
            " 1.04726766e-02 8.13276526e-03 4.50823358e-03 6.13095552e-04\n",
            " 1.45435861e-03 1.31230305e-02 1.19032925e-03 1.89231879e-02\n",
            " 1.61791551e-02 7.39404863e-03 5.09233662e-03 1.62791643e-02\n",
            " 7.04240233e-04 4.56096709e-03 1.43714979e-02 1.92458593e-02\n",
            " 1.92327604e-02 1.19853087e-02 3.19513736e-04 7.70794671e-03\n",
            " 1.78939249e-03 7.68022720e-03 1.41487551e-02 1.13368124e-02\n",
            " 1.30798979e-02 5.71136500e-03 7.45927845e-03 8.58771045e-03\n",
            " 1.12529097e-02 1.49591465e-02 1.04435508e-02 2.26834806e-03\n",
            " 1.30697742e-02 3.66588168e-03 1.95704675e-02 1.18010018e-03\n",
            " 7.63455549e-03 1.90416825e-02 8.31750311e-03 8.94925054e-03\n",
            " 2.53163242e-04 1.13724144e-02 3.79445509e-03 1.67280266e-02\n",
            " 6.08330322e-03 3.90130749e-03 9.41339799e-03 1.85653530e-02\n",
            " 4.06713955e-04 2.67078792e-03 1.49419485e-02 1.60207347e-02\n",
            " 5.23042103e-04 8.36510216e-03 9.39327589e-03 2.02798766e-03\n",
            " 4.75438506e-03 1.57546457e-03 9.98131466e-03 1.88105083e-02\n",
            " 1.73953632e-02 1.54967618e-02 1.18683608e-02 1.02167086e-02\n",
            " 1.44595260e-02 7.02554386e-03 9.87111373e-03 1.05177413e-02\n",
            " 1.35147368e-04 7.10769067e-03 2.26255198e-03 3.31390520e-03\n",
            " 1.42385889e-02 1.71398448e-02 3.18915112e-03 4.75816816e-03\n",
            " 8.64016875e-03 1.84505915e-02 1.21658124e-02 4.17435114e-03\n",
            " 1.69207917e-02 6.46293005e-03 2.64055910e-03 1.86533953e-02\n",
            " 1.10506387e-02 9.77997258e-03 1.96490647e-03 5.77246949e-04\n",
            " 1.91892589e-02 2.73322066e-03 1.39111435e-02 1.42370751e-02\n",
            " 1.68013887e-02 1.75310031e-02 1.91355664e-02 4.25993437e-03\n",
            " 1.02768808e-02 1.42705575e-02 1.41741278e-02 1.86404307e-02\n",
            " 7.86660579e-03 3.95233316e-03 1.59685183e-02 6.27065476e-04\n",
            " 1.66692022e-02 1.69926366e-02 3.42964470e-03 6.47939332e-03\n",
            " 5.34665869e-03 8.06024463e-03 4.90313571e-03 1.63353808e-02\n",
            " 1.63869113e-02 1.63559006e-02 3.30771944e-04 2.71186068e-03\n",
            " 2.98697381e-03 8.01948997e-03 1.32162030e-02 1.42838829e-02\n",
            " 8.26752902e-03 2.20257059e-03 1.42451727e-02 1.71347125e-02\n",
            " 1.40861193e-03 1.12552373e-02 1.57023530e-02 2.45017853e-03\n",
            " 6.01063316e-03 1.06690501e-02 1.39511887e-02 1.15872459e-02\n",
            " 4.02571184e-03 1.40661575e-02 1.95926456e-02 1.15185029e-02\n",
            " 5.38669168e-03 8.70865223e-04 1.05615323e-02 6.78041287e-03\n",
            " 4.29364138e-03 1.53240186e-02 5.01357091e-03 3.82286519e-03\n",
            " 7.12841592e-03 5.18129422e-03 4.53854049e-03 2.84012590e-03\n",
            " 6.44612909e-03 1.86686494e-02 1.80391201e-02 1.06864565e-02\n",
            " 1.10195646e-03 6.68633134e-04 6.01394941e-03 1.35298627e-02\n",
            " 9.85987492e-04 2.07823745e-04 1.13911206e-02 9.65900946e-03\n",
            " 1.09636088e-02 1.29166925e-03 1.91861355e-02 1.61876293e-02\n",
            " 1.45649930e-03 2.10404176e-03 2.88252578e-03 7.71437696e-05\n",
            " 1.49507746e-02 3.78591054e-03 1.81841592e-02 5.48770107e-03\n",
            " 5.28638190e-03 2.28875294e-06 1.22672888e-02 6.67353296e-04\n",
            " 5.60293103e-07 1.96148680e-02 1.11471964e-02 1.94772913e-02\n",
            " 2.30897197e-05 1.72441654e-02 3.93898844e-05 1.35500677e-02\n",
            " 1.67825850e-02 1.05054670e-02 1.10522063e-02 1.52311979e-03\n",
            " 8.62757361e-04 1.14009766e-02 1.61242052e-02 4.51567623e-03\n",
            " 1.67183986e-02 1.57140817e-02 3.88122953e-03 1.44636241e-02\n",
            " 5.00090662e-03 1.07944747e-02 5.00090662e-03 7.49070182e-03\n",
            " 1.93661690e-02 1.84548220e-02 1.03187258e-03 7.31152002e-03\n",
            " 1.90697719e-03 1.78665162e-02 4.03377697e-03 3.10039528e-04\n",
            " 1.54247713e-02 3.91609827e-04 1.07555724e-02 1.43069698e-02\n",
            " 3.12929921e-03 1.39507915e-02 4.95041016e-03 1.80997651e-02\n",
            " 4.31588878e-03 2.46976720e-04 5.23949904e-03 6.22626328e-03\n",
            " 1.82570015e-02 6.57533340e-03 1.31996761e-02 1.57736300e-02\n",
            " 5.56451724e-03 1.70256241e-02 4.64049503e-03 4.88365827e-03\n",
            " 7.35780644e-03 1.93903632e-02 1.18039675e-02 3.05418428e-03\n",
            " 1.32007125e-02 1.51289590e-02 1.73521144e-02 1.09877639e-02\n",
            " 1.45834724e-02 5.53717925e-03 1.71349601e-02 5.88467556e-03\n",
            " 1.28218215e-02 1.91574367e-02 1.83525465e-02 1.95029968e-02\n",
            " 4.84180834e-03 3.88122953e-03 1.34800643e-02 1.41421500e-02\n",
            " 7.93190112e-03 1.07918296e-02 1.42590290e-03 1.26184680e-03\n",
            " 3.79726613e-03 1.58603479e-02 5.35291822e-03 4.02213464e-03\n",
            " 7.00532167e-04 1.73546833e-02 9.23139606e-03 1.10103319e-02\n",
            " 8.36665660e-03 5.60035005e-03 2.33966688e-03 7.51315049e-04\n",
            " 9.43662695e-03 1.91896603e-02 7.13215508e-03 7.53288670e-03\n",
            " 8.87451167e-03 1.93971731e-02 1.14330830e-02 9.84201273e-03\n",
            " 2.94059786e-03 1.53615277e-03 1.31025200e-03 1.44430644e-02\n",
            " 6.27789929e-03 9.91596679e-03 1.08996667e-02 7.29380538e-03\n",
            " 1.76889217e-02 8.68059185e-03 1.36136075e-02 4.24821799e-03\n",
            " 1.39201804e-02 8.05350771e-03 3.82601948e-03 9.05722264e-03\n",
            " 1.35059255e-02 1.84914685e-02 1.87481499e-02 1.93372603e-02\n",
            " 1.30337125e-02 3.16880808e-03 1.50747239e-02 1.33622190e-02\n",
            " 3.33920023e-03 8.96442589e-03 4.89472328e-04 9.26783507e-04\n",
            " 8.92098473e-03 1.42385889e-02 8.46359520e-03 2.71084696e-03\n",
            " 9.82488816e-03 6.11790719e-03 8.34513904e-03 1.67134679e-02\n",
            " 4.05236836e-04 5.70711315e-03 1.45153357e-02 7.57390160e-03\n",
            " 3.78770527e-03 1.05587678e-02 6.91480007e-03 3.57472106e-03\n",
            " 7.86883306e-03 1.53948488e-02 9.47186839e-03 9.71604466e-03\n",
            " 7.37097626e-03 1.71342654e-02 4.83198954e-03 5.71069650e-03\n",
            " 6.69617696e-03 8.52004654e-04 4.00917645e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3350 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.90347300e-03 4.45300378e-03 1.70104883e-02 1.71887746e-02\n",
            " 4.73345807e-03 4.07263526e-03 1.92971062e-02 1.52708494e-02\n",
            " 7.02376997e-04 1.27250564e-02 9.42914204e-03 4.10145984e-03\n",
            " 6.76256728e-03 1.26373477e-02 8.49687784e-03 1.60338962e-02\n",
            " 1.84826887e-02 1.16867078e-02 8.33834546e-03 1.03684691e-02\n",
            " 1.07520179e-02 1.21565123e-02 6.52158073e-03 1.45047827e-02\n",
            " 5.83132673e-03 1.84657999e-02 7.57066507e-03 5.59075325e-03\n",
            " 8.38722294e-03 1.48075826e-03 9.62686311e-03 5.04908370e-03\n",
            " 5.52318666e-03 1.84657999e-02 3.88118359e-03 1.43680694e-05\n",
            " 5.99937154e-03 1.29691639e-02 1.41011724e-02 1.53900509e-02\n",
            " 2.92788223e-03 1.10295692e-02 1.35840069e-02 1.81223974e-02\n",
            " 1.05249288e-04 9.73836467e-03 1.29691639e-02 1.28041344e-02\n",
            " 1.98742185e-03 5.89363021e-09 3.03280641e-03 1.97460132e-05\n",
            " 6.59988235e-03 1.26908459e-02 8.79377554e-03 4.49756785e-04\n",
            " 1.94200267e-07 1.14503055e-02 7.84990825e-03 7.31754523e-03\n",
            " 2.88182311e-03 7.73256763e-03 1.08473756e-02 9.81458814e-03\n",
            " 1.71926494e-02 5.59676153e-03 9.06368098e-03 2.22239947e-03\n",
            " 1.17712184e-02 1.87853288e-02 1.40495889e-02 9.59295517e-03\n",
            " 1.64464366e-02 1.84036003e-02 1.35965337e-02 1.89234304e-02\n",
            " 1.14517524e-02 1.13465341e-02 1.74714733e-02 1.05699122e-03\n",
            " 7.58214137e-03 1.92148391e-02 3.01332567e-03 1.64534325e-02\n",
            " 3.89642175e-04 1.72245992e-02 1.14150836e-03 1.48844916e-02\n",
            " 8.37024458e-03 3.39924074e-03 1.02183469e-02 1.81519726e-02\n",
            " 1.83436664e-02 1.88151519e-02 1.42954613e-02 9.81458814e-03\n",
            " 1.27224671e-02 4.22876794e-04 1.40703126e-02 7.52247514e-03\n",
            " 5.33823945e-03 5.10829684e-03 1.92971062e-02 1.18739224e-02\n",
            " 5.05902869e-04 1.13052420e-02 1.03283748e-02 4.31594853e-03\n",
            " 4.40933833e-03 1.19394436e-03 1.61411429e-02 5.91432066e-03\n",
            " 1.12188625e-02 1.90333997e-02 6.12244970e-04 1.07003698e-03\n",
            " 1.04836099e-02 5.56222337e-03 6.86593397e-05 3.78973474e-03\n",
            " 1.31351122e-02 1.82336492e-02 9.83745171e-03 1.09835600e-02\n",
            " 1.12343732e-02 1.88283054e-03 7.80182547e-03 1.90874037e-02\n",
            " 8.75574863e-03 7.10678283e-04 1.50071804e-02 2.12790403e-03\n",
            " 1.50037036e-02 1.09142872e-02 1.01431729e-02 1.47491862e-02\n",
            " 7.94143249e-03 1.74600248e-02 9.31058618e-03 1.85763569e-02\n",
            " 5.20319625e-03 1.28041344e-02 3.68405662e-03 7.37900165e-05\n",
            " 1.65043177e-02 9.28542785e-03 1.36961504e-02 4.17233333e-03\n",
            " 1.50077803e-02 1.87405183e-02 1.66058691e-02 3.68405662e-03\n",
            " 1.22116592e-02 1.20875764e-02 9.19343252e-03 1.47180527e-02\n",
            " 6.87227879e-03 1.01015082e-03 1.26896509e-02 1.52073416e-02\n",
            " 1.92775625e-02 9.69759288e-03 7.59163408e-03 1.20176830e-02\n",
            " 1.54671425e-03 1.80893449e-02 1.64425908e-02 1.30984879e-02\n",
            " 4.70464745e-05 1.72092941e-02 9.07733477e-03 1.49663627e-02\n",
            " 1.63602189e-02 4.75554558e-03 3.20739581e-03 1.03996635e-02\n",
            " 7.16551958e-03 1.72245992e-02 9.26993637e-03 4.71406936e-03\n",
            " 9.26096909e-03 1.08055443e-02 9.83662387e-03 1.01595538e-02\n",
            " 5.89363021e-09 4.03792692e-03 9.15800470e-03 1.52198038e-02\n",
            " 8.76947335e-03 1.12281577e-03 1.32081280e-02 1.33515327e-02\n",
            " 4.26957973e-03 1.48919540e-02 8.22578342e-03 1.85225826e-03\n",
            " 1.95180771e-02 7.85418422e-03 1.47051002e-02 2.16053268e-03\n",
            " 1.88920202e-02 7.62973298e-03 4.19736355e-03 1.18941489e-02\n",
            " 1.65678042e-02 8.90630520e-03 5.78981561e-03 5.59066648e-03\n",
            " 1.82491987e-02 6.69141411e-03 3.02441333e-03 8.49687784e-03\n",
            " 1.32010596e-02 1.32642511e-02 9.80554109e-03 5.33545984e-03\n",
            " 1.07806065e-02 4.31594853e-03 1.10295692e-02 9.74863265e-03\n",
            " 7.88807892e-03 1.25162621e-02 9.44647954e-03 5.79338473e-03\n",
            " 1.12098315e-02 7.90864500e-03 1.22359775e-02 1.84733398e-02\n",
            " 2.52589531e-03 1.37481399e-02 1.68342915e-04 4.21147055e-03\n",
            " 1.67334837e-02 1.06836387e-02 1.83880622e-02 1.13575779e-02\n",
            " 4.16242217e-03 1.02911168e-02 3.39737245e-03 1.42022883e-02\n",
            " 1.85185739e-02 6.28565015e-03 7.62916370e-03 1.04308864e-02\n",
            " 1.88783283e-02 5.42886859e-04 3.23009701e-03 1.13711599e-02\n",
            " 1.63602189e-02 1.53724384e-02 6.14620224e-03 1.33737247e-02\n",
            " 1.40305338e-06 1.17948390e-02 9.50410225e-05 8.44394465e-04\n",
            " 2.98375715e-03 1.28398957e-02 6.75387438e-03 3.06559310e-03\n",
            " 9.64969237e-03 5.27155509e-03 1.92435934e-02 4.35094914e-04\n",
            " 1.49161310e-02 5.36943144e-03 5.63843437e-03 1.29520696e-02\n",
            " 1.23028813e-03 1.37798567e-02 1.09152080e-02 8.85578235e-04\n",
            " 1.77036108e-02 4.62099469e-03 1.27250564e-02 6.87510648e-03\n",
            " 8.54373740e-03 5.61302427e-03 1.50611354e-02 6.11929459e-03\n",
            " 1.47287502e-02 4.58382294e-03 1.88920202e-02 5.76278148e-03\n",
            " 1.83796180e-02 5.48280415e-03 3.41697221e-03 7.91808837e-03\n",
            " 4.31594853e-03 1.65748065e-02 1.01774773e-02 1.77195929e-02\n",
            " 7.99343361e-03 3.75238555e-03 1.74490731e-02 1.27162975e-03\n",
            " 1.54516974e-03 1.68257983e-02 9.27145292e-03 4.20124698e-03\n",
            " 1.02282153e-02 1.21925124e-02 1.60195617e-03 5.29675612e-03\n",
            " 9.37746382e-03 1.73840007e-02 1.00997509e-04 8.26272814e-03\n",
            " 1.74414983e-02 3.92771882e-16 3.16927870e-03 1.59656104e-02\n",
            " 1.50546805e-02 6.19367675e-03 1.30694800e-02 1.93984475e-02\n",
            " 1.08080104e-02 1.86621255e-02 1.44749558e-02 1.16706094e-02\n",
            " 1.70668323e-02 2.47723647e-04 8.25203301e-03 1.93118281e-02\n",
            " 1.04953755e-02 1.59287043e-02 1.02911168e-02 7.58214137e-03\n",
            " 2.93290168e-03 4.14658056e-03 3.24416203e-03 1.20176830e-02\n",
            " 2.15953149e-03 1.65606365e-02 3.78414482e-03 1.27037849e-02\n",
            " 6.89197072e-03 7.42663357e-03 1.70804523e-03 2.65370382e-04\n",
            " 7.23664263e-03 1.33022097e-02 4.83456104e-03 6.79373207e-03\n",
            " 1.23504686e-02 4.17167210e-03 4.27009709e-04 1.44572143e-02\n",
            " 8.69837820e-03 1.88242167e-02 2.07655070e-03 4.55160045e-03\n",
            " 3.54727574e-03 7.12703382e-03 7.90146384e-03 1.83627095e-04\n",
            " 4.55470743e-03 1.54290927e-02 3.63370179e-03 8.55966399e-03\n",
            " 1.44668256e-02 4.87893872e-03 3.29632371e-03 9.33795115e-03\n",
            " 9.22378312e-03 6.91238104e-03 1.38996239e-02 1.71379364e-02\n",
            " 4.83726098e-03 9.52902571e-03 5.59075325e-03 9.92593281e-03\n",
            " 1.45319324e-02 4.95958032e-03 1.01141273e-02 2.04689692e-04\n",
            " 9.44725641e-03 1.21238078e-02 1.73518085e-03 8.44721658e-03\n",
            " 1.00888972e-02 8.12881995e-03 1.92605413e-02 6.95695722e-03\n",
            " 3.78973474e-03 1.37526890e-03 1.25307954e-02 3.01726558e-03\n",
            " 2.01808863e-03 1.57101916e-02 1.47217446e-02 1.41331818e-02\n",
            " 1.30465480e-03 4.88843372e-03 1.59454248e-02 1.78774312e-03\n",
            " 1.79491465e-02 5.79338473e-03 4.04184535e-03 1.66700333e-02\n",
            " 1.35446237e-02 1.55640487e-03 1.19406320e-02 7.74293399e-03\n",
            " 3.16306157e-03 3.15184884e-03 6.49938065e-03 2.25957587e-03\n",
            " 1.44405184e-02 1.84910159e-02 4.92428780e-06 1.24701063e-02\n",
            " 8.48570025e-04 1.50871991e-02 3.91449466e-03 1.27296168e-03\n",
            " 1.10073774e-02 1.04533028e-02 1.12572513e-05 1.07408628e-02\n",
            " 1.11734993e-02 1.49036915e-02 2.39489311e-03 1.85134637e-04\n",
            " 9.09968412e-03 1.38996239e-02 3.84445229e-03 3.14108150e-03\n",
            " 9.19247463e-03 1.78919500e-03 7.74322849e-04 2.16549165e-03\n",
            " 1.48257268e-02 6.51757979e-04 2.14003862e-03 1.12051786e-03\n",
            " 1.58091900e-02 3.76206399e-03 1.54662336e-02 1.43756382e-02\n",
            " 1.11807252e-02 7.89962117e-03 5.57768369e-05 1.36768020e-02\n",
            " 5.93841524e-04 1.12299384e-02 9.03718335e-04 1.23780634e-02\n",
            " 1.06321273e-02 1.88783283e-02 1.28829825e-02 1.01913477e-02\n",
            " 1.27747233e-02 1.39751652e-02 1.42081875e-02 9.81458814e-03\n",
            " 9.64414222e-03 5.44684361e-03 1.84395387e-02 8.41375560e-03\n",
            " 8.73326915e-03 8.15794884e-03 9.91232406e-03 1.78919500e-03\n",
            " 1.56027878e-02 1.93959602e-02 1.14070588e-02 1.08236687e-02\n",
            " 1.72880250e-02 2.18785568e-03 1.21158238e-02 3.30227878e-03\n",
            " 9.92625616e-03 1.73140743e-02 4.98607795e-03 1.93367200e-02\n",
            " 1.07147579e-02 1.91432249e-03 1.30496495e-02 4.09549157e-03\n",
            " 1.19187736e-02 1.66857154e-02 1.59458491e-02 7.75216336e-03\n",
            " 1.25379466e-02 1.25812423e-02 4.54488766e-03 9.33829524e-03\n",
            " 5.71784655e-04 2.92768462e-03 9.50951378e-03 3.83992716e-03\n",
            " 1.76602717e-02 7.74451663e-03 1.76214732e-02 8.06050669e-03\n",
            " 2.04689692e-04 4.73415279e-03 1.77562805e-02 1.11037127e-02\n",
            " 2.92465124e-03 1.48279603e-02 3.95739206e-03 1.70964757e-02\n",
            " 1.04633972e-02 8.12391480e-03 4.51188177e-03 6.07714436e-04\n",
            " 1.44959454e-03 1.31093019e-02 1.18815808e-03 1.89496250e-02\n",
            " 1.61304248e-02 7.30461363e-03 5.07271624e-03 1.62622546e-02\n",
            " 7.02376997e-04 4.55227486e-03 1.43537012e-02 1.91928926e-02\n",
            " 1.92335036e-02 1.19281754e-02 3.19221752e-04 7.72001337e-03\n",
            " 1.78919500e-03 7.66521508e-03 1.41337079e-02 1.13286693e-02\n",
            " 1.30946939e-02 5.71872215e-03 7.45213513e-03 8.57589693e-03\n",
            " 1.11639403e-02 1.49347273e-02 1.04331686e-02 2.26742886e-03\n",
            " 1.30203197e-02 3.66510811e-03 1.94598834e-02 1.17827798e-03\n",
            " 7.63655427e-03 1.90402153e-02 8.29361397e-03 8.93296326e-03\n",
            " 2.51980393e-04 1.11875044e-02 3.78973474e-03 1.67144868e-02\n",
            " 6.07728232e-03 3.91449466e-03 9.38607649e-03 1.85726184e-02\n",
            " 4.07132022e-04 2.65432278e-03 1.49403386e-02 1.59983619e-02\n",
            " 5.21884734e-04 8.36919037e-03 9.31768938e-03 2.02877126e-03\n",
            " 4.76496141e-03 1.57328274e-03 9.97124378e-03 1.87927474e-02\n",
            " 1.73786118e-02 1.54738989e-02 1.18205785e-02 1.01837606e-02\n",
            " 1.44598566e-02 7.03244024e-03 9.86336940e-03 1.05041982e-02\n",
            " 1.35422802e-04 7.10688131e-03 2.26140042e-03 3.30795561e-03\n",
            " 1.42101083e-02 1.71379364e-02 3.18753673e-03 4.75554558e-03\n",
            " 8.64103334e-03 1.84188325e-02 1.21762425e-02 4.17233333e-03\n",
            " 1.69463904e-02 6.46376228e-03 2.61173451e-03 1.86616990e-02\n",
            " 1.08137465e-02 9.77768412e-03 1.95254099e-03 5.77012979e-04\n",
            " 1.91959236e-02 2.73662523e-03 1.39096112e-02 1.42272770e-02\n",
            " 1.68125677e-02 1.74490731e-02 1.92056143e-02 4.25079339e-03\n",
            " 1.02419027e-02 1.42022883e-02 1.41379713e-02 1.85961104e-02\n",
            " 7.85311848e-03 3.94925627e-03 1.59574288e-02 6.25117727e-04\n",
            " 1.66496094e-02 1.69667227e-02 3.42512470e-03 6.44348439e-03\n",
            " 5.31080657e-03 8.06123317e-03 4.87030073e-03 1.63602189e-02\n",
            " 1.62934239e-02 1.63436513e-02 3.30539682e-04 2.68323466e-03\n",
            " 2.98424360e-03 8.00439434e-03 1.32357755e-02 1.42771179e-02\n",
            " 8.20867673e-03 2.18785568e-03 1.42253816e-02 1.71472088e-02\n",
            " 1.40737741e-03 1.12472642e-02 1.56749586e-02 2.44273754e-03\n",
            " 5.99329501e-03 1.06683702e-02 1.39436021e-02 1.16147034e-02\n",
            " 4.02734107e-03 1.40245685e-02 1.15038822e-02 5.37619450e-03\n",
            " 8.62204589e-04 1.05340977e-02 6.77024249e-03 4.27710752e-03\n",
            " 1.53201564e-02 5.02846913e-03 3.77868648e-03 7.13052230e-03\n",
            " 5.14770937e-03 4.54206450e-03 2.83549351e-03 6.45267200e-03\n",
            " 1.86558437e-02 1.80145988e-02 1.06730765e-02 1.09363434e-03\n",
            " 6.68775457e-04 5.99937154e-03 1.35256407e-02 9.85978788e-04\n",
            " 2.07807122e-04 1.13799545e-02 9.63678584e-03 1.09338182e-02\n",
            " 1.28758170e-03 1.92115836e-02 1.61569306e-02 1.45217796e-03\n",
            " 2.07047868e-03 2.88182311e-03 7.68797480e-05 1.49496143e-02\n",
            " 3.78070173e-03 1.81677738e-02 5.50918005e-03 5.28321797e-03\n",
            " 2.25723733e-06 1.22096217e-02 6.64238882e-04 5.51546931e-07\n",
            " 1.10996260e-02 1.94726571e-02 2.28269756e-05 1.71666423e-02\n",
            " 3.91455957e-05 1.35312342e-02 1.67673324e-02 1.05074860e-02\n",
            " 1.10132065e-02 1.52184383e-03 8.61752929e-04 1.13814563e-02\n",
            " 1.61056522e-02 4.52429554e-03 1.66218856e-02 1.57129409e-02\n",
            " 3.88118359e-03 1.44666705e-02 4.99425904e-03 1.07684874e-02\n",
            " 4.99425904e-03 7.43884071e-03 1.93021255e-02 1.84599217e-02\n",
            " 1.03106567e-03 7.25240166e-03 1.90746258e-03 1.78661935e-02\n",
            " 4.01363435e-03 3.08387045e-04 1.54111064e-02 3.91683766e-04\n",
            " 1.07378263e-02 1.42943358e-02 3.10598372e-03 1.39407409e-02\n",
            " 4.94489970e-03 1.80464169e-02 4.31683503e-03 2.46590797e-04\n",
            " 5.23772850e-03 6.22457283e-03 1.82195335e-02 6.58925853e-03\n",
            " 1.31933776e-02 1.57844259e-02 5.57390449e-03 1.70493924e-02\n",
            " 4.64665764e-03 4.87893872e-03 7.26422909e-03 1.92971062e-02\n",
            " 1.17722713e-02 3.04796089e-03 1.32038984e-02 1.51117459e-02\n",
            " 1.73487668e-02 1.09605018e-02 1.46081154e-02 5.50350472e-03\n",
            " 1.71180892e-02 5.86279547e-03 1.28229313e-02 1.91475554e-02\n",
            " 1.82953843e-02 1.93648800e-02 4.83284501e-03 3.88118359e-03\n",
            " 1.34642174e-02 1.40742672e-02 7.87370629e-03 1.07485101e-02\n",
            " 1.40633363e-03 1.25072511e-03 3.77122135e-03 1.58717284e-02\n",
            " 5.34909759e-03 4.01772767e-03 7.01743264e-04 1.73281592e-02\n",
            " 9.20745372e-03 1.10000661e-02 8.32831408e-03 5.58700380e-03\n",
            " 2.34352375e-03 7.46266378e-04 9.41758434e-03 1.91946656e-02\n",
            " 7.14261938e-03 7.53419912e-03 8.88284433e-03 1.93676672e-02\n",
            " 1.13636696e-02 9.85617995e-03 2.93200792e-03 1.53481733e-03\n",
            " 1.30690641e-03 1.44056232e-02 6.27994706e-03 9.88076706e-03\n",
            " 1.09073117e-02 7.27802367e-03 1.76420892e-02 8.68268243e-03\n",
            " 1.35996612e-02 4.25038589e-03 1.39353229e-02 8.04828397e-03\n",
            " 3.83047523e-03 9.05374768e-03 1.34796329e-02 1.84826887e-02\n",
            " 1.87369172e-02 1.93123392e-02 1.30250496e-02 3.16375514e-03\n",
            " 1.50593570e-02 1.33352406e-02 3.33645928e-03 8.96507667e-03\n",
            " 4.90079693e-04 9.25736819e-04 8.91705175e-03 1.42101083e-02\n",
            " 8.46971326e-03 2.70530176e-03 9.81458814e-03 6.13168407e-03\n",
            " 8.31651381e-03 1.67138654e-02 4.05705231e-04 5.66606370e-03\n",
            " 1.45104841e-02 7.57472832e-03 3.75857415e-03 1.05576638e-02\n",
            " 6.88941932e-03 3.57023390e-03 7.86331953e-03 1.53900509e-02\n",
            " 9.40450274e-03 9.71934748e-03 7.34603557e-03 1.70614509e-02\n",
            " 4.82063351e-03 5.70818089e-03 6.68600544e-03 8.48570025e-04\n",
            " 3.99447427e-03]\n",
            "3360 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.89659541e-03 4.45337128e-03 1.69598605e-02 1.72154361e-02\n",
            " 4.73906264e-03 4.02967615e-03 1.92767117e-02 1.52386410e-02\n",
            " 7.01652146e-04 1.26636606e-02 9.39258366e-03 4.08417401e-03\n",
            " 6.77228303e-03 1.26267207e-02 8.44826517e-03 1.60339195e-02\n",
            " 1.84725210e-02 1.16312351e-02 8.31443501e-03 1.03711931e-02\n",
            " 1.07099431e-02 1.21488199e-02 6.48045588e-03 1.44836121e-02\n",
            " 5.83388083e-03 1.84064335e-02 7.57860130e-03 5.59269567e-03\n",
            " 8.34839742e-03 1.47183578e-03 9.55304600e-03 5.04884615e-03\n",
            " 5.51287509e-03 1.84064335e-02 3.87824868e-03 1.43042933e-05\n",
            " 6.00077089e-03 1.29717422e-02 1.40336758e-02 1.53659614e-02\n",
            " 2.93217212e-03 1.10133344e-02 1.35971373e-02 1.81291494e-02\n",
            " 1.04715855e-04 9.74173127e-03 1.29717422e-02 1.27660117e-02\n",
            " 1.97155216e-03 5.77413879e-09 3.01748419e-03 1.92139457e-05\n",
            " 6.59340771e-03 1.26822341e-02 8.80653805e-03 4.46004594e-04\n",
            " 1.91599415e-07 1.14277221e-02 7.80985731e-03 7.30170898e-03\n",
            " 2.87828877e-03 7.73287364e-03 1.08444320e-02 9.80867943e-03\n",
            " 1.71162819e-02 5.59837665e-03 9.05432597e-03 2.21743190e-03\n",
            " 1.17698153e-02 1.87550712e-02 1.39800315e-02 9.56392023e-03\n",
            " 1.64262661e-02 1.83533820e-02 1.36131039e-02 1.88589859e-02\n",
            " 1.14458319e-02 1.12885835e-02 1.74518307e-02 1.05157705e-03\n",
            " 7.58156833e-03 1.92418967e-02 3.00217581e-03 1.64269953e-02\n",
            " 3.85681649e-04 1.72215286e-02 1.13849008e-03 1.48170200e-02\n",
            " 8.34205985e-03 3.39218460e-03 1.01581972e-02 1.80873659e-02\n",
            " 1.83085991e-02 1.88152131e-02 1.42814163e-02 9.80867943e-03\n",
            " 1.27097416e-02 4.22418563e-04 1.40087054e-02 7.53377502e-03\n",
            " 5.32574765e-03 5.08542287e-03 1.92767117e-02 1.18557201e-02\n",
            " 5.03361620e-04 1.12921597e-02 1.02899584e-02 4.31087596e-03\n",
            " 4.38876079e-03 1.18449796e-03 1.60752000e-02 5.89359123e-03\n",
            " 1.12296582e-02 1.89314313e-02 6.10476714e-04 1.06702930e-03\n",
            " 1.04850413e-02 5.55699311e-03 6.83034781e-05 3.78341632e-03\n",
            " 1.30723853e-02 1.82130323e-02 9.81503374e-03 1.09828369e-02\n",
            " 1.12247410e-02 1.88276070e-03 7.78049933e-03 1.90907104e-02\n",
            " 8.71224889e-03 7.04491310e-04 1.49375023e-02 2.11799088e-03\n",
            " 1.49892581e-02 1.08975196e-02 1.01241742e-02 1.47204879e-02\n",
            " 7.90492175e-03 1.74233018e-02 9.24235975e-03 1.84975868e-02\n",
            " 5.18796112e-03 1.27660117e-02 3.68084688e-03 7.33256759e-05\n",
            " 1.64809512e-02 9.26666595e-03 1.35681738e-02 4.13497989e-03\n",
            " 1.49835329e-02 1.87322588e-02 1.65695412e-02 3.68084688e-03\n",
            " 1.22230903e-02 1.20643631e-02 9.20024179e-03 1.46901790e-02\n",
            " 6.87386943e-03 1.00849207e-03 1.26833275e-02 1.52052169e-02\n",
            " 1.91779227e-02 9.67803614e-03 7.58011857e-03 1.20078038e-02\n",
            " 1.54686841e-03 1.80709289e-02 1.62905865e-02 1.30910058e-02\n",
            " 4.60075891e-05 1.71146385e-02 9.03597227e-03 1.49590910e-02\n",
            " 1.62979233e-02 4.74948321e-03 3.18636509e-03 1.04029065e-02\n",
            " 7.17115392e-03 1.72215286e-02 9.23772389e-03 4.66472828e-03\n",
            " 9.25109816e-03 1.07829492e-02 9.83548302e-03 1.01215623e-02\n",
            " 5.77413879e-09 4.02077382e-03 9.14769172e-03 1.51803714e-02\n",
            " 8.76176159e-03 1.11971313e-03 1.31364101e-02 1.33253951e-02\n",
            " 4.24834838e-03 1.48424038e-02 8.21835529e-03 1.83746989e-03\n",
            " 7.81661346e-03 1.47057102e-02 2.16170536e-03 1.88767874e-02\n",
            " 7.61916632e-03 4.19585174e-03 1.18767811e-02 1.65609915e-02\n",
            " 8.88730106e-03 5.77918958e-03 5.55907578e-03 1.82439716e-02\n",
            " 6.68704011e-03 3.02398436e-03 8.44826517e-03 1.31640921e-02\n",
            " 1.32462095e-02 9.78728788e-03 5.32063579e-03 1.07427726e-02\n",
            " 4.31087596e-03 1.10133344e-02 9.71230418e-03 7.83632471e-03\n",
            " 1.24532083e-02 9.42779925e-03 5.80408646e-03 1.11680114e-02\n",
            " 7.87306316e-03 1.22151063e-02 1.83943854e-02 2.52563956e-03\n",
            " 1.37194141e-02 1.67645645e-04 4.19691163e-03 1.67244733e-02\n",
            " 1.06092709e-02 1.83916751e-02 1.13385286e-02 4.16916122e-03\n",
            " 1.02657077e-02 3.39697728e-03 1.41512582e-02 1.85078157e-02\n",
            " 6.26138960e-03 7.59135631e-03 1.03953298e-02 1.88732853e-02\n",
            " 5.43615280e-04 3.20667202e-03 1.13162740e-02 1.62979233e-02\n",
            " 1.52930698e-02 6.13786783e-03 1.33550037e-02 1.39924944e-06\n",
            " 1.17741720e-02 9.38375733e-05 8.44349138e-04 2.97678820e-03\n",
            " 1.28120896e-02 6.71960538e-03 3.04410305e-03 9.66033405e-03\n",
            " 5.24152718e-03 1.92446441e-02 4.34624285e-04 1.48776372e-02\n",
            " 5.35687584e-03 5.62673175e-03 1.29256037e-02 1.22286181e-03\n",
            " 1.37651117e-02 1.08761609e-02 8.82099180e-04 1.77113771e-02\n",
            " 4.60288453e-03 1.26636606e-02 6.85906557e-03 8.52230814e-03\n",
            " 5.58559106e-03 1.49782470e-02 6.08619664e-03 1.47052897e-02\n",
            " 4.54518833e-03 1.88767874e-02 5.75934483e-03 1.83812514e-02\n",
            " 5.46756119e-03 3.40133724e-03 7.89683821e-03 4.31087596e-03\n",
            " 1.65282495e-02 1.01595413e-02 1.77304841e-02 7.96674519e-03\n",
            " 3.75450260e-03 1.73917826e-02 1.26690055e-03 1.53023557e-03\n",
            " 1.67618928e-02 9.23273486e-03 4.19490731e-03 1.02097750e-02\n",
            " 1.21669218e-02 1.59569677e-03 5.27080415e-03 9.35733555e-03\n",
            " 1.73591818e-02 1.00812671e-04 8.25992341e-03 1.74235056e-02\n",
            " 3.58802524e-16 3.16563466e-03 1.58961319e-02 1.49341164e-02\n",
            " 6.19249952e-03 1.30433871e-02 1.07884849e-02 1.86458706e-02\n",
            " 1.44418522e-02 1.16580717e-02 1.70755582e-02 2.45656055e-04\n",
            " 8.24878245e-03 1.04279652e-02 1.58644871e-02 1.02657077e-02\n",
            " 7.58156833e-03 2.92748494e-03 4.13038027e-03 3.23464144e-03\n",
            " 1.20078038e-02 2.16208646e-03 1.65069432e-02 3.75831795e-03\n",
            " 1.26780037e-02 6.87775323e-03 7.40961574e-03 1.69058931e-03\n",
            " 2.64858127e-04 7.23714894e-03 1.32384970e-02 4.83771659e-03\n",
            " 6.77865547e-03 1.22911909e-02 4.11637174e-03 4.21297557e-04\n",
            " 1.43762911e-02 8.65749810e-03 1.88102064e-02 2.07813939e-03\n",
            " 4.55259894e-03 3.52083680e-03 7.11482829e-03 7.89803470e-03\n",
            " 1.82693293e-04 4.55805032e-03 1.54199608e-02 3.61902588e-03\n",
            " 8.53650934e-03 1.44744006e-02 4.88089197e-03 3.28363358e-03\n",
            " 9.30308538e-03 9.20055713e-03 6.90717669e-03 1.38346748e-02\n",
            " 1.71412714e-02 4.81389108e-03 9.52869986e-03 5.59269567e-03\n",
            " 9.93473903e-03 1.45208547e-02 4.93789473e-03 1.01176619e-02\n",
            " 2.03490079e-04 9.41228729e-03 1.19746122e-02 1.73140391e-03\n",
            " 8.42062705e-03 1.00528177e-02 8.12234316e-03 1.92502898e-02\n",
            " 6.92100465e-03 3.78341632e-03 1.36494848e-03 1.25057537e-02\n",
            " 2.99828667e-03 2.01840327e-03 1.56886897e-02 1.47051891e-02\n",
            " 1.40425266e-02 1.30453453e-03 4.86752466e-03 1.59364496e-02\n",
            " 1.77250175e-03 1.79034597e-02 5.80408646e-03 4.02462990e-03\n",
            " 1.66757762e-02 1.35312213e-02 1.55083828e-03 1.19266999e-02\n",
            " 7.72903856e-03 3.16063465e-03 3.14172287e-03 6.47982391e-03\n",
            " 2.25318523e-03 1.43906516e-02 1.84662278e-02 4.81416127e-06\n",
            " 1.24378352e-02 8.43828344e-04 1.50023006e-02 3.90736012e-03\n",
            " 1.27183309e-03 1.09804076e-02 1.04179812e-02 1.11712965e-05\n",
            " 1.06877440e-02 1.11042680e-02 1.48925567e-02 2.38462007e-03\n",
            " 1.84463768e-04 9.10365616e-03 1.38346748e-02 3.83684661e-03\n",
            " 3.14627187e-03 9.12102602e-03 1.76907780e-03 7.76376627e-04\n",
            " 2.15459135e-03 1.47771342e-02 6.52555591e-04 2.12795933e-03\n",
            " 1.11998076e-03 1.58155900e-02 3.75608572e-03 1.54106821e-02\n",
            " 1.43710851e-02 1.11759163e-02 7.87760154e-03 5.56168687e-05\n",
            " 1.36592575e-02 5.92859667e-04 1.11694734e-02 8.92062549e-04\n",
            " 1.23181016e-02 1.06247739e-02 1.88732853e-02 1.28790389e-02\n",
            " 1.01491320e-02 1.27344966e-02 1.39771442e-02 1.41953199e-02\n",
            " 9.80867943e-03 9.64473392e-03 5.44754447e-03 1.84332864e-02\n",
            " 8.37395261e-03 8.66004560e-03 8.16362805e-03 9.89011416e-03\n",
            " 1.76907780e-03 1.56062054e-02 1.13790781e-02 1.08229738e-02\n",
            " 1.72587485e-02 2.17592033e-03 1.20844584e-02 3.29570288e-03\n",
            " 9.86380714e-03 1.71805583e-02 4.98577190e-03 1.06506424e-02\n",
            " 1.90872923e-03 1.30162113e-02 4.07680549e-03 1.18520783e-02\n",
            " 1.66731221e-02 1.59354091e-02 7.74313487e-03 1.24842835e-02\n",
            " 1.25500291e-02 4.49451446e-03 9.29935826e-03 5.69755040e-04\n",
            " 2.88664202e-03 9.50789289e-03 3.82481477e-03 1.76114720e-02\n",
            " 7.71666862e-03 1.76295346e-02 8.03969969e-03 2.03490079e-04\n",
            " 4.71718187e-03 1.77339379e-02 1.11173617e-02 2.91753302e-03\n",
            " 1.48019961e-02 3.94470499e-03 1.70621423e-02 1.04026210e-02\n",
            " 8.12514981e-03 4.51066331e-03 6.00644770e-04 1.44589629e-03\n",
            " 1.30963836e-02 1.18680434e-03 1.89349842e-02 1.60715481e-02\n",
            " 7.29698604e-03 5.04429238e-03 1.62084135e-02 7.01652146e-04\n",
            " 4.50818425e-03 1.43233981e-02 1.91587509e-02 1.92203624e-02\n",
            " 1.18991434e-02 3.17547841e-04 7.71485965e-03 1.76907780e-03\n",
            " 7.61543230e-03 1.40916474e-02 1.13005377e-02 1.30869394e-02\n",
            " 5.71918985e-03 7.44898535e-03 8.57485793e-03 1.11143705e-02\n",
            " 1.49117131e-02 1.04195332e-02 2.26581284e-03 1.30307064e-02\n",
            " 3.64839084e-03 1.16871774e-03 7.63210318e-03 1.90299720e-02\n",
            " 8.27528362e-03 8.92919370e-03 2.51265064e-04 1.11310165e-02\n",
            " 3.78341632e-03 1.67062832e-02 6.08234413e-03 3.90736012e-03\n",
            " 9.39008898e-03 1.85370132e-02 4.07364998e-04 2.63900817e-03\n",
            " 1.49568667e-02 1.59425497e-02 5.21181195e-04 8.36147263e-03\n",
            " 9.29345603e-03 2.02913353e-03 4.75046270e-03 1.57529933e-03\n",
            " 9.96249495e-03 1.87325521e-02 1.73530532e-02 1.54795511e-02\n",
            " 1.17973323e-02 1.01682338e-02 1.44670395e-02 7.03574888e-03\n",
            " 9.86185214e-03 1.04519870e-02 1.35370564e-04 7.10420591e-03\n",
            " 2.24906160e-03 3.30363633e-03 1.41994346e-02 1.71412714e-02\n",
            " 3.17699475e-03 4.74948321e-03 8.64016951e-03 1.83884602e-02\n",
            " 1.21405777e-02 4.13497989e-03 1.69131896e-02 6.45474259e-03\n",
            " 2.57560500e-03 1.85997717e-02 1.07914089e-02 9.75198978e-03\n",
            " 1.94912346e-03 5.68749433e-04 1.91908530e-02 2.72156395e-03\n",
            " 1.38991528e-02 1.42065260e-02 1.67865905e-02 1.73917826e-02\n",
            " 1.91897362e-02 4.25072438e-03 1.02336453e-02 1.41512582e-02\n",
            " 1.41475487e-02 1.85709743e-02 7.85479852e-03 3.94596346e-03\n",
            " 1.59215495e-02 6.21827891e-04 1.66397766e-02 1.69435743e-02\n",
            " 3.41570348e-03 6.45100375e-03 5.26860923e-03 8.04407636e-03\n",
            " 4.86571504e-03 1.62979233e-02 1.62130696e-02 1.63197539e-02\n",
            " 3.28776588e-04 2.68296579e-03 2.96260264e-03 8.01550294e-03\n",
            " 1.31136478e-02 1.42114118e-02 8.17732761e-03 2.17592033e-03\n",
            " 1.41566493e-02 1.71333440e-02 1.40568286e-03 1.12127445e-02\n",
            " 1.56481698e-02 2.44061486e-03 5.98062357e-03 1.06102384e-02\n",
            " 1.39322849e-02 1.16363281e-02 4.02352391e-03 1.40166351e-02\n",
            " 1.14465950e-02 5.35885332e-03 8.62262884e-04 1.05415335e-02\n",
            " 6.75722656e-03 4.26790940e-03 1.53292173e-02 5.02531576e-03\n",
            " 3.77198944e-03 7.12875414e-03 5.14049722e-03 4.53695547e-03\n",
            " 2.83170392e-03 6.43511954e-03 1.86491836e-02 1.80128887e-02\n",
            " 1.06455741e-02 1.08664372e-03 6.67794736e-04 6.00077089e-03\n",
            " 1.35307315e-02 9.72304578e-04 2.07346817e-04 1.13879924e-02\n",
            " 9.62850747e-03 1.09238250e-02 1.27916478e-03 1.91933977e-02\n",
            " 1.60708092e-02 1.45223830e-03 2.07395559e-03 2.87828877e-03\n",
            " 7.56613945e-05 1.49029358e-02 3.77865733e-03 1.81350316e-02\n",
            " 5.47798262e-03 5.23485929e-03 2.23998903e-06 1.21655959e-02\n",
            " 6.65053630e-04 5.48274550e-07 1.10975197e-02 2.26013746e-05\n",
            " 1.71698539e-02 3.90831797e-05 1.34896035e-02 1.67680015e-02\n",
            " 1.04767015e-02 1.10196967e-02 1.51395303e-03 8.60147064e-04\n",
            " 1.13601870e-02 1.59796881e-02 4.51635978e-03 1.66351189e-02\n",
            " 1.56711028e-02 3.87824868e-03 1.44453348e-02 4.98782644e-03\n",
            " 1.07802827e-02 4.98782644e-03 7.41997348e-03 1.92435104e-02\n",
            " 1.83969342e-02 1.02932072e-03 7.24371272e-03 1.90493660e-03\n",
            " 1.78429825e-02 3.98929145e-03 3.01027045e-04 1.53912795e-02\n",
            " 3.88118439e-04 1.07411288e-02 1.42899637e-02 3.09853478e-03\n",
            " 1.39494185e-02 4.92634651e-03 1.80494159e-02 4.29806954e-03\n",
            " 2.44428593e-04 5.22666690e-03 6.20748037e-03 1.81635192e-02\n",
            " 6.59474803e-03 1.31763274e-02 1.57937484e-02 5.55218641e-03\n",
            " 1.70655422e-02 4.64228425e-03 4.88089197e-03 7.27388232e-03\n",
            " 1.92767117e-02 1.17601951e-02 3.02568069e-03 1.31616905e-02\n",
            " 1.51022544e-02 1.72661227e-02 1.08961726e-02 1.45843481e-02\n",
            " 5.50168414e-03 1.70600144e-02 5.86483973e-03 1.27900479e-02\n",
            " 1.91388195e-02 1.82908425e-02 4.82186766e-03 3.87824868e-03\n",
            " 1.34608362e-02 1.40823685e-02 7.87023708e-03 1.07338391e-02\n",
            " 1.39528181e-03 1.25000250e-03 3.76471855e-03 1.58549245e-02\n",
            " 5.35156986e-03 4.03029955e-03 6.92678570e-04 1.73298429e-02\n",
            " 9.20727901e-03 1.10006830e-02 8.31497574e-03 5.58502103e-03\n",
            " 2.31790389e-03 7.41261053e-04 9.42099920e-03 1.92004365e-02\n",
            " 7.14465075e-03 7.50679771e-03 8.84349563e-03 1.13312776e-02\n",
            " 9.84140336e-03 2.91871516e-03 1.52563769e-03 1.30442950e-03\n",
            " 1.43962128e-02 6.26871752e-03 9.85908481e-03 1.08744283e-02\n",
            " 7.22971692e-03 1.76203707e-02 8.66469822e-03 1.36127356e-02\n",
            " 4.23991469e-03 1.39262499e-02 8.02640498e-03 3.82276970e-03\n",
            " 8.99154488e-03 1.34657081e-02 1.84725210e-02 1.87301385e-02\n",
            " 1.30105595e-02 3.14473443e-03 1.50478767e-02 1.33081281e-02\n",
            " 3.33627588e-03 8.95304631e-03 4.89293469e-04 9.23993433e-04\n",
            " 8.90821206e-03 1.41994346e-02 8.44295193e-03 2.69414141e-03\n",
            " 9.80867943e-03 6.11745572e-03 8.29396308e-03 1.67209291e-02\n",
            " 4.02306355e-04 5.62128788e-03 1.44894994e-02 7.55817264e-03\n",
            " 3.75948092e-03 1.05617839e-02 6.87766925e-03 3.56214862e-03\n",
            " 7.83071220e-03 1.53659614e-02 9.34959747e-03 9.68952688e-03\n",
            " 7.31523997e-03 1.69833954e-02 4.80644123e-03 5.70248920e-03\n",
            " 6.67595519e-03 8.43828344e-04 3.94707421e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3370 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.89117812e-03 4.45066611e-03 1.69461065e-02 1.71659341e-02\n",
            " 4.73215248e-03 4.02764526e-03 1.52318141e-02 7.01599627e-04\n",
            " 1.26416923e-02 9.40085257e-03 4.06516967e-03 6.72023545e-03\n",
            " 1.25887788e-02 8.44751846e-03 1.60093576e-02 1.84509118e-02\n",
            " 1.16173617e-02 8.29830298e-03 1.03459950e-02 1.07363886e-02\n",
            " 1.21120921e-02 6.48731107e-03 1.44440658e-02 5.79935960e-03\n",
            " 1.83323258e-02 7.52081910e-03 5.60880409e-03 8.31969471e-03\n",
            " 1.47068681e-03 9.55270309e-03 5.00189010e-03 5.50497704e-03\n",
            " 1.83323258e-02 3.87144683e-03 1.43251834e-05 6.00276329e-03\n",
            " 1.29536909e-02 1.40235324e-02 1.53263984e-02 2.93265261e-03\n",
            " 1.10068940e-02 1.36330540e-02 1.80902138e-02 1.04082432e-04\n",
            " 9.70583934e-03 1.29536909e-02 1.27551884e-02 1.97445342e-03\n",
            " 5.77851851e-09 3.01742112e-03 1.90984355e-05 6.58561643e-03\n",
            " 1.26423745e-02 8.80666486e-03 4.43678975e-04 1.91780140e-07\n",
            " 1.14262861e-02 7.80268988e-03 7.30299731e-03 2.87287930e-03\n",
            " 7.69121925e-03 1.08210550e-02 9.79728288e-03 1.70945711e-02\n",
            " 5.58379057e-03 9.02303904e-03 2.21414991e-03 1.17626990e-02\n",
            " 1.86949863e-02 1.39941666e-02 9.53705687e-03 1.63537594e-02\n",
            " 1.83170050e-02 1.35567584e-02 1.88738512e-02 1.14513055e-02\n",
            " 1.12821230e-02 1.73931878e-02 1.04147286e-03 7.57664216e-03\n",
            " 2.97604613e-03 1.64357798e-02 3.84110325e-04 1.72025263e-02\n",
            " 1.13647184e-03 1.47580744e-02 8.33208069e-03 3.39109078e-03\n",
            " 1.01502339e-02 1.80286893e-02 1.83429662e-02 1.87939893e-02\n",
            " 1.42520338e-02 9.79728288e-03 1.26704391e-02 4.24070788e-04\n",
            " 1.40053151e-02 7.52465254e-03 5.30344988e-03 5.07208387e-03\n",
            " 1.18187264e-02 5.00876355e-04 1.12412442e-02 1.02424452e-02\n",
            " 4.30920824e-03 4.35067772e-03 1.18569430e-03 1.60818883e-02\n",
            " 5.87999962e-03 1.12205590e-02 1.88809690e-02 6.09574632e-04\n",
            " 1.06656213e-03 1.03997968e-02 5.54770596e-03 6.84470669e-05\n",
            " 3.77723100e-03 1.30060383e-02 1.82003508e-02 9.80477759e-03\n",
            " 1.09887846e-02 1.12105798e-02 1.87799240e-03 7.78093737e-03\n",
            " 1.90689737e-02 8.70543563e-03 6.89810135e-04 1.49382154e-02\n",
            " 2.11353559e-03 1.49881545e-02 1.08905962e-02 1.01291282e-02\n",
            " 1.46509633e-02 7.89682623e-03 1.73995687e-02 9.20772148e-03\n",
            " 1.85036506e-02 5.20755249e-03 1.27551884e-02 3.67776917e-03\n",
            " 7.24605832e-05 1.64701433e-02 9.26568708e-03 1.35717325e-02\n",
            " 4.13858652e-03 1.49328481e-02 1.87345874e-02 1.65375846e-02\n",
            " 3.67776917e-03 1.20894857e-02 1.20644548e-02 9.18192845e-03\n",
            " 1.46838232e-02 6.86856391e-03 1.00772902e-03 1.26558244e-02\n",
            " 1.52094659e-02 1.91544573e-02 9.68921299e-03 7.56602954e-03\n",
            " 1.18598931e-02 1.53428548e-03 1.80432953e-02 1.62879773e-02\n",
            " 1.30324455e-02 4.59145255e-05 1.71207632e-02 9.01473096e-03\n",
            " 1.49905198e-02 1.61785924e-02 4.74367489e-03 3.18811904e-03\n",
            " 1.04160457e-02 7.17662123e-03 1.72025263e-02 9.20096064e-03\n",
            " 4.66951632e-03 9.25482029e-03 1.07650010e-02 9.76725940e-03\n",
            " 1.01076584e-02 5.77851851e-09 4.00371654e-03 9.12077833e-03\n",
            " 1.51455232e-02 8.69983194e-03 1.11872640e-03 1.31308462e-02\n",
            " 1.33180719e-02 4.24473974e-03 1.48025464e-02 8.21475566e-03\n",
            " 1.83348598e-03 7.79819416e-03 1.46938721e-02 2.15904102e-03\n",
            " 1.88919597e-02 7.60128938e-03 4.18954548e-03 1.18558617e-02\n",
            " 1.65454232e-02 8.90002656e-03 5.76956007e-03 5.54467803e-03\n",
            " 1.82120207e-02 6.66517166e-03 3.02310263e-03 8.44751846e-03\n",
            " 1.31734784e-02 1.32171322e-02 9.77393871e-03 5.30987501e-03\n",
            " 1.07455836e-02 4.30920824e-03 1.10068940e-02 9.71301777e-03\n",
            " 7.81013389e-03 1.24445259e-02 9.39767024e-03 5.79749905e-03\n",
            " 1.11165025e-02 7.85388546e-03 1.22084122e-02 1.83637257e-02\n",
            " 2.48459745e-03 1.37185647e-02 1.67998412e-04 4.15160063e-03\n",
            " 1.66192957e-02 1.06128585e-02 1.84097888e-02 1.12774255e-02\n",
            " 4.16695865e-03 1.02411424e-02 3.39678147e-03 1.41307794e-02\n",
            " 1.85141163e-02 6.23889678e-03 7.59726557e-03 1.03528431e-02\n",
            " 1.88905857e-02 5.44022034e-04 3.19462197e-03 1.13071550e-02\n",
            " 1.61785924e-02 1.52980936e-02 6.12826660e-03 1.33055063e-02\n",
            " 1.41698733e-06 1.17604482e-02 9.39704540e-05 8.42681417e-04\n",
            " 2.95964058e-03 1.28467147e-02 6.71880298e-03 3.04442752e-03\n",
            " 9.64205899e-03 5.24717019e-03 4.33630828e-04 1.48805810e-02\n",
            " 5.34192243e-03 5.60262539e-03 1.29165527e-02 1.21644588e-03\n",
            " 1.37358885e-02 1.08756818e-02 8.79767306e-04 1.77286752e-02\n",
            " 4.60676175e-03 1.26416923e-02 6.84790204e-03 8.49408976e-03\n",
            " 5.53940092e-03 1.49668196e-02 6.08406867e-03 1.47114859e-02\n",
            " 4.54357546e-03 1.88919597e-02 5.74958609e-03 1.83367819e-02\n",
            " 5.45892081e-03 3.39534735e-03 7.88104757e-03 4.30920824e-03\n",
            " 1.64839235e-02 1.01412578e-02 1.76908771e-02 7.92746125e-03\n",
            " 3.75143618e-03 1.72544229e-02 1.26630253e-03 1.52590711e-03\n",
            " 1.67342702e-02 9.21970519e-03 4.20058373e-03 1.01794676e-02\n",
            " 1.21535381e-02 1.59436051e-03 5.26406782e-03 9.35943998e-03\n",
            " 1.73233030e-02 9.98353365e-05 8.16553882e-03 1.74002441e-02\n",
            " 3.60618599e-16 3.14832135e-03 1.58927254e-02 1.48314952e-02\n",
            " 6.19231295e-03 1.30424474e-02 1.07431173e-02 1.86492110e-02\n",
            " 1.43870278e-02 1.16341164e-02 1.70832444e-02 2.44204634e-04\n",
            " 8.22594966e-03 1.04137789e-02 1.58631302e-02 1.02411424e-02\n",
            " 7.57664216e-03 2.92840144e-03 4.11558070e-03 3.23543778e-03\n",
            " 1.18598931e-02 2.16187748e-03 1.64738619e-02 3.75448753e-03\n",
            " 1.26425645e-02 6.85259420e-03 7.39358045e-03 1.68889872e-03\n",
            " 2.61023596e-04 7.21259333e-03 1.31934182e-02 4.79571247e-03\n",
            " 6.76864122e-03 1.22629922e-02 4.12104404e-03 4.19734708e-04\n",
            " 1.43857980e-02 8.63634294e-03 1.87253925e-02 2.06700034e-03\n",
            " 4.55345761e-03 3.51978607e-03 7.09871638e-03 7.89844662e-03\n",
            " 1.82029828e-04 4.54051157e-03 1.54157965e-02 3.60385545e-03\n",
            " 8.53870676e-03 1.44322699e-02 4.89430359e-03 3.27826558e-03\n",
            " 9.27277869e-03 9.19603462e-03 6.92866873e-03 1.38267885e-02\n",
            " 1.70860183e-02 4.81411874e-03 9.49482975e-03 5.60880409e-03\n",
            " 9.98035640e-03 1.45176220e-02 4.94263271e-03 1.01226302e-02\n",
            " 2.03361055e-04 9.37018919e-03 1.19852309e-02 1.71890260e-03\n",
            " 8.41637546e-03 1.00442558e-02 8.11089477e-03 6.90453970e-03\n",
            " 3.77723100e-03 1.36492517e-03 1.24972036e-02 2.99524503e-03\n",
            " 2.01526036e-03 1.56886801e-02 1.46971865e-02 1.40161192e-02\n",
            " 1.30378902e-03 4.86530021e-03 1.59178305e-02 1.75763420e-03\n",
            " 1.78427386e-02 5.79749905e-03 4.01493679e-03 1.66568208e-02\n",
            " 1.35299001e-02 1.53786583e-03 1.18778532e-02 7.72013079e-03\n",
            " 3.15148040e-03 3.12750438e-03 6.47721378e-03 2.25419378e-03\n",
            " 1.43100742e-02 1.84416767e-02 4.81736175e-06 1.24067405e-02\n",
            " 8.44774077e-04 1.50199298e-02 3.88801038e-03 1.26986350e-03\n",
            " 1.09661104e-02 1.04250601e-02 1.10826814e-05 1.06543455e-02\n",
            " 1.10768229e-02 1.48796080e-02 2.37908208e-03 1.84203345e-04\n",
            " 9.07851520e-03 1.38267885e-02 3.83156017e-03 3.14217804e-03\n",
            " 9.12213159e-03 1.76784895e-03 7.70179826e-04 2.15203986e-03\n",
            " 1.47346052e-02 6.50704086e-04 2.12432146e-03 1.11510313e-03\n",
            " 1.58361466e-02 3.74732597e-03 1.53983581e-02 1.43290041e-02\n",
            " 1.11256842e-02 7.87166923e-03 5.55960364e-05 1.36349227e-02\n",
            " 5.89403767e-04 1.11632751e-02 8.91659116e-04 1.22932585e-02\n",
            " 1.05934405e-02 1.88905857e-02 1.27615666e-02 1.01526503e-02\n",
            " 1.27460812e-02 1.39097140e-02 1.41899069e-02 9.79728288e-03\n",
            " 9.64066687e-03 5.42237997e-03 1.83788829e-02 8.36075782e-03\n",
            " 8.63996506e-03 8.16271889e-03 9.86144808e-03 1.76784895e-03\n",
            " 1.55551177e-02 1.13763416e-02 1.08137913e-02 1.72781469e-02\n",
            " 2.17143088e-03 1.20741901e-02 3.28556440e-03 9.83157893e-03\n",
            " 1.71879062e-02 4.94381410e-03 1.06445928e-02 1.90408539e-03\n",
            " 1.29886044e-02 4.08582986e-03 1.18462318e-02 1.66120498e-02\n",
            " 1.58889188e-02 7.74867299e-03 1.24665020e-02 1.25503359e-02\n",
            " 4.49628324e-03 9.30044009e-03 5.69728204e-04 2.88216169e-03\n",
            " 9.49938657e-03 3.81509363e-03 1.75910232e-02 7.69203108e-03\n",
            " 1.76403042e-02 8.04443036e-03 2.03361055e-04 4.70026654e-03\n",
            " 1.77261988e-02 1.10408860e-02 2.91223587e-03 1.47940374e-02\n",
            " 3.93265625e-03 1.70646336e-02 1.03917267e-02 8.11258630e-03\n",
            " 4.50837281e-03 5.98890507e-04 1.44396592e-03 1.30846887e-02\n",
            " 1.18572974e-03 1.89063201e-02 1.60534492e-02 7.27866529e-03\n",
            " 5.04741783e-03 1.62328299e-02 7.01599627e-04 4.49866581e-03\n",
            " 1.43136140e-02 1.91361372e-02 1.18897415e-02 3.17610721e-04\n",
            " 7.71631880e-03 1.76784895e-03 7.61332939e-03 1.40902057e-02\n",
            " 1.12999132e-02 1.30347304e-02 5.71350837e-03 7.46040288e-03\n",
            " 8.54291901e-03 1.11093249e-02 1.49214431e-02 1.04166422e-02\n",
            " 2.26291143e-03 1.30061054e-02 3.64231909e-03 1.16670816e-03\n",
            " 7.62010280e-03 1.90193934e-02 8.28304395e-03 8.90392647e-03\n",
            " 2.50726186e-04 1.11103203e-02 3.77723100e-03 1.66972562e-02\n",
            " 6.07409636e-03 3.88801038e-03 9.38183543e-03 1.85312292e-02\n",
            " 4.07749259e-04 2.63806033e-03 1.49491685e-02 1.59079636e-02\n",
            " 5.20351528e-04 8.35614102e-03 9.28054042e-03 2.03020050e-03\n",
            " 4.73818112e-03 1.57035541e-03 9.94667390e-03 1.87301907e-02\n",
            " 1.73494624e-02 1.54348171e-02 1.17693355e-02 1.01506849e-02\n",
            " 1.44678844e-02 7.03733248e-03 9.86398968e-03 1.04603056e-02\n",
            " 1.35628113e-04 7.09498724e-03 2.24532568e-03 3.28987653e-03\n",
            " 1.41933743e-02 1.70860183e-02 3.17994323e-03 4.74367489e-03\n",
            " 8.64064189e-03 1.83605377e-02 1.21248940e-02 4.13858652e-03\n",
            " 1.68788569e-02 6.44830855e-03 2.58687787e-03 1.85672830e-02\n",
            " 1.07695985e-02 9.74777767e-03 1.94839995e-03 5.69085520e-04\n",
            " 1.90984882e-02 2.72170303e-03 1.37960598e-02 1.41890135e-02\n",
            " 1.67621139e-02 1.72544229e-02 1.91605979e-02 4.25188723e-03\n",
            " 1.02106913e-02 1.41307794e-02 1.40879464e-02 1.85415727e-02\n",
            " 7.84019960e-03 3.94273705e-03 1.59079325e-02 6.16588024e-04\n",
            " 1.66462002e-02 1.69513225e-02 3.42318798e-03 6.41335127e-03\n",
            " 5.26552758e-03 8.02034278e-03 4.83866489e-03 1.61785924e-02\n",
            " 1.62126786e-02 1.63034022e-02 3.28696151e-04 2.66865956e-03\n",
            " 2.96088414e-03 7.99141288e-03 1.30507146e-02 1.41966645e-02\n",
            " 8.15489091e-03 2.17143088e-03 1.41404585e-02 1.71511137e-02\n",
            " 1.40794386e-03 1.12192531e-02 1.56409577e-02 2.45317576e-03\n",
            " 5.97112386e-03 1.05922171e-02 1.39305733e-02 1.16410515e-02\n",
            " 4.02160903e-03 1.39635799e-02 1.14288954e-02 5.34344765e-03\n",
            " 8.59155052e-04 1.05775907e-02 6.72126268e-03 4.23140341e-03\n",
            " 1.52770537e-02 5.00130343e-03 3.75990286e-03 7.09826055e-03\n",
            " 5.13497373e-03 4.53608185e-03 2.83148821e-03 6.42551118e-03\n",
            " 1.86289064e-02 1.79344865e-02 1.06294178e-02 1.08584799e-03\n",
            " 6.67366165e-04 6.00276329e-03 1.35100423e-02 9.72288738e-04\n",
            " 2.04380203e-04 1.13092770e-02 9.48695592e-03 1.09167476e-02\n",
            " 1.27877059e-03 1.60446135e-02 1.45253788e-03 2.06597951e-03\n",
            " 2.87287930e-03 7.57025199e-05 1.49046406e-02 3.78098240e-03\n",
            " 1.81207266e-02 5.49626047e-03 5.21744893e-03 2.20883707e-06\n",
            " 1.21790800e-02 6.62169387e-04 5.45856156e-07 1.10040368e-02\n",
            " 2.23828104e-05 1.71480379e-02 3.86736243e-05 1.34662854e-02\n",
            " 1.67465335e-02 1.04684922e-02 1.10200100e-02 1.51121374e-03\n",
            " 8.58657908e-04 1.13699702e-02 1.60196103e-02 4.47506284e-03\n",
            " 1.65286820e-02 1.56775944e-02 3.87144683e-03 1.44386013e-02\n",
            " 4.98617888e-03 1.07666129e-02 4.98617888e-03 7.42372612e-03\n",
            " 1.83865434e-02 1.02931879e-03 7.22062481e-03 1.90214246e-03\n",
            " 1.78019951e-02 3.97155227e-03 3.01085013e-04 1.53177563e-02\n",
            " 3.86370703e-04 1.07569373e-02 1.42793204e-02 3.08490799e-03\n",
            " 1.38659202e-02 4.90512516e-03 1.79709020e-02 4.27334775e-03\n",
            " 2.44258095e-04 5.21856584e-03 6.16513042e-03 1.81327182e-02\n",
            " 6.60120354e-03 1.31586506e-02 1.58043398e-02 5.56523613e-03\n",
            " 1.70645159e-02 4.64202355e-03 4.89430359e-03 7.26539326e-03\n",
            " 1.17340599e-02 3.01788218e-03 1.31149899e-02 1.51022755e-02\n",
            " 1.72581134e-02 1.08740613e-02 1.45579903e-02 5.48694927e-03\n",
            " 1.70326062e-02 5.82868847e-03 1.27895316e-02 1.90643279e-02\n",
            " 1.82634470e-02 4.81133342e-03 3.87144683e-03 1.34630322e-02\n",
            " 1.40429885e-02 7.81930486e-03 1.07365570e-02 1.39476583e-03\n",
            " 1.24181074e-03 3.74939572e-03 1.58655861e-02 5.34740058e-03\n",
            " 4.01162382e-03 6.93476642e-04 1.73282199e-02 9.18852257e-03\n",
            " 1.09807421e-02 8.32051792e-03 5.57188072e-03 2.31565697e-03\n",
            " 7.41922869e-04 9.37976887e-03 7.12286899e-03 7.49354650e-03\n",
            " 8.83760776e-03 1.13046488e-02 9.82127432e-03 2.90047979e-03\n",
            " 1.52371930e-03 1.30129391e-03 1.43907210e-02 6.26381083e-03\n",
            " 9.84806931e-03 1.08417277e-02 7.22771672e-03 1.75863629e-02\n",
            " 8.64349151e-03 1.36251394e-02 4.24529295e-03 1.39039467e-02\n",
            " 8.00665327e-03 3.81482854e-03 8.99873063e-03 1.34393653e-02\n",
            " 1.84509118e-02 1.87259382e-02 1.30141734e-02 3.14419492e-03\n",
            " 1.49962040e-02 1.32799474e-02 3.33384986e-03 8.92683046e-03\n",
            " 4.86888674e-04 9.22337692e-04 8.92035471e-03 1.41933743e-02\n",
            " 8.40744260e-03 2.68877337e-03 9.79728288e-03 6.11243711e-03\n",
            " 8.27815226e-03 1.67157581e-02 4.00808594e-04 5.61940682e-03\n",
            " 1.44578683e-02 7.53721733e-03 3.74655184e-03 1.05931147e-02\n",
            " 6.84038252e-03 3.56098273e-03 7.80331389e-03 1.53263984e-02\n",
            " 9.29366684e-03 9.65861531e-03 7.27135665e-03 1.69988904e-02\n",
            " 4.80618114e-03 5.69491759e-03 6.68287809e-03 8.44774077e-04\n",
            " 3.94602190e-03]\n",
            "3380 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.87717899e-03 4.41829058e-03 1.69035358e-02 1.71040553e-02\n",
            " 4.72354208e-03 4.01574283e-03 1.52319555e-02 7.00717342e-04\n",
            " 1.26090913e-02 9.36306976e-03 4.06378684e-03 6.72522628e-03\n",
            " 1.25739890e-02 8.43110205e-03 1.59284051e-02 1.84806377e-02\n",
            " 1.16011516e-02 8.26492432e-03 1.03492364e-02 1.07127313e-02\n",
            " 1.21114488e-02 6.47326684e-03 1.44283725e-02 5.79530541e-03\n",
            " 1.83254028e-02 7.52474511e-03 5.60736565e-03 8.30668561e-03\n",
            " 1.46531808e-03 9.55654101e-03 4.99719604e-03 5.43776145e-03\n",
            " 1.83254028e-02 3.86607943e-03 1.42572549e-05 5.99410131e-03\n",
            " 1.29512775e-02 1.39877812e-02 1.53051532e-02 2.93309252e-03\n",
            " 1.08700733e-02 1.36394552e-02 1.80714069e-02 1.03215669e-04\n",
            " 9.64834545e-03 1.29512775e-02 1.27616954e-02 1.97154658e-03\n",
            " 5.62142750e-09 3.01114482e-03 1.89629928e-05 6.55433744e-03\n",
            " 1.26007945e-02 8.77474072e-03 4.43158661e-04 1.90370963e-07\n",
            " 1.13909439e-02 7.79372817e-03 7.29009961e-03 2.86933660e-03\n",
            " 7.67269081e-03 1.08453279e-02 9.79224595e-03 1.70793571e-02\n",
            " 5.55542337e-03 9.01495431e-03 2.21720098e-03 1.17920380e-02\n",
            " 1.86767747e-02 1.39521800e-02 9.49492941e-03 1.63707854e-02\n",
            " 1.82086344e-02 1.35843630e-02 1.88308557e-02 1.14013657e-02\n",
            " 1.12482300e-02 1.73766209e-02 1.03820393e-03 7.56395285e-03\n",
            " 2.97043188e-03 1.63987999e-02 3.80553108e-04 1.71927214e-02\n",
            " 1.12825490e-03 1.47453559e-02 8.31777357e-03 3.37702739e-03\n",
            " 1.00875284e-02 1.79963984e-02 1.83106365e-02 1.87417099e-02\n",
            " 1.42288957e-02 9.79224595e-03 1.26711394e-02 4.24419238e-04\n",
            " 1.39752388e-02 7.51541359e-03 5.29639258e-03 5.04914920e-03\n",
            " 1.17755215e-02 5.00302542e-04 1.12146056e-02 1.02024142e-02\n",
            " 4.28651188e-03 4.33543851e-03 1.18149988e-03 1.60580663e-02\n",
            " 5.85267757e-03 1.11426245e-02 1.88355285e-02 6.07837353e-04\n",
            " 1.06549171e-03 1.03819235e-02 5.53042371e-03 6.81736718e-05\n",
            " 3.76218201e-03 1.29423221e-02 1.82082440e-02 9.76545552e-03\n",
            " 1.09709620e-02 1.12031138e-02 1.87443166e-03 7.78436536e-03\n",
            " 8.68282393e-03 6.87460719e-04 1.49118323e-02 2.11592545e-03\n",
            " 1.49878553e-02 1.09099593e-02 1.01146523e-02 1.45994429e-02\n",
            " 7.88087620e-03 1.74349056e-02 9.20031621e-03 1.84659390e-02\n",
            " 5.19579690e-03 1.27616954e-02 3.65810768e-03 7.20183049e-05\n",
            " 1.64375967e-02 9.26758186e-03 1.35136283e-02 4.14241538e-03\n",
            " 1.49221907e-02 1.87210349e-02 1.65307811e-02 3.65810768e-03\n",
            " 1.20517482e-02 1.20237056e-02 9.17650716e-03 1.46689655e-02\n",
            " 6.85962634e-03 1.00521150e-03 1.26607362e-02 1.51848632e-02\n",
            " 9.69159138e-03 7.55604854e-03 1.18512772e-02 1.52557623e-03\n",
            " 1.80375278e-02 1.60824226e-02 1.30064979e-02 4.57435467e-05\n",
            " 1.71107576e-02 8.99430750e-03 1.49737004e-02 1.62101378e-02\n",
            " 4.73981920e-03 3.18347517e-03 1.04266605e-02 7.18402426e-03\n",
            " 1.71927214e-02 9.18980788e-03 4.65805090e-03 9.22060671e-03\n",
            " 1.07411150e-02 9.75841889e-03 1.00779730e-02 5.62142750e-09\n",
            " 3.99982297e-03 9.11779903e-03 1.51208995e-02 8.68630761e-03\n",
            " 1.11616819e-03 1.31121825e-02 1.33016411e-02 4.23676819e-03\n",
            " 1.47862574e-02 8.11083054e-03 1.82548619e-03 7.78110061e-03\n",
            " 1.46956304e-02 2.15171546e-03 7.55350513e-03 4.18551640e-03\n",
            " 1.18284290e-02 1.65440891e-02 8.88302133e-03 5.69485691e-03\n",
            " 5.52770975e-03 1.80868833e-02 6.66489049e-03 3.02211178e-03\n",
            " 8.43110205e-03 1.31414730e-02 1.31911252e-02 9.68493686e-03\n",
            " 5.28889949e-03 1.07211779e-02 4.28651188e-03 1.08700733e-02\n",
            " 9.70371665e-03 7.79141859e-03 1.24010010e-02 9.36810728e-03\n",
            " 5.78414621e-03 1.11069950e-02 7.81555058e-03 1.21965690e-02\n",
            " 1.83340011e-02 2.47127401e-03 1.37085097e-02 1.65622304e-04\n",
            " 4.14055810e-03 1.65896585e-02 1.06025029e-02 1.83761658e-02\n",
            " 1.12901397e-02 4.15514758e-03 1.02029855e-02 3.39017200e-03\n",
            " 1.40737775e-02 1.84129198e-02 6.20428107e-03 7.60317189e-03\n",
            " 1.03292439e-02 1.88920150e-02 5.41791678e-04 3.18851414e-03\n",
            " 1.12577104e-02 1.62101378e-02 1.53082341e-02 6.13501502e-03\n",
            " 1.32898083e-02 1.41846570e-06 1.17410410e-02 9.33844907e-05\n",
            " 8.34689174e-04 2.94284733e-03 1.28202183e-02 6.70591102e-03\n",
            " 3.03816575e-03 9.63833269e-03 5.21991590e-03 4.31124258e-04\n",
            " 1.48543539e-02 5.32439433e-03 5.57393124e-03 1.28852720e-02\n",
            " 1.21375548e-03 1.36513023e-02 1.08339800e-02 8.74629268e-04\n",
            " 1.77528853e-02 4.59778112e-03 1.26090913e-02 6.83769877e-03\n",
            " 8.48280012e-03 5.53677583e-03 1.49504049e-02 6.07770588e-03\n",
            " 1.47007180e-02 4.53890902e-03 5.72849574e-03 1.83465727e-02\n",
            " 5.45116956e-03 3.36628704e-03 7.85424012e-03 4.28651188e-03\n",
            " 1.63772970e-02 1.01396616e-02 1.77056988e-02 7.91815297e-03\n",
            " 3.75317709e-03 1.71554199e-02 1.26331007e-03 1.52481047e-03\n",
            " 1.67110674e-02 9.20657404e-03 4.17738578e-03 1.01778005e-02\n",
            " 1.21487476e-02 1.58715840e-03 5.25613834e-03 9.36834062e-03\n",
            " 1.73021827e-02 9.95963887e-05 8.12926472e-03 1.73916668e-02\n",
            " 3.47000712e-16 3.13851012e-03 1.58494366e-02 1.48219391e-02\n",
            " 6.18629904e-03 1.30492118e-02 1.07215133e-02 1.86423612e-02\n",
            " 1.43951053e-02 1.15829958e-02 1.70569028e-02 2.42125617e-04\n",
            " 8.22610378e-03 1.03777231e-02 1.58257975e-02 1.02029855e-02\n",
            " 7.56395285e-03 2.91300024e-03 4.09398421e-03 3.23217083e-03\n",
            " 1.18512772e-02 2.15870979e-03 1.64382753e-02 3.72954668e-03\n",
            " 1.26339258e-02 6.80899533e-03 7.39319695e-03 1.68069082e-03\n",
            " 2.60635606e-04 7.20155508e-03 1.31866206e-02 4.77422657e-03\n",
            " 6.76637625e-03 1.22300248e-02 4.10178602e-03 4.16150295e-04\n",
            " 1.43197880e-02 8.60954293e-03 1.87087176e-02 2.06156655e-03\n",
            " 4.54384052e-03 3.51591620e-03 7.08772874e-03 7.91546446e-03\n",
            " 1.81712172e-04 4.53884761e-03 1.53584342e-02 3.59407246e-03\n",
            " 8.54714678e-03 1.44334990e-02 4.89410740e-03 3.27744798e-03\n",
            " 9.25036865e-03 9.17527298e-03 6.93636761e-03 1.37960513e-02\n",
            " 1.70914588e-02 4.79985228e-03 9.48940381e-03 5.60736565e-03\n",
            " 9.97134684e-03 1.45150620e-02 4.93556876e-03 1.01202498e-02\n",
            " 2.01590487e-04 9.37625497e-03 1.19873258e-02 1.71745234e-03\n",
            " 8.39785600e-03 1.00077669e-02 8.11593445e-03 6.89657442e-03\n",
            " 3.76218201e-03 1.36617132e-03 1.24764124e-02 2.97716773e-03\n",
            " 2.01577914e-03 1.55898557e-02 1.46941321e-02 1.40102087e-02\n",
            " 1.30339196e-03 4.86683351e-03 1.59266788e-02 1.75186568e-03\n",
            " 1.77889532e-02 5.78414621e-03 3.98832608e-03 1.66406112e-02\n",
            " 1.35103040e-02 1.53577218e-03 1.17973671e-02 7.67027501e-03\n",
            " 3.14346825e-03 3.12829105e-03 6.42201725e-03 2.24945136e-03\n",
            " 1.42661652e-02 1.83335235e-02 4.76619255e-06 1.23895456e-02\n",
            " 8.36465347e-04 1.49964747e-02 3.87957581e-03 1.27177220e-03\n",
            " 1.09622328e-02 1.04034852e-02 1.10370261e-05 1.06297549e-02\n",
            " 1.10940560e-02 1.48245381e-02 2.38145810e-03 1.82289299e-04\n",
            " 9.07059947e-03 1.37960513e-02 3.81385993e-03 3.13886576e-03\n",
            " 9.10156625e-03 1.75630536e-03 7.69955171e-04 2.15087193e-03\n",
            " 1.47226459e-02 6.48077111e-04 2.12130568e-03 1.11255069e-03\n",
            " 1.58609817e-02 3.73428966e-03 1.52750882e-02 1.41853222e-02\n",
            " 1.11215720e-02 7.86430630e-03 5.56580276e-05 1.36048023e-02\n",
            " 5.86861097e-04 1.11538203e-02 8.86314453e-04 1.22265523e-02\n",
            " 1.05471158e-02 1.88920150e-02 1.27391197e-02 1.01260058e-02\n",
            " 1.27633337e-02 1.38329377e-02 1.41766854e-02 9.79224595e-03\n",
            " 9.61777054e-03 5.42004467e-03 1.83543336e-02 8.34775218e-03\n",
            " 8.62211013e-03 8.11208078e-03 9.86405927e-03 1.75630536e-03\n",
            " 1.54687163e-02 1.13247877e-02 1.07764735e-02 1.71920967e-02\n",
            " 2.17313777e-03 1.20596983e-02 3.27971535e-03 9.80022368e-03\n",
            " 1.71629749e-02 4.93069220e-03 1.06384396e-02 1.90258784e-03\n",
            " 1.29825240e-02 4.08100540e-03 1.18216656e-02 1.65688009e-02\n",
            " 1.58658636e-02 7.73547849e-03 1.23880092e-02 1.25381367e-02\n",
            " 4.48142534e-03 9.29860017e-03 5.66155546e-04 2.87467304e-03\n",
            " 9.47198429e-03 3.80715078e-03 1.75466689e-02 7.63698580e-03\n",
            " 1.76494684e-02 8.03643151e-03 2.01590487e-04 4.69408441e-03\n",
            " 1.77247298e-02 1.10283435e-02 2.90721182e-03 1.47825585e-02\n",
            " 3.88832687e-03 1.70621762e-02 1.03897446e-02 8.10381423e-03\n",
            " 4.47881116e-03 5.94129816e-04 1.42980667e-03 1.30819264e-02\n",
            " 1.17393311e-03 1.60532169e-02 7.22485990e-03 5.03754390e-03\n",
            " 1.62355750e-02 7.00717342e-04 4.49342592e-03 1.43021082e-02\n",
            " 1.19048857e-02 3.17540370e-04 7.70219494e-03 1.75630536e-03\n",
            " 7.60238258e-03 1.41024321e-02 1.12827186e-02 1.29997385e-02\n",
            " 5.69874662e-03 7.44202913e-03 8.54473755e-03 1.10597555e-02\n",
            " 1.49241553e-02 1.04097206e-02 2.25760280e-03 1.29509822e-02\n",
            " 3.64643733e-03 1.16308350e-03 7.55591394e-03 8.31608990e-03\n",
            " 8.90845849e-03 2.50143174e-04 1.11170863e-02 3.76218201e-03\n",
            " 1.67035411e-02 6.06527324e-03 3.87957581e-03 9.37687920e-03\n",
            " 1.84575711e-02 4.04165952e-04 2.61324317e-03 1.49494700e-02\n",
            " 1.58807969e-02 5.21831439e-04 8.34120303e-03 9.27257668e-03\n",
            " 2.02742791e-03 4.74585172e-03 1.56791045e-03 9.92842483e-03\n",
            " 1.87470538e-02 1.73280823e-02 1.53582262e-02 1.17520532e-02\n",
            " 1.01080371e-02 1.44455688e-02 7.03080696e-03 9.83305948e-03\n",
            " 1.04496295e-02 1.35767990e-04 7.06107718e-03 2.24058249e-03\n",
            " 3.28370903e-03 1.41854817e-02 1.70914588e-02 3.16765863e-03\n",
            " 4.73981920e-03 8.57892415e-03 1.83092032e-02 1.20874620e-02\n",
            " 4.14241538e-03 1.67883529e-02 6.44026719e-03 2.58442303e-03\n",
            " 1.85265006e-02 1.07179828e-02 9.73590725e-03 1.94483608e-03\n",
            " 5.66070644e-04 2.71159961e-03 1.38043045e-02 1.41705022e-02\n",
            " 1.66905494e-02 1.71554199e-02 4.24743986e-03 1.02141937e-02\n",
            " 1.40737775e-02 1.40414320e-02 1.85495206e-02 7.82257012e-03\n",
            " 3.93734221e-03 1.58783627e-02 6.15401272e-04 1.65733366e-02\n",
            " 1.68738477e-02 3.40589265e-03 6.41612682e-03 5.24971509e-03\n",
            " 8.00652251e-03 4.82928897e-03 1.62101378e-02 1.62107779e-02\n",
            " 1.63109258e-02 3.27045716e-04 2.66235027e-03 2.93135390e-03\n",
            " 7.95322858e-03 1.30108817e-02 1.41788864e-02 8.15777751e-03\n",
            " 2.17313777e-03 1.41350658e-02 1.71483885e-02 1.40748435e-03\n",
            " 1.11480203e-02 1.56014080e-02 2.44518360e-03 5.96607489e-03\n",
            " 1.05636843e-02 1.39233532e-02 1.16106513e-02 4.02196926e-03\n",
            " 1.39173103e-02 1.13921539e-02 5.33861953e-03 8.60406680e-04\n",
            " 1.05781974e-02 6.72217547e-03 4.21999133e-03 1.52018051e-02\n",
            " 4.97347901e-03 3.73086152e-03 7.02467768e-03 5.12796680e-03\n",
            " 4.49596619e-03 2.83125530e-03 6.40839771e-03 1.86494267e-02\n",
            " 1.78694328e-02 1.05925052e-02 1.07326208e-03 6.67702649e-04\n",
            " 5.99410131e-03 1.34978557e-02 9.67110263e-04 2.02676704e-04\n",
            " 1.12633317e-02 9.45071617e-03 1.09109499e-02 1.26959587e-03\n",
            " 1.60090403e-02 1.44516494e-03 2.06725458e-03 2.86933660e-03\n",
            " 7.53685918e-05 1.48791618e-02 3.77795004e-03 1.81095499e-02\n",
            " 5.50001441e-03 5.20698773e-03 2.19231111e-06 1.21571240e-02\n",
            " 6.61109954e-04 5.04111262e-07 1.09288611e-02 2.22226790e-05\n",
            " 1.71454588e-02 3.86508327e-05 1.34746742e-02 1.66817355e-02\n",
            " 1.04347508e-02 1.10338346e-02 1.50298584e-03 8.55248332e-04\n",
            " 1.13218627e-02 1.59989013e-02 4.47566560e-03 1.64979851e-02\n",
            " 1.56517179e-02 3.86607943e-03 1.44451316e-02 4.98844312e-03\n",
            " 1.07257052e-02 4.98844312e-03 7.40200003e-03 1.83566944e-02\n",
            " 1.02865225e-03 7.22183981e-03 1.89726983e-03 1.77957650e-02\n",
            " 3.97109726e-03 2.98974693e-04 1.52990836e-02 3.83994878e-04\n",
            " 1.07271014e-02 1.42625034e-02 3.06961675e-03 1.38276493e-02\n",
            " 4.88132147e-03 1.79889647e-02 4.25122176e-03 2.43693733e-04\n",
            " 5.21702519e-03 6.16700763e-03 1.81276041e-02 6.60933896e-03\n",
            " 1.31337671e-02 1.58348146e-02 5.54606917e-03 1.70486654e-02\n",
            " 4.64582066e-03 4.89410740e-03 7.19874159e-03 1.17159200e-02\n",
            " 3.01690414e-03 1.30590696e-02 1.50855017e-02 1.72211466e-02\n",
            " 1.08541373e-02 1.45253421e-02 5.46832078e-03 1.69996526e-02\n",
            " 5.82617575e-03 1.27646866e-02 1.82406049e-02 4.79811414e-03\n",
            " 3.86607943e-03 1.34583798e-02 1.39983244e-02 7.80013567e-03\n",
            " 1.06270436e-02 1.39096041e-03 1.23855003e-03 3.74938394e-03\n",
            " 1.58319227e-02 5.34850229e-03 3.98169861e-03 6.90322805e-04\n",
            " 1.72897258e-02 9.17229893e-03 1.09663602e-02 8.29312157e-03\n",
            " 5.56390207e-03 2.30506618e-03 7.39286628e-04 9.37070282e-03\n",
            " 7.06486651e-03 7.46242418e-03 8.81246975e-03 1.13102905e-02\n",
            " 9.80529779e-03 2.89820472e-03 1.51849910e-03 1.29710499e-03\n",
            " 1.43571925e-02 6.23161342e-03 9.78208438e-03 1.08042981e-02\n",
            " 7.22050391e-03 1.75158386e-02 8.63174661e-03 1.36161225e-02\n",
            " 4.22424172e-03 1.38323222e-02 7.98238097e-03 3.81121952e-03\n",
            " 8.99229917e-03 1.34601221e-02 1.84806377e-02 1.87237455e-02\n",
            " 1.30119732e-02 3.12626343e-03 1.49604274e-02 1.32439765e-02\n",
            " 3.33254472e-03 8.89063284e-03 4.79270136e-04 9.19547618e-04\n",
            " 8.93176559e-03 1.41854817e-02 8.33450018e-03 2.68261814e-03\n",
            " 9.79224595e-03 6.10088018e-03 8.26468893e-03 1.66944117e-02\n",
            " 4.00422983e-04 5.60721685e-03 1.44338064e-02 7.50508830e-03\n",
            " 3.72493608e-03 1.05934749e-02 6.83546610e-03 3.56654609e-03\n",
            " 7.81324820e-03 1.53051532e-02 9.24964085e-03 9.61210332e-03\n",
            " 7.27228211e-03 1.69707709e-02 4.80869604e-03 5.68256529e-03\n",
            " 6.65059646e-03 8.36465347e-04 3.94147276e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3390 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.87082342e-03 4.40788473e-03 1.68866796e-02 1.70635262e-02\n",
            " 4.70880186e-03 3.99783952e-03 1.52521454e-02 6.99642306e-04\n",
            " 1.25450771e-02 9.36238246e-03 4.06533066e-03 6.70366212e-03\n",
            " 1.25586442e-02 8.40751940e-03 1.59183517e-02 1.84319129e-02\n",
            " 1.15782217e-02 8.22470502e-03 1.03383763e-02 1.07205863e-02\n",
            " 1.21099206e-02 6.46651020e-03 1.44078861e-02 5.76955236e-03\n",
            " 1.83171952e-02 7.53456416e-03 5.59184657e-03 8.28460700e-03\n",
            " 1.45198713e-03 9.54845728e-03 4.99144709e-03 5.43679789e-03\n",
            " 1.83171952e-02 3.87112242e-03 1.41245971e-05 5.97940033e-03\n",
            " 1.29323771e-02 1.39553692e-02 1.52915184e-02 2.93218339e-03\n",
            " 1.08514593e-02 1.36167414e-02 1.80347830e-02 1.03306665e-04\n",
            " 9.66410409e-03 1.29323771e-02 1.27509944e-02 1.95567242e-03\n",
            " 5.61412828e-09 3.00811346e-03 1.87965656e-05 6.53535253e-03\n",
            " 1.25675749e-02 8.78173574e-03 4.42704192e-04 1.90771851e-07\n",
            " 1.13893624e-02 7.79432490e-03 7.28722838e-03 2.87265359e-03\n",
            " 7.65502409e-03 1.08255828e-02 9.79705171e-03 1.70657224e-02\n",
            " 5.55682732e-03 8.98593568e-03 2.20903821e-03 1.17743966e-02\n",
            " 1.39239162e-02 9.45423171e-03 1.63657370e-02 1.81515422e-02\n",
            " 1.35657596e-02 1.13977369e-02 1.12156606e-02 1.73481127e-02\n",
            " 1.03062010e-03 7.55001333e-03 2.96878463e-03 1.63915693e-02\n",
            " 3.79102721e-04 1.71908472e-02 1.11906177e-03 1.47393647e-02\n",
            " 8.31117341e-03 3.37573351e-03 1.00688911e-02 1.79811734e-02\n",
            " 1.82385485e-02 1.42128527e-02 9.79705171e-03 1.26379272e-02\n",
            " 4.23658543e-04 1.39485379e-02 7.49645120e-03 5.26224809e-03\n",
            " 5.03860163e-03 1.17583229e-02 4.97736822e-04 1.11784258e-02\n",
            " 1.01914250e-02 4.27268639e-03 4.29582260e-03 1.17923232e-03\n",
            " 1.60270425e-02 5.85408145e-03 1.11162167e-02 6.06216158e-04\n",
            " 1.06406732e-03 1.03605529e-02 5.51367054e-03 6.75812109e-05\n",
            " 3.75301369e-03 1.29101682e-02 1.81452731e-02 9.75820930e-03\n",
            " 1.09501670e-02 1.11938516e-02 1.86547490e-03 7.74708509e-03\n",
            " 8.65172525e-03 6.83842694e-04 1.49024346e-02 2.11297560e-03\n",
            " 1.49826608e-02 1.08708994e-02 1.00965072e-02 1.45664794e-02\n",
            " 7.87669217e-03 1.74253793e-02 9.19475253e-03 1.84567047e-02\n",
            " 5.18612641e-03 1.27509944e-02 3.64553492e-03 7.14309420e-05\n",
            " 1.64425072e-02 9.24380295e-03 1.34829204e-02 4.12381687e-03\n",
            " 1.48768680e-02 1.65089148e-02 3.64553492e-03 1.20452916e-02\n",
            " 1.19829612e-02 9.13288853e-03 1.46534160e-02 6.84822016e-03\n",
            " 1.00427557e-03 1.26460208e-02 1.51695951e-02 9.67217484e-03\n",
            " 7.54207641e-03 1.18518722e-02 1.52805206e-03 1.79934911e-02\n",
            " 1.60582756e-02 1.29823130e-02 4.55554164e-05 1.70679903e-02\n",
            " 8.97587016e-03 1.49731842e-02 1.62194106e-02 4.73518252e-03\n",
            " 3.17233151e-03 1.03896764e-02 7.18012951e-03 1.71908472e-02\n",
            " 9.17271958e-03 4.64842865e-03 9.20933460e-03 1.07146159e-02\n",
            " 9.71869829e-03 1.00696208e-02 5.61412828e-09 3.98025853e-03\n",
            " 9.10823141e-03 1.51077560e-02 8.69079716e-03 1.11398519e-03\n",
            " 1.30625864e-02 1.32876501e-02 4.23788928e-03 1.47585269e-02\n",
            " 8.11153785e-03 1.82555064e-03 7.80760118e-03 1.46824247e-02\n",
            " 2.13695624e-03 7.54420623e-03 4.18084695e-03 1.18116344e-02\n",
            " 1.65327911e-02 8.88027917e-03 5.69162185e-03 5.51048673e-03\n",
            " 1.80731599e-02 6.64505770e-03 3.02332681e-03 8.40751940e-03\n",
            " 1.30775781e-02 1.31556686e-02 9.69974336e-03 5.28209296e-03\n",
            " 1.06861764e-02 4.27268639e-03 1.08514593e-02 9.69465480e-03\n",
            " 7.76409741e-03 1.23764454e-02 9.34962612e-03 5.78442140e-03\n",
            " 1.10733933e-02 7.81541954e-03 1.21504670e-02 1.83463376e-02\n",
            " 2.47115119e-03 1.36817534e-02 1.65889026e-04 4.13874445e-03\n",
            " 1.65832887e-02 1.05584705e-02 1.83296002e-02 1.12839360e-02\n",
            " 4.13686958e-03 1.01967092e-02 3.38086546e-03 1.40647313e-02\n",
            " 1.84163992e-02 6.21368200e-03 7.56917582e-03 1.02852118e-02\n",
            " 5.38852301e-04 3.18902306e-03 1.12516691e-02 1.62194106e-02\n",
            " 1.53136474e-02 6.13666049e-03 1.32853856e-02 1.38549109e-06\n",
            " 1.17409363e-02 9.30562047e-05 8.29357093e-04 2.93695855e-03\n",
            " 1.27537771e-02 6.69975218e-03 3.02887450e-03 9.61602646e-03\n",
            " 5.21535762e-03 4.27654910e-04 1.48198730e-02 5.33038813e-03\n",
            " 5.57621249e-03 1.28637621e-02 1.19831505e-03 1.36357611e-02\n",
            " 1.08413263e-02 8.72431110e-04 1.77508013e-02 4.59480232e-03\n",
            " 1.25450771e-02 6.83986328e-03 8.47455981e-03 5.53750752e-03\n",
            " 1.49545553e-02 6.06880275e-03 1.46395025e-02 4.53431298e-03\n",
            " 5.69628875e-03 1.82974459e-02 5.44908240e-03 3.35808814e-03\n",
            " 7.82678283e-03 4.27268639e-03 1.63780722e-02 1.01041293e-02\n",
            " 1.76803532e-02 7.90710023e-03 3.74520384e-03 1.71546629e-02\n",
            " 1.26159477e-03 1.51589372e-03 1.66890948e-02 9.19310209e-03\n",
            " 4.17013067e-03 1.01588945e-02 1.21053292e-02 1.58244035e-03\n",
            " 5.24489473e-03 9.30404351e-03 1.73049410e-02 9.88581076e-05\n",
            " 8.10808843e-03 1.73652899e-02 3.40671101e-16 3.11414966e-03\n",
            " 1.58225509e-02 1.47831455e-02 6.17790612e-03 1.29925494e-02\n",
            " 1.06445201e-02 1.86351829e-02 1.43703939e-02 1.15705129e-02\n",
            " 1.70222856e-02 2.41214402e-04 8.23005194e-03 1.03618131e-02\n",
            " 1.58295396e-02 1.01967092e-02 7.55001333e-03 2.91008257e-03\n",
            " 4.08531714e-03 3.22629186e-03 1.18518722e-02 2.15144431e-03\n",
            " 1.64153808e-02 3.72641356e-03 1.26169315e-02 6.80025876e-03\n",
            " 7.38060510e-03 1.67148729e-03 2.59151751e-04 7.18626234e-03\n",
            " 1.31547293e-02 4.77115800e-03 6.76263448e-03 1.22002861e-02\n",
            " 4.07937405e-03 4.13425867e-04 1.42672662e-02 8.60299558e-03\n",
            " 2.06021818e-03 4.54486917e-03 3.51357157e-03 7.08159236e-03\n",
            " 7.89668076e-03 1.81317603e-04 4.53960377e-03 1.52906285e-02\n",
            " 3.58744544e-03 8.53877714e-03 1.44322228e-02 4.88218013e-03\n",
            " 3.27104607e-03 9.23278580e-03 9.17382606e-03 6.92625211e-03\n",
            " 1.37288811e-02 1.70616773e-02 4.78254328e-03 9.47122578e-03\n",
            " 5.59184657e-03 9.96466287e-03 1.44887094e-02 4.92577184e-03\n",
            " 1.00767699e-02 2.01549633e-04 9.36627176e-03 1.19379556e-02\n",
            " 1.71221299e-03 8.38899022e-03 1.00007556e-02 8.13239248e-03\n",
            " 6.88849114e-03 3.75301369e-03 1.36166519e-03 1.24709337e-02\n",
            " 2.97530447e-03 2.01312226e-03 1.55572013e-02 1.46731990e-02\n",
            " 1.40051584e-02 1.30400484e-03 4.85529174e-03 1.58717870e-02\n",
            " 1.73964329e-03 1.77782499e-02 5.78442140e-03 3.98165427e-03\n",
            " 1.66432698e-02 1.35277177e-02 1.53532470e-03 1.17699487e-02\n",
            " 7.64476880e-03 3.14275180e-03 3.11966814e-03 6.40428862e-03\n",
            " 2.24850668e-03 1.42303232e-02 1.83246554e-02 4.73517289e-06\n",
            " 1.23505499e-02 8.35498891e-04 1.49325596e-02 3.87541493e-03\n",
            " 1.26551689e-03 1.09623510e-02 1.03459839e-02 1.09945210e-05\n",
            " 1.06214736e-02 1.10831557e-02 1.47721659e-02 2.36669366e-03\n",
            " 1.81902484e-04 9.05763290e-03 1.37288811e-02 3.80238039e-03\n",
            " 3.12418240e-03 9.08996467e-03 1.74924271e-03 7.66679673e-04\n",
            " 2.14753406e-03 1.47005845e-02 6.45416737e-04 2.11702711e-03\n",
            " 1.11312812e-03 1.58111820e-02 3.72004943e-03 1.52713778e-02\n",
            " 1.41867465e-02 1.11163861e-02 7.81538045e-03 5.54590731e-05\n",
            " 1.35766849e-02 5.85266038e-04 1.11495528e-02 8.81492283e-04\n",
            " 1.22004568e-02 1.05510706e-02 1.27091851e-02 1.01149910e-02\n",
            " 1.27710508e-02 1.38171513e-02 1.41341329e-02 9.79705171e-03\n",
            " 9.61932826e-03 5.41088047e-03 1.83957066e-02 8.33512661e-03\n",
            " 8.57308364e-03 8.09422658e-03 9.86220045e-03 1.74924271e-03\n",
            " 1.54289017e-02 1.12971158e-02 1.07553437e-02 1.71567777e-02\n",
            " 2.16990706e-03 1.20370415e-02 3.27256623e-03 9.76674536e-03\n",
            " 1.71384613e-02 4.90616924e-03 1.06050846e-02 1.89528378e-03\n",
            " 1.29340252e-02 4.06961546e-03 1.17948365e-02 1.65175789e-02\n",
            " 1.58805683e-02 7.72277804e-03 1.23718625e-02 1.24955890e-02\n",
            " 4.47108255e-03 9.30699209e-03 5.65000692e-04 2.86744285e-03\n",
            " 9.43894964e-03 3.80708301e-03 1.75521121e-02 7.64572214e-03\n",
            " 1.76227131e-02 8.03753434e-03 2.01549633e-04 4.67502117e-03\n",
            " 1.77609874e-02 1.09863936e-02 2.90566476e-03 1.47555690e-02\n",
            " 3.88725368e-03 1.70017301e-02 1.03870554e-02 8.09897021e-03\n",
            " 4.48338351e-03 5.93026605e-04 1.42887534e-03 1.30438312e-02\n",
            " 1.17094074e-03 1.60065095e-02 7.19229349e-03 5.02742000e-03\n",
            " 1.61830494e-02 6.99642306e-04 4.47827850e-03 1.42745395e-02\n",
            " 1.18672901e-02 3.15493288e-04 7.67129566e-03 1.74924271e-03\n",
            " 7.59374862e-03 1.40864915e-02 1.12627384e-02 1.29739986e-02\n",
            " 5.69532763e-03 7.45125698e-03 8.54088832e-03 1.10709778e-02\n",
            " 1.48726085e-02 1.04143905e-02 2.25145338e-03 1.29479330e-02\n",
            " 3.64353218e-03 1.16068837e-03 7.54180866e-03 8.29718913e-03\n",
            " 8.89314520e-03 2.49666955e-04 1.11192370e-02 3.75301369e-03\n",
            " 1.66188520e-02 6.03827638e-03 3.87541493e-03 9.33536031e-03\n",
            " 1.84464512e-02 4.05634908e-04 2.59970451e-03 1.49361444e-02\n",
            " 1.58660874e-02 5.18875441e-04 8.29998101e-03 9.27033598e-03\n",
            " 2.03139144e-03 4.74248810e-03 1.56020733e-03 9.89444939e-03\n",
            " 1.72815914e-02 1.53137193e-02 1.17329315e-02 1.01116227e-02\n",
            " 1.43742756e-02 7.02751604e-03 9.79047825e-03 1.04008782e-02\n",
            " 1.35708546e-04 7.05493889e-03 2.23439155e-03 3.25384004e-03\n",
            " 1.41732337e-02 1.70616773e-02 3.16297804e-03 4.73518252e-03\n",
            " 8.57645596e-03 1.82250586e-02 1.20876681e-02 4.12381687e-03\n",
            " 1.67881885e-02 6.42785260e-03 2.57659795e-03 1.85318127e-02\n",
            " 1.06896053e-02 9.74612141e-03 1.94109494e-03 5.62636909e-04\n",
            " 2.70692122e-03 1.37924868e-02 1.41382199e-02 1.66962591e-02\n",
            " 1.71546629e-02 4.23046279e-03 1.01762808e-02 1.40647313e-02\n",
            " 1.40061149e-02 1.85222444e-02 7.79185910e-03 3.90475923e-03\n",
            " 1.58492606e-02 6.10608627e-04 1.65553683e-02 1.68363753e-02\n",
            " 3.40082833e-03 6.40290092e-03 5.23280681e-03 8.00804569e-03\n",
            " 4.80445121e-03 1.62194106e-02 1.61463652e-02 1.62586580e-02\n",
            " 3.24319406e-04 2.65971682e-03 2.91417429e-03 7.93914323e-03\n",
            " 1.29861004e-02 1.41457821e-02 8.13456375e-03 2.16990706e-03\n",
            " 1.41279033e-02 1.70851289e-02 1.39910080e-03 1.11476386e-02\n",
            " 1.55512572e-02 2.44558911e-03 5.93599116e-03 1.05487669e-02\n",
            " 1.38957817e-02 1.16192199e-02 4.01789089e-03 1.39090659e-02\n",
            " 1.13778045e-02 5.34397192e-03 8.55826299e-04 1.04755240e-02\n",
            " 6.69887417e-03 4.20720497e-03 1.51697204e-02 4.96625537e-03\n",
            " 3.72070239e-03 7.03826920e-03 5.12272516e-03 4.49387388e-03\n",
            " 2.82561328e-03 6.40741086e-03 1.86995673e-02 1.78329247e-02\n",
            " 1.05797402e-02 1.07564402e-03 6.66457338e-04 5.97940033e-03\n",
            " 1.34818903e-02 9.63723469e-04 2.02381314e-04 1.12301252e-02\n",
            " 9.44286452e-03 1.09220304e-02 1.26866335e-03 1.59792430e-02\n",
            " 1.43986008e-03 2.06255385e-03 2.87265359e-03 7.48213450e-05\n",
            " 1.48634185e-02 3.76935930e-03 1.80860251e-02 5.48191753e-03\n",
            " 5.19209284e-03 2.18169906e-06 1.21057143e-02 6.61475851e-04\n",
            " 5.00309638e-07 1.09131217e-02 2.19625445e-05 1.71249538e-02\n",
            " 3.83285469e-05 1.34568178e-02 1.66861428e-02 1.04228136e-02\n",
            " 1.09869551e-02 1.49391800e-03 8.52634682e-04 1.13077379e-02\n",
            " 1.59916936e-02 4.45878497e-03 1.64666029e-02 1.56080780e-02\n",
            " 3.87112242e-03 1.44295260e-02 4.97920527e-03 1.06973427e-02\n",
            " 4.97920527e-03 7.39104565e-03 1.83411806e-02 1.02663304e-03\n",
            " 7.19949113e-03 1.88957532e-03 1.77983168e-02 3.96869345e-03\n",
            " 2.97833143e-04 1.52544131e-02 3.82548091e-04 1.07193759e-02\n",
            " 1.42521258e-02 3.07354884e-03 1.38309679e-02 4.88277604e-03\n",
            " 1.79168926e-02 4.25254443e-03 2.43495623e-04 5.19957933e-03\n",
            " 6.16803111e-03 1.80940832e-02 6.58461124e-03 1.31161427e-02\n",
            " 1.57825748e-02 5.55513784e-03 1.70515513e-02 4.64040811e-03\n",
            " 4.88218013e-03 7.16341434e-03 1.16939423e-02 3.00979004e-03\n",
            " 1.30465713e-02 1.50091155e-02 1.72238203e-02 1.08378248e-02\n",
            " 1.45043208e-02 5.46483056e-03 1.69867927e-02 5.81808470e-03\n",
            " 1.27318602e-02 1.82238509e-02 4.78961736e-03 3.87112242e-03\n",
            " 1.34554502e-02 1.39884720e-02 7.78715583e-03 1.06007568e-02\n",
            " 1.39123887e-03 1.23608092e-03 3.74802359e-03 1.58252796e-02\n",
            " 5.34948345e-03 3.97403315e-03 6.87071544e-04 1.73010519e-02\n",
            " 9.16966481e-03 1.09393922e-02 8.26727108e-03 5.56868009e-03\n",
            " 2.29762988e-03 7.34090096e-04 9.35895449e-03 7.05309376e-03\n",
            " 7.43152265e-03 8.78926155e-03 1.12694678e-02 9.79199982e-03\n",
            " 2.89436699e-03 1.51056676e-03 1.28939653e-03 1.43219033e-02\n",
            " 6.23313561e-03 9.75807834e-03 1.07773339e-02 7.20216043e-03\n",
            " 1.74462995e-02 8.63635625e-03 1.35667806e-02 4.21410076e-03\n",
            " 1.38242135e-02 7.96991674e-03 3.80194456e-03 8.96469496e-03\n",
            " 1.34562922e-02 1.84319129e-02 1.29800231e-02 3.12304856e-03\n",
            " 1.48840037e-02 1.32085228e-02 3.33368844e-03 8.88261117e-03\n",
            " 4.76033133e-04 9.16720307e-04 8.92430315e-03 1.41732337e-02\n",
            " 8.33274830e-03 2.67578987e-03 9.79705171e-03 6.09813892e-03\n",
            " 8.22988154e-03 1.66305705e-02 3.98311138e-04 5.61235094e-03\n",
            " 1.44038472e-02 7.50012929e-03 3.68976251e-03 1.05652074e-02\n",
            " 6.82607321e-03 3.56534532e-03 7.78599357e-03 1.52915184e-02\n",
            " 9.24926338e-03 9.60251797e-03 7.28638842e-03 1.69257855e-02\n",
            " 4.80588231e-03 5.67173633e-03 6.64747806e-03 8.35498891e-04\n",
            " 3.93797254e-03]\n",
            "3400 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.85757735e-03 4.39576726e-03 1.68459994e-02 1.70761465e-02\n",
            " 4.70608994e-03 3.98994384e-03 1.52016161e-02 6.96308450e-04\n",
            " 1.25555110e-02 9.34392480e-03 4.05829858e-03 6.64975400e-03\n",
            " 1.24420606e-02 8.38552082e-03 1.58976026e-02 1.15421144e-02\n",
            " 8.23333731e-03 1.03207743e-02 1.06577350e-02 1.20923520e-02\n",
            " 6.45536672e-03 1.44001357e-02 5.67934621e-03 1.82932773e-02\n",
            " 7.52574579e-03 5.57410750e-03 8.26725530e-03 1.44836902e-03\n",
            " 9.53670916e-03 4.97691096e-03 5.43261650e-03 1.82932773e-02\n",
            " 3.86747679e-03 1.41208876e-05 5.97506672e-03 1.29229513e-02\n",
            " 1.39437958e-02 1.52727232e-02 2.92523214e-03 1.07941491e-02\n",
            " 1.35200476e-02 1.80600180e-02 1.02768492e-04 9.67503466e-03\n",
            " 1.29229513e-02 1.26008963e-02 1.94882287e-03 5.47110743e-09\n",
            " 2.99499959e-03 1.86425836e-05 6.53382152e-03 1.25412407e-02\n",
            " 8.76663036e-03 4.40813169e-04 1.83508106e-07 1.13849553e-02\n",
            " 7.77466238e-03 7.27435303e-03 2.86947769e-03 7.65014964e-03\n",
            " 1.08034375e-02 9.75989931e-03 1.70442152e-02 5.50656674e-03\n",
            " 8.96799805e-03 2.19080206e-03 1.17547059e-02 1.39294461e-02\n",
            " 9.45920462e-03 1.63918130e-02 1.81599653e-02 1.35691939e-02\n",
            " 1.13487714e-02 1.12105243e-02 1.73567298e-02 1.02372649e-03\n",
            " 7.53457493e-03 2.93513446e-03 1.63509767e-02 3.76996151e-04\n",
            " 1.71686156e-02 1.11741072e-03 1.46704602e-02 8.29194949e-03\n",
            " 3.33627944e-03 1.00501742e-02 1.79575230e-02 1.82315399e-02\n",
            " 1.41929563e-02 9.75989931e-03 1.26393776e-02 4.22462395e-04\n",
            " 1.39402753e-02 7.46889274e-03 5.21219746e-03 5.02613124e-03\n",
            " 1.17193883e-02 4.87604363e-04 1.11884877e-02 1.01854315e-02\n",
            " 4.26788897e-03 4.29879503e-03 1.17329367e-03 1.60129307e-02\n",
            " 5.78795948e-03 1.11131420e-02 6.06326709e-04 1.05715839e-03\n",
            " 1.03748804e-02 5.50762591e-03 6.75431568e-05 3.73642879e-03\n",
            " 1.29446566e-02 1.80925648e-02 9.72142903e-03 1.08813599e-02\n",
            " 1.11470718e-02 1.86646652e-03 7.73762780e-03 8.61987398e-03\n",
            " 6.86140782e-04 1.48772760e-02 2.11299438e-03 1.49498582e-02\n",
            " 1.08578469e-02 1.00946298e-02 1.45690370e-02 7.87959859e-03\n",
            " 1.74475078e-02 9.17649634e-03 5.14621716e-03 1.26008963e-02\n",
            " 3.64081814e-03 7.16816653e-05 1.64239569e-02 9.24817373e-03\n",
            " 1.34446316e-02 4.12440326e-03 1.48447316e-02 1.64566557e-02\n",
            " 3.64081814e-03 1.20296910e-02 1.19779278e-02 9.02112863e-03\n",
            " 1.46183363e-02 6.83073716e-03 1.00098860e-03 1.26472084e-02\n",
            " 1.51579771e-02 9.66331312e-03 7.49466593e-03 1.18304379e-02\n",
            " 1.52408219e-03 1.79869037e-02 1.59943842e-02 1.28853694e-02\n",
            " 4.53444504e-05 1.70729126e-02 8.96609364e-03 1.49428540e-02\n",
            " 1.62015103e-02 4.73479971e-03 3.16736419e-03 1.03840358e-02\n",
            " 7.15576781e-03 1.71686156e-02 9.16160282e-03 4.64239224e-03\n",
            " 9.17017221e-03 1.06984794e-02 9.69695931e-03 9.99691712e-03\n",
            " 5.47110743e-09 3.97755524e-03 9.09302692e-03 1.50724820e-02\n",
            " 8.69610617e-03 1.10753945e-03 1.30686178e-02 1.32974110e-02\n",
            " 4.22797410e-03 1.47051785e-02 8.08144829e-03 1.81029592e-03\n",
            " 7.77472906e-03 1.46649728e-02 2.13809114e-03 7.53060323e-03\n",
            " 4.17352581e-03 1.17499897e-02 1.65077490e-02 8.85449350e-03\n",
            " 5.68743861e-03 5.50343328e-03 1.80460121e-02 6.66130303e-03\n",
            " 3.01036873e-03 8.38552082e-03 1.30587448e-02 1.31600798e-02\n",
            " 9.62316548e-03 5.21558893e-03 1.06832937e-02 4.26788897e-03\n",
            " 1.07941491e-02 9.69195650e-03 7.72377569e-03 1.23616513e-02\n",
            " 9.33459238e-03 5.78017397e-03 1.10215898e-02 7.80146920e-03\n",
            " 1.21102982e-02 1.82427758e-02 2.47117393e-03 1.37278537e-02\n",
            " 1.65156066e-04 4.12615937e-03 1.65473343e-02 1.05707647e-02\n",
            " 1.83576132e-02 1.12586447e-02 4.14025846e-03 1.01803487e-02\n",
            " 3.37236730e-03 1.40443587e-02 6.17037408e-03 7.57730511e-03\n",
            " 1.02517480e-02 5.38102544e-04 3.18496416e-03 1.12133885e-02\n",
            " 1.62015103e-02 1.53153386e-02 6.12656203e-03 1.32648512e-02\n",
            " 1.38885187e-06 1.17301302e-02 9.26679260e-05 8.23344458e-04\n",
            " 2.92863047e-03 1.27843631e-02 6.67684108e-03 3.03150580e-03\n",
            " 9.51278466e-03 5.22420638e-03 4.26609600e-04 1.47615158e-02\n",
            " 5.31748940e-03 5.54203012e-03 1.28447401e-02 1.19956194e-03\n",
            " 1.36102645e-02 1.08133872e-02 8.67841467e-04 1.77425578e-02\n",
            " 4.59059494e-03 1.25555110e-02 6.82956058e-03 8.45606762e-03\n",
            " 5.53836378e-03 1.48156968e-02 6.04692712e-03 1.46714517e-02\n",
            " 4.53005403e-03 5.67834862e-03 1.82145143e-02 5.43410971e-03\n",
            " 3.34949584e-03 7.75613990e-03 4.26788897e-03 1.62914897e-02\n",
            " 1.00833406e-02 1.76332780e-02 7.90130031e-03 3.72843593e-03\n",
            " 1.70340969e-02 1.25713851e-03 1.49865080e-03 1.66866100e-02\n",
            " 9.16972757e-03 4.15208846e-03 1.01608325e-02 1.21083814e-02\n",
            " 1.57199803e-03 5.23401651e-03 9.26884167e-03 1.72503808e-02\n",
            " 9.85064011e-05 8.11957962e-03 1.73424431e-02 3.35556660e-16\n",
            " 3.10647061e-03 1.58064438e-02 1.47699378e-02 6.15847541e-03\n",
            " 1.29427147e-02 1.06124645e-02 1.43383381e-02 1.15477792e-02\n",
            " 1.70202981e-02 2.40216197e-04 8.20644030e-03 1.03458048e-02\n",
            " 1.58054753e-02 1.01803487e-02 7.53457493e-03 2.90718235e-03\n",
            " 4.08386350e-03 3.22979575e-03 1.18304379e-02 2.13080883e-03\n",
            " 1.63548404e-02 3.70305987e-03 1.25387452e-02 6.76842745e-03\n",
            " 7.36203257e-03 1.65907711e-03 2.55802830e-04 7.18438960e-03\n",
            " 1.31600524e-02 4.78214488e-03 6.74799573e-03 1.22070666e-02\n",
            " 4.07437889e-03 4.09277014e-04 1.42007934e-02 8.59723078e-03\n",
            " 2.05747013e-03 4.52848526e-03 3.48108659e-03 7.06502009e-03\n",
            " 7.87240431e-03 1.81180745e-04 4.53388329e-03 1.52378499e-02\n",
            " 3.57785693e-03 8.49218762e-03 1.44244605e-02 4.86204676e-03\n",
            " 3.26814455e-03 9.21869244e-03 9.11278782e-03 6.92738865e-03\n",
            " 1.37266961e-02 1.70581952e-02 4.76859101e-03 9.46060377e-03\n",
            " 5.57410750e-03 9.93799213e-03 1.44669681e-02 4.91945145e-03\n",
            " 1.00468483e-02 1.98834083e-04 9.33312560e-03 1.19226663e-02\n",
            " 1.69617258e-03 8.37340134e-03 9.97161350e-03 8.12196917e-03\n",
            " 6.88287664e-03 3.73642879e-03 1.35544932e-03 1.24784013e-02\n",
            " 2.95542592e-03 2.00384247e-03 1.55656665e-02 1.46865586e-02\n",
            " 1.39780855e-02 1.29857588e-03 4.84371414e-03 1.58535032e-02\n",
            " 1.73798538e-03 1.77550382e-02 5.78017397e-03 3.97379642e-03\n",
            " 1.66146087e-02 1.35171062e-02 1.51901893e-03 1.17485517e-02\n",
            " 7.65109843e-03 3.12966452e-03 3.11450226e-03 6.39491156e-03\n",
            " 2.23458268e-03 1.42229913e-02 1.82531028e-02 4.69916913e-06\n",
            " 1.23339416e-02 8.31652131e-04 1.49091821e-02 3.87734912e-03\n",
            " 1.26062633e-03 1.09494834e-02 1.03261234e-02 1.06828600e-05\n",
            " 1.06132205e-02 1.11130436e-02 1.47734249e-02 2.35950606e-03\n",
            " 1.81493887e-04 9.04147073e-03 1.37266961e-02 3.78816785e-03\n",
            " 3.06347021e-03 9.06099065e-03 1.74539487e-03 7.66820746e-04\n",
            " 2.13753596e-03 1.47010049e-02 6.44797367e-04 2.10894293e-03\n",
            " 1.10434033e-03 1.58016534e-02 3.66958447e-03 1.52315563e-02\n",
            " 1.40664123e-02 1.11047934e-02 7.81616204e-03 5.53138694e-05\n",
            " 1.35693447e-02 5.79342317e-04 1.11322125e-02 8.78134517e-04\n",
            " 1.21715655e-02 1.05277751e-02 1.26904971e-02 1.00483341e-02\n",
            " 1.27492484e-02 1.38084640e-02 1.41302181e-02 9.75989931e-03\n",
            " 9.61604036e-03 5.39452011e-03 8.32447383e-03 8.48098417e-03\n",
            " 8.09193248e-03 9.81838947e-03 1.74539487e-03 1.54270244e-02\n",
            " 1.12879586e-02 1.07778623e-02 1.70519601e-02 2.15956001e-03\n",
            " 1.20192090e-02 3.25763243e-03 9.71680630e-03 1.71286482e-02\n",
            " 4.90921939e-03 1.06030754e-02 1.89213948e-03 1.29063959e-02\n",
            " 4.04922475e-03 1.17888746e-02 1.65393127e-02 1.58722412e-02\n",
            " 7.68668014e-03 1.23488670e-02 1.24940793e-02 4.46312314e-03\n",
            " 9.27666126e-03 5.63057483e-04 2.86840610e-03 9.42063180e-03\n",
            " 3.77550614e-03 1.74985038e-02 7.61375475e-03 1.74768409e-02\n",
            " 8.02690354e-03 1.98834083e-04 4.67670412e-03 1.77584225e-02\n",
            " 1.08850181e-02 2.89435337e-03 1.47649012e-02 3.84765726e-03\n",
            " 1.69398772e-02 1.03570397e-02 8.08244623e-03 4.46864049e-03\n",
            " 5.88821720e-04 1.42657784e-03 1.30254087e-02 1.16700216e-03\n",
            " 1.59853763e-02 7.18136048e-03 5.03244629e-03 1.61539049e-02\n",
            " 6.96308450e-04 4.45206943e-03 1.42549642e-02 1.18400501e-02\n",
            " 3.14780803e-04 7.66960562e-03 1.74539487e-03 7.57585765e-03\n",
            " 1.40126510e-02 1.12312300e-02 1.29822849e-02 5.69644045e-03\n",
            " 7.44562414e-03 8.55245643e-03 1.10468251e-02 1.48425200e-02\n",
            " 1.04189263e-02 2.23874951e-03 1.29056923e-02 3.61842510e-03\n",
            " 1.14567174e-03 7.53336614e-03 8.26665061e-03 8.85769142e-03\n",
            " 2.48513587e-04 1.11106533e-02 3.73642879e-03 1.66071731e-02\n",
            " 6.03449437e-03 3.87734912e-03 9.33130290e-03 4.03186800e-04\n",
            " 2.60118270e-03 1.48809435e-02 1.58691699e-02 5.04751290e-04\n",
            " 8.28992927e-03 9.25814524e-03 2.02024596e-03 4.71159950e-03\n",
            " 1.53735544e-03 9.89236633e-03 1.72817474e-02 1.53286605e-02\n",
            " 1.17190955e-02 1.00772555e-02 1.44095870e-02 7.02335105e-03\n",
            " 9.80235077e-03 1.04001877e-02 1.35250168e-04 7.04557255e-03\n",
            " 2.23225050e-03 3.24681993e-03 1.41162132e-02 1.70581952e-02\n",
            " 3.14498919e-03 4.73479971e-03 8.55807499e-03 1.80650430e-02\n",
            " 1.20722442e-02 4.12440326e-03 1.67273309e-02 6.42019818e-03\n",
            " 2.56042253e-03 1.06642215e-02 9.73059859e-03 1.93396003e-03\n",
            " 5.61789056e-04 2.70040028e-03 1.37462526e-02 1.41263361e-02\n",
            " 1.66086900e-02 1.70340969e-02 4.22527487e-03 1.01476862e-02\n",
            " 1.40443587e-02 1.40162300e-02 7.77458315e-03 3.87472164e-03\n",
            " 1.58294603e-02 6.02143594e-04 1.65325584e-02 1.67910094e-02\n",
            " 3.36836289e-03 6.39607742e-03 5.19525508e-03 7.99435642e-03\n",
            " 4.77355402e-03 1.62015103e-02 1.61202431e-02 1.62539599e-02\n",
            " 3.22464462e-04 2.65667788e-03 2.85898356e-03 7.92523599e-03\n",
            " 1.29355991e-02 1.41184352e-02 8.10298179e-03 2.15956001e-03\n",
            " 1.41203392e-02 1.70629304e-02 1.37737578e-03 1.10880769e-02\n",
            " 1.55743403e-02 2.42685466e-03 5.85487234e-03 1.05576782e-02\n",
            " 1.38710759e-02 1.15635092e-02 4.01376220e-03 1.38932721e-02\n",
            " 1.13491206e-02 5.30472855e-03 8.50418250e-04 1.04644668e-02\n",
            " 6.69670089e-03 4.19092270e-03 1.51035136e-02 4.92341798e-03\n",
            " 3.71712630e-03 7.00799819e-03 5.09748966e-03 4.48898727e-03\n",
            " 2.81560271e-03 6.38133429e-03 1.78101228e-02 1.04927869e-02\n",
            " 1.06563659e-03 6.65110049e-04 5.97506672e-03 1.34749331e-02\n",
            " 9.61259436e-04 2.01012664e-04 1.12077497e-02 9.36246130e-03\n",
            " 1.08934930e-02 1.26267580e-03 1.59591573e-02 1.43348376e-03\n",
            " 2.04756441e-03 2.86947769e-03 7.44305838e-05 1.48458008e-02\n",
            " 3.75336853e-03 1.80831403e-02 5.46697182e-03 5.18206965e-03\n",
            " 2.17588244e-06 1.20360157e-02 6.62347274e-04 4.99825681e-07\n",
            " 1.08558275e-02 2.12605930e-05 1.71272950e-02 3.81186363e-05\n",
            " 1.34393143e-02 1.66528575e-02 1.04124685e-02 1.09873247e-02\n",
            " 1.49390346e-03 8.49542024e-04 1.12842036e-02 1.59297767e-02\n",
            " 4.39801437e-03 1.64294901e-02 1.55832961e-02 3.86747679e-03\n",
            " 1.43678745e-02 4.91313768e-03 1.06930054e-02 4.91313768e-03\n",
            " 7.35865677e-03 1.82688029e-02 1.02223352e-03 7.20245046e-03\n",
            " 1.87418152e-03 1.77900970e-02 3.94994347e-03 2.97057477e-04\n",
            " 1.51955740e-02 3.80302315e-04 1.06056080e-02 1.42336566e-02\n",
            " 3.06402752e-03 1.38223973e-02 4.86073917e-03 1.79314831e-02\n",
            " 4.24346070e-03 2.41348097e-04 5.21021312e-03 6.16749684e-03\n",
            " 1.80926760e-02 6.56731951e-03 1.31086646e-02 1.57907670e-02\n",
            " 5.53343535e-03 1.70520628e-02 4.63252555e-03 4.86204676e-03\n",
            " 7.13752610e-03 1.17098495e-02 2.99896909e-03 1.30276102e-02\n",
            " 1.49205924e-02 1.72081071e-02 1.08361299e-02 1.44302664e-02\n",
            " 5.46377767e-03 1.69693984e-02 5.79113869e-03 1.26841010e-02\n",
            " 1.82133440e-02 4.74686800e-03 3.86747679e-03 1.34438227e-02\n",
            " 1.39667889e-02 7.75511511e-03 1.05752058e-02 1.38707553e-03\n",
            " 1.23067548e-03 3.74859723e-03 1.58079286e-02 5.34674407e-03\n",
            " 3.96710126e-03 6.82545650e-04 1.72222130e-02 9.16390245e-03\n",
            " 1.09497515e-02 8.26923303e-03 5.55489258e-03 2.28940547e-03\n",
            " 7.30942958e-04 9.36520907e-03 7.05255053e-03 7.34062189e-03\n",
            " 8.73298942e-03 1.12633050e-02 9.77613268e-03 2.87456094e-03\n",
            " 1.50471721e-03 1.28624186e-03 1.43285526e-02 6.21024238e-03\n",
            " 9.73463585e-03 1.07865342e-02 7.19274991e-03 1.74166215e-02\n",
            " 8.64062134e-03 1.35240559e-02 4.20956953e-03 1.38099201e-02\n",
            " 7.92755512e-03 3.75801443e-03 8.97391488e-03 1.33209862e-02\n",
            " 1.29968463e-02 3.11680844e-03 1.48829684e-02 1.31589900e-02\n",
            " 3.31929967e-03 8.86226939e-03 4.70183529e-04 9.13348439e-04\n",
            " 8.93509237e-03 1.41162132e-02 8.30682923e-03 2.67298735e-03\n",
            " 9.75989931e-03 6.08497642e-03 8.21764334e-03 1.66037454e-02\n",
            " 3.91836453e-04 5.58715931e-03 1.43916220e-02 7.47749082e-03\n",
            " 3.68050669e-03 1.05316470e-02 6.82778198e-03 3.55540938e-03\n",
            " 7.73552658e-03 1.52727232e-02 9.18032989e-03 9.57700250e-03\n",
            " 7.26570659e-03 1.69324227e-02 4.80131880e-03 5.63601407e-03\n",
            " 6.63290201e-03 8.31652131e-04 3.93232029e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3410 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.84386552e-03 4.38438935e-03 1.68197476e-02 1.70471246e-02\n",
            " 4.69648491e-03 3.96412820e-03 1.51803269e-02 6.96502771e-04\n",
            " 1.25037695e-02 9.30564964e-03 4.03035223e-03 6.62234024e-03\n",
            " 1.23849932e-02 8.37624081e-03 1.58809141e-02 1.15175351e-02\n",
            " 8.21211895e-03 1.03122112e-02 1.06338715e-02 1.20763901e-02\n",
            " 6.45417257e-03 1.43924343e-02 5.65788493e-03 7.52300151e-03\n",
            " 5.57371913e-03 8.25051768e-03 1.44604327e-03 9.51839402e-03\n",
            " 4.96594748e-03 5.43154901e-03 3.86966378e-03 1.40927334e-05\n",
            " 5.97624755e-03 1.29079482e-02 1.39421742e-02 1.52523059e-02\n",
            " 2.92959712e-03 1.07768817e-02 1.35416474e-02 1.80446252e-02\n",
            " 1.01377351e-04 9.62939114e-03 1.29079482e-02 1.25406624e-02\n",
            " 1.94583575e-03 5.38806896e-09 2.97994552e-03 1.86432127e-05\n",
            " 6.50415717e-03 1.25124008e-02 8.77670970e-03 4.40479539e-04\n",
            " 1.80361229e-07 1.13470198e-02 7.73802739e-03 7.24071014e-03\n",
            " 2.87099669e-03 7.64496294e-03 1.07442251e-02 9.74978424e-03\n",
            " 1.70147812e-02 5.47874339e-03 8.97216379e-03 2.19530131e-03\n",
            " 1.16778991e-02 1.39342068e-02 9.45647158e-03 1.63654884e-02\n",
            " 1.35310266e-02 1.13227839e-02 1.11816668e-02 1.73396996e-02\n",
            " 1.02686134e-03 7.53204091e-03 2.91414595e-03 1.63248960e-02\n",
            " 3.75770139e-04 1.71628736e-02 1.10873387e-03 1.46334568e-02\n",
            " 8.27010980e-03 3.33617461e-03 1.00416547e-02 1.79041333e-02\n",
            " 1.41810693e-02 9.74978424e-03 1.26460349e-02 4.22918888e-04\n",
            " 1.39137492e-02 7.45291084e-03 5.16982047e-03 5.01910529e-03\n",
            " 1.16705673e-02 4.85062020e-04 1.11745558e-02 1.01585569e-02\n",
            " 4.25913299e-03 4.29664252e-03 1.16967783e-03 1.60096386e-02\n",
            " 5.77964755e-03 1.11055776e-02 6.01688530e-04 1.05635239e-03\n",
            " 1.03561621e-02 5.46877991e-03 6.74668285e-05 3.73274034e-03\n",
            " 1.29151775e-02 1.80690949e-02 9.70740351e-03 1.08731970e-02\n",
            " 1.11053524e-02 1.85796660e-03 7.72708723e-03 8.59894916e-03\n",
            " 6.78709143e-04 1.48777484e-02 2.10749857e-03 1.49764449e-02\n",
            " 1.08353729e-02 1.00887239e-02 1.45561353e-02 7.85758328e-03\n",
            " 1.74051618e-02 9.17807338e-03 5.13698265e-03 1.25406624e-02\n",
            " 3.63260082e-03 7.12839111e-05 1.63677373e-02 9.22770244e-03\n",
            " 1.34497315e-02 4.10545351e-03 1.48406647e-02 1.64436491e-02\n",
            " 3.63260082e-03 1.19997928e-02 1.19661203e-02 9.00038698e-03\n",
            " 1.45977130e-02 6.82817258e-03 1.00001870e-03 1.26270921e-02\n",
            " 1.51342378e-02 9.64016479e-03 7.47441097e-03 1.17940086e-02\n",
            " 1.52075105e-03 1.79598834e-02 1.59877733e-02 1.28487118e-02\n",
            " 4.52189414e-05 1.70638273e-02 8.97302256e-03 1.49355033e-02\n",
            " 1.61957127e-02 4.73568423e-03 3.16586655e-03 1.03454129e-02\n",
            " 7.14437127e-03 1.71628736e-02 9.11825161e-03 4.64512396e-03\n",
            " 9.14110521e-03 1.06769340e-02 9.67588921e-03 9.98207955e-03\n",
            " 5.38806896e-09 3.95661596e-03 9.07116533e-03 1.50079921e-02\n",
            " 8.69918914e-03 1.10319862e-03 1.30207747e-02 1.32681763e-02\n",
            " 4.21457818e-03 1.46939867e-02 8.06580092e-03 1.79826925e-03\n",
            " 7.75377510e-03 1.46321107e-02 2.13297232e-03 7.53576737e-03\n",
            " 4.17402366e-03 1.17308010e-02 1.65058211e-02 8.80395443e-03\n",
            " 5.68520935e-03 5.50424004e-03 1.80125804e-02 6.65978677e-03\n",
            " 3.00772729e-03 8.37624081e-03 1.30320059e-02 1.31651206e-02\n",
            " 9.58616451e-03 5.20533381e-03 1.06840724e-02 4.25913299e-03\n",
            " 1.07768817e-02 9.69742409e-03 7.69314469e-03 1.23632434e-02\n",
            " 9.25905920e-03 5.78352796e-03 1.09820578e-02 7.78320915e-03\n",
            " 1.20953551e-02 2.47191703e-03 1.37281025e-02 1.63651571e-04\n",
            " 4.12009654e-03 1.64772961e-02 1.05616070e-02 1.12277335e-02\n",
            " 4.12364198e-03 1.01567107e-02 3.36626820e-03 1.40304264e-02\n",
            " 6.17017380e-03 7.54213775e-03 1.02556137e-02 5.36407014e-04\n",
            " 3.17350348e-03 1.11701789e-02 1.61957127e-02 1.52571937e-02\n",
            " 6.11963069e-03 1.32521371e-02 1.36678732e-06 1.17084842e-02\n",
            " 9.29652623e-05 8.21117635e-04 2.91646023e-03 1.27761479e-02\n",
            " 6.67462004e-03 3.02072316e-03 9.46449454e-03 5.22934553e-03\n",
            " 4.25888448e-04 1.46575851e-02 5.30149129e-03 5.52932408e-03\n",
            " 1.27992911e-02 1.18810633e-03 1.36232045e-02 1.07779825e-02\n",
            " 8.63867642e-04 1.77655155e-02 4.58693192e-03 1.25037695e-02\n",
            " 6.80558157e-03 8.42813062e-03 5.53467293e-03 1.47565625e-02\n",
            " 6.02463368e-03 1.45908112e-02 4.52026276e-03 5.66873893e-03\n",
            " 5.41477761e-03 3.33012766e-03 7.73142159e-03 4.25913299e-03\n",
            " 1.62342147e-02 1.00772168e-02 1.76094990e-02 7.88755420e-03\n",
            " 3.72702282e-03 1.70144107e-02 1.25128157e-03 1.49498402e-03\n",
            " 1.66019137e-02 9.17620746e-03 4.14373136e-03 1.01542302e-02\n",
            " 1.20523627e-02 1.56972306e-03 5.22670736e-03 9.24402992e-03\n",
            " 1.72251231e-02 9.83428946e-05 8.11720251e-03 1.72980051e-02\n",
            " 3.35230569e-16 3.10719396e-03 1.58108227e-02 1.47779612e-02\n",
            " 6.15256246e-03 1.29374555e-02 1.05940043e-02 1.42804621e-02\n",
            " 1.15582063e-02 1.70237430e-02 2.39777570e-04 8.17953924e-03\n",
            " 1.03368481e-02 1.57593264e-02 1.01567107e-02 7.53204091e-03\n",
            " 2.88501989e-03 4.07179807e-03 3.23024420e-03 1.17940086e-02\n",
            " 2.12088721e-03 1.62915492e-02 3.68473631e-03 1.25176506e-02\n",
            " 6.72513727e-03 7.35590803e-03 1.65265573e-03 2.53834857e-04\n",
            " 7.18405930e-03 1.31400702e-02 4.76437867e-03 6.72069858e-03\n",
            " 1.22059233e-02 4.07658485e-03 4.07299063e-04 1.41880903e-02\n",
            " 8.59298952e-03 2.05038224e-03 4.50864248e-03 3.48374572e-03\n",
            " 7.06106924e-03 7.85640757e-03 1.79677971e-04 4.52155694e-03\n",
            " 1.52538163e-02 3.58064005e-03 8.47509423e-03 1.43829514e-02\n",
            " 4.85741280e-03 3.26417572e-03 9.19525895e-03 9.09127925e-03\n",
            " 6.93317416e-03 1.36788630e-02 1.70498709e-02 4.75606984e-03\n",
            " 9.43941345e-03 5.57371913e-03 9.91514517e-03 1.44399604e-02\n",
            " 4.91360559e-03 1.00358558e-02 1.97599211e-04 9.31871283e-03\n",
            " 1.19057395e-02 1.68994775e-03 8.35324579e-03 9.95786236e-03\n",
            " 8.10097040e-03 6.87435009e-03 3.73274034e-03 1.35564722e-03\n",
            " 1.24650446e-02 2.93793462e-03 2.00229249e-03 1.55521638e-02\n",
            " 1.46918861e-02 1.39618746e-02 1.29729413e-03 4.83185255e-03\n",
            " 1.58266879e-02 1.72834291e-03 1.77336587e-02 5.78352796e-03\n",
            " 3.96704433e-03 1.66101295e-02 1.34971712e-02 1.50940826e-03\n",
            " 1.17689681e-02 7.63801230e-03 3.12851406e-03 3.11506464e-03\n",
            " 6.36826194e-03 2.23232785e-03 1.42180113e-02 4.68024309e-06\n",
            " 1.23108664e-02 8.28785218e-04 1.48999345e-02 3.87083863e-03\n",
            " 1.25795936e-03 1.08944149e-02 1.02725292e-02 1.05571906e-05\n",
            " 1.06053260e-02 1.11016836e-02 1.47653703e-02 2.34782256e-03\n",
            " 1.81435664e-04 9.02549441e-03 1.36788630e-02 3.77781919e-03\n",
            " 3.05070112e-03 9.04574748e-03 1.74562066e-03 7.66226257e-04\n",
            " 2.12920296e-03 1.46323885e-02 6.41276708e-04 2.11480635e-03\n",
            " 1.09672650e-03 1.57713991e-02 3.66148408e-03 1.51607516e-02\n",
            " 1.39960200e-02 1.10703559e-02 7.80258646e-03 5.51778265e-05\n",
            " 1.35844214e-02 5.76521082e-04 1.11220334e-02 8.78932784e-04\n",
            " 1.21380022e-02 1.05174103e-02 1.26949916e-02 1.00287734e-02\n",
            " 1.27362060e-02 1.38278762e-02 1.40776429e-02 9.74978424e-03\n",
            " 9.59738350e-03 5.38318692e-03 8.31489599e-03 8.44238739e-03\n",
            " 8.06134685e-03 9.79350126e-03 1.74562066e-03 1.54197314e-02\n",
            " 1.12083337e-02 1.07524611e-02 1.70464954e-02 2.14444812e-03\n",
            " 1.19696589e-02 3.25331502e-03 9.66966826e-03 1.70980895e-02\n",
            " 4.89908678e-03 1.05895048e-02 1.88726776e-03 1.29015959e-02\n",
            " 4.04323220e-03 1.17829600e-02 1.63907305e-02 1.58057426e-02\n",
            " 7.69241493e-03 1.23524523e-02 1.24739647e-02 4.46270760e-03\n",
            " 9.24528743e-03 5.63301011e-04 2.86757581e-03 9.42380503e-03\n",
            " 3.76158041e-03 1.75075266e-02 7.56318555e-03 1.74716999e-02\n",
            " 8.03633185e-03 1.97599211e-04 4.67202078e-03 1.76533696e-02\n",
            " 1.08604520e-02 2.87130817e-03 1.47286520e-02 3.82562600e-03\n",
            " 1.69291471e-02 1.03203926e-02 8.07683568e-03 4.45791829e-03\n",
            " 5.81244832e-04 1.42962215e-03 1.30136844e-02 1.16454456e-03\n",
            " 1.59125499e-02 7.14885655e-03 5.03388976e-03 1.60291515e-02\n",
            " 6.96502771e-04 4.42817225e-03 1.42540018e-02 1.17953200e-02\n",
            " 3.13120360e-04 7.66505820e-03 1.74562066e-03 7.58388038e-03\n",
            " 1.39981361e-02 1.12188934e-02 1.29309070e-02 5.68866995e-03\n",
            " 7.43837984e-03 8.53371986e-03 1.09768634e-02 1.48067773e-02\n",
            " 1.04094746e-02 2.23437685e-03 1.28598851e-02 3.60784991e-03\n",
            " 1.14367614e-03 7.53698016e-03 8.25902494e-03 8.83106880e-03\n",
            " 2.48155289e-04 1.11061619e-02 3.73274034e-03 1.65948414e-02\n",
            " 6.03667957e-03 3.87083863e-03 9.31837342e-03 4.03179343e-04\n",
            " 2.59206334e-03 1.48643508e-02 1.58699687e-02 5.03265125e-04\n",
            " 8.24737295e-03 9.22500834e-03 2.02051223e-03 4.70627992e-03\n",
            " 1.52902767e-03 9.87372848e-03 1.72104644e-02 1.53632300e-02\n",
            " 1.16870556e-02 1.00473507e-02 1.43793972e-02 7.02525236e-03\n",
            " 9.75472150e-03 1.03962930e-02 1.35178684e-04 7.04115919e-03\n",
            " 2.23142941e-03 3.23275618e-03 1.41008739e-02 1.70498709e-02\n",
            " 3.13615055e-03 4.73568423e-03 8.50533020e-03 1.80348781e-02\n",
            " 1.20561264e-02 4.10545351e-03 1.67219902e-02 6.40627628e-03\n",
            " 2.55228065e-03 1.06156436e-02 9.71715380e-03 1.93146218e-03\n",
            " 5.61849994e-04 2.68801713e-03 1.37373024e-02 1.41222098e-02\n",
            " 1.66042442e-02 1.70144107e-02 4.22390898e-03 1.01341451e-02\n",
            " 1.40304264e-02 1.40041438e-02 7.77362321e-03 3.86168938e-03\n",
            " 1.58701800e-02 6.00456735e-04 1.64980774e-02 1.67627978e-02\n",
            " 3.35647901e-03 6.37806847e-03 5.19269405e-03 7.98526434e-03\n",
            " 4.76544498e-03 1.61957127e-02 1.60820144e-02 1.62396460e-02\n",
            " 3.20420567e-04 2.64614863e-03 2.83255006e-03 7.90247645e-03\n",
            " 1.28952201e-02 1.41108297e-02 8.09091982e-03 2.14444812e-03\n",
            " 1.41293866e-02 1.70121789e-02 1.36955669e-03 1.10435717e-02\n",
            " 1.55744290e-02 2.42706342e-03 5.83472862e-03 1.05438192e-02\n",
            " 1.38612646e-02 1.15335372e-02 4.01203977e-03 1.38335484e-02\n",
            " 1.13224548e-02 5.27849485e-03 8.44475694e-04 1.04375319e-02\n",
            " 6.68154476e-03 4.17041836e-03 1.50486146e-02 4.91439359e-03\n",
            " 3.71458948e-03 6.99186041e-03 5.08944213e-03 4.48264973e-03\n",
            " 2.81928301e-03 6.37075218e-03 1.76946981e-02 1.05022316e-02\n",
            " 1.05811349e-03 6.65169450e-04 5.97624755e-03 1.34672865e-02\n",
            " 9.57659588e-04 1.99731369e-04 1.12140036e-02 9.34816391e-03\n",
            " 1.09010037e-02 1.25818921e-03 1.59249114e-02 1.43233907e-03\n",
            " 2.03426768e-03 2.87099669e-03 7.41250137e-05 1.48153115e-02\n",
            " 3.75171004e-03 1.80959284e-02 5.44127748e-03 5.16957776e-03\n",
            " 2.16388879e-06 1.20291186e-02 6.59242283e-04 4.99139031e-07\n",
            " 1.08214667e-02 2.10627913e-05 1.70838214e-02 3.80285955e-05\n",
            " 1.33730713e-02 1.66101729e-02 1.03974916e-02 1.09809440e-02\n",
            " 1.49258224e-03 8.50088368e-04 1.12445233e-02 1.58683163e-02\n",
            " 4.39226519e-03 1.63672717e-02 1.55345706e-02 3.86966378e-03\n",
            " 1.43602083e-02 4.90790858e-03 1.06829670e-02 4.90790858e-03\n",
            " 7.35530843e-03 1.02174165e-03 7.16807870e-03 1.87089127e-03\n",
            " 1.78181417e-02 3.92765264e-03 2.96553169e-04 1.51743050e-02\n",
            " 3.79806501e-04 1.06065164e-02 1.42341801e-02 3.05439440e-03\n",
            " 1.38346749e-02 4.85200341e-03 1.79119791e-02 4.23309982e-03\n",
            " 2.39936169e-04 5.20619079e-03 6.14054982e-03 1.80445842e-02\n",
            " 6.55230284e-03 1.30982447e-02 1.56705196e-02 5.51242468e-03\n",
            " 1.70728556e-02 4.63638124e-03 4.85741280e-03 7.11723865e-03\n",
            " 1.17034373e-02 2.98811251e-03 1.30207206e-02 1.48909460e-02\n",
            " 1.72251225e-02 1.07997623e-02 1.44058880e-02 5.45906966e-03\n",
            " 1.69662454e-02 5.77660960e-03 1.26600826e-02 4.75362760e-03\n",
            " 3.86966378e-03 1.34086893e-02 1.39787156e-02 7.72333111e-03\n",
            " 1.05614352e-02 1.37022509e-03 1.22459882e-03 3.73327013e-03\n",
            " 1.58002059e-02 5.34221646e-03 3.95728295e-03 6.82230841e-04\n",
            " 1.72194970e-02 9.15365808e-03 1.09380424e-02 8.23027815e-03\n",
            " 5.53542145e-03 2.28536537e-03 7.29175457e-04 9.36193228e-03\n",
            " 7.02975767e-03 7.33681297e-03 8.72723379e-03 1.12385710e-02\n",
            " 9.76639066e-03 2.86524551e-03 1.49365653e-03 1.28712355e-03\n",
            " 1.43178351e-02 6.19268240e-03 9.70528714e-03 1.07442717e-02\n",
            " 7.19202114e-03 1.73596290e-02 8.63689585e-03 1.34613399e-02\n",
            " 4.17959382e-03 1.38087351e-02 7.89559191e-03 3.75141908e-03\n",
            " 8.96351388e-03 1.32701497e-02 1.29755418e-02 3.10367419e-03\n",
            " 1.48268977e-02 1.30993954e-02 3.31634124e-03 8.85909777e-03\n",
            " 4.68058882e-04 9.13967950e-04 8.92810124e-03 1.41008739e-02\n",
            " 8.28016111e-03 2.67252011e-03 9.74978424e-03 6.08071613e-03\n",
            " 8.19787973e-03 1.65754206e-02 3.90201327e-04 5.58610786e-03\n",
            " 1.43715104e-02 7.47804539e-03 3.66495392e-03 1.05308276e-02\n",
            " 6.82704121e-03 3.54879469e-03 7.71282663e-03 1.52523059e-02\n",
            " 9.10490529e-03 9.55972052e-03 7.26748100e-03 1.68612610e-02\n",
            " 4.78397056e-03 5.63323241e-03 6.62457473e-03 8.28785218e-04\n",
            " 3.93074507e-03]\n",
            "3420 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.84776059e-03 4.37591620e-03 1.67824316e-02 1.69921989e-02\n",
            " 4.68591924e-03 3.95574795e-03 1.52124589e-02 6.96637972e-04\n",
            " 1.24854201e-02 9.27689508e-03 4.02281110e-03 6.60768532e-03\n",
            " 1.23224273e-02 8.37316908e-03 1.58340328e-02 1.15194726e-02\n",
            " 8.17319866e-03 1.03019133e-02 1.06100218e-02 1.20300043e-02\n",
            " 6.44537724e-03 1.43786600e-02 5.62443889e-03 7.52399025e-03\n",
            " 5.57010899e-03 8.21267885e-03 1.44157011e-03 9.52100613e-03\n",
            " 4.95101733e-03 5.42295866e-03 3.86649357e-03 1.39988377e-05\n",
            " 5.96452494e-03 1.28884690e-02 1.39266696e-02 1.52337689e-02\n",
            " 2.92952216e-03 1.07712211e-02 1.35260357e-02 1.00771567e-04\n",
            " 9.61449639e-03 1.28884690e-02 1.25283111e-02 1.94088534e-03\n",
            " 5.31632235e-09 2.97085427e-03 1.86706695e-05 6.50515643e-03\n",
            " 1.24981930e-02 8.76036370e-03 4.38317152e-04 1.78671443e-07\n",
            " 1.13379137e-02 7.71615971e-03 7.23404541e-03 2.86894901e-03\n",
            " 7.61129611e-03 1.07413485e-02 9.74149481e-03 1.69963181e-02\n",
            " 5.47907373e-03 8.94585581e-03 2.18850142e-03 1.16862077e-02\n",
            " 1.39300158e-02 9.43122032e-03 1.63460604e-02 1.34914131e-02\n",
            " 1.13206939e-02 1.11946374e-02 1.72854238e-02 1.02592184e-03\n",
            " 7.53678384e-03 2.90985845e-03 1.63233707e-02 3.73691648e-04\n",
            " 1.71556868e-02 1.10866347e-03 1.46213256e-02 8.23267285e-03\n",
            " 3.33068223e-03 1.00276355e-02 1.41361154e-02 9.74149481e-03\n",
            " 1.26260307e-02 4.22740016e-04 1.39078244e-02 7.44432592e-03\n",
            " 5.13942025e-03 5.02032565e-03 1.16505569e-02 4.82995322e-04\n",
            " 1.11446304e-02 1.01586646e-02 4.25685162e-03 4.28727082e-03\n",
            " 1.16861048e-03 1.60081843e-02 5.75854197e-03 1.10510356e-02\n",
            " 5.99795462e-04 1.05125523e-03 1.03502979e-02 5.45123550e-03\n",
            " 6.68705698e-05 3.73003518e-03 1.28876875e-02 9.69001140e-03\n",
            " 1.08574944e-02 1.10979801e-02 1.85396525e-03 7.71186003e-03\n",
            " 8.59640172e-03 6.75143825e-04 1.48759440e-02 2.10698659e-03\n",
            " 1.50032432e-02 1.08384756e-02 1.00732921e-02 1.44849853e-02\n",
            " 7.84339525e-03 1.73787169e-02 9.16392224e-03 5.13078231e-03\n",
            " 1.25283111e-02 3.63029304e-03 7.11304719e-05 1.63487073e-02\n",
            " 9.23553084e-03 1.34559452e-02 4.10265623e-03 1.47522676e-02\n",
            " 1.64255730e-02 3.63029304e-03 1.19973933e-02 1.19081900e-02\n",
            " 8.98136908e-03 1.45391299e-02 6.81742260e-03 9.98573557e-04\n",
            " 1.26107414e-02 1.51152975e-02 9.62682371e-03 7.42202190e-03\n",
            " 1.17706537e-02 1.51370489e-03 1.59663114e-02 1.28149960e-02\n",
            " 4.51993942e-05 1.70491102e-02 8.96728839e-03 1.49343335e-02\n",
            " 1.61688487e-02 4.73171225e-03 3.15852130e-03 1.03211479e-02\n",
            " 7.15165209e-03 1.71556868e-02 9.11179923e-03 4.64655151e-03\n",
            " 9.09905952e-03 1.06294170e-02 9.66167908e-03 9.92927702e-03\n",
            " 5.31632235e-09 3.95272865e-03 9.04704924e-03 1.49865060e-02\n",
            " 8.66075642e-03 1.09842536e-03 1.29983489e-02 1.31824728e-02\n",
            " 4.21188093e-03 1.46841529e-02 8.03458808e-03 1.79550469e-03\n",
            " 7.72456987e-03 1.46232637e-02 2.12496510e-03 7.53654255e-03\n",
            " 4.17350413e-03 1.17292964e-02 1.65029771e-02 8.78572585e-03\n",
            " 5.67571843e-03 5.50021487e-03 6.62947416e-03 3.00617969e-03\n",
            " 8.37316908e-03 1.30156982e-02 1.30958476e-02 9.55818785e-03\n",
            " 5.18372409e-03 1.06713355e-02 4.25685162e-03 1.07712211e-02\n",
            " 9.70057696e-03 7.68920984e-03 1.23707544e-02 9.26852181e-03\n",
            " 5.77774239e-03 1.09760668e-02 7.77827113e-03 1.20775326e-02\n",
            " 2.47201034e-03 1.36995143e-02 1.62964326e-04 4.11436820e-03\n",
            " 1.64562476e-02 1.05462866e-02 1.11946649e-02 4.11239438e-03\n",
            " 1.01523566e-02 3.36550686e-03 1.40026406e-02 6.13433252e-03\n",
            " 7.53511410e-03 1.02538129e-02 5.34913905e-04 3.16584831e-03\n",
            " 1.11515856e-02 1.61688487e-02 1.52659256e-02 6.12854933e-03\n",
            " 1.32430542e-02 1.36913947e-06 1.17113338e-02 9.25469373e-05\n",
            " 8.17479861e-04 2.91320831e-03 1.27593032e-02 6.66935991e-03\n",
            " 3.00419178e-03 9.43678629e-03 5.24296409e-03 4.24157878e-04\n",
            " 1.46528664e-02 5.29466726e-03 5.52411674e-03 1.27856512e-02\n",
            " 1.18420143e-03 1.36273161e-02 1.07617272e-02 8.62732155e-04\n",
            " 1.77401725e-02 4.58926482e-03 1.24854201e-02 6.79198470e-03\n",
            " 8.40877274e-03 5.48947310e-03 1.47264729e-02 6.00580590e-03\n",
            " 1.45488932e-02 4.51848362e-03 5.64972979e-03 5.41086752e-03\n",
            " 3.31405389e-03 7.71101480e-03 4.25685162e-03 1.62339655e-02\n",
            " 1.00056599e-02 1.75869475e-02 7.87555641e-03 3.72922531e-03\n",
            " 1.69938156e-02 1.24677981e-03 1.49170663e-03 1.65780191e-02\n",
            " 9.16928975e-03 4.13276437e-03 1.01253898e-02 1.20344618e-02\n",
            " 1.56004464e-03 5.21956805e-03 9.24000543e-03 1.72116841e-02\n",
            " 9.77917340e-05 8.09655027e-03 1.72754328e-02 3.33403562e-16\n",
            " 3.09555341e-03 1.58046181e-02 1.47801652e-02 6.14993821e-03\n",
            " 1.29117209e-02 1.05346219e-02 1.42095536e-02 1.15524519e-02\n",
            " 1.69935106e-02 2.39337824e-04 8.17734817e-03 1.03280875e-02\n",
            " 1.57245338e-02 1.01523566e-02 7.53678384e-03 2.87673091e-03\n",
            " 4.06351847e-03 3.22673411e-03 1.17706537e-02 2.12094927e-03\n",
            " 1.62410521e-02 3.67674826e-03 1.25001542e-02 6.71883049e-03\n",
            " 7.34940811e-03 1.64704929e-03 2.52168664e-04 7.16451108e-03\n",
            " 1.31368544e-02 4.77268103e-03 6.71016528e-03 1.22056252e-02\n",
            " 4.07766823e-03 4.05236218e-04 1.41857640e-02 8.59975207e-03\n",
            " 2.04316594e-03 4.49079989e-03 3.47095302e-03 7.05707516e-03\n",
            " 7.84501013e-03 1.79159436e-04 4.51860202e-03 1.51766417e-02\n",
            " 3.57952679e-03 8.44724589e-03 1.43559151e-02 4.85201125e-03\n",
            " 3.25241448e-03 9.18237100e-03 9.06628060e-03 6.93087431e-03\n",
            " 1.36686240e-02 1.70274702e-02 4.75629306e-03 9.43006881e-03\n",
            " 5.57010899e-03 9.90281665e-03 1.44175224e-02 4.91559330e-03\n",
            " 1.00180461e-02 1.96504587e-04 9.30412015e-03 1.18898996e-02\n",
            " 1.67867241e-03 8.34318241e-03 9.94940808e-03 8.08390822e-03\n",
            " 6.86389202e-03 3.73003518e-03 1.35256146e-03 1.24493681e-02\n",
            " 2.92886670e-03 2.00044919e-03 1.55260689e-02 1.46839401e-02\n",
            " 1.39601971e-02 1.29661161e-03 4.81821576e-03 1.58195766e-02\n",
            " 1.72404806e-03 1.76863060e-02 5.77774239e-03 3.95727752e-03\n",
            " 1.65881424e-02 1.34949192e-02 1.50813738e-03 1.17352253e-02\n",
            " 7.60449953e-03 3.11984928e-03 3.10301964e-03 6.34416970e-03\n",
            " 2.22755713e-03 1.41917285e-02 4.66257127e-06 1.22948062e-02\n",
            " 8.25702754e-04 1.49141615e-02 3.85824994e-03 1.25324242e-03\n",
            " 1.08826483e-02 1.02313419e-02 1.04354183e-05 1.06088374e-02\n",
            " 1.10725461e-02 1.47212351e-02 2.34076721e-03 1.81032053e-04\n",
            " 9.00481042e-03 1.36686240e-02 3.77353422e-03 3.03012683e-03\n",
            " 9.04026837e-03 1.74167755e-03 7.61589005e-04 2.12253169e-03\n",
            " 1.46024155e-02 6.39741591e-04 2.10495768e-03 1.09548861e-03\n",
            " 1.57219063e-02 3.64917697e-03 1.51509706e-02 1.39935423e-02\n",
            " 1.10622143e-02 7.78648936e-03 5.49891193e-05 1.35051845e-02\n",
            " 5.73621813e-04 1.11165973e-02 8.73669491e-04 1.21398001e-02\n",
            " 1.05246246e-02 1.26721562e-02 1.00039931e-02 1.27271502e-02\n",
            " 1.37374893e-02 1.40677623e-02 9.74149481e-03 9.57119163e-03\n",
            " 5.36370136e-03 8.30854436e-03 8.42788529e-03 8.06296848e-03\n",
            " 9.74839464e-03 1.74167755e-03 1.54007321e-02 1.12045075e-02\n",
            " 1.07294246e-02 1.69864676e-02 2.14381790e-03 1.19610973e-02\n",
            " 3.24832667e-03 9.63454425e-03 1.70863858e-02 4.89857961e-03\n",
            " 1.05899416e-02 1.88309038e-03 1.28677390e-02 4.02457563e-03\n",
            " 1.17639399e-02 1.63703730e-02 1.57562202e-02 7.67744112e-03\n",
            " 1.23407613e-02 1.24355991e-02 4.45653566e-03 9.24139821e-03\n",
            " 5.60549872e-04 2.85669247e-03 9.41708263e-03 3.74813594e-03\n",
            " 1.74904737e-02 7.53777200e-03 1.74660252e-02 8.03542881e-03\n",
            " 1.96504587e-04 4.67325445e-03 1.76745452e-02 1.07998577e-02\n",
            " 2.85991429e-03 1.47032886e-02 3.81815026e-03 1.68519650e-02\n",
            " 1.03214705e-02 8.06887828e-03 4.45591125e-03 5.78168690e-04\n",
            " 1.42939708e-03 1.30015638e-02 1.16261341e-03 1.59167223e-02\n",
            " 7.11569240e-03 5.00845202e-03 1.60105301e-02 6.96637972e-04\n",
            " 4.42420183e-03 1.42291357e-02 1.17310724e-02 3.10386155e-04\n",
            " 7.64922269e-03 1.74167755e-03 7.56790507e-03 1.39799914e-02\n",
            " 1.11969053e-02 1.29349474e-02 5.68811610e-03 7.43452841e-03\n",
            " 8.49582154e-03 1.09589258e-02 1.47876407e-02 1.04035866e-02\n",
            " 2.22903279e-03 1.28571625e-02 3.58551671e-03 1.13828035e-03\n",
            " 7.51404193e-03 8.24346395e-03 8.77891395e-03 2.48233479e-04\n",
            " 1.10591217e-02 3.73003518e-03 1.65771282e-02 6.02401607e-03\n",
            " 3.85824994e-03 9.32576695e-03 4.03664772e-04 2.58518269e-03\n",
            " 1.48321450e-02 1.58576323e-02 5.00390593e-04 8.22259639e-03\n",
            " 9.20741706e-03 2.02071527e-03 4.70494612e-03 1.52415581e-03\n",
            " 9.86655760e-03 1.71799792e-02 1.53498121e-02 1.16251709e-02\n",
            " 1.00382025e-02 1.43458783e-02 7.01771158e-03 9.75319757e-03\n",
            " 1.03885525e-02 1.35150056e-04 7.02744537e-03 2.22753790e-03\n",
            " 3.22178101e-03 1.40874040e-02 1.70274702e-02 3.12860974e-03\n",
            " 4.73171225e-03 8.50059520e-03 1.20482096e-02 4.10265623e-03\n",
            " 1.67023804e-02 6.37466800e-03 2.54984945e-03 1.05999104e-02\n",
            " 9.69972263e-03 1.92855868e-03 5.60775757e-04 2.68050172e-03\n",
            " 1.37167135e-02 1.40855073e-02 1.65993268e-02 1.69938156e-02\n",
            " 4.20945730e-03 1.00960641e-02 1.40026406e-02 1.39811771e-02\n",
            " 7.76158325e-03 3.84062568e-03 1.58398767e-02 5.97892329e-04\n",
            " 1.64939994e-02 1.66661094e-02 3.34745024e-03 6.35711102e-03\n",
            " 5.18401513e-03 7.95556159e-03 4.74306532e-03 1.61688487e-02\n",
            " 1.60203193e-02 1.62180806e-02 3.18245859e-04 2.64382926e-03\n",
            " 2.82548340e-03 7.89183710e-03 1.28780923e-02 1.40887051e-02\n",
            " 8.06721410e-03 2.14381790e-03 1.41278886e-02 1.70366682e-02\n",
            " 1.36704673e-03 1.10462149e-02 1.55193973e-02 2.42457026e-03\n",
            " 5.81587968e-03 1.05393314e-02 1.38393304e-02 1.14953483e-02\n",
            " 4.01281717e-03 1.38069916e-02 1.13165245e-02 5.24407095e-03\n",
            " 8.40467589e-04 1.04218482e-02 6.66344625e-03 4.16947789e-03\n",
            " 1.50529952e-02 4.88764769e-03 3.69630680e-03 6.98355665e-03\n",
            " 5.08940520e-03 4.47907295e-03 2.81427914e-03 6.35451439e-03\n",
            " 1.77063126e-02 1.04497856e-02 1.05516437e-03 6.63325540e-04\n",
            " 5.96452494e-03 1.34665340e-02 9.55790297e-04 1.99238966e-04\n",
            " 1.12003425e-02 9.28803871e-03 1.09066006e-02 1.25754527e-03\n",
            " 1.59123690e-02 1.43439057e-03 2.02705820e-03 2.86894901e-03\n",
            " 7.39049809e-05 1.47973658e-02 3.73194772e-03 5.39752312e-03\n",
            " 5.17303331e-03 2.14919353e-06 1.19822238e-02 6.55169096e-04\n",
            " 4.98994339e-07 1.08200358e-02 2.09338138e-05 1.70788697e-02\n",
            " 3.76202676e-05 1.33506260e-02 1.65471753e-02 1.03972712e-02\n",
            " 1.09829100e-02 1.48265326e-03 8.49904880e-04 1.12378893e-02\n",
            " 1.58488932e-02 4.35950100e-03 1.63367565e-02 1.54888762e-02\n",
            " 3.86649357e-03 1.43456142e-02 4.90504910e-03 1.06640932e-02\n",
            " 4.90504910e-03 7.33823699e-03 1.02060483e-03 7.15597067e-03\n",
            " 1.86668114e-03 3.90543504e-03 2.96496742e-04 1.51458412e-02\n",
            " 3.78458460e-04 1.05689716e-02 1.42343705e-02 3.04054179e-03\n",
            " 1.38253083e-02 4.84487035e-03 4.20826227e-03 2.38600008e-04\n",
            " 5.18258145e-03 6.13665534e-03 6.52503420e-03 1.30948151e-02\n",
            " 1.56590837e-02 5.50095286e-03 1.69892114e-02 4.62755979e-03\n",
            " 4.85201125e-03 7.08910644e-03 1.17042535e-02 2.98588465e-03\n",
            " 1.30209267e-02 1.48571667e-02 1.72162598e-02 1.07890198e-02\n",
            " 1.44047870e-02 5.45624162e-03 1.69565372e-02 5.75703917e-03\n",
            " 1.26332145e-02 4.71342710e-03 3.86649357e-03 1.34081465e-02\n",
            " 1.39150648e-02 7.68706204e-03 1.05420478e-02 1.36875912e-03\n",
            " 1.21985963e-03 3.72390392e-03 1.57947913e-02 5.33536233e-03\n",
            " 3.94569265e-03 6.78941203e-04 1.71868661e-02 9.13397016e-03\n",
            " 1.08987081e-02 8.20512074e-03 5.52783122e-03 2.27223488e-03\n",
            " 7.29864437e-04 9.35672285e-03 7.01758181e-03 7.28833368e-03\n",
            " 8.72770332e-03 1.12085870e-02 9.74849337e-03 2.86333112e-03\n",
            " 1.49309914e-03 1.28146785e-03 1.42334403e-02 6.17600202e-03\n",
            " 9.67193355e-03 1.07337292e-02 7.18544548e-03 1.73388212e-02\n",
            " 8.58902648e-03 1.34625661e-02 4.17376730e-03 1.37454459e-02\n",
            " 7.86945883e-03 3.72707922e-03 8.96252389e-03 1.32433909e-02\n",
            " 1.29651678e-02 3.09733768e-03 1.48352985e-02 1.30851349e-02\n",
            " 3.31446540e-03 8.84719806e-03 4.64864061e-04 9.13755875e-04\n",
            " 8.91489399e-03 1.40874040e-02 8.28898976e-03 2.66417107e-03\n",
            " 9.74149481e-03 6.07583421e-03 8.18626359e-03 1.65690579e-02\n",
            " 3.87672374e-04 5.56416081e-03 1.43368931e-02 7.46314169e-03\n",
            " 3.65328851e-03 1.05245487e-02 6.82058014e-03 3.54648871e-03\n",
            " 7.68955591e-03 1.52337689e-02 9.08490787e-03 9.52525950e-03\n",
            " 7.24889332e-03 1.68048593e-02 4.77622357e-03 5.63063683e-03\n",
            " 6.62127084e-03 8.25702754e-04 3.91873646e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3430 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.83783612e-03 4.36354186e-03 1.67666496e-02 1.70003562e-02\n",
            " 4.67121971e-03 3.94790030e-03 1.52260780e-02 6.96152993e-04\n",
            " 1.24639681e-02 9.23216257e-03 4.01171012e-03 6.59045283e-03\n",
            " 1.22902976e-02 8.38010184e-03 1.58289657e-02 1.15209986e-02\n",
            " 8.16480950e-03 1.02632588e-02 1.05834874e-02 1.20150234e-02\n",
            " 6.42572876e-03 1.43682553e-02 5.58198600e-03 7.51955265e-03\n",
            " 5.56565579e-03 8.17744922e-03 1.43989237e-03 9.49851846e-03\n",
            " 4.90335166e-03 5.41703892e-03 3.86348552e-03 1.39837661e-05\n",
            " 5.95298986e-03 1.28861188e-02 1.39252105e-02 1.52302680e-02\n",
            " 2.92747337e-03 1.07365619e-02 1.35379986e-02 1.00046411e-04\n",
            " 9.57025570e-03 1.28861188e-02 1.25166957e-02 1.93528071e-03\n",
            " 5.22982024e-09 2.96534604e-03 1.86510818e-05 6.46453157e-03\n",
            " 1.24153578e-02 8.75999690e-03 4.38235867e-04 1.78017904e-07\n",
            " 1.13069178e-02 7.68074577e-03 7.21794590e-03 2.86657854e-03\n",
            " 7.60996802e-03 1.07098616e-02 9.73349110e-03 1.69759179e-02\n",
            " 5.45951582e-03 8.93887489e-03 2.18851218e-03 1.16630115e-02\n",
            " 1.39291073e-02 9.43789925e-03 1.63099014e-02 1.34540061e-02\n",
            " 1.13094986e-02 1.11613479e-02 1.02565494e-03 7.52477202e-03\n",
            " 2.89713491e-03 1.62933293e-02 3.72673924e-04 1.71483277e-02\n",
            " 1.10075323e-03 1.45954521e-02 8.19571457e-03 3.31876055e-03\n",
            " 1.00259930e-02 1.41452451e-02 9.73349110e-03 1.26079590e-02\n",
            " 4.23549714e-04 1.38798657e-02 7.43165634e-03 5.12495341e-03\n",
            " 5.01607707e-03 1.16122415e-02 4.79823019e-04 1.11366216e-02\n",
            " 1.01373016e-02 4.25398423e-03 4.27618726e-03 1.16875642e-03\n",
            " 1.59786155e-02 5.75389758e-03 1.10362045e-02 5.98649456e-04\n",
            " 1.04998703e-03 1.03398093e-02 5.42130130e-03 6.69071334e-05\n",
            " 3.72785560e-03 1.28762526e-02 9.68128552e-03 1.08362452e-02\n",
            " 1.10638078e-02 1.84792725e-03 7.70813030e-03 8.58547717e-03\n",
            " 6.72510080e-04 1.48796948e-02 2.08695760e-03 1.49926257e-02\n",
            " 1.08206849e-02 1.00499263e-02 1.44397579e-02 7.82482745e-03\n",
            " 9.16294379e-03 5.11427094e-03 1.25166957e-02 3.62894253e-03\n",
            " 7.05739227e-05 1.63022234e-02 9.23679328e-03 1.34669999e-02\n",
            " 4.06218122e-03 1.47667094e-02 1.64215698e-02 3.62894253e-03\n",
            " 1.19949185e-02 1.18975543e-02 8.96307993e-03 1.45174153e-02\n",
            " 6.80087952e-03 9.96777035e-04 1.25723139e-02 1.50795929e-02\n",
            " 9.61471302e-03 7.40933754e-03 1.17643117e-02 1.51105290e-03\n",
            " 1.59196853e-02 1.27907554e-02 4.51814949e-05 1.70468829e-02\n",
            " 8.96448575e-03 1.49208295e-02 1.61803861e-02 4.72604205e-03\n",
            " 3.15816504e-03 1.02924074e-02 7.12928256e-03 1.71483277e-02\n",
            " 9.10457510e-03 4.65032159e-03 9.08528492e-03 1.05937973e-02\n",
            " 9.64781486e-03 9.92395394e-03 5.22982024e-09 3.95719506e-03\n",
            " 9.05839013e-03 1.49392055e-02 8.65771534e-03 1.09306926e-03\n",
            " 1.29521807e-02 1.31437153e-02 4.20611112e-03 1.46805185e-02\n",
            " 8.01103742e-03 1.78530741e-03 7.71558227e-03 1.45618952e-02\n",
            " 2.12460523e-03 7.52581995e-03 4.17129090e-03 1.17053887e-02\n",
            " 1.64954987e-02 8.77747426e-03 5.67288644e-03 5.48448365e-03\n",
            " 6.62612201e-03 3.00340903e-03 8.38010184e-03 1.30006610e-02\n",
            " 1.30625741e-02 9.52045129e-03 5.18001364e-03 1.06532949e-02\n",
            " 4.25398423e-03 1.07365619e-02 9.69987376e-03 7.64581786e-03\n",
            " 1.23691967e-02 9.25547770e-03 5.77498269e-03 1.09356725e-02\n",
            " 7.76380727e-03 1.20604009e-02 2.46486011e-03 1.36990054e-02\n",
            " 1.61968721e-04 4.10567003e-03 1.64184846e-02 1.05500434e-02\n",
            " 1.11671634e-02 4.10399722e-03 1.01419933e-02 3.35978903e-03\n",
            " 1.39687335e-02 6.10665857e-03 7.52205201e-03 1.02482953e-02\n",
            " 5.33792552e-04 3.15992223e-03 1.11540222e-02 1.61803861e-02\n",
            " 1.52575030e-02 6.12771194e-03 1.32313955e-02 1.34591222e-06\n",
            " 1.16447415e-02 9.23967832e-05 8.11901616e-04 2.90581682e-03\n",
            " 1.27659216e-02 6.65429116e-03 3.00216633e-03 9.38503770e-03\n",
            " 5.23047562e-03 4.22937728e-04 1.46397127e-02 5.28949451e-03\n",
            " 5.50560767e-03 1.27348502e-02 1.18180275e-03 1.36116401e-02\n",
            " 1.07220804e-02 8.61371035e-04 4.58080184e-03 1.24639681e-02\n",
            " 6.75500389e-03 8.40198680e-03 5.47792127e-03 1.47030152e-02\n",
            " 5.98702345e-03 1.44934696e-02 4.50984853e-03 5.63962187e-03\n",
            " 5.40298635e-03 3.29559714e-03 7.70342814e-03 4.25398423e-03\n",
            " 1.62145666e-02 9.99691743e-03 7.84921516e-03 3.71588959e-03\n",
            " 1.69766349e-02 1.24062433e-03 1.49001945e-03 1.65614102e-02\n",
            " 9.17302776e-03 4.11850892e-03 1.01134282e-02 1.19676627e-02\n",
            " 1.55714352e-03 5.20923952e-03 9.20124691e-03 1.70811343e-02\n",
            " 9.76252150e-05 8.09545406e-03 1.72421746e-02 3.34008016e-16\n",
            " 3.07917170e-03 1.58043570e-02 1.47803877e-02 6.15447886e-03\n",
            " 1.28841978e-02 1.05071924e-02 1.41958612e-02 1.15383777e-02\n",
            " 1.69618393e-02 2.38039808e-04 8.15217662e-03 1.03246461e-02\n",
            " 1.56950227e-02 1.01419933e-02 7.52477202e-03 2.87303372e-03\n",
            " 4.06115623e-03 3.20534065e-03 1.17643117e-02 2.11646632e-03\n",
            " 1.62236283e-02 3.66290314e-03 1.24772087e-02 6.68953966e-03\n",
            " 7.34558894e-03 1.64403237e-03 2.50592131e-04 7.15192831e-03\n",
            " 1.31308478e-02 4.75903408e-03 6.67824340e-03 1.21969975e-02\n",
            " 4.08037752e-03 4.04642077e-04 1.41486137e-02 8.59011655e-03\n",
            " 2.03099881e-03 4.49094395e-03 3.46856375e-03 7.04609261e-03\n",
            " 7.85276295e-03 1.78182769e-04 4.50221617e-03 1.51656664e-02\n",
            " 3.57264103e-03 8.44104913e-03 1.43294126e-02 4.85554954e-03\n",
            " 3.23806755e-03 9.15286573e-03 9.02442549e-03 6.94215925e-03\n",
            " 1.36429430e-02 1.69944414e-02 4.74485290e-03 9.41439218e-03\n",
            " 5.56565579e-03 9.88056965e-03 1.43964454e-02 4.90583299e-03\n",
            " 9.99180314e-03 1.95338410e-04 9.29717518e-03 1.18916067e-02\n",
            " 1.67348357e-03 8.30926289e-03 9.95067810e-03 8.04465514e-03\n",
            " 6.85427834e-03 3.72785560e-03 1.35029049e-03 1.24403561e-02\n",
            " 2.92085325e-03 2.00244525e-03 1.55172199e-02 1.46560802e-02\n",
            " 1.39424511e-02 1.29555824e-03 4.80612544e-03 1.57962173e-02\n",
            " 1.71798728e-03 5.77498269e-03 3.95250118e-03 1.65910341e-02\n",
            " 1.34721624e-02 1.50207159e-03 1.17107815e-02 7.59759455e-03\n",
            " 3.11474901e-03 3.10319220e-03 6.33389035e-03 2.22307287e-03\n",
            " 1.41780943e-02 4.65249880e-06 1.22782233e-02 8.23461997e-04\n",
            " 1.49058793e-02 3.85875347e-03 1.24888559e-03 1.08672602e-02\n",
            " 1.02159368e-02 1.03532557e-05 1.06044480e-02 1.10609845e-02\n",
            " 1.47115771e-02 2.33691026e-03 1.80697360e-04 8.96991193e-03\n",
            " 1.36429430e-02 3.77151179e-03 3.02399591e-03 9.02845775e-03\n",
            " 1.73710246e-03 7.58154959e-04 2.11759887e-03 1.45824238e-02\n",
            " 6.37166160e-04 2.10730122e-03 1.09361678e-03 1.56868140e-02\n",
            " 3.64064805e-03 1.51502962e-02 1.39769778e-02 1.10391698e-02\n",
            " 7.78395663e-03 5.48812450e-05 1.34637816e-02 5.70914084e-04\n",
            " 1.11162816e-02 8.73983346e-04 1.20909384e-02 1.05059423e-02\n",
            " 1.25671856e-02 9.98606937e-03 1.26785896e-02 1.37465955e-02\n",
            " 1.40498961e-02 9.73349110e-03 9.56221466e-03 5.34004734e-03\n",
            " 8.29897471e-03 8.37667836e-03 8.06196076e-03 9.72929469e-03\n",
            " 1.73710246e-03 1.53798539e-02 1.11852391e-02 1.07427568e-02\n",
            " 1.68887776e-02 2.13125367e-03 1.19437000e-02 3.24189906e-03\n",
            " 9.62677699e-03 1.70573322e-02 4.89471077e-03 1.05878126e-02\n",
            " 1.87982148e-03 1.28725058e-02 4.01021293e-03 1.17627357e-02\n",
            " 1.63264292e-02 1.57199814e-02 7.67635823e-03 1.23391335e-02\n",
            " 1.24198013e-02 4.45385077e-03 9.23106652e-03 5.58154640e-04\n",
            " 2.84715695e-03 9.42744844e-03 3.74173981e-03 7.51025449e-03\n",
            " 8.02327670e-03 1.95338410e-04 4.67346256e-03 1.07803621e-02\n",
            " 2.84804789e-03 1.46435248e-02 3.80293867e-03 1.68123013e-02\n",
            " 1.03170204e-02 8.06826984e-03 4.44764834e-03 5.73638559e-04\n",
            " 1.42699463e-03 1.29912241e-02 1.16069022e-03 1.58894162e-02\n",
            " 7.10121259e-03 4.99058420e-03 1.59674989e-02 6.96152993e-04\n",
            " 4.41115288e-03 1.42183613e-02 1.17140081e-02 3.09523171e-04\n",
            " 7.64771796e-03 1.73710246e-03 7.55416906e-03 1.39934480e-02\n",
            " 1.11688242e-02 1.29349490e-02 5.67723432e-03 7.39520926e-03\n",
            " 8.46734377e-03 1.09318894e-02 1.47576085e-02 1.03898737e-02\n",
            " 2.22294423e-03 1.28208274e-02 3.57171969e-03 1.13289831e-03\n",
            " 7.51136446e-03 8.25053835e-03 8.76993171e-03 2.47578566e-04\n",
            " 1.10489030e-02 3.72785560e-03 1.65529444e-02 6.01701513e-03\n",
            " 3.85875347e-03 9.30335925e-03 4.04118708e-04 2.58289602e-03\n",
            " 1.48170626e-02 1.58478326e-02 4.97951654e-04 8.21026117e-03\n",
            " 9.17383407e-03 2.02283371e-03 4.70167685e-03 1.51736905e-03\n",
            " 9.86145108e-03 1.71375989e-02 1.53649598e-02 1.16131834e-02\n",
            " 1.00258390e-02 1.42878827e-02 7.02000992e-03 9.75273261e-03\n",
            " 1.03842009e-02 1.35270345e-04 6.99673065e-03 2.22138894e-03\n",
            " 3.20811317e-03 1.40733324e-02 1.69944414e-02 3.12539776e-03\n",
            " 4.72604205e-03 8.48924629e-03 1.20356221e-02 4.06218122e-03\n",
            " 1.67107299e-02 6.36514817e-03 2.54813961e-03 1.05802680e-02\n",
            " 9.69317892e-03 1.92589032e-03 5.60921911e-04 2.67639261e-03\n",
            " 1.37160274e-02 1.40708477e-02 1.65925191e-02 1.69766349e-02\n",
            " 4.20241783e-03 1.00823216e-02 1.39687335e-02 1.39304453e-02\n",
            " 7.75036879e-03 3.82893296e-03 1.58418803e-02 5.96179971e-04\n",
            " 1.64902282e-02 1.66737386e-02 3.33726084e-03 6.34436748e-03\n",
            " 5.17797044e-03 7.94632919e-03 4.72653243e-03 1.61803861e-02\n",
            " 1.59908942e-02 1.61968571e-02 3.16984254e-04 2.63293581e-03\n",
            " 2.82521875e-03 7.85758105e-03 1.28825716e-02 1.40821260e-02\n",
            " 8.05911682e-03 2.13125367e-03 1.40957929e-02 1.70257880e-02\n",
            " 1.36164475e-03 1.10368975e-02 1.55151104e-02 2.42099686e-03\n",
            " 5.79763223e-03 1.05458149e-02 1.38205477e-02 1.14872392e-02\n",
            " 4.00943775e-03 1.37997278e-02 1.12987634e-02 5.23041732e-03\n",
            " 8.36788819e-04 1.04337421e-02 6.64322233e-03 4.16428449e-03\n",
            " 1.50218443e-02 4.88734040e-03 3.67651578e-03 6.93327021e-03\n",
            " 5.08465411e-03 4.48059875e-03 2.81587219e-03 6.34096906e-03\n",
            " 1.04479489e-02 1.05209301e-03 6.61754708e-04 5.95298986e-03\n",
            " 1.34624450e-02 9.54227787e-04 1.98655313e-04 1.11686178e-02\n",
            " 9.27989367e-03 1.09067852e-02 1.25412380e-03 1.59027128e-02\n",
            " 1.43308377e-03 2.02113767e-03 2.86657854e-03 7.36896158e-05\n",
            " 1.47818969e-02 3.71728662e-03 5.41040352e-03 5.17443425e-03\n",
            " 2.13577483e-06 1.19770517e-02 6.52485092e-04 5.00122167e-07\n",
            " 1.07903307e-02 2.07572531e-05 1.69854934e-02 3.75870071e-05\n",
            " 1.33439480e-02 1.65293754e-02 1.04025107e-02 1.09276110e-02\n",
            " 1.48254686e-03 8.49067429e-04 1.12302338e-02 1.57347992e-02\n",
            " 4.34775235e-03 1.62523474e-02 1.54447810e-02 3.86348552e-03\n",
            " 1.43310275e-02 4.90035223e-03 1.06505155e-02 4.90035223e-03\n",
            " 7.33182417e-03 1.01955038e-03 7.14195386e-03 1.86186517e-03\n",
            " 3.89814317e-03 2.96734516e-04 1.51405253e-02 3.78110872e-04\n",
            " 1.05823041e-02 1.42290793e-02 3.03317381e-03 1.37666136e-02\n",
            " 4.84610513e-03 4.19852040e-03 2.37797864e-04 5.17960760e-03\n",
            " 6.10708710e-03 6.51740594e-03 1.30984222e-02 1.56300594e-02\n",
            " 5.48585442e-03 1.69863426e-02 4.61787035e-03 4.85554954e-03\n",
            " 7.07374394e-03 1.16439866e-02 2.98640226e-03 1.29952425e-02\n",
            " 1.48392759e-02 1.71876674e-02 1.07812952e-02 1.43763669e-02\n",
            " 5.44119255e-03 1.69278971e-02 5.75293276e-03 1.26132214e-02\n",
            " 4.69855052e-03 3.86348552e-03 1.33771325e-02 1.38946549e-02\n",
            " 7.66167062e-03 1.05433835e-02 1.36456941e-03 1.21390785e-03\n",
            " 3.70128287e-03 1.57408086e-02 5.33497569e-03 3.93049192e-03\n",
            " 6.79531079e-04 1.71709106e-02 9.12730611e-03 1.08791663e-02\n",
            " 8.18970339e-03 5.50650040e-03 2.26843083e-03 7.29236055e-04\n",
            " 9.34640613e-03 6.99623585e-03 7.24784030e-03 8.71576254e-03\n",
            " 1.11769749e-02 9.72412125e-03 2.85591942e-03 1.48769358e-03\n",
            " 1.27680634e-03 1.42190056e-02 6.17550991e-03 9.64591823e-03\n",
            " 1.07338165e-02 7.17926419e-03 8.57543983e-03 1.34368066e-02\n",
            " 4.15426075e-03 1.37465724e-02 7.86599918e-03 3.71625204e-03\n",
            " 8.95786873e-03 1.32176405e-02 1.29379577e-02 3.09052473e-03\n",
            " 1.47341462e-02 1.30105755e-02 3.31160542e-03 8.80444650e-03\n",
            " 4.63302711e-04 9.12825253e-04 8.90066944e-03 1.40733324e-02\n",
            " 8.27042098e-03 2.65985860e-03 9.73349110e-03 6.07717822e-03\n",
            " 8.16098637e-03 1.65202572e-02 3.86072755e-04 5.57231538e-03\n",
            " 1.43056068e-02 7.45611619e-03 3.64650213e-03 1.05169814e-02\n",
            " 6.80669242e-03 3.54560963e-03 7.67043198e-03 1.52302680e-02\n",
            " 9.03322512e-03 9.48413222e-03 7.25260082e-03 1.67793861e-02\n",
            " 4.77332881e-03 5.62093085e-03 6.61220186e-03 8.23461997e-04\n",
            " 3.90371958e-03]\n",
            "3440 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.83342782e-03 4.36215697e-03 1.67520417e-02 1.70133944e-02\n",
            " 4.67489138e-03 3.93489860e-03 1.52253830e-02 6.95074985e-04\n",
            " 1.24578255e-02 9.21632728e-03 3.99390867e-03 6.57895156e-03\n",
            " 1.22912208e-02 8.35679267e-03 1.58219033e-02 1.14927389e-02\n",
            " 8.15776278e-03 1.02619787e-02 1.05638608e-02 1.20193830e-02\n",
            " 6.39849629e-03 1.43588323e-02 5.57502886e-03 7.50671209e-03\n",
            " 5.56067217e-03 8.18184533e-03 1.43795975e-03 9.45106800e-03\n",
            " 4.90294010e-03 5.40660264e-03 3.86642986e-03 1.38314253e-05\n",
            " 5.94171709e-03 1.28556096e-02 1.38887651e-02 1.52262901e-02\n",
            " 2.90840139e-03 1.07004972e-02 1.34139036e-02 9.97274906e-05\n",
            " 9.56192132e-03 1.28556096e-02 1.24390107e-02 1.92415012e-03\n",
            " 5.16504951e-09 2.95145634e-03 1.84043189e-05 6.43501339e-03\n",
            " 1.24083456e-02 8.75101111e-03 4.34160952e-04 1.74383372e-07\n",
            " 1.12742115e-02 7.65992929e-03 7.21060322e-03 2.86876216e-03\n",
            " 7.61254501e-03 1.07092643e-02 9.74498961e-03 1.69230866e-02\n",
            " 5.45665001e-03 8.92801250e-03 2.18280256e-03 1.16563651e-02\n",
            " 1.38811237e-02 9.42835216e-03 1.63060716e-02 1.34656144e-02\n",
            " 1.13168424e-02 1.11327943e-02 1.02252583e-03 7.53213138e-03\n",
            " 2.87679100e-03 1.62729423e-02 3.71245012e-04 1.09732349e-03\n",
            " 1.45893602e-02 8.17738326e-03 3.31039958e-03 1.00001496e-02\n",
            " 1.41426116e-02 9.74498961e-03 1.26064495e-02 4.23250611e-04\n",
            " 1.38315634e-02 7.43047584e-03 5.13608884e-03 5.00279936e-03\n",
            " 1.15604536e-02 4.79604419e-04 1.11324571e-02 1.01216293e-02\n",
            " 4.25008903e-03 4.26521799e-03 1.16540233e-03 1.59439909e-02\n",
            " 5.75814539e-03 1.10343890e-02 5.98048027e-04 1.04352344e-03\n",
            " 1.02847820e-02 5.42276679e-03 6.62282960e-05 3.72560315e-03\n",
            " 1.28733875e-02 9.67378003e-03 1.08270296e-02 1.10514049e-02\n",
            " 1.84796117e-03 7.69857946e-03 8.58409973e-03 6.71325532e-04\n",
            " 1.48413782e-02 2.07645421e-03 1.49652409e-02 1.08155346e-02\n",
            " 1.00591376e-02 1.44306737e-02 7.82247404e-03 9.14046670e-03\n",
            " 5.11231770e-03 1.24390107e-02 3.62681592e-03 7.03948501e-05\n",
            " 1.62669570e-02 9.23864278e-03 1.33991231e-02 4.03490375e-03\n",
            " 1.47810783e-02 1.63819328e-02 3.62681592e-03 1.20213962e-02\n",
            " 1.18944597e-02 8.95762697e-03 1.45175580e-02 6.79283093e-03\n",
            " 9.97107777e-04 1.25547434e-02 1.50831473e-02 9.61851307e-03\n",
            " 7.40250988e-03 1.17515251e-02 1.50850512e-03 1.58381617e-02\n",
            " 1.27909718e-02 4.47361474e-05 8.94024496e-03 1.49168433e-02\n",
            " 1.61896627e-02 4.71328930e-03 3.14260859e-03 1.02820565e-02\n",
            " 7.10396649e-03 9.11083145e-03 4.62977703e-03 9.07792189e-03\n",
            " 1.05879428e-02 9.65216942e-03 9.87789951e-03 5.16504951e-09\n",
            " 3.95756248e-03 9.04841263e-03 1.49314473e-02 8.65045901e-03\n",
            " 1.09212197e-03 1.29190100e-02 1.30719908e-02 4.20626667e-03\n",
            " 1.46519461e-02 8.01245138e-03 1.78631626e-03 7.73008695e-03\n",
            " 1.45550988e-02 2.12714521e-03 7.50906924e-03 4.17017255e-03\n",
            " 1.16945622e-02 1.64640441e-02 8.74727340e-03 5.66182788e-03\n",
            " 5.46141423e-03 6.62870161e-03 3.00367029e-03 8.35679267e-03\n",
            " 1.29766277e-02 1.30696959e-02 9.49892269e-03 5.17210469e-03\n",
            " 1.06400300e-02 4.25008903e-03 1.07004972e-02 9.67270562e-03\n",
            " 7.62312314e-03 1.23369776e-02 9.24496925e-03 5.76467243e-03\n",
            " 1.09086686e-02 7.73659382e-03 1.20546976e-02 2.46893445e-03\n",
            " 1.36823144e-02 1.60494310e-04 4.09709254e-03 1.63926284e-02\n",
            " 1.05085205e-02 1.11585304e-02 4.10368825e-03 1.01469922e-02\n",
            " 3.35355697e-03 1.38968421e-02 6.10110553e-03 7.51475471e-03\n",
            " 1.02340846e-02 5.33286199e-04 3.14466798e-03 1.11341539e-02\n",
            " 1.61896627e-02 1.51992337e-02 6.11270155e-03 1.32184373e-02\n",
            " 1.32625038e-06 1.15844512e-02 9.16459539e-05 8.07831316e-04\n",
            " 2.90549004e-03 1.27573027e-02 6.62825912e-03 3.00334980e-03\n",
            " 9.37530325e-03 5.21528456e-03 4.21601088e-04 1.46297092e-02\n",
            " 5.27685153e-03 5.47990391e-03 1.27125937e-02 1.16902532e-03\n",
            " 1.35808301e-02 1.06917750e-02 8.60880442e-04 4.57142172e-03\n",
            " 1.24578255e-02 6.76132711e-03 8.40066846e-03 5.48066464e-03\n",
            " 1.46236674e-02 5.98088593e-03 1.44681979e-02 4.48987650e-03\n",
            " 5.62125226e-03 5.39366686e-03 3.28412377e-03 7.69796315e-03\n",
            " 4.25008903e-03 1.62075996e-02 9.98322239e-03 7.82453019e-03\n",
            " 3.69947809e-03 1.69793960e-02 1.23971379e-03 1.49349526e-03\n",
            " 1.65440112e-02 9.15059037e-03 4.10910649e-03 1.01090814e-02\n",
            " 1.19633255e-02 1.55355904e-03 5.19622573e-03 9.19760930e-03\n",
            " 9.75154989e-05 8.09417067e-03 3.17688127e-16 3.07487225e-03\n",
            " 1.57634191e-02 1.47514938e-02 6.14832244e-03 1.28640805e-02\n",
            " 1.04922544e-02 1.41969747e-02 1.15142896e-02 1.69336570e-02\n",
            " 2.36340757e-04 8.15508745e-03 1.02903061e-02 1.56833422e-02\n",
            " 1.01469922e-02 7.53213138e-03 2.87234944e-03 4.05364286e-03\n",
            " 3.18790443e-03 1.17515251e-02 2.11496616e-03 1.61843400e-02\n",
            " 3.65852873e-03 1.24626044e-02 6.69218498e-03 7.33587289e-03\n",
            " 1.64518050e-03 2.49959362e-04 7.15355724e-03 1.31373329e-02\n",
            " 4.74101993e-03 6.67650180e-03 1.21534835e-02 4.04542437e-03\n",
            " 4.04362453e-04 1.41287609e-02 8.55797639e-03 2.03162264e-03\n",
            " 4.48627806e-03 3.44956072e-03 7.04503897e-03 7.83657629e-03\n",
            " 1.77298329e-04 4.49660385e-03 1.51700777e-02 3.57383794e-03\n",
            " 8.42409413e-03 1.43296245e-02 4.84708559e-03 3.22905022e-03\n",
            " 9.12077758e-03 9.02026185e-03 6.93623391e-03 1.36109523e-02\n",
            " 1.70001137e-02 4.72357809e-03 9.41364363e-03 5.56067217e-03\n",
            " 9.85852677e-03 1.43771691e-02 4.89320260e-03 9.99760898e-03\n",
            " 1.95129011e-04 9.27471494e-03 1.18615422e-02 1.67607001e-03\n",
            " 8.28844875e-03 9.94459373e-03 8.03243428e-03 6.83213377e-03\n",
            " 3.72560315e-03 1.34754640e-03 1.23582463e-02 2.91432665e-03\n",
            " 1.99902926e-03 1.55153698e-02 1.46430626e-02 1.39027203e-02\n",
            " 1.29605724e-03 4.79749934e-03 1.58140977e-02 1.71536388e-03\n",
            " 5.76467243e-03 3.94376845e-03 1.65799107e-02 1.34673452e-02\n",
            " 1.49120402e-03 1.16821373e-02 7.59310399e-03 3.10697521e-03\n",
            " 3.10745056e-03 6.32462616e-03 2.21726205e-03 1.41323611e-02\n",
            " 4.61200856e-06 1.22457008e-02 8.18091621e-04 1.48726037e-02\n",
            " 3.83379546e-03 1.24404671e-03 1.08463699e-02 1.01800045e-02\n",
            " 1.03619343e-05 1.05824922e-02 1.10527011e-02 1.47171461e-02\n",
            " 2.33304076e-03 1.80194437e-04 8.95749160e-03 1.36109523e-02\n",
            " 3.77165503e-03 3.02927809e-03 9.00156997e-03 1.73156296e-03\n",
            " 7.59150874e-04 2.10996026e-03 1.45621458e-02 6.35181160e-04\n",
            " 2.10945387e-03 1.09043946e-03 1.56844206e-02 3.63946026e-03\n",
            " 1.51149312e-02 1.39751152e-02 1.10358624e-02 7.77105875e-03\n",
            " 5.47885472e-05 1.34403924e-02 5.70303977e-04 1.10891032e-02\n",
            " 8.69529033e-04 1.20899025e-02 1.05070850e-02 1.25277024e-02\n",
            " 9.93365220e-03 1.26825921e-02 1.37245253e-02 1.40067702e-02\n",
            " 9.74498961e-03 9.55579195e-03 5.34056334e-03 8.27718085e-03\n",
            " 8.34162409e-03 8.05758284e-03 9.71793979e-03 1.73156296e-03\n",
            " 1.53813053e-02 1.11611753e-02 1.07412153e-02 1.67660643e-02\n",
            " 2.12325872e-03 1.19345332e-02 3.23799831e-03 9.60121358e-03\n",
            " 4.89057982e-03 1.05821647e-02 1.87256315e-03 1.28660573e-02\n",
            " 3.98905568e-03 1.17311837e-02 1.63341568e-02 1.56428959e-02\n",
            " 7.66810142e-03 1.22961351e-02 1.23934124e-02 4.42726444e-03\n",
            " 9.21575325e-03 5.58613811e-04 2.82812152e-03 9.41881828e-03\n",
            " 3.72264770e-03 7.51419672e-03 8.02295668e-03 1.95129011e-04\n",
            " 4.66339948e-03 1.07861159e-02 2.84796106e-03 1.46471030e-02\n",
            " 3.80484669e-03 1.68041342e-02 1.03152140e-02 8.06444315e-03\n",
            " 4.43429903e-03 5.70736836e-04 1.42023343e-03 1.29822306e-02\n",
            " 1.15959430e-03 1.58441130e-02 7.10800682e-03 4.98310015e-03\n",
            " 1.59657315e-02 6.95074985e-04 4.38498187e-03 1.42056596e-02\n",
            " 1.17286943e-02 3.09609746e-04 7.64487518e-03 1.73156296e-03\n",
            " 7.54173611e-03 1.39811746e-02 1.11564327e-02 1.29211823e-02\n",
            " 5.65308512e-03 7.33743404e-03 8.46178875e-03 1.09098178e-02\n",
            " 1.47350731e-02 1.03872761e-02 2.21837364e-03 1.28117076e-02\n",
            " 3.55568487e-03 1.12392017e-03 7.51462973e-03 8.25436559e-03\n",
            " 8.76709133e-03 2.47526067e-04 1.10397219e-02 3.72560315e-03\n",
            " 1.65118958e-02 6.02255776e-03 3.83379546e-03 9.30032762e-03\n",
            " 4.03870969e-04 2.57623695e-03 1.48039985e-02 1.58147384e-02\n",
            " 4.98966056e-04 8.20882743e-03 9.16591548e-03 2.02197337e-03\n",
            " 4.69247264e-03 1.51574370e-03 9.86604580e-03 1.53783639e-02\n",
            " 1.16071911e-02 1.00184857e-02 1.42130230e-02 7.00229205e-03\n",
            " 9.75627724e-03 1.03562482e-02 1.34947900e-04 6.97323725e-03\n",
            " 2.21091756e-03 3.20065511e-03 1.40759539e-02 1.70001137e-02\n",
            " 3.12102490e-03 4.71328930e-03 8.47523435e-03 1.20292612e-02\n",
            " 4.03490375e-03 1.67028967e-02 6.36282958e-03 2.52563612e-03\n",
            " 1.05815317e-02 9.68805727e-03 1.92377197e-03 5.56711056e-04\n",
            " 2.67279767e-03 1.36967541e-02 1.40812869e-02 1.65583591e-02\n",
            " 1.69793960e-02 4.18984599e-03 1.00476331e-02 1.38968421e-02\n",
            " 1.39193073e-02 7.74634753e-03 3.82272891e-03 1.58417280e-02\n",
            " 5.95416682e-04 1.64691861e-02 1.66208900e-02 3.32155043e-03\n",
            " 6.34120157e-03 5.16629499e-03 7.93336408e-03 4.72494801e-03\n",
            " 1.61896627e-02 1.59555576e-02 1.61722936e-02 3.16829044e-04\n",
            " 2.62961545e-03 2.82987914e-03 7.84838972e-03 1.28824794e-02\n",
            " 1.40250928e-02 8.04122495e-03 2.12325872e-03 1.40838118e-02\n",
            " 1.35872406e-03 1.10390747e-02 1.55395388e-02 2.42216071e-03\n",
            " 5.79298661e-03 1.05231030e-02 1.38070898e-02 1.14678066e-02\n",
            " 4.00930080e-03 1.37783423e-02 1.12834208e-02 5.22690303e-03\n",
            " 8.35200088e-04 1.04357938e-02 6.64028638e-03 4.16068931e-03\n",
            " 1.50087790e-02 4.88731451e-03 3.67743557e-03 6.93948283e-03\n",
            " 5.07916861e-03 4.47114368e-03 2.81110663e-03 6.33739479e-03\n",
            " 1.04329130e-02 1.05120208e-03 6.60185048e-04 5.94171709e-03\n",
            " 1.34691825e-02 9.45838737e-04 1.97530063e-04 1.11518247e-02\n",
            " 9.28082707e-03 1.08923036e-02 1.25280115e-03 1.58600693e-02\n",
            " 1.43182203e-03 2.02316686e-03 2.86876216e-03 7.30088070e-05\n",
            " 1.47767774e-02 3.71461430e-03 5.41870047e-03 5.16049901e-03\n",
            " 2.11568162e-06 1.19562631e-02 6.50138764e-04 4.99203182e-07\n",
            " 1.07781762e-02 2.05582604e-05 1.69606258e-02 3.74891510e-05\n",
            " 1.33087752e-02 1.64870504e-02 1.04006306e-02 1.08531438e-02\n",
            " 1.47672535e-03 8.48258100e-04 1.12172705e-02 1.57097645e-02\n",
            " 4.34253844e-03 1.62878511e-02 1.54258679e-02 3.86642986e-03\n",
            " 1.43336024e-02 4.89208198e-03 1.06452221e-02 4.89208198e-03\n",
            " 7.33694674e-03 1.01861431e-03 7.13771799e-03 1.85957697e-03\n",
            " 3.89692136e-03 2.92704821e-04 1.51481341e-02 3.77017250e-04\n",
            " 1.05372306e-02 1.42612342e-02 3.03277598e-03 1.37075405e-02\n",
            " 4.83000544e-03 4.17794160e-03 2.37045489e-04 5.17427637e-03\n",
            " 6.10135428e-03 6.52302379e-03 1.30857760e-02 1.55769309e-02\n",
            " 5.46243389e-03 1.69615905e-02 4.60902628e-03 4.84708559e-03\n",
            " 7.09214656e-03 1.16054439e-02 2.97668659e-03 1.29839948e-02\n",
            " 1.48313893e-02 1.07573763e-02 1.43641761e-02 5.42522682e-03\n",
            " 1.69008482e-02 5.73054323e-03 1.25928524e-02 4.69350231e-03\n",
            " 3.86642986e-03 1.33467564e-02 1.38995828e-02 7.64788474e-03\n",
            " 1.05521790e-02 1.36033458e-03 1.21298859e-03 3.69676419e-03\n",
            " 1.57296042e-02 5.32776013e-03 3.92896822e-03 6.73818877e-04\n",
            " 9.12358329e-03 1.08684252e-02 8.17895681e-03 5.50021411e-03\n",
            " 2.25362309e-03 7.25535943e-04 9.31621279e-03 6.97540325e-03\n",
            " 7.23400485e-03 8.67605031e-03 1.11683908e-02 9.72788606e-03\n",
            " 2.84432695e-03 1.48571349e-03 1.27490255e-03 1.42046280e-02\n",
            " 6.18147501e-03 9.64534251e-03 1.07219076e-02 7.16145252e-03\n",
            " 8.57768006e-03 1.34469203e-02 4.13692135e-03 1.37130772e-02\n",
            " 7.87143406e-03 3.71566224e-03 8.92588121e-03 1.32028698e-02\n",
            " 1.29181914e-02 3.08753798e-03 1.47014244e-02 1.29899751e-02\n",
            " 3.31180876e-03 8.78342454e-03 4.62417083e-04 9.11941704e-04\n",
            " 8.89050200e-03 1.40759539e-02 8.25985797e-03 2.65350001e-03\n",
            " 9.74498961e-03 6.07683914e-03 8.13972315e-03 1.65057315e-02\n",
            " 3.84536873e-04 5.56359373e-03 1.43060615e-02 7.44811289e-03\n",
            " 3.65157642e-03 1.05091484e-02 6.80254921e-03 3.54436748e-03\n",
            " 7.65835560e-03 1.52262901e-02 9.02526844e-03 9.48116418e-03\n",
            " 7.24550445e-03 1.67532860e-02 4.77423147e-03 5.59241691e-03\n",
            " 6.59892498e-03 8.18091621e-04 3.88500079e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3450 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.82991973e-03 4.35366580e-03 1.67395828e-02 4.67296688e-03\n",
            " 3.92794634e-03 1.52125108e-02 6.94892730e-04 1.24465910e-02\n",
            " 9.19129811e-03 3.99136174e-03 6.56002654e-03 1.22600088e-02\n",
            " 8.34627314e-03 1.57862757e-02 1.14748525e-02 8.14484493e-03\n",
            " 1.02241154e-02 1.05564798e-02 1.19720351e-02 6.39496820e-03\n",
            " 1.43319004e-02 5.56024546e-03 7.49387495e-03 5.55775129e-03\n",
            " 8.15917165e-03 1.43290207e-03 9.42268335e-03 4.89271411e-03\n",
            " 5.40718796e-03 3.85799431e-03 1.37732277e-05 5.80169422e-03\n",
            " 1.28423545e-02 1.38633217e-02 1.52336062e-02 2.90353936e-03\n",
            " 1.06597430e-02 1.34334041e-02 9.89727713e-05 9.49186131e-03\n",
            " 1.28423545e-02 1.24471376e-02 1.92217578e-03 5.09545349e-09\n",
            " 2.95180038e-03 1.82258160e-05 6.41723867e-03 1.24130723e-02\n",
            " 8.73833881e-03 4.32087471e-04 1.74062273e-07 1.12635822e-02\n",
            " 7.66413450e-03 7.20221979e-03 2.86135421e-03 7.58996179e-03\n",
            " 1.07019044e-02 9.74627321e-03 5.45134170e-03 8.91214862e-03\n",
            " 2.17658662e-03 1.16518647e-02 1.38560615e-02 9.43873122e-03\n",
            " 1.62614772e-02 1.34027201e-02 1.13041089e-02 1.11017555e-02\n",
            " 1.01723814e-03 7.51767459e-03 2.86258680e-03 1.62649839e-02\n",
            " 3.70986443e-04 1.09704760e-03 1.45438341e-02 8.14261952e-03\n",
            " 3.30552030e-03 9.97696501e-03 1.41473161e-02 9.74627321e-03\n",
            " 1.25818786e-02 4.23239387e-04 1.37901252e-02 7.40721835e-03\n",
            " 5.12481427e-03 4.99227093e-03 1.15759303e-02 4.79494613e-04\n",
            " 1.11366206e-02 1.01055270e-02 4.24809103e-03 4.25349608e-03\n",
            " 1.16246600e-03 1.59045538e-02 5.72078235e-03 1.10109748e-02\n",
            " 5.95735605e-04 1.03937174e-03 1.02617059e-02 5.41023063e-03\n",
            " 6.59537034e-05 3.72398354e-03 1.28751002e-02 9.67497851e-03\n",
            " 1.08288143e-02 1.10385380e-02 1.84345157e-03 7.69928704e-03\n",
            " 8.57709663e-03 6.70642804e-04 1.48063050e-02 2.07496897e-03\n",
            " 1.49410455e-02 1.08129448e-02 1.00286825e-02 1.44266595e-02\n",
            " 7.82374156e-03 9.13839578e-03 5.10524256e-03 1.24471376e-02\n",
            " 3.62526381e-03 6.97603334e-05 1.62483625e-02 9.21940631e-03\n",
            " 1.33250115e-02 4.01930939e-03 1.47665462e-02 1.63424820e-02\n",
            " 3.62526381e-03 1.20031954e-02 1.18736209e-02 8.93275784e-03\n",
            " 1.44876887e-02 6.77055380e-03 9.96841937e-04 1.25514751e-02\n",
            " 1.50659759e-02 9.61949411e-03 7.40352161e-03 1.17092006e-02\n",
            " 1.49907989e-03 1.57448053e-02 1.27856767e-02 4.43898941e-05\n",
            " 8.90170776e-03 1.48609083e-02 1.61684599e-02 4.70689946e-03\n",
            " 3.13649323e-03 1.02515497e-02 7.08891139e-03 9.09021284e-03\n",
            " 4.61684357e-03 9.07909634e-03 1.05479916e-02 9.64986687e-03\n",
            " 9.87843385e-03 5.09545349e-09 3.94684143e-03 9.04496051e-03\n",
            " 1.49149224e-02 8.65186481e-03 1.08865417e-03 1.29108402e-02\n",
            " 1.30507726e-02 4.20447359e-03 1.46365820e-02 7.97638126e-03\n",
            " 1.78588616e-03 7.73337658e-03 1.45429661e-02 2.12345104e-03\n",
            " 7.49921798e-03 4.16309437e-03 1.16770235e-02 1.64508478e-02\n",
            " 8.75522682e-03 5.66242385e-03 5.44483396e-03 6.60625920e-03\n",
            " 3.00444197e-03 8.34627314e-03 1.29778639e-02 1.30181781e-02\n",
            " 9.47570864e-03 5.17014383e-03 1.05993481e-02 4.24809103e-03\n",
            " 1.06597430e-02 9.65524578e-03 7.63001566e-03 1.23068712e-02\n",
            " 9.23135234e-03 5.74686897e-03 1.09008846e-02 7.70744520e-03\n",
            " 1.20249873e-02 2.45653998e-03 1.36604516e-02 1.60268830e-04\n",
            " 4.08176738e-03 1.63765173e-02 1.04767363e-02 1.10872572e-02\n",
            " 4.08330412e-03 1.01355677e-02 3.34755840e-03 1.39041011e-02\n",
            " 6.08516983e-03 7.51830475e-03 1.02301153e-02 5.31671306e-04\n",
            " 3.12533158e-03 1.10962373e-02 1.61684599e-02 1.52052843e-02\n",
            " 6.09924469e-03 1.31965350e-02 1.33361205e-06 1.15432943e-02\n",
            " 9.13381904e-05 8.03840289e-04 2.89963095e-03 1.27582846e-02\n",
            " 6.60815643e-03 2.99624306e-03 9.36644606e-03 5.20660490e-03\n",
            " 4.21750638e-04 1.46297315e-02 5.26446447e-03 5.47599752e-03\n",
            " 1.27128719e-02 1.17083711e-03 1.35616450e-02 1.06621154e-02\n",
            " 8.61843370e-04 4.55814767e-03 1.24465910e-02 6.75253513e-03\n",
            " 8.38734519e-03 5.47639740e-03 1.45627230e-02 5.97244077e-03\n",
            " 1.44140021e-02 4.47640017e-03 5.62169499e-03 5.38231411e-03\n",
            " 3.27073641e-03 7.69729052e-03 4.24809103e-03 1.61821029e-02\n",
            " 9.98380133e-03 7.82690714e-03 3.70216722e-03 1.23500812e-03\n",
            " 1.49169244e-03 1.65176737e-02 9.10316214e-03 4.09149538e-03\n",
            " 1.00792774e-02 1.18965191e-02 1.54476152e-03 5.17913380e-03\n",
            " 9.18560884e-03 9.73886960e-05 8.06455529e-03 3.05498648e-16\n",
            " 3.07556655e-03 1.57118861e-02 1.46943022e-02 6.14424296e-03\n",
            " 1.28124875e-02 1.04964624e-02 1.41819644e-02 1.15010403e-02\n",
            " 2.34591738e-04 8.12202704e-03 1.02737653e-02 1.56657538e-02\n",
            " 1.01355677e-02 7.51767459e-03 2.86163395e-03 4.03311164e-03\n",
            " 3.18636060e-03 1.17092006e-02 2.11213550e-03 1.61652555e-02\n",
            " 3.64802546e-03 1.24447898e-02 6.68074246e-03 7.33375198e-03\n",
            " 1.64138887e-03 2.48808349e-04 7.11194655e-03 1.31365559e-02\n",
            " 4.71020720e-03 6.66877153e-03 1.21272863e-02 4.02405956e-03\n",
            " 4.04895203e-04 1.40476386e-02 8.54588260e-03 2.02189044e-03\n",
            " 4.48177411e-03 3.43807563e-03 7.05142958e-03 7.82375485e-03\n",
            " 1.76811748e-04 4.48211915e-03 1.51492712e-02 3.56752435e-03\n",
            " 8.42797018e-03 1.43029585e-02 4.84037653e-03 3.21225291e-03\n",
            " 9.11997350e-03 8.98221116e-03 6.94169809e-03 1.35745992e-02\n",
            " 4.71579425e-03 9.40446539e-03 5.55775129e-03 9.82923806e-03\n",
            " 1.43536256e-02 4.88535012e-03 9.99054736e-03 1.94032695e-04\n",
            " 9.24179220e-03 1.18667661e-02 1.67047466e-03 8.29119442e-03\n",
            " 9.93554992e-03 8.01913092e-03 6.80930231e-03 3.72398354e-03\n",
            " 1.34470597e-03 1.23639995e-02 2.90808786e-03 1.99082968e-03\n",
            " 1.55168803e-02 1.46238593e-02 1.38583921e-02 1.29650999e-03\n",
            " 4.78292813e-03 1.58008799e-02 1.69408541e-03 5.74686897e-03\n",
            " 3.94333681e-03 1.65250763e-02 1.34291565e-02 1.48023879e-03\n",
            " 1.16144806e-02 7.56653191e-03 3.09473179e-03 3.10126526e-03\n",
            " 6.31425624e-03 2.21331111e-03 1.40765519e-02 4.55984737e-06\n",
            " 1.22299021e-02 8.13159890e-04 1.48468475e-02 3.83348774e-03\n",
            " 1.24291044e-03 1.08315304e-02 1.01712060e-02 1.03368334e-05\n",
            " 1.05618220e-02 1.10243865e-02 1.46937782e-02 2.33183096e-03\n",
            " 1.79941455e-04 8.91583649e-03 1.35745992e-02 3.77091958e-03\n",
            " 3.02971939e-03 8.96804437e-03 1.71865695e-03 7.54995131e-04\n",
            " 2.10607127e-03 1.45337343e-02 6.30809114e-04 2.10033771e-03\n",
            " 1.08821221e-03 1.56381019e-02 3.63201864e-03 1.50733187e-02\n",
            " 1.39537605e-02 1.09907908e-02 7.77245844e-03 5.45957964e-05\n",
            " 1.33992565e-02 5.68329380e-04 1.10607967e-02 8.62877506e-04\n",
            " 1.20902803e-02 1.04559588e-02 1.25318270e-02 9.92331015e-03\n",
            " 1.26956273e-02 1.37084005e-02 1.39786908e-02 9.74627321e-03\n",
            " 9.53481479e-03 5.31432359e-03 8.25003074e-03 8.32380697e-03\n",
            " 8.03980451e-03 9.71549618e-03 1.71865695e-03 1.53710500e-02\n",
            " 1.11364467e-02 1.06970942e-02 1.67288128e-02 2.11771718e-03\n",
            " 1.19073355e-02 3.23262026e-03 9.58461445e-03 4.88433661e-03\n",
            " 1.05553534e-02 1.86908499e-03 1.28725223e-02 3.98173925e-03\n",
            " 1.17009326e-02 1.63444809e-02 1.56466627e-02 7.66019347e-03\n",
            " 1.22506833e-02 1.24082876e-02 4.41031651e-03 9.18962824e-03\n",
            " 5.58383154e-04 2.81726819e-03 9.41010731e-03 3.71868247e-03\n",
            " 7.48902975e-03 7.97324784e-03 1.94032695e-04 4.66449642e-03\n",
            " 1.08139795e-02 2.84076011e-03 1.46469230e-02 3.79751321e-03\n",
            " 1.67837570e-02 1.02951003e-02 8.05740698e-03 4.42801322e-03\n",
            " 5.69211829e-04 1.41917777e-03 1.29565435e-02 1.15780381e-03\n",
            " 1.58360826e-02 7.09006949e-03 4.98379102e-03 1.59753393e-02\n",
            " 6.94892730e-04 4.35339637e-03 1.41760890e-02 1.17124048e-02\n",
            " 3.07960064e-04 7.64110401e-03 1.71865695e-03 7.51310540e-03\n",
            " 1.39877243e-02 1.11561085e-02 1.28388044e-02 5.63717188e-03\n",
            " 7.34170324e-03 8.45973226e-03 1.09020640e-02 1.47272544e-02\n",
            " 1.03781038e-02 2.21431131e-03 1.27897721e-02 3.54913404e-03\n",
            " 1.12293462e-03 7.50366957e-03 8.23283537e-03 8.72574967e-03\n",
            " 2.47437859e-04 1.10613390e-02 3.72398354e-03 1.64901119e-02\n",
            " 6.00662334e-03 3.83348774e-03 9.28198151e-03 4.01881476e-04\n",
            " 2.56882150e-03 1.47675341e-02 1.58213513e-02 4.99207906e-04\n",
            " 8.17111195e-03 9.15889806e-03 2.01654572e-03 4.67776673e-03\n",
            " 1.51714941e-03 9.84453520e-03 1.53973476e-02 1.16077097e-02\n",
            " 9.97960379e-03 1.41654999e-02 7.00835941e-03 9.74614795e-03\n",
            " 1.03275893e-02 1.34800647e-04 6.96671232e-03 2.20660381e-03\n",
            " 3.20570038e-03 1.40833617e-02 3.11487585e-03 4.70689946e-03\n",
            " 8.47633628e-03 1.19959478e-02 4.01930939e-03 1.66835273e-02\n",
            " 6.35041150e-03 2.51331550e-03 1.05055414e-02 9.68039882e-03\n",
            " 1.92019106e-03 5.53042501e-04 2.66683167e-03 1.36653958e-02\n",
            " 1.40855571e-02 1.64988655e-02 4.18650281e-03 1.00171966e-02\n",
            " 1.39041011e-02 1.38910583e-02 7.72871866e-03 3.82037251e-03\n",
            " 1.58025010e-02 5.91384527e-04 1.64625627e-02 1.66182296e-02\n",
            " 3.31715397e-03 6.30821554e-03 5.16011063e-03 7.90288193e-03\n",
            " 4.70857708e-03 1.61684599e-02 1.59751644e-02 1.61612086e-02\n",
            " 3.16123667e-04 2.62064371e-03 2.82605821e-03 7.85721321e-03\n",
            " 1.28380516e-02 1.39948333e-02 8.02267895e-03 2.11771718e-03\n",
            " 1.40942917e-02 1.35849110e-03 1.10351559e-02 1.55169737e-02\n",
            " 2.41751815e-03 5.78648014e-03 1.05077312e-02 1.37750978e-02\n",
            " 1.14432144e-02 4.00477591e-03 1.37647602e-02 1.12609480e-02\n",
            " 5.20296747e-03 8.31716202e-04 1.04209399e-02 6.62990545e-03\n",
            " 4.15254537e-03 1.50075876e-02 4.87420796e-03 3.66472940e-03\n",
            " 6.91860825e-03 5.07257181e-03 4.46248572e-03 2.80472863e-03\n",
            " 6.31821224e-03 1.04553447e-02 1.04394298e-03 6.58904089e-04\n",
            " 5.80169422e-03 1.34783563e-02 9.40027043e-04 1.96951030e-04\n",
            " 1.11607061e-02 9.24544557e-03 1.08615856e-02 1.24714311e-03\n",
            " 1.58356915e-02 1.42927053e-03 2.01485570e-03 2.86135421e-03\n",
            " 7.24045984e-05 1.47596948e-02 3.69264912e-03 5.42639940e-03\n",
            " 5.15220790e-03 2.09528604e-06 1.19094280e-02 6.45967320e-04\n",
            " 4.93048396e-07 1.07403254e-02 2.05722702e-05 3.73687022e-05\n",
            " 1.33007431e-02 1.64695403e-02 1.03979573e-02 1.08190761e-02\n",
            " 1.47230748e-03 8.47668626e-04 1.12123902e-02 1.56565437e-02\n",
            " 4.33502649e-03 1.62514652e-02 1.54030314e-02 3.85799431e-03\n",
            " 1.43137423e-02 4.88736767e-03 1.06170380e-02 4.88736767e-03\n",
            " 7.31831096e-03 1.01868698e-03 7.12602142e-03 1.84967430e-03\n",
            " 3.88505528e-03 2.90201557e-04 1.51275806e-02 3.74887214e-04\n",
            " 1.05130230e-02 1.42666793e-02 3.02278106e-03 1.37024428e-02\n",
            " 4.82797749e-03 4.17379456e-03 2.36877487e-04 5.16389200e-03\n",
            " 6.09358736e-03 6.50566134e-03 1.30629340e-02 1.55560895e-02\n",
            " 5.45974278e-03 4.60149439e-03 4.84037653e-03 7.01987524e-03\n",
            " 1.16183839e-02 2.97212968e-03 1.29638017e-02 1.48293105e-02\n",
            " 1.07117674e-02 1.43433182e-02 5.41853433e-03 5.72085389e-03\n",
            " 1.25594364e-02 4.67124898e-03 3.85799431e-03 1.33316630e-02\n",
            " 1.38857742e-02 7.64796048e-03 1.05491412e-02 1.35740072e-03\n",
            " 1.20601006e-03 3.68050124e-03 1.57022656e-02 5.30895962e-03\n",
            " 3.92753239e-03 6.68925102e-04 9.11562382e-03 1.08454355e-02\n",
            " 8.15404795e-03 5.48273190e-03 2.24047897e-03 7.19598221e-04\n",
            " 9.28639758e-03 6.97613738e-03 7.24356817e-03 8.64663859e-03\n",
            " 1.11610810e-02 9.69545668e-03 2.83351989e-03 1.48341406e-03\n",
            " 1.27013320e-03 1.42029751e-02 6.16790665e-03 9.63219571e-03\n",
            " 1.06822162e-02 7.15081864e-03 8.56336904e-03 1.34373593e-02\n",
            " 4.13385157e-03 1.36892313e-02 7.85752585e-03 3.70215546e-03\n",
            " 8.91022677e-03 1.31916005e-02 1.29131867e-02 3.08226181e-03\n",
            " 1.47089854e-02 1.29801330e-02 3.31239037e-03 8.75864692e-03\n",
            " 4.60699666e-04 9.11278791e-04 8.89942976e-03 1.40833617e-02\n",
            " 8.23829751e-03 2.64652094e-03 9.74627321e-03 6.06625282e-03\n",
            " 8.12372414e-03 1.64918020e-02 3.82598421e-04 5.52908524e-03\n",
            " 1.42729311e-02 7.43058496e-03 3.63115162e-03 1.05047704e-02\n",
            " 6.78634619e-03 3.53874346e-03 7.66970897e-03 1.52336062e-02\n",
            " 9.00922636e-03 9.46735357e-03 7.24305011e-03 1.67435116e-02\n",
            " 4.76358785e-03 5.57790370e-03 6.59265541e-03 8.13159890e-04\n",
            " 3.87382815e-03]\n",
            "3460 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.82820467e-03 4.34554994e-03 4.66002458e-03 3.91845147e-03\n",
            " 1.52055849e-02 6.94084270e-04 1.24471039e-02 9.16042375e-03\n",
            " 3.98366132e-03 6.55588213e-03 1.22630688e-02 8.33088562e-03\n",
            " 1.57869434e-02 1.14763672e-02 8.13636500e-03 1.02190482e-02\n",
            " 1.05231482e-02 1.19499896e-02 6.39318553e-03 1.43221056e-02\n",
            " 5.54304565e-03 7.48374548e-03 5.54615813e-03 8.13894729e-03\n",
            " 1.42832966e-03 9.42186663e-03 4.88071197e-03 5.39419796e-03\n",
            " 3.85245387e-03 1.36332836e-05 5.77225508e-03 1.28439725e-02\n",
            " 1.38500376e-02 1.52112068e-02 2.89663114e-03 1.06036508e-02\n",
            " 1.33781472e-02 9.86250921e-05 9.44991003e-03 1.28439725e-02\n",
            " 1.23338811e-02 1.91579411e-03 4.90400693e-09 2.93218978e-03\n",
            " 1.82013443e-05 6.38633135e-03 1.23899841e-02 8.71455808e-03\n",
            " 4.29717729e-04 1.70092123e-07 1.12388281e-02 7.62522487e-03\n",
            " 7.17296569e-03 2.85769397e-03 7.57221370e-03 1.06671407e-02\n",
            " 9.73936281e-03 5.45040887e-03 8.88858691e-03 2.16734725e-03\n",
            " 1.16639750e-02 1.38311652e-02 9.41318783e-03 1.62677565e-02\n",
            " 1.33959150e-02 1.13038067e-02 1.10875562e-02 1.01601657e-03\n",
            " 7.50700370e-03 2.85370171e-03 1.62512784e-02 3.67343925e-04\n",
            " 1.09088147e-03 1.45207602e-02 8.09478435e-03 3.29221207e-03\n",
            " 9.94561005e-03 1.40810088e-02 9.73936281e-03 1.25737280e-02\n",
            " 4.22261546e-04 1.37873958e-02 7.37475635e-03 5.09602105e-03\n",
            " 4.99969250e-03 1.15538464e-02 4.77289887e-04 1.11276486e-02\n",
            " 1.00738738e-02 4.23915155e-03 4.24094665e-03 1.15481577e-03\n",
            " 1.59060063e-02 5.65912676e-03 1.09808768e-02 5.95322799e-04\n",
            " 1.03455736e-03 1.02356121e-02 5.41152068e-03 6.52715159e-05\n",
            " 3.72303552e-03 1.28776068e-02 9.65040002e-03 1.07984766e-02\n",
            " 1.10107265e-02 1.83951861e-03 7.66967287e-03 8.55677129e-03\n",
            " 6.66547985e-04 1.48072957e-02 2.07084783e-03 1.49168586e-02\n",
            " 1.08050218e-02 9.99479964e-03 1.44126148e-02 7.80556343e-03\n",
            " 9.14986197e-03 5.09068269e-03 1.23338811e-02 3.61827930e-03\n",
            " 6.92453933e-05 1.62200504e-02 9.22215222e-03 1.33085253e-02\n",
            " 4.02513075e-03 1.47052666e-02 1.63274403e-02 3.61827930e-03\n",
            " 1.20349141e-02 1.18176119e-02 8.90302872e-03 1.44496222e-02\n",
            " 6.75262796e-03 9.94950324e-04 1.25278429e-02 1.50477745e-02\n",
            " 9.62238450e-03 7.39219855e-03 1.16723272e-02 1.49764187e-03\n",
            " 1.56977078e-02 1.27629226e-02 4.43188574e-05 8.89055138e-03\n",
            " 1.48394616e-02 1.61752537e-02 4.70916168e-03 3.12807299e-03\n",
            " 1.02418207e-02 7.08099834e-03 9.09398928e-03 4.61840742e-03\n",
            " 9.06749440e-03 1.05227889e-02 9.64206665e-03 9.83648699e-03\n",
            " 4.90400693e-09 3.94429673e-03 9.02434793e-03 1.48812974e-02\n",
            " 8.63278635e-03 1.07828539e-03 1.29082900e-02 1.30366603e-02\n",
            " 4.19075461e-03 1.46193328e-02 7.96848706e-03 1.77755941e-03\n",
            " 7.70178760e-03 1.45172724e-02 2.11149794e-03 7.48462236e-03\n",
            " 4.16471099e-03 1.16531809e-02 1.64421636e-02 8.73648107e-03\n",
            " 5.64807064e-03 5.43928305e-03 6.59645259e-03 3.00374298e-03\n",
            " 8.33088562e-03 1.29267852e-02 1.29977393e-02 9.45166927e-03\n",
            " 5.16757777e-03 1.05977663e-02 4.23915155e-03 1.06036508e-02\n",
            " 9.66240419e-03 7.61416419e-03 1.22773884e-02 9.23257981e-03\n",
            " 5.73166097e-03 1.08783793e-02 7.70062121e-03 1.20013447e-02\n",
            " 2.45897633e-03 1.36600368e-02 1.59405988e-04 4.06253985e-03\n",
            " 1.63313124e-02 1.04690397e-02 1.10905753e-02 4.07458928e-03\n",
            " 1.01173643e-02 3.34620222e-03 1.38550502e-02 6.06779737e-03\n",
            " 7.50005016e-03 1.01807221e-02 5.31175201e-04 3.11800572e-03\n",
            " 1.10675576e-02 1.61752537e-02 1.51941759e-02 6.10006378e-03\n",
            " 1.31853425e-02 1.32235009e-06 1.15127549e-02 9.09636115e-05\n",
            " 8.04019009e-04 2.88896946e-03 1.27247102e-02 6.58120123e-03\n",
            " 2.99230432e-03 9.34355054e-03 5.19139844e-03 4.19286781e-04\n",
            " 1.46171503e-02 5.24223369e-03 5.46738537e-03 1.26882928e-02\n",
            " 1.16112989e-03 1.35426675e-02 1.06230834e-02 8.60292642e-04\n",
            " 4.55908202e-03 1.24471039e-02 6.71780945e-03 8.37955415e-03\n",
            " 5.46532156e-03 1.44902716e-02 5.94660758e-03 1.44186976e-02\n",
            " 4.46909341e-03 5.61097854e-03 5.36078034e-03 3.26828020e-03\n",
            " 7.69243297e-03 4.23915155e-03 1.61070635e-02 9.95474369e-03\n",
            " 7.80870051e-03 3.69692835e-03 1.22937775e-03 1.49349485e-03\n",
            " 9.09886649e-03 4.07958268e-03 1.00693834e-02 1.18847041e-02\n",
            " 1.53721818e-03 5.17630621e-03 9.18016203e-03 9.72905557e-05\n",
            " 8.02809690e-03 3.05600853e-16 3.07082257e-03 1.56980938e-02\n",
            " 1.47079874e-02 6.13123449e-03 1.27862146e-02 1.04631169e-02\n",
            " 1.41565806e-02 1.14788886e-02 2.34196535e-04 8.13080902e-03\n",
            " 1.02712250e-02 1.56187766e-02 1.01173643e-02 7.50700370e-03\n",
            " 2.86097360e-03 4.02881683e-03 3.18285138e-03 1.16723272e-02\n",
            " 2.11179525e-03 1.60817234e-02 3.61108622e-03 1.24225391e-02\n",
            " 6.64997934e-03 7.33097737e-03 1.63743541e-03 2.48213667e-04\n",
            " 7.09909912e-03 1.31241901e-02 4.71516816e-03 6.65157077e-03\n",
            " 1.21291327e-02 4.02375946e-03 4.03163604e-04 1.40059438e-02\n",
            " 8.53957732e-03 2.01986812e-03 4.46576251e-03 3.42856774e-03\n",
            " 7.04488344e-03 7.81145795e-03 1.75745948e-04 4.47799513e-03\n",
            " 1.51195726e-02 3.55614221e-03 8.41128693e-03 1.43087247e-02\n",
            " 4.83867923e-03 3.21048607e-03 9.06996120e-03 8.92776374e-03\n",
            " 6.92926417e-03 1.35645778e-02 4.71652016e-03 9.39992283e-03\n",
            " 5.54615813e-03 9.80141896e-03 1.43035893e-02 4.88505104e-03\n",
            " 9.96688399e-03 1.91027540e-04 9.21046590e-03 1.18615140e-02\n",
            " 1.65903941e-03 8.27373223e-03 9.88768789e-03 8.02283154e-03\n",
            " 6.80911590e-03 3.72303552e-03 1.34148687e-03 1.23383747e-02\n",
            " 2.88635370e-03 1.98605691e-03 1.55221549e-02 1.46180046e-02\n",
            " 1.38634077e-02 1.29620396e-03 4.76994189e-03 1.57442141e-02\n",
            " 1.69473518e-03 5.73166097e-03 3.93462821e-03 1.33896245e-02\n",
            " 1.47009595e-03 1.15707497e-02 7.56091071e-03 3.07974763e-03\n",
            " 3.08929904e-03 6.30100974e-03 2.20048573e-03 1.40172857e-02\n",
            " 4.51285003e-06 1.22016426e-02 8.07370729e-04 1.48378057e-02\n",
            " 3.82958751e-03 1.24038851e-03 1.08035904e-02 1.01111167e-02\n",
            " 1.02373380e-05 1.05678822e-02 1.10203198e-02 1.46801268e-02\n",
            " 2.32066743e-03 1.79252339e-04 8.91412352e-03 1.35645778e-02\n",
            " 3.75788327e-03 3.02158862e-03 8.94586832e-03 1.71357607e-03\n",
            " 7.54912312e-04 2.09614646e-03 1.44818041e-02 6.26546736e-04\n",
            " 2.09741360e-03 1.08349662e-03 1.56111347e-02 3.61751665e-03\n",
            " 1.50784049e-02 1.39401078e-02 1.09589680e-02 7.74766124e-03\n",
            " 5.43950870e-05 1.33572733e-02 5.65236386e-04 1.10494527e-02\n",
            " 8.57097482e-04 1.20641644e-02 1.04538814e-02 1.24915746e-02\n",
            " 9.87136948e-03 1.26901606e-02 1.36661896e-02 1.39741167e-02\n",
            " 9.73936281e-03 9.50997360e-03 5.30932881e-03 8.25149970e-03\n",
            " 8.29309529e-03 8.03442820e-03 9.69147953e-03 1.71357607e-03\n",
            " 1.53810065e-02 1.10805680e-02 1.06614366e-02 2.10992235e-03\n",
            " 1.18599874e-02 3.22436957e-03 9.55347314e-03 4.86956991e-03\n",
            " 1.05185750e-02 1.86833601e-03 1.28775399e-02 3.96046860e-03\n",
            " 1.16937519e-02 1.63609405e-02 1.56353907e-02 7.65676599e-03\n",
            " 1.22435225e-02 1.23814843e-02 4.40779132e-03 9.15744294e-03\n",
            " 5.57252931e-04 2.81119335e-03 9.39814416e-03 3.69516431e-03\n",
            " 7.46099535e-03 7.96011966e-03 1.91027540e-04 4.64601335e-03\n",
            " 1.07983591e-02 2.84154274e-03 1.46104512e-02 3.78960955e-03\n",
            " 1.02820632e-02 8.05783335e-03 4.41383977e-03 5.61756166e-04\n",
            " 1.41524934e-03 1.29288040e-02 1.15663566e-03 1.57921457e-02\n",
            " 7.07149799e-03 4.97161355e-03 1.59023324e-02 6.94084270e-04\n",
            " 4.32890023e-03 1.41417425e-02 1.17491935e-02 3.06172055e-04\n",
            " 7.60905983e-03 1.71357607e-03 7.50536192e-03 1.39860951e-02\n",
            " 1.11152576e-02 1.28186655e-02 5.62140524e-03 7.31235687e-03\n",
            " 8.43706102e-03 1.08724581e-02 1.46980732e-02 1.03616389e-02\n",
            " 2.20450639e-03 1.28027192e-02 3.52433466e-03 1.12395397e-03\n",
            " 7.48050813e-03 8.22200667e-03 8.71889150e-03 2.47338215e-04\n",
            " 1.10727863e-02 3.72303552e-03 1.64866698e-02 5.99657947e-03\n",
            " 3.82958751e-03 9.28251307e-03 4.02211736e-04 2.55523816e-03\n",
            " 1.47751868e-02 1.58114786e-02 4.96287812e-04 8.16521666e-03\n",
            " 9.13129492e-03 2.01788580e-03 4.67991293e-03 1.51134606e-03\n",
            " 9.85067701e-03 1.53718783e-02 1.15734481e-02 9.96339647e-03\n",
            " 1.41296786e-02 6.98889062e-03 9.74476625e-03 1.03262097e-02\n",
            " 1.34749219e-04 6.94632710e-03 2.20454364e-03 3.19336916e-03\n",
            " 1.40832676e-02 3.09427717e-03 4.70916168e-03 8.45448158e-03\n",
            " 1.19571320e-02 4.02513075e-03 6.34124087e-03 2.50684050e-03\n",
            " 1.04879423e-02 9.64357821e-03 1.91425473e-03 5.52705368e-04\n",
            " 2.66164418e-03 1.36481122e-02 1.40694258e-02 4.17759369e-03\n",
            " 1.00060213e-02 1.38550502e-02 1.38722969e-02 7.71075964e-03\n",
            " 3.80888403e-03 1.57474153e-02 5.89128221e-04 1.64453883e-02\n",
            " 3.29554031e-03 6.31193232e-03 5.15237911e-03 7.87554267e-03\n",
            " 4.68294036e-03 1.61752537e-02 1.58921068e-02 1.61554593e-02\n",
            " 3.13242117e-04 2.61799347e-03 2.82284398e-03 7.83461429e-03\n",
            " 1.27987832e-02 1.39978009e-02 8.01665840e-03 2.10992235e-03\n",
            " 1.40975311e-02 1.35253935e-03 1.10042516e-02 1.55099912e-02\n",
            " 2.41244938e-03 5.75844918e-03 1.05119505e-02 1.37517735e-02\n",
            " 1.13995201e-02 3.99627197e-03 1.37501200e-02 1.12521174e-02\n",
            " 5.16866238e-03 8.29826287e-04 1.03811442e-02 6.61556244e-03\n",
            " 4.14018950e-03 1.50142323e-02 4.84835615e-03 3.66661933e-03\n",
            " 6.90522834e-03 5.07455503e-03 4.44350565e-03 2.79824507e-03\n",
            " 6.29011647e-03 1.04116044e-02 1.03860131e-03 6.57816657e-04\n",
            " 5.77225508e-03 1.34818831e-02 9.40448897e-04 1.96248254e-04\n",
            " 1.11581973e-02 9.21185417e-03 1.08630812e-02 1.24075873e-03\n",
            " 1.58262802e-02 1.42942880e-03 2.01293359e-03 2.85769397e-03\n",
            " 7.23720549e-05 1.46605025e-02 3.68031594e-03 5.41557525e-03\n",
            " 5.15439167e-03 2.06752734e-06 1.18583911e-02 6.44748895e-04\n",
            " 4.92762089e-07 1.07406153e-02 2.02954086e-05 3.69712763e-05\n",
            " 1.32615169e-02 1.64513598e-02 1.03921899e-02 1.07925148e-02\n",
            " 1.47017919e-03 8.46676542e-04 1.12038575e-02 1.55905280e-02\n",
            " 4.32766715e-03 1.62442395e-02 1.53775224e-02 3.85245387e-03\n",
            " 1.43039846e-02 4.87853509e-03 1.05981293e-02 4.87853509e-03\n",
            " 7.28887056e-03 1.01651236e-03 7.11104867e-03 1.84085054e-03\n",
            " 3.87325139e-03 2.90322072e-04 1.51208823e-02 3.72905805e-04\n",
            " 1.04806806e-02 1.42636593e-02 3.00832894e-03 1.36776279e-02\n",
            " 4.80961068e-03 4.15522926e-03 2.33316913e-04 5.15568211e-03\n",
            " 6.09395977e-03 6.50098237e-03 1.30437706e-02 1.54850434e-02\n",
            " 5.43265549e-03 4.59861967e-03 4.83867923e-03 7.00246660e-03\n",
            " 1.16132393e-02 2.97144830e-03 1.29122425e-02 1.47973014e-02\n",
            " 1.07217724e-02 1.43142803e-02 5.40211706e-03 5.69269716e-03\n",
            " 1.25293630e-02 4.64231612e-03 3.85245387e-03 1.33160182e-02\n",
            " 1.38730902e-02 7.62168164e-03 1.05207640e-02 1.34596384e-03\n",
            " 1.20409577e-03 3.68050121e-03 1.56644178e-02 5.29787690e-03\n",
            " 3.91772243e-03 6.68106079e-04 9.10430988e-03 1.08222479e-02\n",
            " 8.13218845e-03 5.46923618e-03 2.22822792e-03 7.18047442e-04\n",
            " 9.28015284e-03 6.95269761e-03 7.19187467e-03 8.63397680e-03\n",
            " 1.11330322e-02 9.65367445e-03 2.83134300e-03 1.48132291e-03\n",
            " 1.26483722e-03 1.41948036e-02 6.11355755e-03 9.59321683e-03\n",
            " 1.06948167e-02 7.15225253e-03 8.55675914e-03 1.34406175e-02\n",
            " 4.11247136e-03 1.36763236e-02 7.83251816e-03 3.68257575e-03\n",
            " 8.90233796e-03 1.31799645e-02 1.28921548e-02 3.06480582e-03\n",
            " 1.46534804e-02 1.29312912e-02 3.31152709e-03 8.71188966e-03\n",
            " 4.59742109e-04 9.10239612e-04 8.89097002e-03 1.40832676e-02\n",
            " 8.21849346e-03 2.64380254e-03 9.73936281e-03 6.06451238e-03\n",
            " 8.11451568e-03 3.80403406e-04 5.52988147e-03 1.42881777e-02\n",
            " 7.40330311e-03 3.62151610e-03 1.04898076e-02 6.78375360e-03\n",
            " 3.53217827e-03 7.66756725e-03 1.52112068e-02 8.96585871e-03\n",
            " 9.41572700e-03 7.19996402e-03 4.74425011e-03 5.55418311e-03\n",
            " 6.57905736e-03 8.07370729e-04 3.85600601e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3470 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.81149069e-03 4.31045695e-03 4.65533518e-03 3.91390669e-03\n",
            " 1.51856923e-02 6.92147587e-04 1.24160027e-02 9.15496290e-03\n",
            " 3.96209309e-03 6.54939542e-03 1.22535150e-02 8.32004956e-03\n",
            " 1.57710629e-02 1.14625973e-02 8.12337012e-03 1.01906620e-02\n",
            " 1.05202256e-02 1.18928239e-02 6.39307422e-03 1.43123928e-02\n",
            " 5.52740148e-03 7.47477457e-03 5.53916627e-03 8.12262541e-03\n",
            " 1.42176616e-03 9.39645298e-03 4.86735704e-03 5.38122439e-03\n",
            " 3.85345348e-03 1.35303970e-05 5.77452872e-03 1.28515292e-02\n",
            " 1.38425977e-02 1.52152524e-02 2.89454792e-03 1.06192322e-02\n",
            " 1.33777271e-02 9.73711435e-05 9.40606351e-03 1.28515292e-02\n",
            " 1.22947029e-02 1.90820446e-03 4.88297392e-09 2.92952702e-03\n",
            " 1.80846415e-05 6.36369477e-03 1.23491927e-02 8.70062954e-03\n",
            " 4.29165740e-04 1.66418665e-07 1.12295566e-02 7.63739738e-03\n",
            " 7.16477503e-03 2.85710402e-03 7.56700136e-03 1.06216502e-02\n",
            " 9.73333371e-03 5.41917128e-03 8.86188919e-03 2.15981505e-03\n",
            " 1.16349002e-02 1.38130697e-02 9.41862544e-03 1.33687289e-02\n",
            " 1.12817319e-02 1.10632561e-02 1.01238164e-03 7.51432006e-03\n",
            " 2.83754050e-03 3.65744240e-04 1.08667042e-03 1.45005215e-02\n",
            " 8.09051807e-03 3.28322858e-03 9.94248767e-03 1.40767622e-02\n",
            " 9.73333371e-03 1.25774141e-02 4.22145084e-04 1.37607148e-02\n",
            " 7.36642283e-03 5.08790589e-03 4.98610033e-03 1.15510249e-02\n",
            " 4.76554303e-04 1.10871061e-02 1.00710469e-02 4.21279276e-03\n",
            " 4.21247933e-03 1.15181116e-03 1.58830175e-02 5.65854428e-03\n",
            " 1.09933786e-02 5.94182186e-04 1.03078404e-03 1.02100241e-02\n",
            " 5.36637989e-03 6.47795413e-05 3.71655820e-03 1.28300611e-02\n",
            " 9.64544489e-03 1.07691626e-02 1.09886614e-02 1.83039720e-03\n",
            " 7.63325422e-03 8.55349574e-03 6.58847241e-04 1.48016061e-02\n",
            " 2.06232278e-03 1.49270827e-02 1.07773826e-02 9.98109277e-03\n",
            " 1.44116786e-02 7.80953532e-03 9.14726893e-03 5.07372738e-03\n",
            " 1.22947029e-02 3.59753840e-03 6.83208985e-05 1.61679334e-02\n",
            " 9.19665710e-03 1.32978734e-02 4.00530933e-03 1.46831026e-02\n",
            " 3.59753840e-03 1.20367987e-02 1.18165233e-02 8.88706927e-03\n",
            " 1.44375917e-02 6.73298831e-03 9.92152967e-04 1.25114605e-02\n",
            " 1.50382076e-02 9.61570161e-03 7.39286194e-03 1.16140236e-02\n",
            " 1.48255804e-03 1.56799042e-02 1.27162443e-02 4.40892516e-05\n",
            " 8.86782850e-03 1.48337956e-02 1.61629760e-02 4.69725989e-03\n",
            " 3.12470139e-03 1.02159680e-02 7.02767784e-03 9.04409667e-03\n",
            " 4.61421016e-03 9.05770732e-03 1.05116750e-02 9.60067135e-03\n",
            " 9.84866233e-03 4.88297392e-09 3.91999151e-03 9.01263325e-03\n",
            " 1.48297742e-02 8.62930309e-03 1.07223666e-03 1.29165365e-02\n",
            " 1.30247192e-02 4.17600477e-03 1.45743100e-02 7.96572791e-03\n",
            " 1.77628517e-03 7.71096249e-03 1.44803420e-02 2.09919396e-03\n",
            " 7.47004193e-03 4.11426202e-03 1.16369258e-02 8.71999313e-03\n",
            " 5.63380863e-03 5.42195596e-03 6.60615428e-03 2.99528787e-03\n",
            " 8.32004956e-03 1.28954393e-02 1.30052381e-02 9.41264064e-03\n",
            " 5.15303089e-03 1.05813848e-02 4.21279276e-03 1.06192322e-02\n",
            " 9.65538920e-03 7.60158728e-03 1.22571113e-02 9.16918091e-03\n",
            " 5.73263632e-03 1.08474669e-02 7.69503342e-03 1.20024794e-02\n",
            " 2.45972816e-03 1.36062410e-02 1.58962549e-04 4.06005174e-03\n",
            " 1.04391059e-02 1.10391008e-02 4.07137394e-03 1.01120891e-02\n",
            " 3.33621758e-03 1.38243365e-02 6.07053663e-03 7.49839882e-03\n",
            " 1.01798368e-02 5.29054405e-04 3.10698269e-03 1.10841940e-02\n",
            " 1.61629760e-02 1.52088141e-02 6.08973929e-03 1.31361753e-02\n",
            " 1.30159858e-06 1.14974051e-02 9.08044034e-05 8.02204959e-04\n",
            " 2.88300481e-03 1.27036369e-02 6.59633068e-03 2.98421329e-03\n",
            " 9.33449332e-03 5.17618808e-03 4.18116154e-04 1.46119691e-02\n",
            " 5.23310730e-03 5.43177873e-03 1.26308017e-02 1.15508056e-03\n",
            " 1.35190423e-02 1.05981205e-02 8.58332380e-04 4.55938452e-03\n",
            " 1.24160027e-02 6.71046981e-03 8.37723811e-03 5.43716594e-03\n",
            " 1.44535599e-02 5.94226709e-03 1.43936386e-02 4.46285731e-03\n",
            " 5.61310560e-03 5.35256751e-03 3.23881338e-03 7.67667323e-03\n",
            " 4.21279276e-03 1.60358964e-02 9.94115663e-03 7.79284086e-03\n",
            " 3.68396150e-03 1.22741918e-03 1.48994487e-03 9.08374000e-03\n",
            " 4.06276428e-03 1.00490754e-02 1.18800855e-02 1.52991368e-03\n",
            " 5.16204163e-03 9.16784236e-03 9.69054700e-05 8.01449558e-03\n",
            " 3.01097763e-16 3.06016746e-03 1.56775332e-02 1.47101489e-02\n",
            " 6.12855817e-03 1.27596129e-02 1.04611744e-02 1.40961963e-02\n",
            " 1.14613650e-02 2.32817404e-04 8.10460370e-03 1.02618711e-02\n",
            " 1.56155533e-02 1.01120891e-02 7.51432006e-03 2.84780107e-03\n",
            " 4.02381556e-03 3.16925210e-03 1.16140236e-02 2.10797137e-03\n",
            " 1.60064805e-02 3.60851959e-03 1.24109735e-02 6.63705189e-03\n",
            " 7.33056486e-03 1.63407210e-03 2.47166411e-04 7.08290818e-03\n",
            " 1.30958152e-02 4.69732662e-03 6.64042258e-03 1.21204255e-02\n",
            " 4.01717357e-03 4.01835015e-04 1.40048472e-02 8.51885782e-03\n",
            " 2.01466227e-03 4.45374831e-03 3.42663037e-03 7.02688184e-03\n",
            " 7.76196617e-03 1.75453613e-04 4.46487613e-03 1.51241762e-02\n",
            " 3.54941522e-03 8.39890347e-03 1.42624755e-02 4.83519402e-03\n",
            " 3.20657380e-03 9.05091150e-03 8.91974734e-03 6.93108788e-03\n",
            " 1.34992717e-02 4.70553736e-03 9.38735016e-03 5.53916627e-03\n",
            " 9.80194559e-03 1.42800384e-02 4.87292438e-03 9.94733646e-03\n",
            " 1.90977977e-04 9.19930302e-03 1.18621149e-02 1.65672410e-03\n",
            " 8.25840843e-03 9.89088625e-03 7.99457523e-03 6.78967978e-03\n",
            " 3.71655820e-03 1.34100884e-03 1.23225738e-02 2.88722046e-03\n",
            " 1.98252368e-03 1.55112277e-02 1.45756271e-02 1.38362108e-02\n",
            " 1.29263627e-03 4.76702053e-03 1.57300767e-02 1.68965688e-03\n",
            " 5.73263632e-03 3.93542142e-03 1.34011331e-02 1.46039084e-03\n",
            " 1.15144324e-02 7.56002485e-03 3.06946586e-03 3.08518904e-03\n",
            " 6.28546454e-03 2.19651860e-03 1.40044334e-02 4.49776553e-06\n",
            " 1.22048441e-02 8.05401954e-04 1.48216291e-02 3.83159366e-03\n",
            " 1.23497203e-03 1.07836603e-02 1.00800585e-02 1.02080294e-05\n",
            " 1.05649371e-02 1.09803922e-02 1.46581499e-02 2.31696090e-03\n",
            " 1.78762487e-04 8.86234657e-03 1.34992717e-02 3.75143306e-03\n",
            " 3.02058299e-03 8.93797075e-03 1.71334063e-03 7.54373379e-04\n",
            " 2.09658021e-03 1.44024591e-02 6.21932195e-04 2.09727496e-03\n",
            " 1.07573630e-03 1.55827681e-02 3.61238302e-03 1.50422506e-02\n",
            " 1.38839919e-02 1.09092711e-02 7.73980169e-03 5.44826012e-05\n",
            " 1.33416432e-02 5.63122743e-04 1.10377361e-02 8.53731978e-04\n",
            " 1.20571548e-02 1.04316034e-02 1.25063817e-02 9.86364076e-03\n",
            " 1.26651315e-02 1.36651470e-02 1.39568244e-02 9.73333371e-03\n",
            " 9.49101084e-03 5.28752738e-03 8.23035992e-03 8.26575161e-03\n",
            " 8.02596637e-03 9.65313099e-03 1.71334063e-03 1.53913410e-02\n",
            " 1.10502427e-02 1.06339835e-02 2.10243782e-03 1.18359716e-02\n",
            " 3.21718522e-03 9.49527338e-03 4.85576671e-03 1.05094117e-02\n",
            " 1.86128374e-03 1.28464854e-02 3.95527269e-03 1.16981421e-02\n",
            " 1.55737447e-02 7.63415293e-03 1.22247505e-02 1.23250261e-02\n",
            " 4.40619599e-03 9.16355918e-03 5.57943934e-04 2.79657293e-03\n",
            " 9.37108034e-03 3.69145443e-03 7.46770623e-03 7.95070403e-03\n",
            " 1.90977977e-04 4.63587213e-03 1.07976615e-02 2.82317480e-03\n",
            " 1.46084093e-02 3.77353212e-03 1.02755235e-02 8.05925587e-03\n",
            " 4.40530176e-03 5.57471909e-04 1.41404033e-03 1.29004700e-02\n",
            " 1.15470868e-03 1.57636166e-02 7.08076129e-03 4.97075568e-03\n",
            " 1.58839381e-02 6.92147587e-04 4.32384989e-03 1.41258605e-02\n",
            " 1.16574503e-02 3.03558886e-04 7.60484690e-03 1.71334063e-03\n",
            " 7.50937724e-03 1.39546309e-02 1.11104239e-02 1.28317638e-02\n",
            " 5.60765478e-03 7.30673173e-03 8.39313892e-03 1.08459772e-02\n",
            " 1.46675778e-02 1.03575533e-02 2.19996854e-03 1.27474776e-02\n",
            " 3.51569958e-03 1.11721172e-03 7.48525090e-03 8.17286911e-03\n",
            " 8.71202384e-03 2.46314194e-04 1.10703271e-02 3.71655820e-03\n",
            " 5.98136798e-03 3.83159366e-03 9.24829111e-03 4.02740451e-04\n",
            " 2.54497639e-03 1.47400225e-02 1.58330811e-02 4.95649891e-04\n",
            " 8.17029662e-03 9.11698569e-03 2.01869969e-03 4.67014095e-03\n",
            " 1.50800444e-03 9.81363557e-03 1.53978006e-02 1.15728446e-02\n",
            " 9.91617053e-03 1.41288342e-02 6.98203709e-03 9.73006016e-03\n",
            " 1.03102876e-02 1.34505288e-04 6.92910093e-03 2.20027128e-03\n",
            " 3.17501086e-03 1.40521685e-02 3.09255243e-03 4.69725989e-03\n",
            " 8.45194009e-03 1.19506363e-02 4.00530933e-03 6.33529130e-03\n",
            " 2.49878651e-03 1.04447139e-02 9.64727230e-03 1.90520412e-03\n",
            " 5.51752010e-04 2.65994179e-03 1.36273945e-02 1.40612982e-02\n",
            " 4.17165658e-03 9.96909991e-03 1.38243365e-02 1.38549826e-02\n",
            " 7.69206328e-03 3.79981353e-03 1.57383804e-02 5.88184526e-04\n",
            " 3.28283780e-03 6.28812012e-03 5.15118825e-03 7.88032376e-03\n",
            " 4.66580407e-03 1.61629760e-02 1.58693966e-02 1.61257710e-02\n",
            " 3.12452073e-04 2.60337930e-03 2.80995054e-03 7.82419436e-03\n",
            " 1.27889744e-02 1.39841038e-02 7.98201442e-03 2.10243782e-03\n",
            " 1.40984446e-02 1.34954715e-03 1.10089607e-02 1.55001176e-02\n",
            " 2.40377618e-03 5.75861640e-03 1.04995748e-02 1.36965146e-02\n",
            " 1.13825552e-02 3.99656231e-03 1.37138404e-02 1.12499203e-02\n",
            " 5.14055886e-03 8.21771018e-04 1.03712517e-02 6.60669094e-03\n",
            " 4.10275765e-03 1.49748993e-02 4.84347933e-03 3.65870914e-03\n",
            " 6.84917876e-03 5.05580748e-03 4.43136857e-03 2.80002426e-03\n",
            " 6.28429477e-03 1.04083605e-02 1.03418122e-03 6.56320096e-04\n",
            " 5.77452872e-03 1.34806644e-02 9.39027135e-04 1.95255635e-04\n",
            " 1.11436587e-02 9.18957765e-03 1.08427917e-02 1.23823553e-03\n",
            " 1.57671326e-02 1.43468213e-03 1.99627593e-03 2.85710402e-03\n",
            " 7.21322914e-05 1.46537320e-02 3.67535708e-03 5.40308519e-03\n",
            " 5.12828549e-03 2.03362151e-06 1.18219096e-02 6.41698138e-04\n",
            " 4.92167359e-07 1.06892599e-02 2.00621902e-05 3.67832057e-05\n",
            " 1.32465894e-02 1.04013493e-02 1.07864873e-02 1.46609265e-03\n",
            " 8.45515499e-04 1.11693861e-02 1.55844121e-02 4.32149962e-03\n",
            " 1.53449139e-02 3.85345348e-03 1.42873978e-02 4.87070125e-03\n",
            " 1.05872113e-02 4.87070125e-03 7.28142792e-03 1.01535104e-03\n",
            " 7.09404063e-03 1.83746053e-03 3.86649028e-03 2.89534205e-04\n",
            " 1.50848751e-02 3.72229238e-04 1.04424352e-02 1.42231587e-02\n",
            " 3.00113951e-03 1.36530069e-02 4.80677940e-03 4.14982547e-03\n",
            " 2.32935123e-04 5.13924307e-03 6.04514018e-03 6.48904503e-03\n",
            " 1.30568442e-02 1.54411022e-02 5.43785166e-03 4.59453626e-03\n",
            " 4.83519402e-03 6.98677415e-03 1.15926319e-02 2.96476477e-03\n",
            " 1.29070472e-02 1.47745387e-02 1.06971370e-02 1.42932602e-02\n",
            " 5.39716699e-03 5.65565829e-03 1.25148694e-02 4.62964663e-03\n",
            " 3.85345348e-03 1.32947907e-02 1.38698287e-02 7.59634114e-03\n",
            " 1.05136750e-02 1.34305849e-03 1.20087215e-03 3.66758405e-03\n",
            " 1.56623765e-02 5.30025219e-03 3.91205557e-03 6.66344591e-04\n",
            " 9.10025885e-03 1.08271085e-02 8.12487564e-03 5.46167252e-03\n",
            " 2.22466038e-03 7.14566655e-04 9.25347449e-03 6.94816994e-03\n",
            " 7.19387724e-03 8.61652583e-03 1.10650186e-02 9.65036163e-03\n",
            " 2.82376136e-03 1.46999223e-03 1.26286099e-03 1.41563814e-02\n",
            " 6.06565189e-03 9.58916374e-03 1.06961306e-02 7.15004968e-03\n",
            " 8.54758021e-03 1.34260087e-02 4.11273464e-03 1.36817972e-02\n",
            " 7.80453561e-03 3.67449178e-03 8.88613749e-03 1.31329427e-02\n",
            " 1.28779845e-02 3.05186152e-03 1.45751984e-02 1.29136396e-02\n",
            " 3.30237092e-03 8.70418536e-03 4.59568259e-04 9.08984367e-04\n",
            " 8.85656045e-03 1.40521685e-02 8.18449347e-03 2.64211281e-03\n",
            " 9.73333371e-03 6.05105662e-03 8.08219403e-03 3.80555390e-04\n",
            " 5.51636407e-03 1.42214291e-02 7.40933487e-03 3.60874038e-03\n",
            " 1.04787012e-02 6.77096507e-03 3.52570767e-03 7.66146747e-03\n",
            " 1.52152524e-02 8.92521662e-03 9.42093095e-03 7.19377987e-03\n",
            " 4.73568697e-03 5.54699429e-03 6.56499643e-03 8.05401954e-04\n",
            " 3.84946974e-03]\n",
            "3480 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.80701749e-03 4.29876553e-03 4.64894036e-03 3.89430504e-03\n",
            " 1.51692630e-02 6.92563928e-04 1.24235186e-02 9.15289717e-03\n",
            " 3.95420168e-03 6.53249876e-03 1.22420825e-02 8.31205419e-03\n",
            " 1.57396758e-02 1.14459623e-02 8.12647250e-03 1.01927299e-02\n",
            " 1.05301145e-02 1.18746319e-02 6.39109960e-03 1.43097263e-02\n",
            " 5.52840186e-03 7.44883735e-03 5.53338643e-03 8.09958721e-03\n",
            " 1.41578551e-03 9.38228289e-03 4.86279120e-03 5.37047941e-03\n",
            " 3.85912691e-03 1.34761201e-05 5.77445830e-03 1.28423642e-02\n",
            " 1.38237935e-02 1.51834930e-02 2.89650104e-03 1.06126528e-02\n",
            " 1.34236296e-02 9.70552132e-05 9.39959613e-03 1.28423642e-02\n",
            " 1.22902653e-02 1.90416432e-03 4.74468380e-09 2.91443738e-03\n",
            " 1.78651793e-05 6.34302843e-03 1.23594019e-02 8.70888975e-03\n",
            " 4.24794091e-04 1.64991211e-07 1.12070459e-02 7.63134224e-03\n",
            " 7.13636667e-03 2.86147027e-03 7.56841578e-03 1.06049630e-02\n",
            " 9.72618116e-03 5.39853048e-03 8.86039231e-03 2.14878344e-03\n",
            " 1.16212292e-02 1.37948445e-02 9.42033512e-03 1.33706101e-02\n",
            " 1.12282607e-02 1.10357914e-02 1.01656767e-03 7.51978367e-03\n",
            " 2.83204642e-03 3.64136783e-04 1.08239437e-03 1.44819782e-02\n",
            " 8.05278387e-03 3.27556962e-03 9.92149480e-03 1.40513522e-02\n",
            " 9.72618116e-03 1.25792806e-02 4.22434030e-04 1.37360509e-02\n",
            " 7.35707393e-03 5.07468467e-03 4.97757982e-03 1.15553746e-02\n",
            " 4.75956344e-04 1.10919800e-02 1.00686360e-02 4.20262870e-03\n",
            " 4.20950178e-03 1.14894768e-03 5.65306992e-03 1.09988325e-02\n",
            " 5.93710642e-04 1.02947389e-03 1.01951506e-02 5.36245429e-03\n",
            " 6.45517000e-05 3.71426648e-03 1.28236447e-02 9.63995175e-03\n",
            " 1.07646408e-02 1.09624009e-02 1.82224572e-03 7.60584739e-03\n",
            " 8.49712384e-03 6.56910051e-04 1.47839513e-02 2.05952612e-03\n",
            " 1.49096289e-02 1.07614592e-02 9.96845718e-03 1.44044325e-02\n",
            " 7.78910611e-03 9.13783804e-03 5.07626799e-03 1.22902653e-02\n",
            " 3.59001068e-03 6.84042255e-05 9.15822350e-03 1.32470407e-02\n",
            " 4.00676051e-03 1.46863662e-02 3.59001068e-03 1.20107561e-02\n",
            " 1.18085430e-02 8.86670282e-03 1.44037402e-02 6.73628559e-03\n",
            " 9.90357818e-04 1.24831108e-02 1.50384868e-02 9.59752537e-03\n",
            " 7.38951144e-03 1.14563400e-02 1.48093010e-03 1.56527492e-02\n",
            " 1.27129638e-02 4.37525229e-05 8.86050250e-03 1.48261261e-02\n",
            " 4.69149357e-03 3.09866102e-03 1.02176007e-02 7.03727491e-03\n",
            " 9.05049160e-03 4.60227506e-03 9.03755152e-03 1.04908173e-02\n",
            " 9.59677688e-03 9.83536053e-03 4.74468380e-09 3.91838455e-03\n",
            " 9.02352306e-03 1.47907756e-02 8.59564388e-03 1.07080579e-03\n",
            " 1.29235712e-02 1.29482100e-02 4.16099125e-03 1.45534913e-02\n",
            " 7.96350726e-03 1.76522345e-03 7.72246597e-03 1.44535466e-02\n",
            " 2.09257959e-03 7.46456930e-03 4.11035938e-03 1.16256537e-02\n",
            " 8.71157989e-03 5.62117531e-03 5.41545148e-03 6.61385265e-03\n",
            " 2.99434408e-03 8.31205419e-03 1.28900341e-02 1.29923214e-02\n",
            " 9.32555490e-03 5.07286505e-03 1.05369835e-02 4.20262870e-03\n",
            " 1.06126528e-02 9.65067356e-03 7.60149563e-03 1.22489513e-02\n",
            " 9.14905257e-03 5.73106092e-03 1.08233908e-02 7.67611687e-03\n",
            " 1.19939581e-02 2.44519504e-03 1.36170054e-02 1.58586028e-04\n",
            " 4.04533983e-03 1.04357644e-02 1.10259144e-02 4.07226061e-03\n",
            " 1.01029458e-02 3.33040598e-03 1.38138112e-02 6.04712159e-03\n",
            " 7.47536319e-03 1.01782102e-02 5.29886928e-04 3.10563973e-03\n",
            " 1.10765405e-02 1.52176841e-02 6.09544871e-03 1.31355014e-02\n",
            " 1.28982581e-06 1.15081737e-02 9.05877282e-05 8.01480503e-04\n",
            " 2.87751374e-03 1.27044950e-02 6.56842135e-03 2.97976315e-03\n",
            " 9.33896145e-03 5.18129155e-03 4.16324173e-04 1.46027982e-02\n",
            " 5.22552447e-03 5.42606132e-03 1.25803262e-02 1.15196548e-03\n",
            " 1.35138327e-02 1.05600586e-02 8.54735255e-04 4.55639640e-03\n",
            " 1.24235186e-02 6.70486787e-03 8.37318444e-03 5.41954887e-03\n",
            " 1.44293401e-02 5.92540885e-03 1.43563166e-02 4.45220250e-03\n",
            " 5.59630870e-03 5.33963107e-03 3.23352575e-03 7.62718047e-03\n",
            " 4.20262870e-03 9.92282688e-03 7.78865073e-03 3.68891763e-03\n",
            " 1.22214109e-03 1.49238992e-03 9.07690244e-03 4.06140337e-03\n",
            " 1.00547536e-02 1.18444385e-02 1.53174532e-03 5.15192652e-03\n",
            " 9.16799184e-03 9.67047372e-05 7.98838993e-03 2.94670543e-16\n",
            " 3.06118270e-03 1.56589459e-02 1.46698750e-02 6.12468172e-03\n",
            " 1.27523496e-02 1.04282303e-02 1.40420256e-02 1.14568408e-02\n",
            " 2.32391095e-04 8.10840241e-03 1.02410624e-02 1.55710769e-02\n",
            " 1.01029458e-02 7.51978367e-03 2.84658834e-03 4.01739626e-03\n",
            " 3.16657713e-03 1.14563400e-02 2.10450501e-03 3.59448050e-03\n",
            " 1.24005049e-02 6.61035567e-03 7.32735857e-03 1.62829458e-03\n",
            " 2.47242275e-04 7.07879875e-03 1.30808358e-02 4.68729872e-03\n",
            " 6.62337436e-03 1.21089681e-02 4.00404800e-03 3.96604587e-04\n",
            " 1.39898087e-02 8.51024764e-03 2.01377589e-03 4.44478199e-03\n",
            " 3.42257106e-03 7.02357017e-03 7.75202316e-03 1.74394349e-04\n",
            " 4.46853478e-03 1.50664381e-02 3.55395574e-03 8.38978142e-03\n",
            " 1.42532846e-02 4.83103160e-03 3.19866389e-03 8.99225985e-03\n",
            " 8.89604901e-03 6.93862510e-03 1.34511789e-02 4.69341289e-03\n",
            " 9.38770644e-03 5.53338643e-03 9.78731988e-03 1.42687577e-02\n",
            " 4.86906491e-03 9.92807617e-03 1.89485246e-04 9.19189557e-03\n",
            " 1.18084341e-02 1.65400837e-03 8.25308299e-03 9.86998058e-03\n",
            " 7.98003551e-03 6.78559245e-03 3.71426648e-03 1.34083956e-03\n",
            " 1.23206813e-02 2.87246276e-03 1.98323234e-03 1.53986076e-02\n",
            " 1.45874149e-02 1.38179793e-02 1.29203763e-03 4.76434810e-03\n",
            " 1.57009821e-02 1.68727092e-03 5.73106092e-03 3.93121843e-03\n",
            " 1.34066230e-02 1.46022591e-03 1.14958907e-02 7.56852700e-03\n",
            " 3.07033960e-03 3.08537011e-03 6.27429253e-03 2.19021080e-03\n",
            " 1.40061770e-02 4.47127703e-06 1.21888656e-02 7.97873200e-04\n",
            " 1.48289207e-02 3.82355639e-03 1.23020102e-03 1.07669253e-02\n",
            " 1.00529069e-02 1.01539157e-05 1.05574038e-02 1.09740796e-02\n",
            " 1.46667857e-02 2.30479728e-03 1.78310007e-04 8.86229090e-03\n",
            " 1.34511789e-02 3.74226034e-03 3.01922713e-03 8.92076196e-03\n",
            " 1.70665134e-03 7.56434095e-04 2.09633342e-03 1.43480165e-02\n",
            " 6.22951952e-04 2.09503582e-03 1.07366902e-03 1.55539370e-02\n",
            " 3.58916043e-03 1.50219334e-02 1.38503848e-02 1.08851698e-02\n",
            " 7.72797233e-03 5.44971658e-05 1.33499433e-02 5.61476343e-04\n",
            " 1.10075146e-02 8.50924869e-04 1.20379054e-02 1.04087453e-02\n",
            " 1.25029565e-02 9.86073851e-03 1.26479509e-02 1.36818495e-02\n",
            " 1.39547963e-02 9.72618116e-03 9.49779409e-03 5.27528500e-03\n",
            " 8.22061152e-03 8.25868064e-03 8.02267437e-03 9.63775536e-03\n",
            " 1.70665134e-03 1.53862226e-02 1.10410563e-02 1.06333348e-02\n",
            " 2.09080771e-03 1.18158961e-02 3.21923850e-03 9.47830756e-03\n",
            " 4.83962667e-03 1.04785151e-02 1.86180984e-03 1.28515001e-02\n",
            " 3.95786411e-03 1.16798553e-02 1.55464558e-02 7.62632581e-03\n",
            " 1.22118726e-02 1.22971810e-02 4.39000821e-03 9.14994828e-03\n",
            " 5.58245697e-04 2.78051168e-03 9.37873875e-03 3.68390065e-03\n",
            " 7.43478303e-03 7.96000840e-03 1.89485246e-04 4.62374418e-03\n",
            " 1.08238475e-02 2.82401094e-03 1.46100001e-02 3.76347312e-03\n",
            " 1.02536098e-02 8.05728303e-03 4.39430555e-03 5.52280599e-04\n",
            " 1.41282070e-03 1.28839338e-02 1.15415951e-03 1.57330241e-02\n",
            " 7.07801956e-03 4.96698735e-03 6.92563928e-04 4.29495515e-03\n",
            " 1.41002029e-02 1.14288527e-02 3.01325481e-04 7.55783504e-03\n",
            " 1.70665134e-03 7.50634699e-03 1.39265938e-02 1.10909078e-02\n",
            " 1.28125132e-02 5.58837733e-03 7.31227156e-03 8.38586616e-03\n",
            " 1.08046803e-02 1.46497243e-02 1.03531348e-02 2.19695690e-03\n",
            " 1.27405887e-02 3.50631634e-03 1.11794770e-03 7.49217932e-03\n",
            " 8.14586743e-03 8.71239652e-03 2.46536017e-04 1.10606769e-02\n",
            " 3.71426648e-03 5.98340973e-03 3.82355639e-03 9.23005201e-03\n",
            " 4.02595572e-04 2.54551090e-03 1.47454723e-02 1.58204000e-02\n",
            " 4.96377933e-04 8.16876663e-03 9.09680786e-03 2.01960277e-03\n",
            " 4.64580282e-03 1.50682796e-03 9.83407251e-03 1.53816494e-02\n",
            " 1.15632753e-02 9.89983476e-03 1.41255583e-02 6.98824082e-03\n",
            " 9.70416864e-03 1.02950270e-02 1.34322776e-04 6.92684920e-03\n",
            " 2.19749556e-03 3.16665351e-03 1.40415423e-02 3.08508137e-03\n",
            " 4.69149357e-03 8.44144759e-03 1.19034783e-02 4.00676051e-03\n",
            " 6.32925946e-03 2.48619502e-03 1.04512278e-02 9.62535626e-03\n",
            " 1.90590978e-03 5.49737371e-04 2.64355794e-03 1.35796324e-02\n",
            " 1.40563379e-02 4.16939654e-03 9.95582940e-03 1.38138112e-02\n",
            " 1.38569043e-02 7.69524509e-03 3.79316542e-03 1.56596854e-02\n",
            " 5.84571818e-04 3.27422564e-03 6.29319011e-03 5.14441447e-03\n",
            " 7.86220172e-03 4.65572883e-03 3.11266500e-04 2.59725877e-03\n",
            " 2.81156985e-03 7.82117241e-03 1.27759397e-02 1.39730810e-02\n",
            " 7.96895232e-03 2.09080771e-03 1.41263077e-02 1.34537860e-03\n",
            " 1.09549425e-02 1.55196888e-02 2.40834133e-03 5.74877102e-03\n",
            " 1.04910070e-02 1.36811478e-02 1.14010956e-02 3.99558239e-03\n",
            " 1.37052576e-02 1.12302119e-02 5.12093608e-03 8.20087742e-04\n",
            " 1.03955832e-02 6.59123136e-03 4.10674158e-03 1.49542137e-02\n",
            " 4.84684544e-03 3.66162889e-03 6.83041247e-03 5.04971671e-03\n",
            " 4.42565778e-03 2.79837651e-03 6.26868414e-03 1.03817385e-02\n",
            " 1.02555733e-03 6.55149898e-04 5.77445830e-03 1.34896939e-02\n",
            " 9.34938429e-04 1.94953741e-04 1.11634050e-02 9.14526383e-03\n",
            " 1.08462284e-02 1.23426356e-03 1.57381389e-02 1.43618578e-03\n",
            " 1.99254804e-03 2.86147027e-03 7.16548278e-05 1.46285872e-02\n",
            " 3.67863332e-03 5.39387041e-03 5.12231423e-03 2.03482310e-06\n",
            " 1.16256694e-02 6.38150123e-04 4.91623678e-07 1.06791523e-02\n",
            " 2.00167305e-05 3.64888943e-05 1.32054219e-02 1.04006210e-02\n",
            " 1.07812452e-02 1.46251347e-03 8.45657584e-04 1.11515666e-02\n",
            " 1.55210706e-02 4.29477894e-03 1.53266854e-02 3.85912691e-03\n",
            " 1.42739465e-02 4.87660306e-03 1.05906974e-02 4.87660306e-03\n",
            " 7.26392514e-03 1.01545995e-03 7.09161057e-03 1.83497111e-03\n",
            " 3.85874038e-03 2.88217960e-04 1.50743689e-02 3.71157833e-04\n",
            " 1.04135493e-02 1.42150245e-02 2.99391643e-03 1.36549489e-02\n",
            " 4.79291576e-03 4.15007572e-03 2.30505796e-04 5.13618860e-03\n",
            " 6.04653972e-03 6.48965531e-03 1.30428517e-02 1.54503422e-02\n",
            " 5.43329455e-03 4.58832965e-03 4.83103160e-03 6.98401904e-03\n",
            " 1.15842525e-02 2.95408171e-03 1.28889465e-02 1.47630211e-02\n",
            " 1.06904852e-02 1.42804180e-02 5.39355866e-03 5.64300779e-03\n",
            " 1.25007340e-02 4.63313260e-03 3.85912691e-03 1.32886955e-02\n",
            " 1.38635484e-02 7.59640575e-03 1.05127101e-02 1.33759486e-03\n",
            " 1.19926880e-03 3.66919596e-03 1.56527797e-02 5.29706007e-03\n",
            " 3.91440875e-03 6.64984048e-04 9.08726756e-03 1.08250719e-02\n",
            " 8.11298995e-03 5.45778634e-03 2.21210074e-03 7.14407650e-04\n",
            " 9.25315379e-03 6.94336376e-03 7.10479905e-03 8.60610432e-03\n",
            " 1.10178780e-02 9.63626474e-03 2.81837844e-03 1.46365043e-03\n",
            " 1.25890973e-03 1.41479878e-02 6.04669381e-03 9.56665688e-03\n",
            " 1.07067302e-02 7.13921464e-03 8.50419376e-03 1.34193406e-02\n",
            " 4.10203959e-03 1.36644225e-02 7.75353133e-03 3.66538715e-03\n",
            " 8.86214500e-03 1.31061815e-02 1.28644445e-02 3.04253762e-03\n",
            " 1.45424752e-02 1.28914814e-02 3.30066543e-03 8.69794371e-03\n",
            " 4.59442504e-04 9.09168030e-04 8.85324592e-03 1.40415423e-02\n",
            " 8.17963686e-03 2.63834714e-03 9.72618116e-03 6.05797414e-03\n",
            " 8.07961412e-03 3.80128003e-04 5.49631138e-03 1.42332704e-02\n",
            " 7.40152218e-03 3.60028338e-03 1.04679971e-02 6.76718181e-03\n",
            " 3.52092986e-03 7.65078066e-03 1.51834930e-02 8.89894208e-03\n",
            " 9.38574924e-03 7.17293065e-03 4.70897446e-03 5.55442729e-03\n",
            " 6.56460905e-03 7.97873200e-04 3.84411760e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3490 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.79676560e-03 4.29327400e-03 4.64710026e-03 3.86178417e-03\n",
            " 1.51410425e-02 6.90887569e-04 1.23883303e-02 9.14209972e-03\n",
            " 3.94431989e-03 6.52982414e-03 1.22212152e-02 8.27057861e-03\n",
            " 1.13877854e-02 8.11765697e-03 1.01721684e-02 1.05306328e-02\n",
            " 1.18663779e-02 6.36810724e-03 1.42737583e-02 5.50219929e-03\n",
            " 7.44047395e-03 5.51511458e-03 8.10081800e-03 1.41457588e-03\n",
            " 9.32991850e-03 4.85591407e-03 5.36206331e-03 3.85441129e-03\n",
            " 1.33616166e-05 5.76219796e-03 1.28395791e-02 1.37528516e-02\n",
            " 1.51835435e-02 2.88916810e-03 1.05913421e-02 1.34076557e-02\n",
            " 9.67540654e-05 9.37480603e-03 1.28395791e-02 1.23092888e-02\n",
            " 1.89256912e-03 4.67419754e-09 2.90857061e-03 1.73022758e-05\n",
            " 6.31431599e-03 1.23489773e-02 8.69352124e-03 4.20590996e-04\n",
            " 1.65070302e-07 1.11944805e-02 7.59214707e-03 7.12377985e-03\n",
            " 2.85723679e-03 7.56167577e-03 1.05697084e-02 9.72315651e-03\n",
            " 5.39478933e-03 8.83871647e-03 2.14458795e-03 1.16203515e-02\n",
            " 1.37375620e-02 9.39874327e-03 1.33664354e-02 1.12204695e-02\n",
            " 1.10198563e-02 1.00342465e-03 7.51643409e-03 2.81154875e-03\n",
            " 3.61527916e-04 1.08065844e-03 1.44716430e-02 8.03373516e-03\n",
            " 3.26708069e-03 9.86128458e-03 1.39983630e-02 9.72315651e-03\n",
            " 1.25600351e-02 4.21732380e-04 1.36572646e-02 7.33985008e-03\n",
            " 5.04604814e-03 4.95693706e-03 1.15227267e-02 4.74230419e-04\n",
            " 1.10758481e-02 1.00519911e-02 4.20033138e-03 4.17758572e-03\n",
            " 1.14210879e-03 5.64683617e-03 1.09874470e-02 5.93355245e-04\n",
            " 1.02876921e-03 1.01767825e-02 5.35908843e-03 6.40739821e-05\n",
            " 3.69669507e-03 1.28182958e-02 9.63076807e-03 1.07320171e-02\n",
            " 1.09472711e-02 1.82315103e-03 7.60812116e-03 8.49135434e-03\n",
            " 6.51617775e-04 1.47118258e-02 2.06025951e-03 1.49033130e-02\n",
            " 1.07484451e-02 9.93142456e-03 1.44162767e-02 7.78098802e-03\n",
            " 9.08172500e-03 5.06337869e-03 1.23092888e-02 3.58653958e-03\n",
            " 6.80059317e-05 9.14823986e-03 1.31196900e-02 3.96792989e-03\n",
            " 1.46940081e-02 3.58653958e-03 1.19777281e-02 1.17851469e-02\n",
            " 8.85290950e-03 1.43795763e-02 6.71751549e-03 9.88868693e-04\n",
            " 1.24802937e-02 1.50340661e-02 9.59110359e-03 7.37071650e-03\n",
            " 1.14837875e-02 1.47537007e-03 1.27093077e-02 4.28592390e-05\n",
            " 8.79569859e-03 1.48126700e-02 4.68912396e-03 3.08141271e-03\n",
            " 1.01948350e-02 7.02219172e-03 9.06122655e-03 4.54260686e-03\n",
            " 9.01829951e-03 1.04760293e-02 9.57027541e-03 9.82121000e-03\n",
            " 4.67419754e-09 3.91696629e-03 9.00005888e-03 1.47455056e-02\n",
            " 8.60438163e-03 1.06445767e-03 1.29307183e-02 1.29605257e-02\n",
            " 4.14961716e-03 1.45702355e-02 7.95212733e-03 1.75776623e-03\n",
            " 7.70247377e-03 1.44529399e-02 2.09064233e-03 7.45202007e-03\n",
            " 4.10312425e-03 1.15975338e-02 8.70495332e-03 5.61228825e-03\n",
            " 5.39132373e-03 6.61761446e-03 2.99291516e-03 8.27057861e-03\n",
            " 1.28833827e-02 1.29631072e-02 9.27540344e-03 5.06524975e-03\n",
            " 1.04928579e-02 4.20033138e-03 1.05913421e-02 9.60583702e-03\n",
            " 7.56769382e-03 1.21763975e-02 9.13920273e-03 5.72871501e-03\n",
            " 1.08091123e-02 7.64569478e-03 1.19745619e-02 2.44685077e-03\n",
            " 1.36147649e-02 1.56957916e-04 4.03004213e-03 1.03839711e-02\n",
            " 1.10368174e-02 4.06969537e-03 1.00855914e-02 3.32831173e-03\n",
            " 1.37802638e-02 6.04821717e-03 7.46817881e-03 1.01511701e-02\n",
            " 5.29645505e-04 3.08850434e-03 1.10154471e-02 1.51961128e-02\n",
            " 6.09295378e-03 1.31244827e-02 1.28785385e-06 1.14744558e-02\n",
            " 8.94078132e-05 7.97518815e-04 2.87456457e-03 1.26805051e-02\n",
            " 6.52749696e-03 2.97402485e-03 9.32321632e-03 5.15418730e-03\n",
            " 4.14885502e-04 1.46036966e-02 5.22388783e-03 5.40904564e-03\n",
            " 1.25573605e-02 1.14937997e-03 1.34962093e-02 1.05307047e-02\n",
            " 8.51791180e-04 4.53141858e-03 1.23883303e-02 6.70276107e-03\n",
            " 8.34797965e-03 5.42340606e-03 1.44446780e-02 5.90790804e-03\n",
            " 1.43485923e-02 4.41326518e-03 5.56297511e-03 5.32486759e-03\n",
            " 3.22765825e-03 7.61043716e-03 4.20033138e-03 9.90912396e-03\n",
            " 7.76171226e-03 3.68721228e-03 1.21825157e-03 1.48995986e-03\n",
            " 9.00882523e-03 4.05257267e-03 1.00418142e-02 1.18370411e-02\n",
            " 1.52873156e-03 5.12554753e-03 9.15753419e-03 9.65261100e-05\n",
            " 7.97654815e-03 2.67485189e-16 3.05303772e-03 1.46016842e-02\n",
            " 6.11177838e-03 1.27371457e-02 1.03953890e-02 1.40381747e-02\n",
            " 1.14324617e-02 2.29626966e-04 8.10984891e-03 1.01781894e-02\n",
            " 1.00855914e-02 7.51643409e-03 2.84095601e-03 4.00403598e-03\n",
            " 3.16332611e-03 1.14837875e-02 2.10371496e-03 3.57381710e-03\n",
            " 1.23758521e-02 6.58837960e-03 7.30319302e-03 1.62472659e-03\n",
            " 2.45979546e-04 7.06550898e-03 1.30758060e-02 4.69153928e-03\n",
            " 6.61528640e-03 1.20314494e-02 3.94433239e-03 3.95763164e-04\n",
            " 1.39567781e-02 8.46380678e-03 2.01047670e-03 4.43445889e-03\n",
            " 3.40681748e-03 7.01253797e-03 7.73744637e-03 1.73559665e-04\n",
            " 4.46741220e-03 1.50431287e-02 3.54225935e-03 8.38893250e-03\n",
            " 1.42638166e-02 4.81437450e-03 3.18159548e-03 8.97030201e-03\n",
            " 8.86149916e-03 6.93472766e-03 1.33805868e-02 4.65528690e-03\n",
            " 9.37627293e-03 5.51511458e-03 9.74862845e-03 1.42519842e-02\n",
            " 4.84467288e-03 9.91915801e-03 1.88333897e-04 9.19277861e-03\n",
            " 1.17880850e-02 1.65095805e-03 8.24227781e-03 9.84710847e-03\n",
            " 7.99617546e-03 6.75556623e-03 3.69669507e-03 1.33047557e-03\n",
            " 1.23157276e-02 2.85905697e-03 1.98259220e-03 1.53996083e-02\n",
            " 1.45617005e-02 1.37454549e-02 1.29176303e-03 4.75315245e-03\n",
            " 1.66754274e-03 5.72871501e-03 3.92504097e-03 1.34125754e-02\n",
            " 1.44938919e-03 1.14595443e-02 7.53686391e-03 3.06320325e-03\n",
            " 3.08021260e-03 6.25602604e-03 2.18830118e-03 1.39040964e-02\n",
            " 4.38322591e-06 1.21684376e-02 7.96586554e-04 1.47587999e-02\n",
            " 3.81251828e-03 1.23077004e-03 1.07526642e-02 1.00351260e-02\n",
            " 1.00721927e-05 1.05055454e-02 1.09494984e-02 1.46516675e-02\n",
            " 2.30110445e-03 1.77747661e-04 8.85419911e-03 1.33805868e-02\n",
            " 3.73660719e-03 3.01755023e-03 8.86399934e-03 1.68402614e-03\n",
            " 7.54291495e-04 2.08869535e-03 1.43297574e-02 6.19526321e-04\n",
            " 2.08543304e-03 1.07055995e-03 1.55269314e-02 3.57808758e-03\n",
            " 1.49211838e-02 1.38189634e-02 1.08485167e-02 7.69740550e-03\n",
            " 5.42391503e-05 1.33051282e-02 5.60164266e-04 1.09556532e-02\n",
            " 8.38381345e-04 1.20085951e-02 1.03685659e-02 1.24800902e-02\n",
            " 9.87576197e-03 1.26273249e-02 1.36689663e-02 1.39354617e-02\n",
            " 9.72315651e-03 9.48187791e-03 5.27470711e-03 8.17830657e-03\n",
            " 8.20779266e-03 8.00650129e-03 9.63700928e-03 1.68402614e-03\n",
            " 1.53770522e-02 1.10295024e-02 1.06000230e-02 2.08559807e-03\n",
            " 1.18055462e-02 3.21426397e-03 9.45570046e-03 4.83418786e-03\n",
            " 1.04574628e-02 1.85643747e-03 1.28371702e-02 3.95176068e-03\n",
            " 1.16216315e-02 1.55325520e-02 7.60590944e-03 1.21582361e-02\n",
            " 1.22873142e-02 4.34036026e-03 9.12858761e-03 5.56982099e-04\n",
            " 2.76557021e-03 9.35952387e-03 3.67363818e-03 7.41795515e-03\n",
            " 7.94562176e-03 1.88333897e-04 4.61750613e-03 1.07949403e-02\n",
            " 2.82195272e-03 1.45982917e-02 3.75080508e-03 1.02255339e-02\n",
            " 8.04525967e-03 4.37276099e-03 5.46903018e-04 1.40889986e-03\n",
            " 1.28639206e-02 1.15118562e-03 7.07497762e-03 4.95292939e-03\n",
            " 6.90887569e-04 4.26619882e-03 1.40804985e-02 1.14373339e-02\n",
            " 3.00725883e-04 7.55156083e-03 1.68402614e-03 7.46767226e-03\n",
            " 1.39218474e-02 1.10742455e-02 1.27817396e-02 5.57585008e-03\n",
            " 7.31980308e-03 8.39002436e-03 1.07467420e-02 1.46445179e-02\n",
            " 1.03384300e-02 2.19310749e-03 1.27286380e-02 3.50837986e-03\n",
            " 1.11195163e-03 7.46143659e-03 8.15016626e-03 8.70144653e-03\n",
            " 2.45736621e-04 1.10629419e-02 3.69669507e-03 5.97678341e-03\n",
            " 3.81251828e-03 9.21437229e-03 4.02151568e-04 2.53114730e-03\n",
            " 1.47448738e-02 4.94598145e-04 8.15205881e-03 9.08131123e-03\n",
            " 2.01847977e-03 4.63959323e-03 1.50682091e-03 9.83447476e-03\n",
            " 1.53586399e-02 1.15542469e-02 9.87378544e-03 1.41122026e-02\n",
            " 6.98573554e-03 9.70867539e-03 1.02359521e-02 1.34181206e-04\n",
            " 6.91143543e-03 2.18229289e-03 3.16212904e-03 1.40385207e-02\n",
            " 3.08147416e-03 4.68912396e-03 8.43161097e-03 1.18744178e-02\n",
            " 3.96792989e-03 6.33338720e-03 2.45427141e-03 1.04391046e-02\n",
            " 9.60377046e-03 1.90344886e-03 5.41244479e-04 2.63499631e-03\n",
            " 1.35863695e-02 1.40198183e-02 4.16647625e-03 9.95900078e-03\n",
            " 1.37802638e-02 1.38424505e-02 7.68450805e-03 3.77415828e-03\n",
            " 5.80785360e-04 3.26736428e-03 6.27897004e-03 5.10596814e-03\n",
            " 7.83505022e-03 4.64675620e-03 3.10610077e-04 2.58945656e-03\n",
            " 2.81060007e-03 7.81737950e-03 1.27509532e-02 1.38969102e-02\n",
            " 7.94040858e-03 2.08559807e-03 1.41189972e-02 1.34464002e-03\n",
            " 1.09429590e-02 1.55122092e-02 2.40367696e-03 5.74028650e-03\n",
            " 1.04378190e-02 1.36558336e-02 1.13672954e-02 3.98941553e-03\n",
            " 1.37039644e-02 1.11980396e-02 5.10752206e-03 8.20813282e-04\n",
            " 1.03967042e-02 6.58537509e-03 4.09860821e-03 1.49526648e-02\n",
            " 4.83304468e-03 3.65773492e-03 6.80808600e-03 5.04197085e-03\n",
            " 4.40978035e-03 2.79526131e-03 6.24715862e-03 1.03378823e-02\n",
            " 1.01947144e-03 6.53577209e-04 5.76219796e-03 1.34840851e-02\n",
            " 9.19806665e-04 1.94315599e-04 1.11277627e-02 9.13507555e-03\n",
            " 1.08268243e-02 1.22913700e-03 1.43021527e-03 1.99283351e-03\n",
            " 2.85723679e-03 7.05209330e-05 1.46005149e-02 3.67419271e-03\n",
            " 5.37921707e-03 5.08558506e-03 2.02584559e-06 1.16238118e-02\n",
            " 6.35766523e-04 4.86300923e-07 1.06373850e-02 1.98715499e-05\n",
            " 3.64532748e-05 1.31971768e-02 1.03843531e-02 1.07532876e-02\n",
            " 1.45105108e-03 8.42144512e-04 1.11143435e-02 1.54202792e-02\n",
            " 4.28278285e-03 1.53046497e-02 3.85441129e-03 1.42684318e-02\n",
            " 4.87179131e-03 1.05580388e-02 4.87179131e-03 7.26452200e-03\n",
            " 1.01196393e-03 7.09489899e-03 1.82731801e-03 3.85071012e-03\n",
            " 2.81471661e-04 1.50567511e-02 3.68314797e-04 1.03844550e-02\n",
            " 1.41892979e-02 2.97857284e-03 1.36348106e-02 4.77056745e-03\n",
            " 4.13853594e-03 2.29332357e-04 5.13623417e-03 6.05199839e-03\n",
            " 6.48268197e-03 1.30197841e-02 1.54285148e-02 5.41920372e-03\n",
            " 4.57783863e-03 4.81437450e-03 6.99706615e-03 1.15578873e-02\n",
            " 2.93232610e-03 1.28669332e-02 1.47633146e-02 1.06412618e-02\n",
            " 1.42462213e-02 5.38420957e-03 5.65593647e-03 1.25014215e-02\n",
            " 4.61234732e-03 3.85441129e-03 1.32902109e-02 1.38596188e-02\n",
            " 7.58152935e-03 1.05036879e-02 1.33076760e-03 1.19737955e-03\n",
            " 3.66272021e-03 5.28703978e-03 3.90104681e-03 6.53565699e-04\n",
            " 9.08031542e-03 1.08160711e-02 8.10295340e-03 5.44273605e-03\n",
            " 2.18438469e-03 7.04142178e-04 9.23125631e-03 6.91707198e-03\n",
            " 7.08044402e-03 8.55155735e-03 1.10175926e-02 9.61969668e-03\n",
            " 2.80309589e-03 1.46159445e-03 1.25047432e-03 1.41374079e-02\n",
            " 6.01294493e-03 9.55146061e-03 1.06871638e-02 7.09017186e-03\n",
            " 8.47561699e-03 1.34201008e-02 4.09637490e-03 1.36677391e-02\n",
            " 7.73764941e-03 3.66299284e-03 8.81464325e-03 1.31089004e-02\n",
            " 1.28537321e-02 3.02302204e-03 1.45199804e-02 1.28647950e-02\n",
            " 3.29900875e-03 8.66410037e-03 4.57900515e-04 9.05372262e-04\n",
            " 8.81335595e-03 1.40385207e-02 8.15463525e-03 2.62224267e-03\n",
            " 9.72315651e-03 6.04482193e-03 8.05029441e-03 3.76749455e-04\n",
            " 5.50185945e-03 1.42393543e-02 7.37222515e-03 3.60374535e-03\n",
            " 1.04352930e-02 6.74412693e-03 3.51527092e-03 7.63337143e-03\n",
            " 1.51835435e-02 8.86546591e-03 9.36251316e-03 7.17154760e-03\n",
            " 4.70076852e-03 5.55208143e-03 6.55421229e-03 7.96586554e-04\n",
            " 3.82625884e-03]\n",
            "3500 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.79329138e-03 4.28759421e-03 4.62559069e-03 3.84464532e-03\n",
            " 1.51179242e-02 6.90300771e-04 1.23717768e-02 9.09253960e-03\n",
            " 3.93917499e-03 6.53364524e-03 1.22339844e-02 8.26228951e-03\n",
            " 1.13627684e-02 8.07583208e-03 1.01851006e-02 1.05140810e-02\n",
            " 1.18437724e-02 6.35980357e-03 1.42352377e-02 5.49565179e-03\n",
            " 7.43741153e-03 5.51765813e-03 8.08198637e-03 1.41013082e-03\n",
            " 9.30538906e-03 4.84965853e-03 5.35809758e-03 3.85684890e-03\n",
            " 1.31723162e-05 5.75892622e-03 1.28329398e-02 1.37350099e-02\n",
            " 1.51566670e-02 2.85397663e-03 1.05831290e-02 1.31981608e-02\n",
            " 9.63400594e-05 9.34335614e-03 1.28329398e-02 1.22249548e-02\n",
            " 1.87876275e-03 4.55909478e-09 2.90904554e-03 1.71233430e-05\n",
            " 6.30045934e-03 1.23376098e-02 8.69704714e-03 4.14864556e-04\n",
            " 1.61438238e-07 1.12002853e-02 7.58011168e-03 7.09907207e-03\n",
            " 2.85930224e-03 7.54696478e-03 1.05627617e-02 9.71188360e-03\n",
            " 5.38936803e-03 8.83493770e-03 2.13914630e-03 1.15666290e-02\n",
            " 1.36991837e-02 9.40035377e-03 1.33525915e-02 1.12230658e-02\n",
            " 1.10053580e-02 9.93440703e-04 7.51977774e-03 2.79525764e-03\n",
            " 3.59759434e-04 1.07957118e-03 1.44675951e-02 8.02361499e-03\n",
            " 3.25788037e-03 9.83804162e-03 1.39541511e-02 9.71188360e-03\n",
            " 1.25437576e-02 4.21289956e-04 1.36296495e-02 7.32361375e-03\n",
            " 5.01729401e-03 4.93734626e-03 1.15271911e-02 4.72853683e-04\n",
            " 1.10596958e-02 1.00539735e-02 4.19107517e-03 4.16519496e-03\n",
            " 1.14155237e-03 5.62319231e-03 1.09604247e-02 5.89112410e-04\n",
            " 1.02915330e-03 1.01810253e-02 5.33350034e-03 6.31745812e-05\n",
            " 3.69648124e-03 1.27883593e-02 9.63426155e-03 1.07289434e-02\n",
            " 1.09339593e-02 1.81850811e-03 7.59237090e-03 8.47817765e-03\n",
            " 6.47649604e-04 1.46925713e-02 2.05500054e-03 1.48914991e-02\n",
            " 1.07097375e-02 9.90825121e-03 1.43909881e-02 7.76928663e-03\n",
            " 9.07562828e-03 5.05444499e-03 1.22249548e-02 3.57671995e-03\n",
            " 6.74526741e-05 9.12436042e-03 1.30983109e-02 3.93371925e-03\n",
            " 1.46571823e-02 3.57671995e-03 1.19495385e-02 1.17594847e-02\n",
            " 8.84371889e-03 1.43630799e-02 6.69894241e-03 9.87275294e-04\n",
            " 1.24574630e-02 1.50276933e-02 9.57866177e-03 7.34812607e-03\n",
            " 1.14836672e-02 1.47480316e-03 1.26955496e-02 4.24953976e-05\n",
            " 8.77017758e-03 1.48257972e-02 4.69579693e-03 3.06146019e-03\n",
            " 1.01406449e-02 7.03651667e-03 9.06406210e-03 4.51994043e-03\n",
            " 8.99005232e-03 1.04541576e-02 9.56209249e-03 9.80219309e-03\n",
            " 4.55909478e-09 3.90243616e-03 8.98076058e-03 1.47227680e-02\n",
            " 8.58066930e-03 1.05969443e-03 1.28493344e-02 1.29635546e-02\n",
            " 4.14922283e-03 1.45577022e-02 7.93777086e-03 1.75591214e-03\n",
            " 7.68566380e-03 1.44264067e-02 2.08051065e-03 7.44537716e-03\n",
            " 4.10390117e-03 1.15930918e-02 8.67364363e-03 5.61022697e-03\n",
            " 5.38357695e-03 6.60548949e-03 2.99037022e-03 8.26228951e-03\n",
            " 1.28431041e-02 1.29481109e-02 9.26654875e-03 5.05657167e-03\n",
            " 1.04643532e-02 4.19107517e-03 1.05831290e-02 9.47970587e-03\n",
            " 7.55150079e-03 1.21338995e-02 9.11950725e-03 5.74308554e-03\n",
            " 1.08060005e-02 7.62627376e-03 1.19666507e-02 2.44719763e-03\n",
            " 1.35737539e-02 1.56041830e-04 4.03071093e-03 1.03604582e-02\n",
            " 1.10322334e-02 4.05393370e-03 1.00572460e-02 3.33088085e-03\n",
            " 1.37889573e-02 6.05060927e-03 7.44011279e-03 1.01442417e-02\n",
            " 5.26149632e-04 3.08566902e-03 1.09967351e-02 6.08623919e-03\n",
            " 1.31230901e-02 1.26102485e-06 1.14446701e-02 8.89802681e-05\n",
            " 7.94245742e-04 2.87392810e-03 1.26211230e-02 6.52685595e-03\n",
            " 2.96426398e-03 9.30999305e-03 5.13687145e-03 4.13976842e-04\n",
            " 1.45231566e-02 5.21454726e-03 5.39226111e-03 1.25293228e-02\n",
            " 1.12444271e-03 1.34880020e-02 1.05161918e-02 8.47634363e-04\n",
            " 4.52173323e-03 1.23717768e-02 6.70932066e-03 8.33576696e-03\n",
            " 5.41862143e-03 1.44192745e-02 5.90077248e-03 1.43268038e-02\n",
            " 4.40168743e-03 5.53526969e-03 5.30885132e-03 3.22152829e-03\n",
            " 7.57504364e-03 4.19107517e-03 9.89039919e-03 7.76770934e-03\n",
            " 3.65741911e-03 1.21561444e-03 1.48504794e-03 8.99490746e-03\n",
            " 4.01969620e-03 1.00197159e-02 1.18279378e-02 1.52020633e-03\n",
            " 5.11604087e-03 9.15608875e-03 9.61098992e-05 7.95733761e-03\n",
            " 2.59434580e-16 3.05188758e-03 1.45794851e-02 6.10281340e-03\n",
            " 1.27264205e-02 1.04045896e-02 1.40365914e-02 1.14181386e-02\n",
            " 2.28052242e-04 8.10534671e-03 1.01599239e-02 1.00572460e-02\n",
            " 7.51977774e-03 2.83144369e-03 4.00226563e-03 3.15835889e-03\n",
            " 1.14836672e-02 2.10030558e-03 3.56670754e-03 1.23376913e-02\n",
            " 6.58965260e-03 7.29705850e-03 1.62664671e-03 2.43495162e-04\n",
            " 7.06081437e-03 1.30594385e-02 4.70037305e-03 6.61248690e-03\n",
            " 1.20245465e-02 3.93357052e-03 3.93813333e-04 1.39738546e-02\n",
            " 8.46004976e-03 2.01175434e-03 4.41771411e-03 3.40394176e-03\n",
            " 6.98942199e-03 7.73754984e-03 1.73046454e-04 4.46917290e-03\n",
            " 1.50430885e-02 3.52470608e-03 8.36759076e-03 1.42408504e-02\n",
            " 4.81448510e-03 3.17710245e-03 8.93141394e-03 8.84907482e-03\n",
            " 6.93030788e-03 1.33185071e-02 4.63398425e-03 9.36578447e-03\n",
            " 5.51765813e-03 9.75703075e-03 1.42448249e-02 4.83494371e-03\n",
            " 9.90032572e-03 1.87705269e-04 9.16964618e-03 1.17849873e-02\n",
            " 1.64924223e-03 8.23003824e-03 9.85190674e-03 7.98862708e-03\n",
            " 6.74785886e-03 3.69648124e-03 1.32593336e-03 1.22116819e-02\n",
            " 2.84446860e-03 1.98190589e-03 1.45598549e-02 1.37080394e-02\n",
            " 1.29045986e-03 4.74978442e-03 1.65713738e-03 5.74308554e-03\n",
            " 3.91054111e-03 1.34133861e-02 1.43844155e-03 1.13983602e-02\n",
            " 7.52075789e-03 3.05815137e-03 3.07018939e-03 6.23987385e-03\n",
            " 2.18325171e-03 1.38650412e-02 4.34100842e-06 1.21738977e-02\n",
            " 7.87422374e-04 1.47622907e-02 3.81601202e-03 1.22978135e-03\n",
            " 1.07493765e-02 1.00043091e-02 1.00190419e-05 1.04992637e-02\n",
            " 1.08833797e-02 1.46094075e-02 2.29614718e-03 1.77530031e-04\n",
            " 8.84606655e-03 1.33185071e-02 3.72692931e-03 3.00789050e-03\n",
            " 8.85823233e-03 1.67957349e-03 7.51432720e-04 2.08055852e-03\n",
            " 1.42987722e-02 6.16498239e-04 2.08048915e-03 1.06838554e-03\n",
            " 3.57022094e-03 1.49097426e-02 1.38334652e-02 1.08335859e-02\n",
            " 7.66835538e-03 5.40535500e-05 1.32897789e-02 5.59027045e-04\n",
            " 1.09337774e-02 8.33903921e-04 1.20173370e-02 1.03674983e-02\n",
            " 1.24850820e-02 9.86199243e-03 1.26019955e-02 1.36623217e-02\n",
            " 1.38883726e-02 9.71188360e-03 9.44429395e-03 5.27176347e-03\n",
            " 8.16839806e-03 8.17534993e-03 7.99476681e-03 9.62281220e-03\n",
            " 1.67957349e-03 1.09598543e-02 1.05498664e-02 2.08367354e-03\n",
            " 1.17910665e-02 3.21623503e-03 9.44481878e-03 4.82671282e-03\n",
            " 1.04475515e-02 1.85445416e-03 1.28341653e-02 3.93769843e-03\n",
            " 1.15953359e-02 7.58962593e-03 1.21395801e-02 1.22477317e-02\n",
            " 4.32832514e-03 9.14467982e-03 5.55385783e-04 2.74903705e-03\n",
            " 9.32144061e-03 3.66596143e-03 7.39582922e-03 7.93842727e-03\n",
            " 1.87705269e-04 4.61445272e-03 1.07342512e-02 2.81090772e-03\n",
            " 1.45802598e-02 3.74945579e-03 1.02032766e-02 8.04152824e-03\n",
            " 4.37789567e-03 5.42241136e-04 1.40711811e-03 1.28467646e-02\n",
            " 1.15078892e-03 7.03196444e-03 4.93697878e-03 6.90300771e-04\n",
            " 4.26497170e-03 1.40828982e-02 1.13763988e-02 2.98974117e-04\n",
            " 7.54255350e-03 1.67957349e-03 7.44183730e-03 1.39061229e-02\n",
            " 1.10514735e-02 1.27810144e-02 5.58136745e-03 7.22509171e-03\n",
            " 8.37863092e-03 1.07310859e-02 1.46271259e-02 1.03453498e-02\n",
            " 2.18695418e-03 1.27313592e-02 3.50553438e-03 1.10836353e-03\n",
            " 7.44856335e-03 8.14908585e-03 8.67934187e-03 2.45278330e-04\n",
            " 1.09889897e-02 3.69648124e-03 5.95965722e-03 3.81601202e-03\n",
            " 9.20051755e-03 4.02026043e-04 2.52047663e-03 1.47510939e-02\n",
            " 4.92475836e-04 8.13835527e-03 9.08193320e-03 2.02007178e-03\n",
            " 4.62801328e-03 1.50752977e-03 9.80541761e-03 1.15375353e-02\n",
            " 9.87049538e-03 1.41123483e-02 6.98236054e-03 9.67576607e-03\n",
            " 1.02053816e-02 1.33934028e-04 6.90526622e-03 2.17629912e-03\n",
            " 3.14247132e-03 1.40269613e-02 3.07224915e-03 4.69579693e-03\n",
            " 8.41668041e-03 1.18733266e-02 3.93371925e-03 6.31477753e-03\n",
            " 2.44633250e-03 1.04049815e-02 9.60064316e-03 1.90091940e-03\n",
            " 5.37824626e-04 2.60931507e-03 1.36011154e-02 1.39839157e-02\n",
            " 4.16619003e-03 9.96150878e-03 1.37889573e-02 1.38399808e-02\n",
            " 7.68069409e-03 3.75691778e-03 5.75352865e-04 3.25459223e-03\n",
            " 6.28156936e-03 5.09500924e-03 7.83815473e-03 4.61515734e-03\n",
            " 3.09269676e-04 2.58013151e-03 2.80234298e-03 7.79081371e-03\n",
            " 1.27130222e-02 1.38822197e-02 7.93283849e-03 2.08367354e-03\n",
            " 1.40753839e-02 1.34153641e-03 1.09528083e-02 2.40029171e-03\n",
            " 5.74068243e-03 1.04010338e-02 1.36244667e-02 1.13012281e-02\n",
            " 3.99304399e-03 1.36979194e-02 1.11851900e-02 5.10588115e-03\n",
            " 8.17543040e-04 1.03658131e-02 6.56694447e-03 4.09594129e-03\n",
            " 1.49263804e-02 4.82258966e-03 3.64689631e-03 6.80221387e-03\n",
            " 5.03669321e-03 4.38363695e-03 2.78988544e-03 6.23295849e-03\n",
            " 1.03240988e-02 1.01891445e-03 6.53701379e-04 5.75892622e-03\n",
            " 1.34577613e-02 9.15178317e-04 1.93394643e-04 1.11267030e-02\n",
            " 9.12382611e-03 1.08246383e-02 1.22818400e-03 1.43271908e-03\n",
            " 1.98643762e-03 2.85930224e-03 7.02220947e-05 1.45816884e-02\n",
            " 3.66488217e-03 5.36068046e-03 5.07690380e-03 1.99853111e-06\n",
            " 1.15676239e-02 6.32475550e-04 4.69179208e-07 1.06541256e-02\n",
            " 1.98304499e-05 3.64349039e-05 1.31731454e-02 1.03776743e-02\n",
            " 1.07386675e-02 1.44512865e-03 8.41506370e-04 1.11055324e-02\n",
            " 4.27063437e-03 3.85684890e-03 1.42684664e-02 4.87252330e-03\n",
            " 1.05272773e-02 4.87252330e-03 7.26277023e-03 1.01110531e-03\n",
            " 7.08078062e-03 1.82650895e-03 3.84086597e-03 2.79674816e-04\n",
            " 1.50392102e-02 3.66905846e-04 1.03302294e-02 1.41897419e-02\n",
            " 2.97162075e-03 1.36147870e-02 4.76427443e-03 4.11118524e-03\n",
            " 2.28714689e-04 5.12855626e-03 6.02857433e-03 6.46189490e-03\n",
            " 1.30160341e-02 5.41952567e-03 4.58172985e-03 4.81448510e-03\n",
            " 6.95906368e-03 1.15348020e-02 2.92439700e-03 1.28433948e-02\n",
            " 1.47475575e-02 1.06309115e-02 1.42417175e-02 5.37264840e-03\n",
            " 5.66099085e-03 1.24936841e-02 4.59111684e-03 3.85684890e-03\n",
            " 1.33017599e-02 1.38552980e-02 7.53517522e-03 1.04705020e-02\n",
            " 1.32638248e-03 1.19397086e-03 3.64518995e-03 5.28461353e-03\n",
            " 3.88294332e-03 6.48500002e-04 9.06625270e-03 1.08146521e-02\n",
            " 8.10858855e-03 5.44537361e-03 2.17732616e-03 7.01271084e-04\n",
            " 9.23568197e-03 6.89478369e-03 7.03613461e-03 8.54616713e-03\n",
            " 1.10097152e-02 9.62008032e-03 2.80172590e-03 1.45567355e-03\n",
            " 1.24586726e-03 1.41300393e-02 6.00422476e-03 9.55117808e-03\n",
            " 1.06333539e-02 7.05200569e-03 8.46846042e-03 1.33995519e-02\n",
            " 4.06575936e-03 1.36466789e-02 7.72713806e-03 3.65651385e-03\n",
            " 8.79281411e-03 1.30706389e-02 1.28489516e-02 3.01634045e-03\n",
            " 1.44665006e-02 1.28293481e-02 3.29544911e-03 8.64917053e-03\n",
            " 4.57079123e-04 9.04729665e-04 8.79328344e-03 1.40269613e-02\n",
            " 8.15982984e-03 2.61510849e-03 9.71188360e-03 6.04126048e-03\n",
            " 8.02541829e-03 3.75769148e-04 5.49671353e-03 1.42261595e-02\n",
            " 7.36062522e-03 3.58957381e-03 1.04393994e-02 6.73375281e-03\n",
            " 3.51339754e-03 7.61366545e-03 1.51566670e-02 8.86769578e-03\n",
            " 9.37139544e-03 7.17368372e-03 4.69222473e-03 5.52767412e-03\n",
            " 6.53162861e-03 7.87422374e-04 3.82557977e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3510 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.77617647e-03 4.26118898e-03 4.61706517e-03 3.83759668e-03\n",
            " 6.90169098e-04 1.23454689e-02 9.10327523e-03 3.92592360e-03\n",
            " 6.53054052e-03 1.22013525e-02 8.25109828e-03 1.13459475e-02\n",
            " 8.07992035e-03 1.01846644e-02 1.05094541e-02 1.18385297e-02\n",
            " 6.34003263e-03 1.41862963e-02 5.50311810e-03 7.42779746e-03\n",
            " 5.51507069e-03 8.06697092e-03 1.40958599e-03 9.28661646e-03\n",
            " 4.82878747e-03 5.35975881e-03 3.84159026e-03 1.31986538e-05\n",
            " 5.74782832e-03 1.28199832e-02 1.36735350e-02 2.85860901e-03\n",
            " 1.05612215e-02 1.31864762e-02 9.66740212e-05 9.33117757e-03\n",
            " 1.28199832e-02 1.22209760e-02 1.87543665e-03 4.56881341e-09\n",
            " 2.90229707e-03 1.69316633e-05 6.30536304e-03 1.23153138e-02\n",
            " 8.69516658e-03 4.13944142e-04 1.59924071e-07 1.11887743e-02\n",
            " 7.56650440e-03 7.09459556e-03 2.84753630e-03 7.48378429e-03\n",
            " 1.05375707e-02 9.72413911e-03 5.36141758e-03 8.83156243e-03\n",
            " 2.13669497e-03 1.15383374e-02 1.36411585e-02 9.27660299e-03\n",
            " 1.33399803e-02 1.11671141e-02 1.09848024e-02 9.92228212e-04\n",
            " 7.50250895e-03 2.78034142e-03 3.60064611e-04 1.07296703e-03\n",
            " 1.44392245e-02 8.03059596e-03 3.25777645e-03 9.79230797e-03\n",
            " 1.39004144e-02 9.72413911e-03 1.25250123e-02 4.19806205e-04\n",
            " 1.36223955e-02 7.32871478e-03 5.02385007e-03 4.91567946e-03\n",
            " 1.14889815e-02 4.71181030e-04 1.10386166e-02 1.00586235e-02\n",
            " 4.19027157e-03 4.17206460e-03 1.13944328e-03 5.60479243e-03\n",
            " 1.09858644e-02 5.87750047e-04 1.02871030e-03 1.01929225e-02\n",
            " 5.32584243e-03 6.33638455e-05 3.69871934e-03 1.27611272e-02\n",
            " 9.59469156e-03 1.07208395e-02 1.09292801e-02 1.80768741e-03\n",
            " 7.59158962e-03 8.46441794e-03 6.45137554e-04 1.46689690e-02\n",
            " 2.05263941e-03 1.06906395e-02 9.87923218e-03 1.43679651e-02\n",
            " 7.73335770e-03 9.03512236e-03 5.03679663e-03 1.22209760e-02\n",
            " 3.57507943e-03 6.73078119e-05 9.11702640e-03 1.30543046e-02\n",
            " 3.92464128e-03 1.46364257e-02 3.57507943e-03 1.19175923e-02\n",
            " 1.17604727e-02 8.84300459e-03 1.43539800e-02 6.69581318e-03\n",
            " 9.83446644e-04 1.24501113e-02 9.56302329e-03 7.32773330e-03\n",
            " 1.14904358e-02 1.47193943e-03 1.26774760e-02 4.21238230e-05\n",
            " 8.76135326e-03 4.69349854e-03 3.05482284e-03 1.01298581e-02\n",
            " 7.01923030e-03 9.05803808e-03 4.50698847e-03 8.98242530e-03\n",
            " 1.04554135e-02 9.54863062e-03 9.78979846e-03 4.56881341e-09\n",
            " 3.90050756e-03 8.97688811e-03 1.47025848e-02 8.57641758e-03\n",
            " 1.05811358e-03 1.28434861e-02 1.29795263e-02 4.14361168e-03\n",
            " 1.45260491e-02 7.92204795e-03 1.74768061e-03 7.67949275e-03\n",
            " 1.44271508e-02 2.07478016e-03 7.43760069e-03 4.10232921e-03\n",
            " 1.15771280e-02 8.66016188e-03 5.61243725e-03 5.37316172e-03\n",
            " 6.60658626e-03 2.98767588e-03 8.25109828e-03 1.28405862e-02\n",
            " 1.29511747e-02 9.24536683e-03 5.05193452e-03 1.04447233e-02\n",
            " 4.19027157e-03 1.05612215e-02 9.46882182e-03 7.56346614e-03\n",
            " 1.21169721e-02 9.09804945e-03 5.74236209e-03 1.08003902e-02\n",
            " 7.58159573e-03 1.19532446e-02 2.44117749e-03 1.35943740e-02\n",
            " 1.55423707e-04 4.02840484e-03 1.03478797e-02 1.10500822e-02\n",
            " 4.03737201e-03 1.00361611e-02 3.32519549e-03 1.37500579e-02\n",
            " 6.03353797e-03 7.42963064e-03 1.01356091e-02 5.27431225e-04\n",
            " 3.08365123e-03 1.09807048e-02 6.05604627e-03 1.31051568e-02\n",
            " 1.26140425e-06 1.14336708e-02 8.87443712e-05 7.93788337e-04\n",
            " 2.87306861e-03 1.26476477e-02 6.51067713e-03 2.96245923e-03\n",
            " 9.29869516e-03 5.12695361e-03 4.13972478e-04 1.45013406e-02\n",
            " 5.21089178e-03 5.38470454e-03 1.25095302e-02 1.12221320e-03\n",
            " 1.34778677e-02 1.04873663e-02 8.43900369e-04 4.51015025e-03\n",
            " 1.23454689e-02 6.68766124e-03 8.31513871e-03 5.42433705e-03\n",
            " 1.44405089e-02 5.89225365e-03 1.43085040e-02 4.39616907e-03\n",
            " 5.52747463e-03 5.30592069e-03 3.21162412e-03 7.56216182e-03\n",
            " 4.19027157e-03 9.89135553e-03 7.73768360e-03 3.64790762e-03\n",
            " 1.21283060e-03 1.48143612e-03 8.98469432e-03 4.01734065e-03\n",
            " 1.00185790e-02 1.18084075e-02 1.51917736e-03 5.10261991e-03\n",
            " 9.14053078e-03 9.57292831e-05 7.95709120e-03 2.52038503e-16\n",
            " 3.05155274e-03 1.45660520e-02 6.10023374e-03 1.27188652e-02\n",
            " 1.03902481e-02 1.39791231e-02 1.14049818e-02 2.27143680e-04\n",
            " 8.08196273e-03 1.01374259e-02 1.00361611e-02 7.50250895e-03\n",
            " 2.83387402e-03 3.98226260e-03 3.16076347e-03 1.14904358e-02\n",
            " 2.09958160e-03 3.56745123e-03 1.23203986e-02 6.58344831e-03\n",
            " 7.29746686e-03 1.61981931e-03 2.43080958e-04 7.06024072e-03\n",
            " 1.30450314e-02 4.69723534e-03 6.59797581e-03 1.20121672e-02\n",
            " 3.91649189e-03 3.93752219e-04 1.39676150e-02 8.44725432e-03\n",
            " 2.00794674e-03 4.42032201e-03 3.38630372e-03 6.95715744e-03\n",
            " 7.71889199e-03 1.72721737e-04 4.45886666e-03 3.52281240e-03\n",
            " 8.36354451e-03 1.42237955e-02 4.80944409e-03 3.17215387e-03\n",
            " 8.91854697e-03 8.84181990e-03 6.92106734e-03 1.33005579e-02\n",
            " 4.61312222e-03 9.34750208e-03 5.51507069e-03 9.74288468e-03\n",
            " 1.42508206e-02 4.81751320e-03 9.87543945e-03 1.88053601e-04\n",
            " 9.16883242e-03 1.17581542e-02 1.64020745e-03 8.21592837e-03\n",
            " 9.85308567e-03 7.98051254e-03 6.73619032e-03 3.69871934e-03\n",
            " 1.32166037e-03 1.22085552e-02 2.83973454e-03 1.97808270e-03\n",
            " 1.45632502e-02 1.36661218e-02 1.28959355e-03 4.74623161e-03\n",
            " 1.64875317e-03 5.74236209e-03 3.90505831e-03 1.33817799e-02\n",
            " 1.43009029e-03 1.13809992e-02 7.50276488e-03 3.05718734e-03\n",
            " 3.06523912e-03 6.22434246e-03 2.18262455e-03 1.38618720e-02\n",
            " 4.32335644e-06 1.21767923e-02 7.87264447e-04 1.47153090e-02\n",
            " 3.80940315e-03 1.22879424e-03 1.07529894e-02 9.98681096e-03\n",
            " 1.00245094e-05 1.04642392e-02 1.08373294e-02 1.46143293e-02\n",
            " 2.29237013e-03 1.77452277e-04 8.82567391e-03 1.33005579e-02\n",
            " 3.72267758e-03 2.99852793e-03 8.83681705e-03 1.67634140e-03\n",
            " 7.50379593e-04 2.08040697e-03 1.42917567e-02 6.17780759e-04\n",
            " 2.06969956e-03 1.06811721e-03 3.57202333e-03 1.38136498e-02\n",
            " 1.08296956e-02 7.67169410e-03 5.38930644e-05 1.32810500e-02\n",
            " 5.58535236e-04 1.08932843e-02 8.31933471e-04 1.19916378e-02\n",
            " 1.03347700e-02 1.24777226e-02 9.84874106e-03 1.25910848e-02\n",
            " 1.36613429e-02 1.38782159e-02 9.72413911e-03 9.44025226e-03\n",
            " 5.26870794e-03 8.15323112e-03 8.15584770e-03 7.98232368e-03\n",
            " 9.61620139e-03 1.67634140e-03 1.09698748e-02 1.05194923e-02\n",
            " 2.07502845e-03 1.17889464e-02 3.20192636e-03 9.42166358e-03\n",
            " 4.82717355e-03 1.04133665e-02 1.85541117e-03 1.28449517e-02\n",
            " 3.93719095e-03 1.15652243e-02 7.58424576e-03 1.21138104e-02\n",
            " 1.22533940e-02 4.31629769e-03 9.13269265e-03 5.54569130e-04\n",
            " 2.74267206e-03 9.31390074e-03 3.66601772e-03 7.38474812e-03\n",
            " 7.94236369e-03 1.88053601e-04 4.61294749e-03 1.07388601e-02\n",
            " 2.79918627e-03 1.45567325e-02 3.73546587e-03 1.01809532e-02\n",
            " 8.03507410e-03 4.37494715e-03 5.41316535e-04 1.40922131e-03\n",
            " 1.28210422e-02 1.14984725e-03 7.03548944e-03 4.93451793e-03\n",
            " 6.90169098e-04 4.25325029e-03 1.40661540e-02 1.13677270e-02\n",
            " 2.98812909e-04 7.53976035e-03 1.67634140e-03 7.41286581e-03\n",
            " 1.38862248e-02 1.10494065e-02 1.27538273e-02 5.57596037e-03\n",
            " 7.21789633e-03 8.37058905e-03 1.07182848e-02 1.46042894e-02\n",
            " 1.03148977e-02 2.18425654e-03 1.27065832e-02 3.49984302e-03\n",
            " 1.10320337e-03 7.38844191e-03 8.11528593e-03 8.69533843e-03\n",
            " 2.44450295e-04 1.09652505e-02 3.69871934e-03 5.95363909e-03\n",
            " 3.80940315e-03 9.19960032e-03 4.01848689e-04 2.51182385e-03\n",
            " 1.47351454e-02 4.91884282e-04 8.13772420e-03 9.06876555e-03\n",
            " 2.01799496e-03 4.61545431e-03 1.50210096e-03 9.76070079e-03\n",
            " 1.15396273e-02 9.85083688e-03 1.41099297e-02 6.98577095e-03\n",
            " 9.65359883e-03 1.01919872e-02 1.33154852e-04 6.90072137e-03\n",
            " 2.17070949e-03 3.13584256e-03 1.40212218e-02 3.06728943e-03\n",
            " 4.69349854e-03 8.37657570e-03 1.18559261e-02 3.92464128e-03\n",
            " 6.30495237e-03 2.42795014e-03 1.03895821e-02 9.58792291e-03\n",
            " 1.89578591e-03 5.34899001e-04 2.60833550e-03 1.35669177e-02\n",
            " 1.39632118e-02 4.16263266e-03 9.96322130e-03 1.37500579e-02\n",
            " 1.38098572e-02 7.63757978e-03 3.74514745e-03 5.75734087e-04\n",
            " 3.25047859e-03 6.28190245e-03 5.08905259e-03 7.84366395e-03\n",
            " 4.59511677e-03 3.08293581e-04 2.57118340e-03 2.79902250e-03\n",
            " 7.74552107e-03 1.27201421e-02 1.38620698e-02 7.89832992e-03\n",
            " 2.07502845e-03 1.40862699e-02 1.33923068e-03 1.09358864e-02\n",
            " 2.39393716e-03 5.73639309e-03 1.03710824e-02 1.36048994e-02\n",
            " 1.13176453e-02 3.98230884e-03 1.36683260e-02 1.11496043e-02\n",
            " 5.09899619e-03 8.15194325e-04 1.03812137e-02 6.53803122e-03\n",
            " 4.09155543e-03 4.82300076e-03 3.62768135e-03 6.77656267e-03\n",
            " 5.01884520e-03 4.37961126e-03 2.77668810e-03 6.23705542e-03\n",
            " 1.03025007e-02 1.01398028e-03 6.52800657e-04 5.74782832e-03\n",
            " 1.34204540e-02 9.09269863e-04 1.92886470e-04 1.11062025e-02\n",
            " 9.13122335e-03 1.08242698e-02 1.22609043e-03 1.43287514e-03\n",
            " 1.97761946e-03 2.84753630e-03 6.96492727e-05 1.45698272e-02\n",
            " 3.66836860e-03 5.35338921e-03 5.06370571e-03 2.00882941e-06\n",
            " 1.15491838e-02 6.31603963e-04 4.68503278e-07 1.06179809e-02\n",
            " 1.97163722e-05 3.63221607e-05 1.31774331e-02 1.03523602e-02\n",
            " 1.07244778e-02 1.43949291e-03 8.42887097e-04 1.10990749e-02\n",
            " 4.27775290e-03 3.84159026e-03 1.42224583e-02 4.87020562e-03\n",
            " 1.05253502e-02 4.87020562e-03 7.24180449e-03 1.00877238e-03\n",
            " 7.07721483e-03 1.82689600e-03 3.83602187e-03 2.77718681e-04\n",
            " 3.65485180e-04 1.03349873e-02 1.41688657e-02 2.96747172e-03\n",
            " 1.35681449e-02 4.75566529e-03 4.12064644e-03 2.28014418e-04\n",
            " 5.11980055e-03 6.02316580e-03 6.45802143e-03 1.29981663e-02\n",
            " 5.40753405e-03 4.57763400e-03 4.80944409e-03 6.95847367e-03\n",
            " 1.15375102e-02 2.91538885e-03 1.28362744e-02 1.47335135e-02\n",
            " 1.06198254e-02 1.42218818e-02 5.36668394e-03 5.61832883e-03\n",
            " 1.24907384e-02 4.59540295e-03 3.84159026e-03 1.32975344e-02\n",
            " 1.38300886e-02 7.53975684e-03 1.04477083e-02 1.32679652e-03\n",
            " 1.19095277e-03 3.64108696e-03 5.23260270e-03 3.86307202e-03\n",
            " 6.46183733e-04 9.04565206e-03 1.07850725e-02 8.10139924e-03\n",
            " 5.44323190e-03 2.17320194e-03 6.99485848e-04 9.23233571e-03\n",
            " 6.88276401e-03 7.01652511e-03 8.54324231e-03 1.10044924e-02\n",
            " 9.58908916e-03 2.79385937e-03 1.45140156e-03 1.24259341e-03\n",
            " 1.41404483e-02 6.00049913e-03 9.49854865e-03 1.06215886e-02\n",
            " 7.02357628e-03 8.46764116e-03 1.33385661e-02 4.06099685e-03\n",
            " 1.35980539e-02 7.72909342e-03 3.65406262e-03 8.77512215e-03\n",
            " 1.30689712e-02 1.28467344e-02 3.01417523e-03 1.44476508e-02\n",
            " 1.28087404e-02 3.29223066e-03 8.65032853e-03 4.56818682e-04\n",
            " 9.06219990e-04 8.79846468e-03 1.40212218e-02 8.15428289e-03\n",
            " 2.60818462e-03 9.72413911e-03 6.02711777e-03 8.01445990e-03\n",
            " 3.75281848e-04 5.49750852e-03 1.42350821e-02 7.35018458e-03\n",
            " 3.57161648e-03 1.04353153e-02 6.73421712e-03 3.50533167e-03\n",
            " 7.60732913e-03 8.85000291e-03 9.36584852e-03 7.16515691e-03\n",
            " 4.68044343e-03 5.53404930e-03 6.51840793e-03 7.87264447e-04\n",
            " 3.82102649e-03]\n",
            "3520 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.76508647e-03 4.25906980e-03 4.61304168e-03 3.81973937e-03\n",
            " 6.89556668e-04 1.23359592e-02 9.09550481e-03 3.92816908e-03\n",
            " 6.50077404e-03 1.22001668e-02 8.20990048e-03 1.13083685e-02\n",
            " 8.07046274e-03 1.01791921e-02 1.04986262e-02 1.18179486e-02\n",
            " 6.31793169e-03 1.41633417e-02 5.48963385e-03 7.43607927e-03\n",
            " 5.50702790e-03 8.05801274e-03 1.40610298e-03 9.23451384e-03\n",
            " 4.82979407e-03 5.35782164e-03 3.83593980e-03 1.31733154e-05\n",
            " 5.74228718e-03 1.28074821e-02 1.36251332e-02 2.85510045e-03\n",
            " 1.05557648e-02 1.31911987e-02 9.62945905e-05 9.32048808e-03\n",
            " 1.28074821e-02 1.22006163e-02 1.86109266e-03 4.56209310e-09\n",
            " 2.89684038e-03 1.65629521e-05 6.30148875e-03 1.22574683e-02\n",
            " 8.69572570e-03 4.13003428e-04 1.60711634e-07 1.11662859e-02\n",
            " 7.55031030e-03 7.07767812e-03 2.84328612e-03 7.48125861e-03\n",
            " 1.05273717e-02 9.72100742e-03 5.33152693e-03 8.82239255e-03\n",
            " 2.13306603e-03 1.15507809e-02 1.35991304e-02 9.25656881e-03\n",
            " 1.33015609e-02 1.11164404e-02 1.09861463e-02 9.84127590e-04\n",
            " 7.49898473e-03 2.76884655e-03 3.59986027e-04 1.06722716e-03\n",
            " 1.44349312e-02 8.03105959e-03 3.25731872e-03 9.75336254e-03\n",
            " 1.38862806e-02 9.72100742e-03 1.25239916e-02 4.19602442e-04\n",
            " 1.35708127e-02 7.31672365e-03 5.02062675e-03 4.90245981e-03\n",
            " 1.14639727e-02 4.69383697e-04 1.10215834e-02 1.00664035e-02\n",
            " 4.18851945e-03 4.14773019e-03 1.13585998e-03 5.60338487e-03\n",
            " 1.09718178e-02 5.86840714e-04 1.02712863e-03 1.01673456e-02\n",
            " 5.31852216e-03 6.32573449e-05 3.69042680e-03 1.27443190e-02\n",
            " 9.57337973e-03 1.06936395e-02 1.09406493e-02 1.80530804e-03\n",
            " 7.58250261e-03 8.46341971e-03 6.41443808e-04 2.05061021e-03\n",
            " 1.06712587e-02 9.86169832e-03 1.43459840e-02 7.72846922e-03\n",
            " 8.99722608e-03 5.03086200e-03 1.22006163e-02 3.57398923e-03\n",
            " 6.65646381e-05 9.12221617e-03 1.29634719e-02 3.89847485e-03\n",
            " 3.57398923e-03 1.19129435e-02 1.17490856e-02 8.81116908e-03\n",
            " 1.43248629e-02 6.68723990e-03 9.83099956e-04 1.24335996e-02\n",
            " 9.53672799e-03 7.31838620e-03 1.14893106e-02 1.47227986e-03\n",
            " 1.26525419e-02 4.15978647e-05 8.72809858e-03 4.69074930e-03\n",
            " 3.03954273e-03 1.01035224e-02 7.00662745e-03 9.04252093e-03\n",
            " 4.46811654e-03 8.98926158e-03 1.04298844e-02 9.53720551e-03\n",
            " 9.78646528e-03 4.56209310e-09 3.89408770e-03 8.98685132e-03\n",
            " 8.57119836e-03 1.05372052e-03 1.28272291e-02 1.29799739e-02\n",
            " 4.13404462e-03 1.44954729e-02 7.91041641e-03 1.73465026e-03\n",
            " 7.67034329e-03 1.44027697e-02 2.06261847e-03 7.42079800e-03\n",
            " 4.09887572e-03 1.15658904e-02 8.64935972e-03 5.60914048e-03\n",
            " 5.34787002e-03 6.59424959e-03 2.98749517e-03 8.20990048e-03\n",
            " 1.28040236e-02 1.29487560e-02 9.25137333e-03 5.04912908e-03\n",
            " 1.04130463e-02 4.18851945e-03 1.05557648e-02 9.43792848e-03\n",
            " 7.55671052e-03 1.20557336e-02 9.10471977e-03 5.75388663e-03\n",
            " 1.07873264e-02 7.54099578e-03 1.19324243e-02 2.42822216e-03\n",
            " 1.35810211e-02 1.54759051e-04 4.02389658e-03 1.02977164e-02\n",
            " 1.10504155e-02 4.03252931e-03 1.00237200e-02 3.32352428e-03\n",
            " 1.37429473e-02 6.03943324e-03 7.42379132e-03 1.01203529e-02\n",
            " 5.26908898e-04 3.07143890e-03 1.09208438e-02 6.05071598e-03\n",
            " 1.30578039e-02 1.25025757e-06 1.14259785e-02 8.80466585e-05\n",
            " 7.92532798e-04 2.86806309e-03 1.25893407e-02 6.48458568e-03\n",
            " 2.95815498e-03 9.28028106e-03 5.11242065e-03 4.13413903e-04\n",
            " 1.44767718e-02 5.19923493e-03 5.37331370e-03 1.24792919e-02\n",
            " 1.12155712e-03 1.34486766e-02 1.04853089e-02 8.41584939e-04\n",
            " 4.49263257e-03 1.23359592e-02 6.67929670e-03 8.30494151e-03\n",
            " 5.42613790e-03 1.44510416e-02 5.88356557e-03 1.43020487e-02\n",
            " 4.37830553e-03 5.52904443e-03 5.30499523e-03 3.21074375e-03\n",
            " 7.55923242e-03 4.18851945e-03 9.87501000e-03 7.72584848e-03\n",
            " 3.63125987e-03 1.21164057e-03 1.47708863e-03 8.94917656e-03\n",
            " 4.01869703e-03 1.00110592e-02 1.17820812e-02 1.51214830e-03\n",
            " 5.08043443e-03 9.11395815e-03 9.57020730e-05 7.92798531e-03\n",
            " 2.35993345e-16 3.04066385e-03 6.09414747e-03 1.26597900e-02\n",
            " 1.03719743e-02 1.39363664e-02 1.13827608e-02 2.25426909e-04\n",
            " 8.07492338e-03 1.00972582e-02 1.00237200e-02 7.49898473e-03\n",
            " 2.82552664e-03 3.98229708e-03 3.14972577e-03 1.14893106e-02\n",
            " 2.09240731e-03 3.56551703e-03 1.23107505e-02 6.57148616e-03\n",
            " 7.28891825e-03 1.61244061e-03 2.42459727e-04 7.04485212e-03\n",
            " 1.30330129e-02 4.70175115e-03 6.57629165e-03 1.19703765e-02\n",
            " 3.87416494e-03 3.94093957e-04 1.39627723e-02 8.42705046e-03\n",
            " 2.00768116e-03 4.41144431e-03 3.37286175e-03 6.94486299e-03\n",
            " 7.70262043e-03 1.72656301e-04 4.44737449e-03 3.51620775e-03\n",
            " 8.33541972e-03 1.42077929e-02 4.80034895e-03 3.15807485e-03\n",
            " 8.91503628e-03 8.83278620e-03 6.91463026e-03 1.32521516e-02\n",
            " 4.59048065e-03 9.31890440e-03 5.50702790e-03 9.71775192e-03\n",
            " 1.42343395e-02 4.79234187e-03 9.82279936e-03 1.88036184e-04\n",
            " 9.15973275e-03 1.17629131e-02 1.63391381e-03 8.19476886e-03\n",
            " 9.83990726e-03 7.98145136e-03 6.70869351e-03 3.69042680e-03\n",
            " 1.31265051e-03 1.21968713e-02 2.83382598e-03 1.97570682e-03\n",
            " 1.45407733e-02 1.36204725e-02 1.28957711e-03 4.72452635e-03\n",
            " 1.63805035e-03 5.75388663e-03 3.89969244e-03 1.33931067e-02\n",
            " 1.42495833e-03 1.13375220e-02 7.49512780e-03 3.05433459e-03\n",
            " 3.05201335e-03 6.21587010e-03 2.17802345e-03 1.38092801e-02\n",
            " 4.26478886e-06 1.21651122e-02 7.86333326e-04 3.79790056e-03\n",
            " 1.22633463e-03 1.07391291e-02 9.99196018e-03 9.98246792e-06\n",
            " 1.03991254e-02 1.08422119e-02 2.28761553e-03 1.77178124e-04\n",
            " 8.82227690e-03 1.32521516e-02 3.71401743e-03 2.98467580e-03\n",
            " 8.79475353e-03 1.66432683e-03 7.48868169e-04 2.07756536e-03\n",
            " 1.42613698e-02 6.15513160e-04 2.06861993e-03 1.06642286e-03\n",
            " 3.56159825e-03 1.38141001e-02 1.08212544e-02 7.64131002e-03\n",
            " 5.37496457e-05 1.32689706e-02 5.55915505e-04 1.08607108e-02\n",
            " 8.26226653e-04 1.19700205e-02 1.03200212e-02 1.24677391e-02\n",
            " 9.82358661e-03 1.25717929e-02 1.36599277e-02 1.38780134e-02\n",
            " 9.72100742e-03 9.42452705e-03 5.26523721e-03 8.12448623e-03\n",
            " 8.11258285e-03 7.96301753e-03 9.59171234e-03 1.66432683e-03\n",
            " 1.09658654e-02 1.05020652e-02 2.07123617e-03 1.17786440e-02\n",
            " 3.18683738e-03 9.40628581e-03 4.81468961e-03 1.04067963e-02\n",
            " 1.84880925e-03 1.28121820e-02 3.92090776e-03 1.15169708e-02\n",
            " 7.58743941e-03 1.20784769e-02 1.22411274e-02 4.28877211e-03\n",
            " 9.13385530e-03 5.53490069e-04 2.73102346e-03 9.28775413e-03\n",
            " 3.66508520e-03 7.36654084e-03 7.92652861e-03 1.88036184e-04\n",
            " 4.60210873e-03 1.07134427e-02 2.80004098e-03 1.45411662e-02\n",
            " 3.72376971e-03 1.01601016e-02 8.02450938e-03 4.37381850e-03\n",
            " 5.40473101e-04 1.40734445e-03 1.27886112e-02 1.14707666e-03\n",
            " 7.02342371e-03 4.92966032e-03 6.89556668e-04 4.23629057e-03\n",
            " 1.40700355e-02 1.13709315e-02 2.97999114e-04 7.54197464e-03\n",
            " 1.66432683e-03 7.38195386e-03 1.38344743e-02 1.10344908e-02\n",
            " 1.27550576e-02 5.57074135e-03 7.20785139e-03 8.36768197e-03\n",
            " 1.06871517e-02 1.03168032e-02 2.18526643e-03 1.26763484e-02\n",
            " 3.48545678e-03 1.09597212e-03 7.37536353e-03 8.09081715e-03\n",
            " 8.67876945e-03 2.44127274e-04 1.09385266e-02 3.69042680e-03\n",
            " 5.93803105e-03 3.79790056e-03 9.20751981e-03 4.00287965e-04\n",
            " 2.50573645e-03 4.89131598e-04 8.13272575e-03 9.04737254e-03\n",
            " 2.01184101e-03 4.61939084e-03 1.49725504e-03 9.74379839e-03\n",
            " 1.15306773e-02 9.85036704e-03 1.41000997e-02 6.99133466e-03\n",
            " 9.64076909e-03 1.01432784e-02 1.32969188e-04 6.89407311e-03\n",
            " 2.15863869e-03 3.12238662e-03 1.40197083e-02 3.06492780e-03\n",
            " 4.69074930e-03 8.34284933e-03 1.18577224e-02 3.89847485e-03\n",
            " 6.29141876e-03 2.39825137e-03 1.03914623e-02 9.59700790e-03\n",
            " 1.89346305e-03 5.29025590e-04 2.60655784e-03 1.35296190e-02\n",
            " 1.39320121e-02 4.15293805e-03 9.96084516e-03 1.37429473e-02\n",
            " 1.37686004e-02 7.62444712e-03 3.74357397e-03 5.72536175e-04\n",
            " 3.24781842e-03 6.28336879e-03 5.06342728e-03 7.84531641e-03\n",
            " 4.58377172e-03 3.07406978e-04 2.56865606e-03 2.79115167e-03\n",
            " 7.71127287e-03 1.27009197e-02 1.37909428e-02 7.86095217e-03\n",
            " 2.07123617e-03 1.40695958e-02 1.33476181e-03 1.09032922e-02\n",
            " 2.39221185e-03 5.71861799e-03 1.03327431e-02 1.35752995e-02\n",
            " 1.13142453e-02 3.97980176e-03 1.36538959e-02 1.11523531e-02\n",
            " 5.10059769e-03 8.10284882e-04 1.03560261e-02 6.51919971e-03\n",
            " 4.06993016e-03 4.79497414e-03 3.61775989e-03 6.78453192e-03\n",
            " 5.00885241e-03 4.38132902e-03 2.77143292e-03 6.22523646e-03\n",
            " 1.02947163e-02 1.01281400e-03 6.51284193e-04 5.74228718e-03\n",
            " 1.34208542e-02 8.98822961e-04 1.92662113e-04 1.10528666e-02\n",
            " 9.07986043e-03 1.08054428e-02 1.22197282e-03 1.42993276e-03\n",
            " 1.97794461e-03 2.84328612e-03 6.85054721e-05 3.66008512e-03\n",
            " 5.32752547e-03 5.04861671e-03 2.00098508e-06 1.15425086e-02\n",
            " 6.28212440e-04 4.64721192e-07 1.05739135e-02 1.95332662e-05\n",
            " 3.59865132e-05 1.31648189e-02 1.03540265e-02 1.06801875e-02\n",
            " 1.43327023e-03 8.40690774e-04 1.10883616e-02 4.26832611e-03\n",
            " 3.83593980e-03 1.42105307e-02 4.86586074e-03 1.05255617e-02\n",
            " 4.86586074e-03 7.23836305e-03 1.00632618e-03 7.05337726e-03\n",
            " 1.82432394e-03 3.82421263e-03 2.73320366e-04 3.62902144e-04\n",
            " 1.03416647e-02 1.41610657e-02 2.96001762e-03 1.35729494e-02\n",
            " 4.75938962e-03 4.10806103e-03 2.27519844e-04 5.10824566e-03\n",
            " 6.01212887e-03 6.44183521e-03 1.29799741e-02 5.39526958e-03\n",
            " 4.57021575e-03 4.80034895e-03 6.96064128e-03 1.15435390e-02\n",
            " 2.90155820e-03 1.28426598e-02 1.05743164e-02 1.42360526e-02\n",
            " 5.36821727e-03 5.61208197e-03 1.24607752e-02 4.58403634e-03\n",
            " 3.83593980e-03 1.32910545e-02 1.38338931e-02 7.53674203e-03\n",
            " 1.04300559e-02 1.32362878e-03 1.18842472e-03 3.63980207e-03\n",
            " 5.22553779e-03 3.85419430e-03 6.39374800e-04 9.03514939e-03\n",
            " 1.07748655e-02 8.07235373e-03 5.44306250e-03 2.15727857e-03\n",
            " 6.92961504e-04 9.24341172e-03 6.88985031e-03 7.01208789e-03\n",
            " 8.50201705e-03 1.09939539e-02 9.58088801e-03 2.78303253e-03\n",
            " 1.45049158e-03 1.24100308e-03 1.41264987e-02 5.98534317e-03\n",
            " 9.47443947e-03 1.06140158e-02 6.99506373e-03 8.46533774e-03\n",
            " 1.32870512e-02 4.05802190e-03 1.35986293e-02 7.70665909e-03\n",
            " 3.63493035e-03 8.72922524e-03 1.30419718e-02 1.28364981e-02\n",
            " 3.00925920e-03 1.44010051e-02 1.27663891e-02 3.29197212e-03\n",
            " 8.64756738e-03 4.55544698e-04 9.03808276e-04 8.77351610e-03\n",
            " 1.40197083e-02 8.15682715e-03 2.59590560e-03 9.72100742e-03\n",
            " 6.01733219e-03 8.00543477e-03 3.73073698e-04 5.49524616e-03\n",
            " 1.42062395e-02 7.34126348e-03 3.56302907e-03 1.04219920e-02\n",
            " 6.73319162e-03 3.50260216e-03 7.59511896e-03 8.83174343e-03\n",
            " 9.34994246e-03 7.16065802e-03 4.67458248e-03 5.53280330e-03\n",
            " 6.51292682e-03 7.86333326e-04 3.81909014e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3530 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.74953977e-03 4.24501261e-03 4.58942322e-03 3.81631772e-03\n",
            " 6.89999909e-04 1.23179828e-02 9.06151662e-03 3.92390466e-03\n",
            " 6.49250258e-03 1.21613335e-02 8.21346071e-03 1.13022270e-02\n",
            " 8.04725118e-03 1.01721753e-02 1.04717253e-02 1.18086712e-02\n",
            " 6.31357406e-03 1.41525754e-02 5.47738088e-03 7.43735695e-03\n",
            " 5.50423021e-03 8.02216367e-03 1.40322052e-03 9.22010914e-03\n",
            " 4.81047211e-03 5.35588952e-03 3.83372003e-03 1.31279297e-05\n",
            " 5.73589337e-03 1.28004471e-02 1.36218028e-02 2.85786298e-03\n",
            " 1.05362109e-02 1.32269439e-02 9.57211224e-05 9.26598752e-03\n",
            " 1.28004471e-02 1.21921920e-02 1.85318856e-03 4.48740332e-09\n",
            " 2.88324517e-03 1.65186870e-05 6.27163496e-03 1.21977979e-02\n",
            " 8.69100800e-03 4.12379020e-04 1.58799628e-07 1.11396059e-02\n",
            " 7.54298807e-03 7.04430941e-03 2.84143445e-03 7.48406300e-03\n",
            " 1.05210887e-02 9.72268022e-03 5.29728097e-03 8.81241495e-03\n",
            " 2.12917274e-03 1.15511075e-02 1.35993386e-02 9.26423854e-03\n",
            " 1.32772226e-02 1.10979078e-02 1.09648309e-02 9.80424852e-04\n",
            " 7.50005388e-03 2.76034701e-03 3.58591141e-04 1.05789111e-03\n",
            " 8.01140122e-03 3.24429328e-03 9.74124596e-03 1.38928351e-02\n",
            " 9.72268022e-03 1.25133538e-02 4.19745592e-04 1.35461427e-02\n",
            " 7.30109656e-03 4.99678284e-03 4.90446413e-03 1.14293010e-02\n",
            " 4.66813889e-04 1.10178460e-02 1.00392843e-02 4.18098116e-03\n",
            " 4.13875745e-03 1.13454822e-03 5.57951246e-03 1.09699836e-02\n",
            " 5.82509436e-04 1.02221682e-03 1.01442512e-02 5.28485321e-03\n",
            " 6.31277331e-05 3.68521110e-03 1.27343155e-02 9.55879870e-03\n",
            " 1.06626412e-02 1.09282407e-02 1.80090387e-03 7.54634361e-03\n",
            " 8.44732847e-03 6.37434312e-04 2.04556880e-03 1.06440028e-02\n",
            " 9.84380269e-03 7.71240846e-03 8.99470072e-03 5.02374055e-03\n",
            " 1.21921920e-02 3.56974649e-03 6.62522788e-05 9.10609102e-03\n",
            " 1.29509083e-02 3.88577442e-03 3.56974649e-03 1.19247558e-02\n",
            " 1.17413724e-02 8.81004125e-03 6.65888204e-03 9.82278265e-04\n",
            " 1.23979407e-02 9.52459477e-03 7.29389772e-03 1.14669896e-02\n",
            " 1.47370115e-03 1.26422887e-02 4.15091051e-05 8.72362465e-03\n",
            " 4.68656104e-03 3.03393226e-03 1.00963371e-02 6.98402650e-03\n",
            " 9.02774370e-03 4.47173469e-03 8.97963413e-03 1.04049475e-02\n",
            " 9.53037738e-03 9.75751759e-03 4.48740332e-09 3.89487984e-03\n",
            " 8.97207766e-03 8.56757639e-03 1.05254208e-03 1.27511158e-02\n",
            " 1.29593725e-02 4.12811758e-03 7.88445532e-03 1.72301810e-03\n",
            " 7.63971938e-03 2.05322540e-03 7.39997056e-03 4.09715365e-03\n",
            " 1.15489868e-02 8.62645364e-03 5.60679296e-03 5.32742832e-03\n",
            " 6.60222570e-03 2.98799478e-03 8.21346071e-03 1.27655400e-02\n",
            " 1.29468225e-02 9.24363751e-03 5.05096932e-03 1.04163853e-02\n",
            " 4.18098116e-03 1.05362109e-02 9.43879887e-03 7.56474631e-03\n",
            " 1.20448528e-02 9.08864241e-03 5.75104360e-03 1.07649649e-02\n",
            " 7.50642181e-03 1.18997631e-02 2.42074014e-03 1.35465622e-02\n",
            " 1.54336654e-04 4.01621171e-03 1.02834240e-02 1.10145722e-02\n",
            " 4.03435255e-03 1.00077427e-02 3.31780482e-03 1.37032223e-02\n",
            " 6.05319416e-03 7.39798516e-03 1.00935686e-02 5.26019073e-04\n",
            " 3.07275479e-03 1.09091232e-02 6.04381655e-03 1.30419485e-02\n",
            " 1.22336869e-06 1.14280570e-02 8.78611658e-05 7.91597194e-04\n",
            " 2.85694249e-03 1.25785666e-02 6.47998836e-03 2.94769955e-03\n",
            " 9.27385349e-03 5.10014262e-03 4.12459010e-04 5.18206306e-03\n",
            " 5.35595177e-03 1.24629005e-02 1.11829548e-03 1.34170387e-02\n",
            " 1.04629226e-02 8.39558388e-04 4.48548017e-03 1.23179828e-02\n",
            " 6.65752224e-03 8.29614679e-03 5.41568164e-03 5.86979346e-03\n",
            " 1.42783714e-02 4.37559399e-03 5.52100344e-03 5.29190901e-03\n",
            " 3.19971992e-03 7.54187842e-03 4.18098116e-03 9.85024008e-03\n",
            " 7.71209571e-03 3.62330436e-03 1.20743653e-03 1.47628434e-03\n",
            " 8.95242360e-03 4.00404841e-03 9.99894441e-03 1.17863199e-02\n",
            " 1.50696988e-03 5.07332901e-03 9.09296972e-03 9.55993131e-05\n",
            " 7.90251979e-03 2.35530806e-16 3.02685665e-03 6.08699523e-03\n",
            " 1.26196389e-02 1.03337005e-02 1.39134157e-02 1.13576559e-02\n",
            " 2.24436031e-04 8.05951343e-03 1.00938417e-02 1.00077427e-02\n",
            " 7.50005388e-03 2.82665582e-03 3.97849582e-03 3.14030343e-03\n",
            " 1.14669896e-02 2.09272611e-03 3.54686962e-03 1.22987585e-02\n",
            " 6.55155208e-03 7.28293013e-03 1.60680333e-03 2.41950598e-04\n",
            " 7.03973944e-03 1.30380275e-02 4.68848149e-03 6.55905864e-03\n",
            " 1.19504535e-02 3.87341256e-03 3.92715832e-04 1.39434376e-02\n",
            " 8.42655432e-03 1.99967147e-03 4.40996763e-03 3.35872997e-03\n",
            " 6.93921335e-03 7.68027156e-03 1.71531408e-04 4.43227336e-03\n",
            " 3.51124476e-03 8.32235864e-03 1.41788722e-02 4.79662015e-03\n",
            " 3.15465533e-03 8.89983933e-03 8.80438559e-03 6.91959807e-03\n",
            " 1.32632372e-02 4.58132069e-03 9.30288371e-03 5.50423021e-03\n",
            " 9.71977572e-03 1.41976827e-02 4.78723089e-03 9.78210566e-03\n",
            " 1.87030912e-04 9.13661870e-03 1.17567829e-02 1.62668754e-03\n",
            " 8.17172001e-03 9.81197424e-03 7.96787813e-03 6.69664929e-03\n",
            " 3.68521110e-03 1.31040372e-03 1.21848633e-02 2.82141664e-03\n",
            " 1.97482152e-03 1.36161625e-02 1.28985687e-03 4.70366092e-03\n",
            " 1.63062460e-03 5.75104360e-03 3.89031702e-03 1.33522627e-02\n",
            " 1.42104310e-03 1.13208828e-02 7.50007428e-03 3.05079580e-03\n",
            " 3.03761781e-03 6.19344167e-03 2.17023350e-03 1.38163138e-02\n",
            " 4.24300759e-06 1.21399805e-02 7.82867598e-04 3.78540320e-03\n",
            " 1.21987276e-03 1.07267895e-02 9.94967822e-03 9.92588192e-06\n",
            " 1.03927045e-02 1.08292799e-02 2.28496765e-03 1.77059759e-04\n",
            " 8.80639086e-03 1.32632372e-02 3.69664025e-03 2.97885225e-03\n",
            " 8.77888778e-03 1.66391506e-03 7.46982009e-04 2.07196549e-03\n",
            " 1.42479509e-02 6.14269131e-04 2.06905962e-03 1.05988788e-03\n",
            " 3.55954292e-03 1.38040162e-02 1.08129226e-02 7.62937129e-03\n",
            " 5.36279470e-05 1.32662544e-02 5.53116360e-04 1.08595843e-02\n",
            " 8.26998837e-04 1.19091059e-02 1.03209943e-02 1.24005957e-02\n",
            " 9.73704317e-03 1.25309588e-02 1.36368938e-02 1.38502034e-02\n",
            " 9.72268022e-03 9.39913747e-03 5.25435304e-03 8.11735098e-03\n",
            " 8.10018269e-03 7.95605085e-03 9.59104218e-03 1.66391506e-03\n",
            " 1.09060166e-02 1.04978994e-02 2.06248402e-03 1.17511200e-02\n",
            " 3.18104002e-03 9.39934457e-03 4.81055855e-03 1.03872716e-02\n",
            " 1.84754801e-03 1.27777675e-02 3.90252591e-03 1.15147455e-02\n",
            " 7.58348324e-03 1.20678702e-02 1.22205266e-02 4.28919651e-03\n",
            " 9.11835399e-03 5.50940214e-04 2.72339702e-03 9.29506644e-03\n",
            " 3.64570761e-03 7.33509313e-03 7.92351114e-03 1.87030912e-04\n",
            " 4.58797804e-03 1.07152911e-02 2.79313487e-03 3.71510937e-03\n",
            " 1.01477773e-02 8.02022694e-03 4.36379639e-03 5.39123451e-04\n",
            " 1.40653866e-03 1.27636570e-02 1.14519233e-03 7.01674735e-03\n",
            " 4.92915330e-03 6.89999909e-04 4.20836417e-03 1.40571608e-02\n",
            " 1.13742772e-02 2.96316565e-04 7.53619716e-03 1.66391506e-03\n",
            " 7.37930712e-03 1.38259273e-02 1.09865268e-02 1.27410036e-02\n",
            " 5.56237373e-03 7.18030174e-03 8.35913658e-03 1.06821328e-02\n",
            " 1.03037829e-02 2.17657055e-03 1.26454165e-02 3.47358417e-03\n",
            " 1.09056169e-03 7.37196593e-03 8.04546565e-03 8.68952460e-03\n",
            " 2.43736943e-04 1.09329058e-02 3.68521110e-03 5.92324286e-03\n",
            " 3.78540320e-03 9.20097530e-03 4.00325935e-04 2.49774855e-03\n",
            " 4.88817643e-04 8.10807784e-03 9.02770610e-03 2.01264146e-03\n",
            " 4.60949426e-03 1.49008394e-03 9.73968652e-03 1.15213002e-02\n",
            " 9.83680002e-03 1.40830316e-02 6.99551735e-03 9.62116118e-03\n",
            " 1.01418736e-02 1.32928778e-04 6.87407205e-03 2.15310583e-03\n",
            " 3.10674266e-03 1.40057133e-02 3.05085342e-03 4.68656104e-03\n",
            " 8.31208865e-03 1.18472939e-02 3.88577442e-03 6.27207513e-03\n",
            " 2.40492936e-03 1.03829095e-02 9.58939710e-03 1.88978673e-03\n",
            " 5.28990756e-04 2.59184239e-03 1.34961214e-02 1.39201035e-02\n",
            " 4.14787095e-03 9.93392520e-03 1.37032223e-02 1.37449272e-02\n",
            " 7.61446374e-03 3.73393421e-03 5.70710997e-04 3.23269483e-03\n",
            " 6.27752004e-03 5.06775459e-03 7.83569761e-03 4.56078398e-03\n",
            " 3.06355792e-04 2.56160216e-03 2.78673503e-03 7.68226123e-03\n",
            " 1.26449491e-02 1.37848186e-02 7.84775103e-03 2.06248402e-03\n",
            " 1.40722135e-02 1.33256192e-03 1.08873107e-02 2.39208945e-03\n",
            " 5.70878394e-03 1.03281708e-02 1.35445274e-02 1.13316462e-02\n",
            " 3.97895719e-03 1.36099079e-02 1.11457137e-02 5.08425056e-03\n",
            " 8.05088643e-04 1.03610371e-02 6.50180829e-03 4.05850526e-03\n",
            " 4.78755406e-03 3.60371558e-03 6.74886030e-03 5.00497078e-03\n",
            " 4.38078905e-03 2.76762224e-03 6.20554225e-03 1.02826603e-02\n",
            " 1.00887576e-03 6.50576714e-04 5.73589337e-03 1.34209207e-02\n",
            " 8.98872556e-04 1.91869830e-04 1.10268164e-02 9.05958065e-03\n",
            " 1.08066844e-02 1.21661017e-03 1.42658880e-03 1.97346597e-03\n",
            " 2.84143445e-03 6.83633205e-05 3.63897198e-03 5.34320837e-03\n",
            " 5.05347717e-03 1.98556964e-06 1.15082621e-02 6.26261291e-04\n",
            " 4.65890687e-07 1.05390676e-02 1.94689895e-05 3.58574943e-05\n",
            " 1.31409477e-02 1.03449315e-02 1.06610873e-02 1.43260644e-03\n",
            " 8.39154883e-04 1.10573040e-02 4.27051661e-03 3.83372003e-03\n",
            " 1.41961520e-02 4.86091329e-03 1.05328813e-02 4.86091329e-03\n",
            " 7.21797540e-03 1.00562440e-03 7.03167693e-03 1.81999904e-03\n",
            " 3.80680868e-03 2.73554053e-04 3.61538160e-04 1.03512613e-02\n",
            " 1.41549082e-02 2.94897103e-03 1.35751409e-02 4.74564828e-03\n",
            " 4.09578186e-03 2.26052785e-04 5.10067346e-03 5.96466108e-03\n",
            " 6.44212290e-03 1.29683069e-02 5.38056631e-03 4.56638899e-03\n",
            " 4.79662015e-03 6.96593110e-03 1.15316626e-02 2.90377354e-03\n",
            " 1.28316893e-02 1.05753819e-02 1.42149699e-02 5.35946846e-03\n",
            " 5.59643903e-03 1.24232875e-02 4.57573932e-03 3.83372003e-03\n",
            " 1.32354740e-02 1.38263656e-02 7.52190761e-03 1.04287344e-02\n",
            " 1.32129938e-03 1.18687173e-03 3.63023654e-03 5.23071500e-03\n",
            " 3.83978764e-03 6.38368072e-04 9.03421666e-03 1.07525279e-02\n",
            " 8.05470483e-03 5.42459592e-03 2.15439175e-03 6.90734664e-04\n",
            " 9.22818809e-03 6.87698826e-03 7.01722240e-03 8.50020220e-03\n",
            " 1.09924298e-02 9.55457894e-03 2.78011146e-03 1.44412955e-03\n",
            " 1.23761410e-03 1.41083857e-02 5.96847710e-03 9.46142598e-03\n",
            " 1.05593734e-02 6.99993174e-03 8.44242760e-03 1.32733650e-02\n",
            " 4.03792610e-03 1.35834942e-02 7.69738604e-03 3.61216217e-03\n",
            " 8.71272714e-03 1.30212650e-02 1.28169170e-02 2.99809228e-03\n",
            " 1.27002971e-02 3.29254069e-03 8.62985882e-03 4.54004102e-04\n",
            " 9.02123583e-04 8.75552733e-03 1.40057133e-02 8.14676745e-03\n",
            " 2.59542989e-03 9.72268022e-03 6.01689970e-03 7.99378057e-03\n",
            " 3.72743535e-04 5.47234124e-03 1.41812844e-02 7.33477905e-03\n",
            " 3.56071577e-03 1.04161441e-02 6.72915338e-03 3.49629449e-03\n",
            " 7.59089782e-03 8.80608743e-03 9.32467266e-03 7.16971371e-03\n",
            " 4.67216808e-03 5.49979768e-03 6.50743542e-03 7.82867598e-04\n",
            " 3.80210819e-03]\n",
            "3540 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.74415470e-03 4.23028270e-03 4.57772862e-03 3.81293789e-03\n",
            " 6.89913630e-04 1.22979960e-02 9.06859001e-03 3.91575017e-03\n",
            " 6.48207136e-03 1.21588167e-02 8.20385660e-03 1.13025570e-02\n",
            " 8.04957257e-03 1.01432930e-02 1.04403151e-02 1.17784872e-02\n",
            " 6.30221971e-03 5.47257512e-03 7.44195451e-03 5.49874257e-03\n",
            " 8.01063274e-03 1.40044702e-03 9.20282882e-03 4.79383191e-03\n",
            " 5.35131896e-03 3.83352166e-03 1.30672550e-05 5.73149050e-03\n",
            " 1.27885523e-02 1.36218792e-02 2.86114664e-03 1.05336754e-02\n",
            " 1.31952126e-02 9.55338439e-05 9.26343303e-03 1.27885523e-02\n",
            " 1.22048939e-02 1.84717266e-03 4.46335604e-09 2.87393494e-03\n",
            " 1.65506180e-05 6.26705642e-03 1.21724277e-02 8.69173293e-03\n",
            " 4.11993542e-04 1.58354621e-07 1.11180956e-02 7.52141417e-03\n",
            " 7.03344065e-03 2.84147152e-03 7.47117720e-03 1.04859689e-02\n",
            " 9.70972421e-03 5.28700613e-03 8.78873329e-03 2.12570007e-03\n",
            " 1.15437161e-02 1.35841416e-02 9.26626813e-03 1.32316592e-02\n",
            " 1.10893957e-02 1.09570777e-02 9.78051714e-04 7.50444348e-03\n",
            " 2.75250029e-03 3.57894380e-04 1.04982920e-03 7.99126959e-03\n",
            " 3.24760795e-03 9.74285694e-03 1.38756571e-02 9.70972421e-03\n",
            " 1.25067412e-02 4.18526749e-04 1.35394077e-02 7.29822929e-03\n",
            " 5.00472874e-03 4.89304718e-03 1.14140739e-02 4.66670716e-04\n",
            " 1.09998243e-02 1.00418377e-02 4.16508548e-03 4.13270349e-03\n",
            " 1.13318282e-03 5.58973076e-03 1.09516856e-02 5.80326761e-04\n",
            " 1.01938987e-03 1.01430572e-02 5.25320137e-03 6.27809243e-05\n",
            " 3.67987039e-03 1.27191228e-02 9.55468990e-03 1.06266182e-02\n",
            " 1.09099896e-02 1.79489684e-03 7.53403726e-03 8.44377086e-03\n",
            " 6.34565415e-04 2.04022907e-03 1.06300755e-02 9.82382170e-03\n",
            " 7.70360276e-03 8.98509030e-03 4.99253702e-03 1.22048939e-02\n",
            " 3.55643705e-03 6.58903928e-05 9.10219573e-03 1.29553512e-02\n",
            " 3.88087002e-03 3.55643705e-03 1.18790776e-02 1.17323144e-02\n",
            " 8.80478188e-03 6.65069480e-03 9.80709146e-04 1.23778322e-02\n",
            " 9.51660100e-03 7.28620275e-03 1.14430935e-02 1.46693785e-03\n",
            " 1.26309698e-02 4.14117423e-05 8.71803419e-03 4.68413856e-03\n",
            " 3.03239443e-03 1.00789306e-02 6.96314294e-03 9.01051854e-03\n",
            " 4.47272341e-03 8.98002898e-03 1.03802589e-02 9.52080325e-03\n",
            " 9.75251745e-03 4.46335604e-09 3.88404541e-03 8.95724545e-03\n",
            " 8.54789380e-03 1.04665089e-03 1.27257285e-02 1.29441771e-02\n",
            " 4.12576973e-03 7.86873210e-03 1.72070827e-03 7.64126844e-03\n",
            " 2.04570602e-03 7.38591995e-03 4.08411426e-03 1.13572882e-02\n",
            " 8.60746703e-03 5.60117982e-03 5.33074115e-03 6.60170551e-03\n",
            " 2.97750214e-03 8.20385660e-03 1.27326997e-02 1.29508628e-02\n",
            " 9.25221830e-03 5.04721034e-03 1.04135909e-02 4.16508548e-03\n",
            " 1.05336754e-02 9.43883521e-03 7.56100306e-03 1.20264306e-02\n",
            " 9.07166693e-03 5.76342511e-03 1.07504083e-02 7.50752705e-03\n",
            " 1.18935822e-02 2.42274378e-03 1.34979184e-02 1.54271891e-04\n",
            " 4.01139363e-03 1.02727042e-02 1.09928212e-02 4.02263022e-03\n",
            " 9.98751211e-03 3.31192040e-03 1.36861673e-02 6.02682038e-03\n",
            " 7.38998078e-03 1.00712561e-02 5.24684629e-04 3.06489954e-03\n",
            " 1.09252885e-02 6.03497582e-03 1.30030906e-02 1.20521753e-06\n",
            " 1.14238652e-02 8.78847535e-05 7.89314627e-04 2.85181058e-03\n",
            " 1.25461676e-02 6.47437516e-03 2.94171952e-03 9.27322186e-03\n",
            " 5.09596687e-03 4.11835186e-04 5.17977917e-03 5.34892676e-03\n",
            " 1.24459947e-02 1.11656994e-03 1.33997306e-02 1.04618193e-02\n",
            " 8.37997063e-04 4.48365277e-03 1.22979960e-02 6.63865322e-03\n",
            " 8.28642879e-03 5.40298856e-03 5.85978928e-03 4.37437074e-03\n",
            " 5.51771386e-03 5.28859898e-03 3.19705296e-03 7.53722581e-03\n",
            " 4.16508548e-03 9.82256028e-03 7.69292295e-03 3.61313481e-03\n",
            " 1.20667863e-03 1.47457198e-03 8.94023708e-03 3.99651254e-03\n",
            " 9.98636097e-03 1.17499590e-02 1.50031767e-03 5.06753727e-03\n",
            " 9.06830137e-03 9.53645069e-05 7.88466360e-03 2.35976608e-16\n",
            " 3.01864119e-03 6.09102338e-03 1.25930132e-02 1.03286116e-02\n",
            " 1.38877783e-02 1.13436051e-02 2.24057233e-04 8.04105662e-03\n",
            " 1.00828834e-02 9.98751211e-03 7.50444348e-03 2.82132101e-03\n",
            " 3.97472185e-03 3.13649373e-03 1.14430935e-02 2.09082947e-03\n",
            " 3.54789602e-03 1.22773861e-02 6.56029668e-03 7.27090074e-03\n",
            " 1.60296343e-03 2.40973811e-04 7.02621635e-03 1.30291438e-02\n",
            " 4.66292310e-03 6.55031492e-03 1.19522081e-02 3.87377727e-03\n",
            " 3.91925998e-04 1.39405234e-02 8.42352063e-03 1.98882625e-03\n",
            " 4.40433366e-03 3.35928402e-03 6.93440762e-03 7.64559524e-03\n",
            " 1.71149531e-04 4.42922561e-03 3.50957615e-03 8.30975654e-03\n",
            " 4.78668323e-03 3.15078829e-03 8.90706592e-03 8.78200078e-03\n",
            " 6.89880274e-03 1.32566997e-02 4.57193109e-03 9.27380518e-03\n",
            " 5.49874257e-03 9.69387660e-03 4.78157072e-03 9.76343901e-03\n",
            " 1.86757561e-04 9.13053784e-03 1.17542968e-02 1.62240717e-03\n",
            " 8.17441812e-03 9.81312025e-03 7.95175979e-03 6.68555487e-03\n",
            " 3.67987039e-03 1.30983642e-03 1.21800846e-02 2.82071043e-03\n",
            " 1.97425705e-03 1.36064062e-02 1.28534811e-03 4.69144400e-03\n",
            " 1.63015104e-03 5.76342511e-03 3.88977117e-03 1.33471332e-02\n",
            " 1.41552411e-03 1.12732262e-02 7.47856000e-03 3.04758421e-03\n",
            " 3.03171730e-03 6.18451776e-03 2.16805872e-03 1.38006273e-02\n",
            " 4.23472168e-06 1.21415293e-02 7.79951433e-04 3.77768179e-03\n",
            " 1.21585696e-03 1.07034213e-02 9.93371187e-03 9.90555865e-06\n",
            " 1.03891476e-02 1.08284713e-02 2.27997881e-03 1.76869639e-04\n",
            " 8.79511325e-03 1.32566997e-02 3.69458718e-03 2.97911935e-03\n",
            " 8.77612756e-03 1.66549660e-03 7.44668739e-04 2.06571779e-03\n",
            " 6.12783336e-04 2.06582946e-03 1.05452890e-03 3.55683401e-03\n",
            " 1.37928788e-02 1.07850481e-02 7.62848152e-03 5.35643499e-05\n",
            " 1.32453744e-02 5.51893748e-04 1.08565122e-02 8.26300615e-04\n",
            " 1.19006006e-02 1.03250877e-02 1.23946803e-02 9.72301572e-03\n",
            " 1.24978199e-02 1.36079300e-02 1.38329887e-02 9.70972421e-03\n",
            " 9.37948334e-03 5.24014083e-03 8.11129061e-03 8.07794236e-03\n",
            " 7.93570775e-03 9.57144079e-03 1.66549660e-03 1.09152959e-02\n",
            " 1.05003372e-02 2.05918748e-03 1.17207160e-02 3.17113127e-03\n",
            " 9.37641019e-03 4.80584703e-03 1.03740840e-02 1.84367401e-03\n",
            " 1.27720194e-02 3.90060031e-03 1.15072384e-02 7.56655469e-03\n",
            " 1.20681120e-02 1.21809516e-02 4.29042462e-03 9.08882018e-03\n",
            " 5.48955433e-04 2.72185824e-03 9.27022998e-03 3.64655968e-03\n",
            " 7.32467813e-03 7.90014246e-03 1.86757561e-04 4.57295591e-03\n",
            " 1.06742101e-02 2.78291734e-03 3.71421842e-03 1.01083763e-02\n",
            " 8.00623573e-03 4.36646826e-03 5.37653970e-04 1.40341895e-03\n",
            " 1.27355058e-02 1.14306800e-03 7.01662155e-03 4.92275350e-03\n",
            " 6.89913630e-04 4.20957945e-03 1.40320441e-02 1.13870366e-02\n",
            " 2.95162675e-04 7.53761080e-03 1.66549660e-03 7.36512259e-03\n",
            " 1.38128745e-02 1.09801975e-02 1.27083239e-02 5.56244922e-03\n",
            " 7.16841542e-03 8.33497220e-03 1.06698183e-02 1.03043851e-02\n",
            " 2.17674225e-03 1.26368694e-02 3.46755939e-03 1.08790598e-03\n",
            " 7.37391685e-03 8.02286992e-03 8.64269515e-03 2.42785899e-04\n",
            " 1.09246484e-02 3.67987039e-03 5.91507762e-03 3.77768179e-03\n",
            " 9.18634630e-03 4.00382526e-04 2.49192044e-03 4.87675347e-04\n",
            " 8.10447526e-03 9.01109280e-03 2.01283283e-03 4.59925629e-03\n",
            " 1.48949404e-03 9.72487441e-03 1.15136607e-02 9.82798398e-03\n",
            " 1.40193133e-02 6.98355315e-03 9.58268018e-03 1.01314627e-02\n",
            " 1.32805641e-04 6.87112779e-03 2.14856104e-03 3.09216844e-03\n",
            " 1.39809557e-02 3.04956684e-03 4.68413856e-03 8.32303836e-03\n",
            " 1.18512935e-02 3.88087002e-03 6.25755681e-03 2.40652786e-03\n",
            " 1.03738197e-02 9.57498366e-03 1.88598793e-03 5.29094050e-04\n",
            " 2.58717759e-03 1.34731347e-02 1.39046964e-02 4.13808511e-03\n",
            " 9.91243224e-03 1.36861673e-02 1.37507834e-02 7.60352710e-03\n",
            " 3.73445422e-03 5.70022367e-04 3.22761370e-03 6.25904085e-03\n",
            " 5.07135839e-03 7.82742862e-03 4.54960662e-03 3.06245913e-04\n",
            " 2.55803803e-03 2.78785402e-03 7.68709545e-03 1.26233232e-02\n",
            " 1.37727127e-02 7.83688917e-03 2.05918748e-03 1.40881562e-02\n",
            " 1.32977783e-03 1.08551804e-02 2.38198718e-03 5.70681294e-03\n",
            " 1.03268274e-02 1.35046089e-02 1.13207144e-02 3.97716971e-03\n",
            " 1.35751964e-02 1.11107634e-02 5.07111191e-03 7.98520017e-04\n",
            " 1.03540988e-02 6.48528554e-03 4.04749379e-03 4.78181724e-03\n",
            " 3.59917203e-03 6.71294349e-03 4.99400965e-03 4.37884513e-03\n",
            " 2.76536797e-03 6.20332510e-03 1.02875201e-02 1.00753945e-03\n",
            " 6.49348918e-04 5.73149050e-03 1.34072873e-02 8.98750753e-04\n",
            " 1.91314015e-04 1.10306996e-02 9.05648016e-03 1.08050301e-02\n",
            " 1.21612254e-03 1.42493868e-03 1.97020914e-03 2.84147152e-03\n",
            " 6.81894512e-05 3.63412097e-03 5.34081111e-03 5.04537254e-03\n",
            " 1.97215094e-06 1.14770037e-02 6.24795823e-04 4.67080141e-07\n",
            " 1.04966318e-02 1.93931220e-05 3.56702285e-05 1.31197869e-02\n",
            " 1.03353737e-02 1.06576524e-02 1.43134716e-03 8.37767560e-04\n",
            " 1.10386692e-02 4.27595544e-03 3.83352166e-03 4.84995296e-03\n",
            " 1.05351477e-02 4.84995296e-03 7.21062266e-03 1.00404973e-03\n",
            " 7.01284951e-03 1.81824842e-03 3.79647208e-03 2.73834786e-04\n",
            " 3.60766958e-04 1.03387045e-02 2.94437942e-03 1.35742821e-02\n",
            " 4.74317998e-03 4.09737699e-03 2.25477201e-04 5.09309034e-03\n",
            " 5.93676904e-03 6.44172503e-03 1.29557076e-02 5.38161532e-03\n",
            " 4.55787264e-03 4.78668323e-03 6.96561201e-03 1.15292568e-02\n",
            " 2.89429703e-03 1.28102119e-02 1.05609211e-02 5.37076696e-03\n",
            " 5.58240916e-03 1.24095482e-02 4.57159980e-03 3.83352166e-03\n",
            " 1.32308528e-02 1.38043041e-02 7.52453855e-03 1.04167346e-02\n",
            " 1.31906396e-03 1.18496673e-03 3.61884819e-03 5.23343704e-03\n",
            " 3.82568653e-03 6.38233356e-04 9.02265004e-03 1.07431443e-02\n",
            " 8.02712699e-03 5.42510363e-03 2.15396144e-03 6.89430526e-04\n",
            " 9.23067423e-03 6.87380783e-03 6.99467383e-03 8.50635202e-03\n",
            " 1.09784175e-02 9.54412796e-03 2.77855929e-03 1.44263086e-03\n",
            " 1.23619450e-03 5.96752878e-03 9.45514094e-03 1.05397878e-02\n",
            " 6.98614826e-03 8.41781983e-03 1.32537916e-02 4.02186928e-03\n",
            " 1.35526425e-02 7.69111049e-03 3.61177103e-03 8.70086852e-03\n",
            " 1.30060056e-02 1.27979241e-02 2.99151735e-03 1.26614536e-02\n",
            " 3.28108151e-03 8.62559620e-03 4.52621440e-04 9.00644348e-04\n",
            " 8.72685154e-03 1.39809557e-02 8.14086076e-03 2.58959123e-03\n",
            " 9.70972421e-03 6.00533349e-03 7.98680375e-03 3.72447754e-04\n",
            " 5.47530937e-03 7.33343342e-03 3.54990503e-03 1.04065188e-02\n",
            " 6.72797050e-03 3.48866477e-03 7.58527202e-03 8.79426129e-03\n",
            " 9.32032517e-03 7.14127198e-03 4.66490470e-03 5.50127015e-03\n",
            " 6.50680570e-03 7.79951433e-04 3.79577878e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3550 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.74072774e-03 4.22215851e-03 4.57799115e-03 3.80897139e-03\n",
            " 6.89485331e-04 1.23009535e-02 9.07058169e-03 3.90995066e-03\n",
            " 6.46762269e-03 1.21427061e-02 8.18813768e-03 1.12951997e-02\n",
            " 8.04365627e-03 1.01286736e-02 1.04275389e-02 1.17464420e-02\n",
            " 6.30020211e-03 5.46227210e-03 7.45279150e-03 5.48791912e-03\n",
            " 8.00189458e-03 1.39550821e-03 9.19471802e-03 4.80190372e-03\n",
            " 5.34288774e-03 3.83363084e-03 1.30315069e-05 5.72488624e-03\n",
            " 1.27864690e-02 1.36090726e-02 2.85589004e-03 1.05325959e-02\n",
            " 1.31782992e-02 9.52696955e-05 9.26265170e-03 1.27864690e-02\n",
            " 1.21978717e-02 1.84587097e-03 4.44466092e-09 2.86785477e-03\n",
            " 1.65590104e-05 6.26467365e-03 1.21743426e-02 8.68558703e-03\n",
            " 4.09730666e-04 1.58395659e-07 1.11083830e-02 7.51192149e-03\n",
            " 7.02322634e-03 2.84182186e-03 7.45255807e-03 1.04834417e-02\n",
            " 9.70646495e-03 5.28473351e-03 8.76994494e-03 2.11677254e-03\n",
            " 1.15254438e-02 1.35769319e-02 9.24533267e-03 1.32384956e-02\n",
            " 1.10796637e-02 1.09216032e-02 9.74652023e-04 7.50134288e-03\n",
            " 2.75808182e-03 3.55623823e-04 1.04701172e-03 7.96710408e-03\n",
            " 3.24049627e-03 9.73571265e-03 9.70646495e-03 1.24882852e-02\n",
            " 4.17881441e-04 1.35381897e-02 7.29990485e-03 4.98956113e-03\n",
            " 4.89330506e-03 1.13931314e-02 4.66382201e-04 1.09795670e-02\n",
            " 1.00270268e-02 4.16291502e-03 4.13079157e-03 1.13407007e-03\n",
            " 5.56570472e-03 1.09013700e-02 5.78721008e-04 1.01617348e-03\n",
            " 1.01410483e-02 5.25835158e-03 6.25601027e-05 3.67492179e-03\n",
            " 1.26903449e-02 9.54931977e-03 1.06095994e-02 1.08962941e-02\n",
            " 1.78971676e-03 7.51166643e-03 8.43994556e-03 6.33472949e-04\n",
            " 2.02999312e-03 1.06103496e-02 9.82231828e-03 7.69146373e-03\n",
            " 8.97037226e-03 4.97881752e-03 1.21978717e-02 3.55521285e-03\n",
            " 6.58389833e-05 9.07230578e-03 1.29522892e-02 3.87486652e-03\n",
            " 3.55521285e-03 1.18389236e-02 1.17201061e-02 8.79624471e-03\n",
            " 6.64922789e-03 9.80759424e-04 1.23631708e-02 9.52587217e-03\n",
            " 7.26989813e-03 1.14413915e-02 1.46456973e-03 1.26075448e-02\n",
            " 4.12987885e-05 8.70683063e-03 4.67104311e-03 3.02997460e-03\n",
            " 1.00691722e-02 6.94778714e-03 8.96123941e-03 4.47122290e-03\n",
            " 8.94711672e-03 1.03699344e-02 9.50592413e-03 9.73031200e-03\n",
            " 4.44466092e-09 3.86952977e-03 8.93452985e-03 8.52515195e-03\n",
            " 1.03913697e-03 1.26773920e-02 1.29508584e-02 4.12309435e-03\n",
            " 7.86331950e-03 1.71779521e-03 7.62878255e-03 2.04508390e-03\n",
            " 7.38266480e-03 4.07624807e-03 1.13552739e-02 8.59594378e-03\n",
            " 5.59270352e-03 5.32411651e-03 6.59700265e-03 2.96592403e-03\n",
            " 8.18813768e-03 1.27071301e-02 1.29287061e-02 9.26457312e-03\n",
            " 5.05059001e-03 1.04037808e-02 4.16291502e-03 1.05325959e-02\n",
            " 9.34485050e-03 7.52724668e-03 1.20206447e-02 9.06647914e-03\n",
            " 5.77239517e-03 1.07384098e-02 7.51711573e-03 1.18712627e-02\n",
            " 2.42279767e-03 1.34821941e-02 1.53816867e-04 3.99451406e-03\n",
            " 1.02517340e-02 1.09853079e-02 4.00374676e-03 9.96824316e-03\n",
            " 3.29930929e-03 1.36460631e-02 6.00552100e-03 7.39400559e-03\n",
            " 1.00528229e-02 5.22713615e-04 3.06759914e-03 1.09225141e-02\n",
            " 6.03002124e-03 1.29803482e-02 1.19801685e-06 1.13959588e-02\n",
            " 8.77217662e-05 7.87500675e-04 2.84923173e-03 1.25242752e-02\n",
            " 6.46925059e-03 2.93284430e-03 9.27618208e-03 5.10388051e-03\n",
            " 4.10403847e-04 5.17752862e-03 5.34424860e-03 1.24373738e-02\n",
            " 1.11682406e-03 1.33894032e-02 1.04433026e-02 8.35157142e-04\n",
            " 4.48455058e-03 1.23009535e-02 6.63437979e-03 8.28187681e-03\n",
            " 5.39088404e-03 5.85083576e-03 4.37054759e-03 5.50609407e-03\n",
            " 5.27474193e-03 3.18708869e-03 7.53960086e-03 4.16291502e-03\n",
            " 9.80797945e-03 7.67536084e-03 3.60867121e-03 1.20588207e-03\n",
            " 1.46724044e-03 8.94004054e-03 3.99119066e-03 9.97621672e-03\n",
            " 1.17015556e-02 1.49287829e-03 5.06286804e-03 9.05793005e-03\n",
            " 9.51571842e-05 7.87329936e-03 2.35001142e-16 3.01612773e-03\n",
            " 6.08534782e-03 1.25813064e-02 1.03255703e-02 1.13357175e-02\n",
            " 2.23799828e-04 8.04195963e-03 1.00718624e-02 9.96824316e-03\n",
            " 7.50134288e-03 2.81297334e-03 3.95988203e-03 3.13069263e-03\n",
            " 1.14413915e-02 2.08928187e-03 3.54443912e-03 1.22651674e-02\n",
            " 6.56155492e-03 7.26009838e-03 1.59483148e-03 2.39636564e-04\n",
            " 7.00685535e-03 1.30252533e-02 4.66103225e-03 6.54788785e-03\n",
            " 1.19515786e-02 3.87463698e-03 3.90408969e-04 8.41994319e-03\n",
            " 1.98541916e-03 4.38579443e-03 3.35635268e-03 6.91571146e-03\n",
            " 7.66112712e-03 1.70707552e-04 4.42752637e-03 3.50167244e-03\n",
            " 8.30025202e-03 4.77795490e-03 3.14524186e-03 8.90200870e-03\n",
            " 8.78852676e-03 6.89449605e-03 1.32601615e-02 4.56326430e-03\n",
            " 9.25720301e-03 5.48791912e-03 9.67892690e-03 4.78304604e-03\n",
            " 9.75518888e-03 1.86648891e-04 9.13061173e-03 1.17208640e-02\n",
            " 1.61738957e-03 8.16441576e-03 9.81413184e-03 7.95251007e-03\n",
            " 6.68437777e-03 3.67492179e-03 1.30913917e-03 1.21758758e-02\n",
            " 2.81167261e-03 1.97431614e-03 1.35944680e-02 1.27315588e-03\n",
            " 4.68012885e-03 1.62152046e-03 5.77239517e-03 3.88639301e-03\n",
            " 1.33689678e-02 1.41900946e-03 1.12529898e-02 7.45847341e-03\n",
            " 3.03349186e-03 3.01944519e-03 6.16068672e-03 2.16540509e-03\n",
            " 1.38160391e-02 4.22393279e-06 1.21423345e-02 7.79054374e-04\n",
            " 3.76133951e-03 1.21409035e-03 1.07070501e-02 9.88807781e-03\n",
            " 9.88064939e-06 1.04044744e-02 1.08154171e-02 2.27583140e-03\n",
            " 1.76446486e-04 8.77526146e-03 1.32601615e-02 3.68706099e-03\n",
            " 2.97756025e-03 8.76748095e-03 1.66235360e-03 7.43838112e-04\n",
            " 2.06253580e-03 6.09999592e-04 2.06350413e-03 1.05213022e-03\n",
            " 3.55272063e-03 1.37927439e-02 1.07664116e-02 7.61864679e-03\n",
            " 5.34456737e-05 1.32147814e-02 5.50872994e-04 1.08551457e-02\n",
            " 8.24733087e-04 1.19036485e-02 1.03200352e-02 1.23738538e-02\n",
            " 9.71505228e-03 1.24835346e-02 1.35962193e-02 9.70646495e-03\n",
            " 9.34116906e-03 5.23180112e-03 8.10833322e-03 8.07721236e-03\n",
            " 7.90749805e-03 9.55871899e-03 1.66235360e-03 1.09126607e-02\n",
            " 1.04953524e-02 2.05628371e-03 1.17228565e-02 3.16749570e-03\n",
            " 9.33373703e-03 4.80252924e-03 1.03564412e-02 1.84016323e-03\n",
            " 1.27657544e-02 3.89271669e-03 1.15150011e-02 7.55549104e-03\n",
            " 1.20628207e-02 1.21430089e-02 4.28786140e-03 9.09052816e-03\n",
            " 5.49069795e-04 2.71448255e-03 9.25414392e-03 3.62672326e-03\n",
            " 7.32348226e-03 7.89876425e-03 1.86648891e-04 4.56717866e-03\n",
            " 1.06583577e-02 2.78243029e-03 3.71422273e-03 1.00841020e-02\n",
            " 7.99324131e-03 4.36821663e-03 5.36263793e-04 1.40065479e-03\n",
            " 1.27182275e-02 1.14190366e-03 7.01451620e-03 4.91613244e-03\n",
            " 6.89485331e-04 4.21093840e-03 1.13838309e-02 2.94240908e-04\n",
            " 7.54212507e-03 1.66235360e-03 7.35600801e-03 1.37966836e-02\n",
            " 1.09641680e-02 1.26794029e-02 5.55908176e-03 7.16240371e-03\n",
            " 8.31642325e-03 1.06720231e-02 1.03099644e-02 2.17041016e-03\n",
            " 1.26412368e-02 3.45570247e-03 1.08644531e-03 7.31702111e-03\n",
            " 8.02521563e-03 8.63820379e-03 2.42835369e-04 1.09258045e-02\n",
            " 3.67492179e-03 5.90366348e-03 3.76133951e-03 9.17279162e-03\n",
            " 4.00146806e-04 2.48577292e-03 4.86622061e-04 8.07560938e-03\n",
            " 9.00469009e-03 2.01225444e-03 4.58514034e-03 1.48756999e-03\n",
            " 9.70457839e-03 1.15105886e-02 9.82953003e-03 6.98625717e-03\n",
            " 9.56445682e-03 1.01260204e-02 1.32762415e-04 6.86092762e-03\n",
            " 2.14487067e-03 3.08816689e-03 3.03844689e-03 4.67104311e-03\n",
            " 8.29413207e-03 1.18385467e-02 3.87486652e-03 6.24691741e-03\n",
            " 2.40411286e-03 1.03658901e-02 9.55944886e-03 1.88222664e-03\n",
            " 5.28890485e-04 2.57928204e-03 1.34575013e-02 4.13003052e-03\n",
            " 9.90023922e-03 1.36460631e-02 1.37596192e-02 7.57843563e-03\n",
            " 3.72702915e-03 5.70295890e-04 3.22648125e-03 6.25080727e-03\n",
            " 5.05962043e-03 7.81794149e-03 4.55061967e-03 3.05402700e-04\n",
            " 2.55662729e-03 2.77976900e-03 7.68320361e-03 1.25835701e-02\n",
            " 1.37628315e-02 7.82884261e-03 2.05628371e-03 1.32405865e-03\n",
            " 1.08506463e-02 2.37707213e-03 5.70060781e-03 1.03230544e-02\n",
            " 1.34789808e-02 1.13144808e-02 3.97714702e-03 1.35640366e-02\n",
            " 1.11008764e-02 5.06467385e-03 7.96157723e-04 1.03260614e-02\n",
            " 6.47614537e-03 4.03358751e-03 4.77100176e-03 3.60251217e-03\n",
            " 6.71613569e-03 4.99222008e-03 4.37368297e-03 2.76347955e-03\n",
            " 6.19687121e-03 1.02878534e-02 1.00832752e-03 6.49032306e-04\n",
            " 5.72488624e-03 1.34009637e-02 8.97435466e-04 1.90090523e-04\n",
            " 1.10119426e-02 9.03699150e-03 1.07925668e-02 1.21564301e-03\n",
            " 1.42461962e-03 1.96992974e-03 2.84182186e-03 6.80503673e-05\n",
            " 3.63301845e-03 5.32772962e-03 5.03866333e-03 1.96560587e-06\n",
            " 1.14629538e-02 6.23702132e-04 4.65914495e-07 1.04769121e-02\n",
            " 1.93769801e-05 3.54028828e-05 1.31212731e-02 1.03306099e-02\n",
            " 1.06425970e-02 1.42983129e-03 8.36415855e-04 1.10267785e-02\n",
            " 4.27227416e-03 3.83363084e-03 4.82719046e-03 1.05218901e-02\n",
            " 4.82719046e-03 7.20158060e-03 1.00342997e-03 7.01036962e-03\n",
            " 1.81273578e-03 3.79222291e-03 2.74003234e-04 3.59900692e-04\n",
            " 1.03030654e-02 2.93604492e-03 1.35525615e-02 4.73705302e-03\n",
            " 4.08838032e-03 2.25497606e-04 5.08766798e-03 5.92450111e-03\n",
            " 6.43011084e-03 1.29496741e-02 5.37309182e-03 4.55649426e-03\n",
            " 4.77795490e-03 6.94722043e-03 1.15165024e-02 2.89134110e-03\n",
            " 1.27885020e-02 1.05545505e-02 5.36923390e-03 5.56798942e-03\n",
            " 1.23990148e-02 4.56157740e-03 3.83363084e-03 1.32326496e-02\n",
            " 1.37769749e-02 7.51883421e-03 1.03843051e-02 1.31771917e-03\n",
            " 1.18503433e-03 3.61241123e-03 5.22401779e-03 3.82753257e-03\n",
            " 6.36467746e-04 9.01602057e-03 1.07357756e-02 8.00155387e-03\n",
            " 5.42814974e-03 2.15333182e-03 6.89020787e-04 9.22806041e-03\n",
            " 6.86414692e-03 6.97214922e-03 8.50714929e-03 1.09481986e-02\n",
            " 9.53502435e-03 2.77893906e-03 1.44268406e-03 1.23187340e-03\n",
            " 5.95794830e-03 9.43714617e-03 1.05192169e-02 6.97490978e-03\n",
            " 8.42683754e-03 1.32416890e-02 4.00351706e-03 1.35518550e-02\n",
            " 7.69039182e-03 3.60757628e-03 8.69612291e-03 1.29893746e-02\n",
            " 1.27932275e-02 2.98621371e-03 1.26477330e-02 3.26109526e-03\n",
            " 8.58765858e-03 4.51332255e-04 8.99151481e-04 8.66991660e-03\n",
            " 8.12893324e-03 2.58588762e-03 9.70646495e-03 6.00332205e-03\n",
            " 7.95991060e-03 3.71930343e-04 5.48026857e-03 7.32780374e-03\n",
            " 3.54474479e-03 1.03864130e-02 6.71221553e-03 3.49192380e-03\n",
            " 7.57945864e-03 8.78999558e-03 9.31029436e-03 7.14782177e-03\n",
            " 4.65509123e-03 5.48300025e-03 6.50454279e-03 7.79054374e-04\n",
            " 3.78894858e-03]\n",
            "3560 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.18009157e-03 4.36931658e-03 4.36036179e-03 3.60968512e-03\n",
            " 6.93341901e-04 1.23581936e-02 8.60450831e-03 3.81444512e-03\n",
            " 7.75708179e-03 1.17248472e-02 8.56622022e-03 1.08730449e-02\n",
            " 7.81984176e-03 1.17245731e-02 1.17108902e-02 1.17492492e-02\n",
            " 5.47930894e-03 5.10788839e-03 7.86213147e-03 5.89017757e-03\n",
            " 8.78552587e-03 1.50653737e-03 9.15887375e-03 4.22870943e-03\n",
            " 5.69883586e-03 3.88741794e-03 1.26674055e-05 4.50175685e-03\n",
            " 1.05959981e-02 3.48228283e-03 1.19009602e-02 1.28720609e-02\n",
            " 1.03410922e-04 7.56494189e-03 1.05959981e-02 1.02095806e-02\n",
            " 1.97916044e-03 4.38384211e-09 4.20604042e-03 1.70895290e-05\n",
            " 5.92550991e-03 1.25482388e-02 1.12284388e-02 3.12822701e-04\n",
            " 1.01182594e-07 1.20919755e-02 7.73102121e-03 7.50375881e-03\n",
            " 2.87167052e-03 7.13426989e-03 1.16814641e-02 9.80449730e-03\n",
            " 6.25876674e-03 9.45835815e-03 2.47645291e-03 1.04647421e-02\n",
            " 1.31309094e-02 8.90070961e-03 1.23153472e-02 1.15909011e-02\n",
            " 1.09737181e-02 9.75822874e-04 7.50979216e-03 2.49873331e-03\n",
            " 3.49650401e-04 1.13564915e-03 7.84274616e-03 2.97194898e-03\n",
            " 9.82963644e-03 9.80449730e-03 1.13761951e-02 4.09541775e-04\n",
            " 1.32069480e-02 8.20049907e-03 5.52676611e-03 4.52268155e-03\n",
            " 1.20741620e-02 4.70976968e-04 1.06070644e-02 8.89715671e-03\n",
            " 4.41347556e-03 4.51195575e-03 1.28397436e-03 6.11749167e-03\n",
            " 1.06916643e-02 6.97516829e-04 9.89574399e-04 1.03500675e-02\n",
            " 4.96067539e-03 6.00271955e-05 4.20051311e-03 1.13577470e-02\n",
            " 1.05017029e-02 1.58947573e-02 1.03499813e-02 1.79695493e-03\n",
            " 1.02090711e-02 1.00287155e-02 8.48654920e-04 2.39563992e-03\n",
            " 1.11238642e-02 1.03002602e-02 7.56282277e-03 9.62738581e-03\n",
            " 4.53668548e-03 1.02095806e-02 3.79560175e-03 7.95580654e-05\n",
            " 8.75955642e-03 1.38578713e-02 3.50016575e-03 3.79560175e-03\n",
            " 1.35563786e-02 1.13597977e-02 9.59949376e-03 6.30030274e-03\n",
            " 1.12289015e-03 1.22421715e-02 1.31293023e-02 7.48214586e-03\n",
            " 1.13097360e-02 1.34227256e-03 1.26020673e-02 3.42440206e-05\n",
            " 8.11712965e-03 5.47700639e-03 3.02691140e-03 1.10299755e-02\n",
            " 6.35260011e-03 9.25436372e-03 5.94170344e-03 8.24207843e-03\n",
            " 1.06229382e-02 1.00413961e-02 9.10298542e-03 4.38384211e-09\n",
            " 3.80551510e-03 8.00970150e-03 8.10097870e-03 1.04153436e-03\n",
            " 1.32369584e-02 1.18442021e-02 3.81620036e-03 9.36097235e-03\n",
            " 2.12120630e-03 7.03843244e-03 2.42108364e-03 8.25063948e-03\n",
            " 4.35033518e-03 1.18001910e-02 8.47953397e-03 6.06807913e-03\n",
            " 4.82026488e-03 6.37827560e-03 3.12796255e-03 8.56622022e-03\n",
            " 1.47390058e-02 1.23687460e-02 8.80209359e-03 4.94584335e-03\n",
            " 1.19544107e-02 4.41347556e-03 1.19009602e-02 9.17683850e-03\n",
            " 6.90737805e-03 1.10463709e-02 9.32869389e-03 5.37918154e-03\n",
            " 9.87853876e-03 7.03701810e-03 1.47778223e-02 2.41241090e-03\n",
            " 1.19434381e-02 2.07377890e-04 3.69005223e-03 1.08784761e-02\n",
            " 1.13627550e-02 4.06842598e-03 1.03810247e-02 3.83883363e-03\n",
            " 7.69213850e-03 8.61504424e-03 9.91485029e-03 5.42543256e-04\n",
            " 2.88930640e-03 1.11895280e-02 6.42212567e-03 1.75090680e-02\n",
            " 1.46898590e-06 1.21438431e-02 7.24005385e-05 7.57410063e-04\n",
            " 2.94336059e-03 1.77680469e-02 7.83646276e-03 3.00886478e-03\n",
            " 8.67816035e-03 4.97196752e-03 4.51223465e-04 6.44419722e-03\n",
            " 4.92158974e-03 1.19215407e-02 1.29911383e-03 1.49076441e-02\n",
            " 1.01678421e-02 8.82881614e-04 4.95243716e-03 1.23581936e-02\n",
            " 6.98777327e-03 8.33400599e-03 4.77306817e-03 5.85808597e-03\n",
            " 4.19867064e-03 4.93902212e-03 5.13086781e-03 3.14633613e-03\n",
            " 8.11110998e-03 4.41347556e-03 1.09379927e-02 8.48696320e-03\n",
            " 4.29911737e-03 1.27851911e-03 1.78913650e-03 9.59694621e-03\n",
            " 3.63066095e-03 9.50588797e-03 1.18188615e-02 1.47121808e-03\n",
            " 5.17265205e-03 1.19541853e-02 1.12847224e-04 7.42746024e-03\n",
            " 1.35304197e-16 3.48318331e-03 6.53707970e-03 1.64596279e-02\n",
            " 1.25403536e-02 1.24590620e-02 1.99161078e-04 9.32386599e-03\n",
            " 9.61134858e-03 1.03810247e-02 7.50979216e-03 2.92186940e-03\n",
            " 3.83665611e-03 2.95217705e-03 1.13097360e-02 3.36164194e-03\n",
            " 3.39906095e-03 1.13573129e-02 6.32832843e-03 8.18852683e-03\n",
            " 2.10143634e-03 2.11645256e-04 8.69754728e-03 1.71523861e-02\n",
            " 4.10368324e-03 6.89300679e-03 1.14097804e-02 3.64146402e-03\n",
            " 3.68975593e-04 7.76911993e-03 1.89425805e-03 4.17223095e-03\n",
            " 3.04885953e-03 9.04244933e-03 1.19590690e-02 1.77418215e-04\n",
            " 4.36214956e-03 3.08782111e-03 8.46437747e-03 5.43757168e-03\n",
            " 3.01873515e-03 8.60770100e-03 8.99730779e-03 6.53417443e-03\n",
            " 1.28141849e-02 5.16502593e-03 1.08622202e-02 5.89017757e-03\n",
            " 9.99235349e-03 4.55090947e-03 1.22829727e-02 1.71182123e-04\n",
            " 9.12517103e-03 1.96528927e-02 1.75954381e-03 8.44420192e-03\n",
            " 1.01141011e-02 7.26945904e-03 6.61846104e-03 4.20051311e-03\n",
            " 2.05469286e-03 1.48700741e-02 3.02852537e-03 1.63475514e-03\n",
            " 1.30716664e-02 1.36455189e-03 5.23034540e-03 2.01036021e-03\n",
            " 5.37918154e-03 3.75982872e-03 1.46475825e-02 1.17891406e-03\n",
            " 1.07304569e-02 7.13172519e-03 3.07396453e-03 3.00555246e-03\n",
            " 6.27099730e-03 3.59278266e-03 4.77331924e-06 1.19851602e-02\n",
            " 8.33765363e-04 3.57332532e-03 1.33459385e-03 1.20490628e-02\n",
            " 9.34539151e-03 1.33063563e-05 1.04672200e-02 1.93608242e-02\n",
            " 2.10820609e-03 1.94521931e-04 8.63287788e-03 1.28141849e-02\n",
            " 3.98637521e-03 3.07950423e-03 9.60932162e-03 1.68670915e-03\n",
            " 6.64397557e-04 2.25880847e-03 5.84257547e-04 1.71486385e-03\n",
            " 1.09519498e-03 3.50323836e-03 1.44082205e-02 8.23183191e-03\n",
            " 5.72720237e-05 1.30804752e-02 6.50174422e-04 1.03337971e-02\n",
            " 1.20170168e-03 1.18538914e-02 9.89478046e-03 1.16987831e-02\n",
            " 9.21214166e-03 1.24498723e-02 9.80449730e-03 8.89860140e-03\n",
            " 5.06801718e-03 7.89879503e-03 9.61941013e-03 7.73970028e-03\n",
            " 1.30066059e-02 1.68670915e-03 9.87441300e-03 9.11519089e-03\n",
            " 2.24779690e-03 1.15636677e-02 3.59980308e-03 9.36271847e-03\n",
            " 4.39032722e-03 9.87862080e-03 1.75210845e-03 1.83650947e-02\n",
            " 3.96231274e-03 1.09983001e-02 8.60360856e-03 1.48311111e-02\n",
            " 1.28860299e-02 4.02815265e-03 8.56962236e-03 4.90555301e-04\n",
            " 2.43430163e-03 9.91161372e-03 3.53054341e-03 7.29090404e-03\n",
            " 9.77592061e-03 1.71182123e-04 4.64982746e-03 1.45913134e-02\n",
            " 2.60357325e-03 3.45000081e-03 1.09542120e-02 8.47230757e-03\n",
            " 4.35223944e-03 5.40889021e-04 1.56135252e-03 1.32744052e-02\n",
            " 1.28673606e-03 7.56555240e-03 4.58203486e-03 6.93341901e-04\n",
            " 3.88462366e-03 1.28138582e-02 3.62197466e-04 9.38250680e-03\n",
            " 1.68670915e-03 6.91960886e-03 1.15718301e-02 1.20747328e-02\n",
            " 5.98928752e-03 6.93658185e-03 7.79128144e-03 1.00831940e-02\n",
            " 9.38579969e-03 2.38772856e-03 1.35458942e-02 3.80053037e-03\n",
            " 1.08372040e-03 8.80409035e-03 9.78359838e-03 9.00396254e-03\n",
            " 2.12305746e-04 1.04483435e-02 4.20051311e-03 6.88829277e-03\n",
            " 3.57332532e-03 9.54291869e-03 1.18815119e-03 2.59820968e-03\n",
            " 5.30382716e-04 8.45281189e-03 8.99356653e-03 5.40747672e-03\n",
            " 5.17053774e-03 1.43350108e-03 1.14581060e-02 1.25661867e-02\n",
            " 9.65163388e-03 6.72036961e-03 9.99185124e-03 1.02996286e-02\n",
            " 1.59860195e-04 6.80335239e-03 2.35745488e-03 4.47640150e-03\n",
            " 3.15441420e-03 5.47700639e-03 8.61294953e-03 1.16895019e-02\n",
            " 3.50016575e-03 7.02470452e-03 2.99836660e-03 9.27490464e-03\n",
            " 8.55827755e-03 1.90176146e-03 4.96988256e-04 2.66761694e-03\n",
            " 1.47376268e-02 4.82674887e-03 9.48149400e-03 9.13855772e-03\n",
            " 4.25483340e-03 5.14802410e-04 3.15673177e-03 5.97589587e-03\n",
            " 4.89080099e-03 7.42127278e-03 5.76343196e-03 3.28921890e-04\n",
            " 2.82312144e-03 2.64522818e-03 7.13610691e-03 1.23710890e-02\n",
            " 9.31014486e-03 2.24779690e-03 1.46644054e-03 1.18488930e-02\n",
            " 2.22126598e-03 5.84654973e-03 9.95090225e-03 1.49342413e-02\n",
            " 1.41301797e-02 3.79035996e-03 1.27474336e-02 1.09247252e-02\n",
            " 4.49827497e-03 8.97014491e-04 1.27343521e-02 6.57928895e-03\n",
            " 4.64615071e-03 6.17906005e-03 3.55060130e-03 8.94026096e-03\n",
            " 5.86396053e-03 5.26011579e-03 2.82898238e-03 6.05144735e-03\n",
            " 1.07501534e-02 9.85685877e-04 7.19157304e-04 4.50175685e-03\n",
            " 1.32766418e-02 8.41567188e-04 2.09523463e-04 1.09173959e-02\n",
            " 1.26268463e-02 1.54374280e-02 1.14775769e-03 1.62587173e-03\n",
            " 3.13710716e-03 2.87167052e-03 7.75467229e-05 3.39978094e-03\n",
            " 6.23003734e-03 4.81211361e-03 1.82605140e-06 1.07654512e-02\n",
            " 6.52334565e-04 3.98947700e-07 1.32703794e-02 2.56289721e-05\n",
            " 4.80535352e-05 1.33301280e-02 1.06805372e-02 1.18837685e-02\n",
            " 1.33181147e-03 9.50450410e-04 1.21170441e-02 4.06229261e-03\n",
            " 3.88741794e-03 5.29490502e-03 1.13793524e-02 5.29490502e-03\n",
            " 1.07819248e-02 1.09526767e-03 7.26722026e-03 1.87843052e-03\n",
            " 3.84206923e-03 2.34547039e-04 4.02235138e-04 8.90160445e-03\n",
            " 3.63408381e-03 1.25919411e-02 4.40478501e-03 3.71091772e-03\n",
            " 2.28583122e-04 4.84336547e-03 5.98135552e-03 7.30691892e-03\n",
            " 1.28629224e-02 6.46992415e-03 4.94167381e-03 5.43757168e-03\n",
            " 1.03060294e-02 1.08604293e-02 2.94319701e-03 1.18581778e-02\n",
            " 1.02979745e-02 7.59969645e-03 5.50320370e-03 1.34479130e-02\n",
            " 5.64905404e-03 3.88741794e-03 1.40524637e-02 7.69314007e-03\n",
            " 9.89271148e-03 1.22973564e-03 1.09019211e-03 3.30842651e-03\n",
            " 5.91034595e-03 4.07801925e-03 5.69643208e-04 1.12627332e-02\n",
            " 1.04843056e-02 8.13746345e-03 5.49096404e-03 1.91420776e-03\n",
            " 1.04263067e-03 8.94287766e-03 6.19908653e-03 6.72713784e-03\n",
            " 8.13836944e-03 1.26921614e-02 9.79850170e-03 2.68830594e-03\n",
            " 1.44427079e-03 1.25383150e-03 6.97553421e-03 9.31862691e-03\n",
            " 1.27236785e-02 6.67514630e-03 8.78728645e-03 1.71193210e-02\n",
            " 4.56034903e-03 1.27999435e-02 1.00907517e-02 4.67760938e-03\n",
            " 8.40200052e-03 1.17153779e-02 1.31528995e-02 3.23296570e-03\n",
            " 1.34935134e-02 3.41812556e-03 8.18786703e-03 4.53014232e-04\n",
            " 1.02592077e-03 7.45485617e-03 7.87020000e-03 2.59652465e-03\n",
            " 9.80449730e-03 5.20200863e-03 7.56741693e-03 3.56799058e-04\n",
            " 5.57236334e-03 7.19715229e-03 4.37824869e-03 1.11598672e-02\n",
            " 6.12059009e-03 3.58627561e-03 7.56674943e-03 8.29456082e-03\n",
            " 9.69763712e-03 7.52235918e-03 4.91604513e-03 6.27524739e-03\n",
            " 6.26070002e-03 8.33765363e-04 3.65732463e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3570 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.16248773e-03 4.35805772e-03 4.36243618e-03 3.59968914e-03\n",
            " 6.92327194e-04 1.23022563e-02 8.60630818e-03 3.79789144e-03\n",
            " 7.71589254e-03 1.16996401e-02 8.55494386e-03 1.08655181e-02\n",
            " 7.79188714e-03 1.16763490e-02 1.16957011e-02 1.17344411e-02\n",
            " 5.47639688e-03 5.08788409e-03 7.85587030e-03 5.88233202e-03\n",
            " 8.74964342e-03 1.49528942e-03 9.14940067e-03 4.21071542e-03\n",
            " 5.69012244e-03 3.88377920e-03 1.25044061e-05 4.49686717e-03\n",
            " 1.05771539e-02 3.46288092e-03 1.18688528e-02 1.28244053e-02\n",
            " 1.01681146e-04 7.54178289e-03 1.05771539e-02 1.02063204e-02\n",
            " 1.97019459e-03 4.34522505e-09 4.19490156e-03 1.70827772e-05\n",
            " 5.91226567e-03 1.24931179e-02 1.11503943e-02 3.11563357e-04\n",
            " 1.00720452e-07 1.20711396e-02 7.71607422e-03 7.49612401e-03\n",
            " 2.86879207e-03 7.12686564e-03 1.15982495e-02 9.79163194e-03\n",
            " 6.24898117e-03 9.41637408e-03 2.46228021e-03 1.04165651e-02\n",
            " 1.31256720e-02 8.89988498e-03 1.22865808e-02 1.15549882e-02\n",
            " 1.09596482e-02 9.61724937e-04 7.50588313e-03 2.49111905e-03\n",
            " 3.46762249e-04 1.12984101e-03 7.82128167e-03 2.96901222e-03\n",
            " 9.83182905e-03 9.79163194e-03 1.13552839e-02 4.09672706e-04\n",
            " 1.32064363e-02 8.14442239e-03 5.49765995e-03 4.52391494e-03\n",
            " 1.20313500e-02 4.68974181e-04 1.06093402e-02 8.87785012e-03\n",
            " 4.41194782e-03 4.45391059e-03 1.28065227e-03 6.08989748e-03\n",
            " 1.06654103e-02 6.92948556e-04 9.86342628e-04 1.03098111e-02\n",
            " 4.95183461e-03 5.92659822e-05 4.19687832e-03 1.13225419e-02\n",
            " 1.04885769e-02 1.03117921e-02 1.79280945e-03 1.01138671e-02\n",
            " 9.97618678e-03 8.47254228e-04 2.39085161e-03 1.10782575e-02\n",
            " 1.02762076e-02 7.55925497e-03 9.61218987e-03 4.52306662e-03\n",
            " 1.02063204e-02 3.79460610e-03 7.81347213e-05 8.71953597e-03\n",
            " 1.38847332e-02 3.47978027e-03 3.79460610e-03 1.34587762e-02\n",
            " 1.13414985e-02 9.58460613e-03 6.29820906e-03 1.12224836e-03\n",
            " 1.22279073e-02 1.30940196e-02 7.47037318e-03 1.13017647e-02\n",
            " 1.34146083e-03 1.26032813e-02 3.41671829e-05 8.10284853e-03\n",
            " 5.46770272e-03 3.02519654e-03 1.09602944e-02 6.34550190e-03\n",
            " 9.21905340e-03 5.93600351e-03 8.22635370e-03 1.06125484e-02\n",
            " 9.99515477e-03 9.10319099e-03 4.34522505e-09 3.78745663e-03\n",
            " 7.98367722e-03 8.08965454e-03 1.03612467e-03 1.32001536e-02\n",
            " 1.18586344e-02 3.80650858e-03 9.35657229e-03 2.10434777e-03\n",
            " 6.99950268e-03 2.41100761e-03 8.23856982e-03 4.34160493e-03\n",
            " 1.17903260e-02 8.45973384e-03 6.05646024e-03 4.81961566e-03\n",
            " 6.35812116e-03 3.12307259e-03 8.55494386e-03 1.46608602e-02\n",
            " 1.23364561e-02 8.80146799e-03 4.93591210e-03 1.19415457e-02\n",
            " 4.41194782e-03 1.18688528e-02 9.18310409e-03 6.84471040e-03\n",
            " 1.10293908e-02 9.33347303e-03 5.38953135e-03 9.85640347e-03\n",
            " 7.01982028e-03 1.47330224e-02 2.40985983e-03 1.18741475e-02\n",
            " 2.06236829e-04 3.68213921e-03 1.07909088e-02 1.13476707e-02\n",
            " 4.06685717e-03 1.03716167e-02 3.83949110e-03 7.61586039e-03\n",
            " 8.58967189e-03 9.85242053e-03 5.40540054e-04 2.87862748e-03\n",
            " 1.11763990e-02 6.41233129e-03 1.43712594e-06 1.21380654e-02\n",
            " 7.18594648e-05 7.55664170e-04 2.93265989e-03 7.84540482e-03\n",
            " 2.99639602e-03 8.68165604e-03 4.95435458e-03 4.47756116e-04\n",
            " 6.42299046e-03 4.92359472e-03 1.19341067e-02 1.28802813e-03\n",
            " 1.48843254e-02 1.01525003e-02 8.77080787e-04 4.94995097e-03\n",
            " 1.23022563e-02 6.96380067e-03 8.32171065e-03 4.77662610e-03\n",
            " 5.84599713e-03 4.19324348e-03 4.94117744e-03 5.12038367e-03\n",
            " 3.12999116e-03 8.08997465e-03 4.41194782e-03 1.09003341e-02\n",
            " 8.43572558e-03 4.27169503e-03 1.27626229e-03 1.77705518e-03\n",
            " 9.56657365e-03 3.62757738e-03 9.47218377e-03 1.18095362e-02\n",
            " 1.46167007e-03 5.16041661e-03 1.18984153e-02 1.11877051e-04\n",
            " 7.41449015e-03 1.35984702e-16 3.46209548e-03 6.53420617e-03\n",
            " 1.24810991e-02 1.24303643e-02 1.98719344e-04 9.29614394e-03\n",
            " 9.59653622e-03 1.03716167e-02 7.50588313e-03 2.91447891e-03\n",
            " 3.82701978e-03 2.94739823e-03 1.13017647e-02 3.34235560e-03\n",
            " 3.39092263e-03 1.13349613e-02 6.32662599e-03 8.16804290e-03\n",
            " 2.09459635e-03 2.09909860e-04 8.66020730e-03 4.11133443e-03\n",
            " 6.87942038e-03 1.13979254e-02 3.64775150e-03 3.67716588e-04\n",
            " 7.76472908e-03 1.89222158e-03 4.16118702e-03 3.04850795e-03\n",
            " 9.00183534e-03 1.18824144e-02 1.76596526e-04 4.34744856e-03\n",
            " 3.07381321e-03 8.42858155e-03 5.42524391e-03 3.02386083e-03\n",
            " 8.59035688e-03 8.98739512e-03 6.53469882e-03 1.28105886e-02\n",
            " 5.14770731e-03 1.08035858e-02 5.88233202e-03 9.97939825e-03\n",
            " 4.54428340e-03 1.22069832e-02 1.70911248e-04 9.09988960e-03\n",
            " 1.75542417e-03 8.41510226e-03 1.01047302e-02 7.25832984e-03\n",
            " 6.61068987e-03 4.19687832e-03 2.04581959e-03 1.48350987e-02\n",
            " 3.02525520e-03 1.63009974e-03 1.30602851e-02 1.36271609e-03\n",
            " 5.21135229e-03 2.00937033e-03 5.38953135e-03 3.74530595e-03\n",
            " 1.46040238e-02 1.17530109e-03 1.06523202e-02 7.11160603e-03\n",
            " 3.06045514e-03 2.99616265e-03 6.24915512e-03 3.57523555e-03\n",
            " 4.74870730e-06 1.19808051e-02 8.31381312e-04 3.56365146e-03\n",
            " 1.33047286e-03 1.20033089e-02 9.31894833e-03 1.32689134e-05\n",
            " 1.04297062e-02 2.10076107e-03 1.93959995e-04 8.63373038e-03\n",
            " 1.28105886e-02 3.97820053e-03 3.07944331e-03 9.59050172e-03\n",
            " 1.68286983e-03 6.60365693e-04 2.24852921e-03 5.79982159e-04\n",
            " 1.69796174e-03 1.09304913e-03 3.49278467e-03 1.43449618e-02\n",
            " 8.13095567e-03 5.72305570e-05 1.30241141e-02 6.47069116e-04\n",
            " 1.03344821e-02 1.19491078e-03 1.18325606e-02 9.85405366e-03\n",
            " 1.16864852e-02 9.20968307e-03 1.24327883e-02 9.79163194e-03\n",
            " 8.86347858e-03 5.05091515e-03 7.88268448e-03 9.62261727e-03\n",
            " 7.72365347e-03 1.29214127e-02 1.68286983e-03 9.83991329e-03\n",
            " 9.05662059e-03 2.23631027e-03 1.15596855e-02 3.57950471e-03\n",
            " 9.33016559e-03 4.39478266e-03 9.85938367e-03 1.74412549e-03\n",
            " 3.94376625e-03 1.09976549e-02 8.58470228e-03 1.47949272e-02\n",
            " 1.28330411e-02 4.02780721e-03 8.56114134e-03 4.88591720e-04\n",
            " 2.42456492e-03 9.86936502e-03 3.52178284e-03 7.27963082e-03\n",
            " 9.74152626e-03 1.70911248e-04 4.63024687e-03 1.45543593e-02\n",
            " 2.59605493e-03 3.44899382e-03 1.09055629e-02 8.45761679e-03\n",
            " 4.34753125e-03 5.36088691e-04 1.55909771e-03 1.32424435e-02\n",
            " 1.28395679e-03 7.53568441e-03 4.55889534e-03 6.92327194e-04\n",
            " 3.88347379e-03 1.27665411e-02 3.59861069e-04 9.38612690e-03\n",
            " 1.68286983e-03 6.91311974e-03 1.15573743e-02 1.20514730e-02\n",
            " 5.96711113e-03 6.94233116e-03 7.76210862e-03 1.00804314e-02\n",
            " 9.37899375e-03 2.37140880e-03 1.35128831e-02 3.79494959e-03\n",
            " 1.08287785e-03 8.79847766e-03 9.72238958e-03 8.98934195e-03\n",
            " 2.12188578e-04 1.04099340e-02 4.19687832e-03 6.85774359e-03\n",
            " 3.56365146e-03 9.51550437e-03 1.17852189e-03 2.57748652e-03\n",
            " 5.27707632e-04 8.44592944e-03 8.98075455e-03 5.36664392e-03\n",
            " 5.15053777e-03 1.43107440e-03 1.13432561e-02 1.25269364e-02\n",
            " 9.64538592e-03 6.71345357e-03 9.97535055e-03 1.02882268e-02\n",
            " 1.59595563e-04 6.78435321e-03 2.34627702e-03 4.44698626e-03\n",
            " 3.14409377e-03 5.46770272e-03 8.58722692e-03 1.16475912e-02\n",
            " 3.47978027e-03 7.01018501e-03 2.99681383e-03 9.26520616e-03\n",
            " 8.54503064e-03 1.89692103e-03 4.97184041e-04 2.65977706e-03\n",
            " 1.47160208e-02 4.80700020e-03 9.49543130e-03 9.09828106e-03\n",
            " 4.22569476e-03 5.13994182e-04 3.15435315e-03 5.94706669e-03\n",
            " 4.88704020e-03 7.40797564e-03 5.75070031e-03 3.27161782e-04\n",
            " 2.81178325e-03 2.63566795e-03 7.13192061e-03 1.23452590e-02\n",
            " 9.27758892e-03 2.23631027e-03 1.45359412e-03 1.18113141e-02\n",
            " 2.22261735e-03 5.84247382e-03 9.92394261e-03 1.48862144e-02\n",
            " 1.40820083e-02 3.79113291e-03 1.27461992e-02 1.08854523e-02\n",
            " 4.49205995e-03 8.90159042e-04 1.26466365e-02 6.56511185e-03\n",
            " 4.62656831e-03 6.15987470e-03 3.53669761e-03 8.91651219e-03\n",
            " 5.85305771e-03 5.23981242e-03 2.82462595e-03 6.04905455e-03\n",
            " 1.06898102e-02 9.83063533e-04 7.17301445e-04 4.49686717e-03\n",
            " 1.32857639e-02 8.40223121e-04 2.08120084e-04 1.08576030e-02\n",
            " 1.25696510e-02 1.14514247e-03 1.62368176e-03 3.12094936e-03\n",
            " 2.86879207e-03 7.72962823e-05 3.38631880e-03 6.13993149e-03\n",
            " 4.81591083e-03 1.77058083e-06 1.07443305e-02 6.48075109e-04\n",
            " 4.00688495e-07 1.31996469e-02 2.54466699e-05 4.74829583e-05\n",
            " 1.33060104e-02 1.06540640e-02 1.18578811e-02 1.32887772e-03\n",
            " 9.48918342e-04 1.20894066e-02 4.04872033e-03 3.88377920e-03\n",
            " 5.28873017e-03 1.13339206e-02 5.28873017e-03 1.07403526e-02\n",
            " 1.09173382e-03 7.24378370e-03 1.87423360e-03 3.83160762e-03\n",
            " 2.34644761e-04 4.00674908e-04 8.85114818e-03 3.60764957e-03\n",
            " 1.25718767e-02 4.38440845e-03 3.69347372e-03 2.27347552e-04\n",
            " 4.80660208e-03 5.98870663e-03 7.24668180e-03 1.28550270e-02\n",
            " 6.46764637e-03 4.93444451e-03 5.42524391e-03 1.03023214e-02\n",
            " 1.08275141e-02 2.93337511e-03 1.18427624e-02 1.02788105e-02\n",
            " 7.56998053e-03 5.49872401e-03 1.34248355e-02 5.62038027e-03\n",
            " 3.88377920e-03 1.40300906e-02 7.68192990e-03 9.87048791e-03\n",
            " 1.22448349e-03 1.08719055e-03 3.30241731e-03 5.90778776e-03\n",
            " 4.06460744e-03 5.68944740e-04 1.12329127e-02 1.04801410e-02\n",
            " 8.12051186e-03 5.47113484e-03 1.91082843e-03 1.03177176e-03\n",
            " 8.91882568e-03 6.18451266e-03 6.73438437e-03 8.13778452e-03\n",
            " 1.26413762e-02 9.78725274e-03 2.69000579e-03 1.43900539e-03\n",
            " 1.24608856e-03 6.91759811e-03 9.29855151e-03 1.26492095e-02\n",
            " 6.66722732e-03 8.75845867e-03 4.54304334e-03 1.28044046e-02\n",
            " 1.00886739e-02 4.67267016e-03 8.37570742e-03 1.17372730e-02\n",
            " 1.31219709e-02 3.21281541e-03 1.34844808e-02 3.41277138e-03\n",
            " 8.16425251e-03 4.50647509e-04 1.02418471e-03 7.43558265e-03\n",
            " 7.87356933e-03 2.59481071e-03 9.79163194e-03 5.19177925e-03\n",
            " 7.55700717e-03 3.55925232e-04 5.54135812e-03 7.19319301e-03\n",
            " 4.36619107e-03 1.11467060e-02 6.09679077e-03 3.58598837e-03\n",
            " 7.55100285e-03 8.27240053e-03 9.69415673e-03 7.50670483e-03\n",
            " 4.90229462e-03 6.24989039e-03 6.24813048e-03 8.31381312e-04\n",
            " 3.63948027e-03]\n",
            "3580 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.16192175e-03 4.35279644e-03 4.34488883e-03 3.59345035e-03\n",
            " 6.91079333e-04 1.22894941e-02 8.59884851e-03 3.79354780e-03\n",
            " 7.70335207e-03 1.16973228e-02 8.54579452e-03 1.08480892e-02\n",
            " 7.78798308e-03 1.16553640e-02 1.16808538e-02 1.17096575e-02\n",
            " 5.47313209e-03 5.05752674e-03 7.85546990e-03 5.87991907e-03\n",
            " 8.72951278e-03 1.48992932e-03 9.14304484e-03 4.19840446e-03\n",
            " 5.66890716e-03 3.88191238e-03 1.24301293e-05 4.49829912e-03\n",
            " 1.05662188e-02 3.43668836e-03 1.18540154e-02 1.26773441e-02\n",
            " 1.01299821e-04 7.51777435e-03 1.05662188e-02 1.00851241e-02\n",
            " 1.95866162e-03 4.26058915e-09 4.18403492e-03 1.68610723e-05\n",
            " 5.91682305e-03 1.24883588e-02 1.11501453e-02 3.07806080e-04\n",
            " 9.89526098e-08 1.20735977e-02 7.71845609e-03 7.46728675e-03\n",
            " 2.86779285e-03 7.12313173e-03 1.15751869e-02 9.79640099e-03\n",
            " 6.24380697e-03 9.38417197e-03 2.44881520e-03 1.04006516e-02\n",
            " 1.31245173e-02 8.88765380e-03 1.22721044e-02 1.15490298e-02\n",
            " 1.09303049e-02 9.52578090e-04 7.48797335e-03 2.47474407e-03\n",
            " 3.44699826e-04 1.12532935e-03 7.82335519e-03 2.96384704e-03\n",
            " 9.81291506e-03 9.79640099e-03 1.13583655e-02 4.09308686e-04\n",
            " 1.31932117e-02 8.13500262e-03 5.46813970e-03 4.52289124e-03\n",
            " 1.20014623e-02 4.67052154e-04 1.06053680e-02 8.86111073e-03\n",
            " 4.40275521e-03 4.44023023e-03 1.27624839e-03 6.06508866e-03\n",
            " 1.06625001e-02 6.89712718e-04 9.83570674e-04 1.02895479e-02\n",
            " 4.95375732e-03 5.89990868e-05 4.18438828e-03 1.12843562e-02\n",
            " 1.04749965e-02 1.02956188e-02 1.79037446e-03 1.00765864e-02\n",
            " 9.95279186e-03 8.46986917e-04 2.38113258e-03 1.10792669e-02\n",
            " 1.02582911e-02 7.53495527e-03 9.57677780e-03 4.51003670e-03\n",
            " 1.00851241e-02 3.79049600e-03 7.75858897e-05 8.69143442e-03\n",
            " 1.38632891e-02 3.45316565e-03 3.79049600e-03 1.34173064e-02\n",
            " 1.13291469e-02 9.54222161e-03 6.29078267e-03 1.12113723e-03\n",
            " 1.22092269e-02 1.30707065e-02 7.44196707e-03 1.13132651e-02\n",
            " 1.33989636e-03 1.25824053e-02 3.39504094e-05 8.08849485e-03\n",
            " 5.45774298e-03 3.01199575e-03 1.09456485e-02 6.34040017e-03\n",
            " 9.20901765e-03 5.91892749e-03 8.22373253e-03 1.05928105e-02\n",
            " 9.97036336e-03 9.08554336e-03 4.26058915e-09 3.77496170e-03\n",
            " 7.95585305e-03 8.08602711e-03 1.03177525e-03 1.31899539e-02\n",
            " 1.18703609e-02 3.79857808e-03 9.34015219e-03 2.09806570e-03\n",
            " 6.96395818e-03 2.40242452e-03 8.12082369e-03 4.33520864e-03\n",
            " 1.17735254e-02 8.45770604e-03 6.03075972e-03 4.81574188e-03\n",
            " 6.36369615e-03 3.12269037e-03 8.54579452e-03 1.23095533e-02\n",
            " 8.79651630e-03 4.92162719e-03 1.19386877e-02 4.40275521e-03\n",
            " 1.18540154e-02 9.17313112e-03 6.81903898e-03 1.10063961e-02\n",
            " 9.32252193e-03 5.38874444e-03 9.82492087e-03 7.00175260e-03\n",
            " 2.40607759e-03 1.18577236e-02 2.05899011e-04 3.67509069e-03\n",
            " 1.07770301e-02 1.13470661e-02 4.06646376e-03 1.03578991e-02\n",
            " 3.82548016e-03 7.55668556e-03 8.55297081e-03 9.82797962e-03\n",
            " 5.40422100e-04 2.88063230e-03 1.11454941e-02 6.40604978e-03\n",
            " 1.43275872e-06 1.21028011e-02 7.16055805e-05 7.51870683e-04\n",
            " 2.92941551e-03 7.81891346e-03 2.98190337e-03 8.67130321e-03\n",
            " 4.93223810e-03 4.46557764e-04 6.40078474e-03 4.91712981e-03\n",
            " 1.19411778e-02 1.27052662e-03 1.01431553e-02 8.73935100e-04\n",
            " 4.93210622e-03 1.22894941e-02 6.94023125e-03 8.30478117e-03\n",
            " 4.76199463e-03 5.83583084e-03 4.19110257e-03 4.93279659e-03\n",
            " 5.11121622e-03 3.12370079e-03 8.06084157e-03 4.40275521e-03\n",
            " 1.08808368e-02 8.40262057e-03 4.24632032e-03 1.27553681e-03\n",
            " 1.77125656e-03 9.52812043e-03 3.61609361e-03 9.46393049e-03\n",
            " 1.18102924e-02 1.45486283e-03 5.15125104e-03 1.18379731e-02\n",
            " 1.11430642e-04 7.38949951e-03 1.32976466e-16 3.45481272e-03\n",
            " 6.53119940e-03 1.24562900e-02 1.22714708e-02 1.98081186e-04\n",
            " 9.29735429e-03 9.56828589e-03 1.03578991e-02 7.48797335e-03\n",
            " 2.91396353e-03 3.82047553e-03 2.94568014e-03 1.13132651e-02\n",
            " 3.33915698e-03 3.38115634e-03 1.12915016e-02 6.32387414e-03\n",
            " 8.15736481e-03 2.08768277e-03 2.07867163e-04 8.62854345e-03\n",
            " 4.11618447e-03 6.86949255e-03 1.13778067e-02 3.63512581e-03\n",
            " 3.65388393e-04 7.76167605e-03 1.88862298e-03 4.16763726e-03\n",
            " 3.04364359e-03 8.96807505e-03 1.18443952e-02 1.76071231e-04\n",
            " 4.34000396e-03 3.07268023e-03 8.42127028e-03 5.42277465e-03\n",
            " 3.01420895e-03 8.56648488e-03 8.96950686e-03 6.52799437e-03\n",
            " 1.28025107e-02 5.12481612e-03 1.07975221e-02 5.87991907e-03\n",
            " 9.96643142e-03 4.53887063e-03 1.22070522e-02 1.70389909e-04\n",
            " 9.09640085e-03 1.74403332e-03 8.40530287e-03 1.00906307e-02\n",
            " 7.26205450e-03 6.59767975e-03 4.18438828e-03 2.03739980e-03\n",
            " 3.01663485e-03 1.62874745e-03 1.30384644e-02 1.36277152e-03\n",
            " 5.20111601e-03 1.99803859e-03 5.38874444e-03 3.74110358e-03\n",
            " 1.16733135e-03 1.06203846e-02 7.11407269e-03 3.05619438e-03\n",
            " 2.98957550e-03 6.23541902e-03 3.56563579e-03 4.70163745e-06\n",
            " 1.19803705e-02 8.24872348e-04 3.56404254e-03 1.32547390e-03\n",
            " 1.19917194e-02 9.31079562e-03 1.30739735e-05 1.03990670e-02\n",
            " 2.09902562e-03 1.93181153e-04 8.61033420e-03 1.28025107e-02\n",
            " 3.97340324e-03 3.05385830e-03 9.56418152e-03 1.67747237e-03\n",
            " 6.57984779e-04 2.24358486e-03 5.78920225e-04 1.69595353e-03\n",
            " 1.09117906e-03 3.47992127e-03 8.10700103e-03 5.72576483e-05\n",
            " 1.30211092e-02 6.43351633e-04 1.03182835e-02 1.18847280e-03\n",
            " 1.17994369e-02 9.82544548e-03 1.16636043e-02 9.18211875e-03\n",
            " 1.24022268e-02 9.79640099e-03 8.82498354e-03 5.04969392e-03\n",
            " 7.87382094e-03 9.56643240e-03 7.72235788e-03 1.28916083e-02\n",
            " 1.67747237e-03 9.80541116e-03 9.03226879e-03 2.22851304e-03\n",
            " 1.15602786e-02 3.56673545e-03 9.29459252e-03 4.39016812e-03\n",
            " 9.84356375e-03 1.74430457e-03 3.93303422e-03 1.09673759e-02\n",
            " 8.57007894e-03 1.27980574e-02 4.01868605e-03 8.55064002e-03\n",
            " 4.86310973e-04 2.41627971e-03 9.84214035e-03 3.51120595e-03\n",
            " 7.27221221e-03 9.72133205e-03 1.70389909e-04 4.62549222e-03\n",
            " 2.59677449e-03 3.43780412e-03 1.08612533e-02 8.45226393e-03\n",
            " 4.33990552e-03 5.34403280e-04 1.54768079e-03 1.32139810e-02\n",
            " 1.27559818e-03 7.53650367e-03 4.55069897e-03 6.91079333e-04\n",
            " 3.86846119e-03 1.27781734e-02 3.59023553e-04 9.39048928e-03\n",
            " 1.67747237e-03 6.91117054e-03 1.15235644e-02 1.20045137e-02\n",
            " 5.95143561e-03 6.88725468e-03 7.72876675e-03 1.00764370e-02\n",
            " 9.37324169e-03 2.36355821e-03 1.35039624e-02 3.77944650e-03\n",
            " 1.07697235e-03 8.78915483e-03 9.69509284e-03 8.98891150e-03\n",
            " 2.11452413e-04 1.04107128e-02 4.18438828e-03 6.84195060e-03\n",
            " 3.56404254e-03 9.49895946e-03 1.17948273e-03 2.57232890e-03\n",
            " 5.23369761e-04 8.43473650e-03 8.97162203e-03 5.35659421e-03\n",
            " 5.13696270e-03 1.42365529e-03 1.13041588e-02 1.25089782e-02\n",
            " 9.64578520e-03 6.71281815e-03 9.94319632e-03 1.02759684e-02\n",
            " 1.59470059e-04 6.77795495e-03 2.34235504e-03 4.42393234e-03\n",
            " 3.14602389e-03 5.45774298e-03 8.58312726e-03 1.16065691e-02\n",
            " 3.45316565e-03 6.99224435e-03 2.99182737e-03 9.25089997e-03\n",
            " 8.53769024e-03 1.89203605e-03 4.95564845e-04 2.64628164e-03\n",
            " 4.79954669e-03 9.48629253e-03 9.08684226e-03 4.21170085e-03\n",
            " 5.09767775e-04 3.14682941e-03 5.93265367e-03 4.86801757e-03\n",
            " 7.39549327e-03 5.74601564e-03 3.25636680e-04 2.80864995e-03\n",
            " 2.62080140e-03 7.11787787e-03 1.23130124e-02 9.24902018e-03\n",
            " 2.22851304e-03 1.44544455e-03 1.18019173e-02 2.21915467e-03\n",
            " 5.81911272e-03 9.91728484e-03 1.40654351e-02 3.80045579e-03\n",
            " 1.27196354e-02 1.08491910e-02 4.48477614e-03 8.85746128e-04\n",
            " 1.26296498e-02 6.55565304e-03 4.61355271e-03 6.12540217e-03\n",
            " 3.53529999e-03 8.90864471e-03 5.84631621e-03 5.21636262e-03\n",
            " 2.82421153e-03 6.03697708e-03 1.06565078e-02 9.82792399e-04\n",
            " 7.17175395e-04 4.49829912e-03 1.32631447e-02 8.38277714e-04\n",
            " 2.06647401e-04 1.08452157e-02 1.24988063e-02 1.14204374e-03\n",
            " 1.61811515e-03 3.11440258e-03 2.86779285e-03 7.69878340e-05\n",
            " 3.37903027e-03 6.13171027e-03 4.80179797e-03 1.75080347e-06\n",
            " 1.07154496e-02 6.45038097e-04 4.00789502e-07 1.31705185e-02\n",
            " 2.52723098e-05 4.71601169e-05 1.33121892e-02 1.06416736e-02\n",
            " 1.18566800e-02 1.32554712e-03 9.44811278e-04 1.20779705e-02\n",
            " 4.02676181e-03 3.88191238e-03 5.28737977e-03 1.13243203e-02\n",
            " 5.28737977e-03 1.07196880e-02 1.09032790e-03 7.23452084e-03\n",
            " 1.86932023e-03 3.81905230e-03 2.33500644e-04 3.98478018e-04\n",
            " 8.82705733e-03 3.58985955e-03 1.25632455e-02 4.36820584e-03\n",
            " 3.68757030e-03 2.26492986e-04 4.79098189e-03 5.97568397e-03\n",
            " 7.24621249e-03 1.28484245e-02 6.44869854e-03 4.93842207e-03\n",
            " 5.42277465e-03 1.03037851e-02 1.08325964e-02 2.92268707e-03\n",
            " 1.18381595e-02 1.02628085e-02 7.54869081e-03 5.47775842e-03\n",
            " 1.33797798e-02 5.60329473e-03 3.88191238e-03 1.40003966e-02\n",
            " 7.63418233e-03 9.84327864e-03 1.22197208e-03 1.08752478e-03\n",
            " 3.29778305e-03 5.90596995e-03 4.06259960e-03 5.66390320e-04\n",
            " 1.12344835e-02 1.04819617e-02 8.11313354e-03 5.45948079e-03\n",
            " 1.90309576e-03 1.02889420e-03 8.92342215e-03 6.17340340e-03\n",
            " 6.70500844e-03 8.11705248e-03 1.26445401e-02 9.76215390e-03\n",
            " 2.68225665e-03 1.43545374e-03 1.24006630e-03 6.87723651e-03\n",
            " 9.27242050e-03 1.26077669e-02 6.65826974e-03 8.75548750e-03\n",
            " 4.53001663e-03 1.27929974e-02 1.00641428e-02 4.65996793e-03\n",
            " 8.36659063e-03 1.16860481e-02 1.31065513e-02 3.20595695e-03\n",
            " 1.34559609e-02 3.41244749e-03 8.13803314e-03 4.47527040e-04\n",
            " 1.01935213e-03 7.44336994e-03 7.85717070e-03 2.58978683e-03\n",
            " 9.79640099e-03 5.18299741e-03 7.55368433e-03 3.53856375e-04\n",
            " 5.53077165e-03 7.18167780e-03 4.35672076e-03 1.11422022e-02\n",
            " 6.08904022e-03 3.58715968e-03 7.53648093e-03 8.25362215e-03\n",
            " 9.66375994e-03 7.51666621e-03 4.88737879e-03 6.23496779e-03\n",
            " 6.22578836e-03 8.24872348e-04 3.62594313e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3590 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.14638447e-03 4.34836747e-03 4.32985068e-03 3.57833640e-03\n",
            " 6.90916336e-04 1.22169163e-02 8.58749612e-03 3.78928284e-03\n",
            " 7.67678900e-03 1.16834872e-02 8.52463895e-03 1.08315029e-02\n",
            " 7.78038613e-03 1.16346654e-02 1.16676655e-02 1.17036673e-02\n",
            " 5.45930526e-03 5.03666607e-03 7.85654583e-03 5.87798770e-03\n",
            " 8.72673811e-03 1.48781820e-03 9.10973965e-03 4.18204099e-03\n",
            " 5.67038110e-03 3.87561850e-03 1.23805985e-05 4.49401988e-03\n",
            " 1.05447857e-02 3.43434172e-03 1.18265611e-02 1.26750869e-02\n",
            " 1.00695364e-04 7.48675628e-03 1.05447857e-02 1.00913299e-02\n",
            " 1.95329887e-03 4.24558879e-09 4.17406816e-03 1.66302036e-05\n",
            " 5.89558211e-03 1.24427421e-02 1.11381935e-02 3.07082650e-04\n",
            " 9.81820879e-08 1.20516617e-02 7.69678162e-03 7.47606624e-03\n",
            " 2.86373174e-03 7.11833762e-03 1.15519328e-02 9.78903225e-03\n",
            " 6.22574623e-03 9.36780016e-03 2.43809689e-03 1.03948339e-02\n",
            " 1.30897783e-02 8.87465104e-03 1.22675004e-02 1.15191777e-02\n",
            " 1.09252192e-02 9.48166236e-04 7.48836970e-03 2.45972702e-03\n",
            " 3.43498519e-04 1.11952195e-03 7.81741571e-03 2.96267520e-03\n",
            " 9.79610028e-03 9.78903225e-03 1.13529385e-02 4.09179658e-04\n",
            " 1.31535179e-02 8.12716021e-03 5.45400049e-03 4.49377041e-03\n",
            " 1.19822747e-02 4.65126850e-04 1.05963639e-02 8.86649202e-03\n",
            " 4.37908854e-03 4.42165847e-03 1.26663670e-03 6.06037992e-03\n",
            " 1.06668815e-02 6.88165188e-04 9.82242969e-04 1.02664374e-02\n",
            " 4.94441350e-03 5.88643390e-05 4.18120850e-03 1.12652329e-02\n",
            " 1.04665169e-02 1.02762716e-02 1.78768824e-03 1.00770647e-02\n",
            " 9.94685631e-03 8.40345232e-04 2.37813245e-03 1.10690217e-02\n",
            " 1.02383257e-02 7.52317935e-03 9.56202957e-03 4.50791918e-03\n",
            " 1.00913299e-02 3.77109558e-03 7.68318901e-05 8.68897129e-03\n",
            " 3.42802291e-03 3.77109558e-03 1.13131894e-02 9.52508905e-03\n",
            " 6.27541272e-03 1.11835454e-03 1.21893367e-02 1.30262998e-02\n",
            " 7.43518647e-03 1.12599964e-02 1.33824077e-03 1.25509769e-02\n",
            " 3.36955077e-05 8.05752925e-03 5.45176944e-03 3.00476676e-03\n",
            " 1.09205219e-02 6.32188335e-03 9.17707794e-03 5.89821272e-03\n",
            " 8.21927373e-03 1.05891858e-02 9.94975356e-03 9.07430142e-03\n",
            " 4.24558879e-09 3.76838245e-03 7.93751883e-03 8.09893721e-03\n",
            " 1.02874786e-03 1.32022715e-02 1.18755631e-02 3.78725328e-03\n",
            " 9.32946406e-03 2.08804441e-03 6.96473946e-03 2.39859292e-03\n",
            " 8.09982715e-03 4.33093310e-03 1.17475461e-02 8.43815667e-03\n",
            " 6.03179915e-03 4.81211189e-03 6.35142854e-03 3.11964524e-03\n",
            " 8.52463895e-03 1.22893830e-02 8.77022005e-03 4.91015691e-03\n",
            " 1.18964083e-02 4.37908854e-03 1.18265611e-02 9.16144142e-03\n",
            " 6.79388665e-03 1.09644832e-02 9.30371748e-03 5.38951209e-03\n",
            " 9.79613022e-03 6.97244356e-03 2.40710730e-03 1.18337107e-02\n",
            " 2.05138727e-04 3.67128933e-03 1.07567007e-02 1.13194803e-02\n",
            " 4.06808520e-03 1.03169473e-02 3.81602952e-03 7.52687852e-03\n",
            " 8.52958662e-03 9.80901102e-03 5.39475706e-04 2.87211040e-03\n",
            " 1.11151851e-02 6.39617631e-03 1.41941849e-06 1.20905082e-02\n",
            " 7.12961974e-05 7.48721714e-04 2.92230272e-03 7.78241553e-03\n",
            " 2.98020417e-03 8.64567153e-03 4.91269042e-03 4.46223856e-04\n",
            " 6.37313453e-03 4.90598580e-03 1.19255506e-02 1.26739747e-03\n",
            " 1.01329650e-02 8.68825344e-04 4.91413495e-03 1.22169163e-02\n",
            " 6.91069968e-03 8.29528699e-03 4.76534371e-03 5.82899452e-03\n",
            " 4.17851122e-03 4.92460127e-03 5.09487508e-03 3.11336704e-03\n",
            " 8.04166391e-03 4.37908854e-03 1.08649843e-02 8.37622616e-03\n",
            " 4.24117433e-03 1.27519371e-03 1.76835676e-03 9.49821144e-03\n",
            " 3.60642819e-03 9.45675335e-03 1.17946983e-02 1.44514268e-03\n",
            " 5.13853139e-03 1.17879528e-02 1.10836064e-04 7.37067451e-03\n",
            " 1.27583460e-16 3.43972695e-03 6.52038363e-03 1.24345014e-02\n",
            " 1.22439616e-02 1.96884320e-04 9.28644975e-03 9.53599542e-03\n",
            " 1.03169473e-02 7.48836970e-03 2.90490506e-03 3.81375013e-03\n",
            " 2.94042378e-03 1.12599964e-02 3.33223005e-03 3.37859604e-03\n",
            " 1.12437775e-02 6.31061912e-03 8.15622118e-03 2.08036057e-03\n",
            " 2.06571380e-04 8.61595637e-03 4.11628513e-03 6.86070113e-03\n",
            " 1.13600134e-02 3.61849152e-03 3.63393056e-04 7.72208709e-03\n",
            " 1.88211542e-03 4.16343810e-03 3.03965051e-03 8.96129770e-03\n",
            " 1.18403184e-02 1.75496046e-04 4.32655913e-03 3.06916629e-03\n",
            " 8.42060069e-03 5.42087530e-03 3.00773722e-03 8.55652361e-03\n",
            " 8.95217255e-03 6.52825660e-03 1.27887101e-02 5.11546453e-03\n",
            " 1.07733596e-02 5.87798770e-03 9.97839276e-03 4.51380842e-03\n",
            " 1.21888147e-02 1.70162744e-04 9.07263866e-03 1.73837823e-03\n",
            " 8.40176977e-03 1.00847627e-02 7.25231951e-03 6.57932108e-03\n",
            " 4.18120850e-03 2.03079677e-03 3.00700720e-03 1.62616314e-03\n",
            " 1.30129787e-02 1.36157894e-03 5.18968920e-03 1.98790333e-03\n",
            " 5.38951209e-03 3.72858543e-03 1.15899592e-03 1.05631606e-02\n",
            " 7.11169532e-03 3.05633679e-03 2.98732522e-03 6.22478161e-03\n",
            " 3.56125024e-03 4.65277663e-06 1.19717622e-02 8.23643892e-04\n",
            " 3.55727441e-03 1.32401116e-03 1.19692319e-02 9.29472276e-03\n",
            " 1.29307720e-05 1.03748891e-02 2.09834258e-03 1.93100786e-04\n",
            " 8.60990567e-03 1.27887101e-02 3.96225983e-03 3.04714340e-03\n",
            " 9.52396358e-03 1.66904830e-03 6.54944366e-04 2.23616124e-03\n",
            " 5.77653713e-04 1.69727814e-03 1.08967305e-03 3.47040804e-03\n",
            " 8.08956263e-03 5.71405914e-05 1.30137151e-02 6.41570144e-04\n",
            " 1.03004484e-02 1.18353356e-03 1.17682423e-02 9.80096389e-03\n",
            " 1.16475288e-02 9.15403473e-03 1.23761338e-02 9.78903225e-03\n",
            " 8.79839878e-03 5.05257958e-03 7.85656000e-03 9.52844123e-03\n",
            " 7.71411570e-03 1.28513119e-02 1.66904830e-03 9.80601649e-03\n",
            " 9.01975383e-03 2.22181055e-03 1.15500273e-02 3.55563252e-03\n",
            " 9.27101950e-03 4.38796710e-03 9.83515958e-03 1.74647255e-03\n",
            " 3.91771764e-03 1.09417043e-02 8.56740708e-03 1.27597041e-02\n",
            " 4.00561212e-03 8.54672812e-03 4.85933329e-04 2.40992443e-03\n",
            " 9.80429158e-03 3.50459478e-03 7.25899029e-03 9.71245427e-03\n",
            " 1.70162744e-04 4.61628131e-03 2.58661078e-03 3.42112626e-03\n",
            " 1.08186308e-02 8.44498245e-03 4.33019552e-03 5.31383429e-04\n",
            " 1.54666515e-03 1.27353783e-03 7.51032163e-03 4.54240299e-03\n",
            " 6.90916336e-04 3.85571163e-03 1.27558124e-02 3.58928285e-04\n",
            " 9.36527732e-03 1.66904830e-03 6.89838880e-03 1.15043254e-02\n",
            " 1.19748393e-02 5.93651301e-03 6.88013818e-03 7.72670647e-03\n",
            " 1.00550595e-02 9.37121193e-03 2.35267124e-03 3.77745958e-03\n",
            " 1.07299727e-03 8.77849706e-03 9.71140894e-03 8.96556187e-03\n",
            " 2.11383382e-04 1.04020026e-02 4.18120850e-03 6.83398821e-03\n",
            " 3.55727441e-03 9.47970215e-03 1.17904950e-03 2.57099031e-03\n",
            " 5.21565914e-04 8.42978629e-03 8.96012497e-03 5.34902614e-03\n",
            " 5.14439373e-03 1.41897694e-03 1.12740797e-02 1.24873570e-02\n",
            " 9.63606385e-03 6.71094625e-03 9.93017926e-03 1.02581613e-02\n",
            " 1.59309739e-04 6.76127678e-03 2.33422904e-03 4.41031065e-03\n",
            " 3.13907525e-03 5.45176944e-03 8.58145671e-03 1.15837063e-02\n",
            " 3.42802291e-03 6.98625925e-03 2.96707010e-03 9.22089643e-03\n",
            " 8.52786346e-03 1.88818979e-03 4.92458844e-04 2.64083383e-03\n",
            " 4.79346924e-03 9.48141223e-03 9.06394389e-03 4.19671988e-03\n",
            " 5.07274760e-04 3.14287917e-03 5.92556638e-03 4.85540286e-03\n",
            " 7.38667721e-03 5.73702547e-03 3.24242235e-04 2.80443836e-03\n",
            " 2.61283441e-03 7.09450604e-03 1.22899940e-02 9.22811838e-03\n",
            " 2.22181055e-03 1.43763939e-03 1.17792422e-02 2.22037332e-03\n",
            " 5.80969194e-03 9.88926990e-03 3.80145667e-03 1.26985062e-02\n",
            " 1.08403612e-02 4.48024456e-03 8.81196180e-04 1.26099882e-02\n",
            " 6.55220061e-03 4.59606649e-03 6.11399529e-03 3.52537377e-03\n",
            " 8.86909770e-03 5.82879013e-03 5.21373236e-03 2.81993465e-03\n",
            " 6.03020391e-03 1.06401927e-02 9.79085936e-04 7.17186488e-04\n",
            " 4.49401988e-03 8.32800569e-04 2.05593094e-04 1.08276142e-02\n",
            " 1.24649727e-02 1.13826243e-03 1.61346890e-03 3.10611389e-03\n",
            " 2.86373174e-03 7.63627901e-05 3.37261925e-03 6.13058069e-03\n",
            " 4.75769218e-03 1.72487688e-06 1.06985621e-02 6.40518331e-04\n",
            " 3.99963847e-07 1.31421877e-02 2.50479658e-05 4.71393932e-05\n",
            " 1.06374589e-02 1.18322920e-02 1.32196558e-03 9.43612441e-04\n",
            " 1.20565281e-02 4.00697536e-03 3.87561850e-03 5.28443487e-03\n",
            " 1.13097011e-02 5.28443487e-03 1.07243189e-02 1.08860373e-03\n",
            " 7.21177669e-03 1.86317574e-03 3.81271421e-03 2.31405781e-04\n",
            " 3.96831666e-04 8.83393768e-03 3.57496068e-03 1.25633284e-02\n",
            " 4.36383227e-03 3.68465765e-03 2.25895759e-04 4.78151234e-03\n",
            " 5.96792183e-03 7.24759080e-03 1.28395482e-02 6.44350834e-03\n",
            " 4.94040718e-03 5.42087530e-03 1.02877660e-02 1.08238122e-02\n",
            " 2.91372951e-03 1.18307344e-02 1.02232803e-02 7.54781961e-03\n",
            " 5.47108063e-03 5.59832596e-03 3.87561850e-03 7.60296289e-03\n",
            " 9.83930960e-03 1.21757751e-03 1.08569963e-03 3.29827948e-03\n",
            " 5.89377671e-03 4.03926058e-03 5.62451306e-04 1.12300107e-02\n",
            " 1.04772902e-02 8.10016806e-03 5.44044959e-03 1.89511316e-03\n",
            " 1.02183241e-03 8.91792361e-03 6.17693662e-03 6.69712201e-03\n",
            " 8.09754331e-03 1.26350912e-02 9.75590527e-03 2.67274349e-03\n",
            " 1.43478342e-03 1.23576838e-03 6.87473310e-03 9.25119684e-03\n",
            " 1.25939240e-02 6.64481824e-03 8.74661806e-03 4.52283139e-03\n",
            " 1.27878138e-02 1.00316387e-02 4.64874855e-03 8.34885897e-03\n",
            " 1.16549141e-02 1.30875218e-02 3.20114085e-03 3.40898502e-03\n",
            " 8.12684582e-03 4.45163579e-04 1.01800587e-03 7.39828889e-03\n",
            " 7.84297698e-03 2.58387693e-03 9.78903225e-03 5.17863216e-03\n",
            " 7.54580610e-03 3.52384758e-04 5.51883407e-03 7.16860422e-03\n",
            " 4.34455446e-03 1.11388108e-02 6.07734359e-03 3.58180227e-03\n",
            " 7.51659495e-03 8.23470748e-03 9.66444724e-03 7.49606667e-03\n",
            " 4.87926450e-03 6.20857970e-03 6.21744142e-03 8.23643892e-04\n",
            " 3.60603240e-03]\n",
            "3600 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.12626427e-03 4.34134522e-03 4.32912818e-03 3.56747170e-03\n",
            " 6.89569366e-04 1.22156862e-02 8.58715281e-03 3.77233630e-03\n",
            " 7.66251040e-03 1.16700679e-02 8.48569495e-03 1.08023511e-02\n",
            " 7.77766447e-03 1.16139236e-02 1.16724905e-02 1.16846964e-02\n",
            " 5.44308095e-03 5.03222449e-03 7.83023901e-03 5.86488104e-03\n",
            " 8.70014591e-03 1.48628709e-03 9.05835830e-03 4.17832278e-03\n",
            " 5.66846847e-03 3.86778276e-03 1.22621744e-05 4.48869763e-03\n",
            " 1.05392661e-02 3.42899982e-03 1.17883869e-02 1.26735990e-02\n",
            " 1.00575882e-04 7.48300111e-03 1.05392661e-02 1.00979311e-02\n",
            " 1.94270245e-03 4.24899262e-09 4.17594453e-03 1.63703280e-05\n",
            " 5.87067331e-03 1.23774280e-02 1.11004217e-02 3.06793237e-04\n",
            " 9.83250995e-08 1.20181933e-02 7.68318481e-03 7.47021864e-03\n",
            " 2.85803850e-03 7.10774050e-03 1.15366588e-02 9.78940015e-03\n",
            " 6.20662401e-03 9.35995149e-03 2.43057266e-03 1.03919689e-02\n",
            " 8.82709562e-03 1.22532819e-02 1.15025898e-02 1.09082193e-02\n",
            " 9.41509143e-04 7.49457707e-03 2.44622632e-03 3.42809391e-04\n",
            " 1.11337553e-03 7.79785809e-03 2.96279809e-03 9.76779989e-03\n",
            " 9.78940015e-03 1.13422051e-02 4.09540551e-04 8.11880766e-03\n",
            " 5.44933065e-03 4.47132603e-03 1.19689280e-02 4.63470483e-04\n",
            " 1.05821137e-02 8.86071629e-03 4.36725559e-03 4.41201306e-03\n",
            " 1.26225421e-03 6.06723663e-03 1.06442950e-02 6.85796681e-04\n",
            " 9.81333446e-04 1.02451107e-02 4.92850787e-03 5.82539298e-05\n",
            " 4.17995898e-03 1.12732788e-02 1.04593625e-02 1.02599520e-02\n",
            " 1.78415822e-03 1.00743885e-02 9.94645559e-03 8.32457292e-04\n",
            " 2.36659763e-03 1.10500700e-02 1.01991633e-02 7.51219049e-03\n",
            " 9.52488389e-03 4.50476220e-03 1.00979311e-02 3.76158760e-03\n",
            " 7.64750844e-05 8.67806271e-03 3.40828383e-03 3.76158760e-03\n",
            " 1.13063325e-02 9.51770332e-03 6.26665420e-03 1.11892367e-03\n",
            " 1.21883307e-02 7.43244599e-03 1.12242359e-02 1.33711899e-03\n",
            " 1.25415709e-02 3.31449063e-05 8.03381688e-03 5.44308650e-03\n",
            " 2.99506926e-03 1.08930400e-02 6.29861251e-03 9.14743675e-03\n",
            " 5.86142622e-03 8.21343595e-03 1.05731619e-02 9.92772358e-03\n",
            " 9.08163707e-03 4.24899262e-09 3.76227711e-03 7.93015877e-03\n",
            " 8.10128158e-03 1.02676855e-03 1.18891131e-02 3.77733502e-03\n",
            " 9.30943411e-03 2.07523623e-03 6.95655298e-03 2.39053078e-03\n",
            " 8.09477041e-03 4.32781929e-03 1.17425825e-02 8.44132451e-03\n",
            " 6.02875010e-03 4.79363326e-03 6.35565329e-03 3.11881804e-03\n",
            " 8.48569495e-03 1.22833560e-02 8.78442629e-03 4.91526600e-03\n",
            " 1.18663964e-02 4.36725559e-03 1.17883869e-02 9.13719148e-03\n",
            " 6.77558955e-03 1.09370322e-02 9.28997416e-03 5.38777954e-03\n",
            " 9.79533141e-03 6.94506746e-03 2.40417369e-03 1.18334690e-02\n",
            " 2.03987843e-04 3.66641427e-03 1.07050359e-02 1.13071571e-02\n",
            " 4.06129004e-03 1.03285355e-02 3.81118735e-03 7.52956855e-03\n",
            " 8.52229367e-03 9.78343374e-03 5.37259848e-04 2.85363406e-03\n",
            " 1.10788666e-02 6.38991532e-03 1.40866820e-06 1.20912703e-02\n",
            " 7.08824451e-05 7.47960368e-04 2.91663923e-03 7.75211251e-03\n",
            " 2.97206093e-03 8.64050576e-03 4.90886072e-03 4.44296840e-04\n",
            " 6.36042073e-03 4.90190040e-03 1.19221174e-02 1.26650695e-03\n",
            " 1.01287763e-02 8.67603939e-04 4.89826103e-03 1.22156862e-02\n",
            " 6.89936185e-03 8.28860741e-03 4.75677052e-03 5.82580106e-03\n",
            " 4.15743086e-03 4.92956322e-03 5.09144682e-03 3.10842809e-03\n",
            " 8.03155404e-03 4.36725559e-03 1.08425045e-02 8.36537313e-03\n",
            " 4.22718825e-03 1.27378214e-03 1.76411958e-03 9.46695244e-03\n",
            " 3.60424482e-03 9.44473378e-03 1.17798085e-02 1.44340418e-03\n",
            " 5.11630342e-03 1.17698198e-02 1.10484837e-04 7.35631775e-03\n",
            " 1.20371000e-16 3.42821191e-03 6.50355842e-03 1.23843942e-02\n",
            " 1.22352507e-02 1.95363487e-04 9.27714255e-03 9.51076574e-03\n",
            " 1.03285355e-02 7.49457707e-03 2.89743538e-03 3.80967205e-03\n",
            " 2.93492519e-03 1.12242359e-02 3.33018026e-03 3.38039590e-03\n",
            " 1.12479774e-02 6.31604144e-03 8.14237146e-03 2.07644849e-03\n",
            " 2.06224068e-04 8.60948239e-03 4.08992581e-03 6.84611959e-03\n",
            " 1.13190890e-02 3.58912509e-03 3.62216218e-04 7.68574458e-03\n",
            " 1.87817764e-03 4.15588510e-03 3.03415130e-03 8.95709267e-03\n",
            " 1.17834046e-02 1.74697339e-04 4.31393773e-03 3.05859902e-03\n",
            " 8.40250034e-03 5.40461683e-03 3.00013806e-03 8.56379041e-03\n",
            " 8.94899936e-03 6.53343318e-03 1.27397835e-02 5.09844311e-03\n",
            " 1.07524382e-02 5.86488104e-03 9.97328272e-03 4.49427322e-03\n",
            " 1.21336862e-02 1.70307218e-04 9.04836939e-03 1.73391122e-03\n",
            " 8.36644270e-03 1.00876659e-02 7.25434093e-03 6.55414960e-03\n",
            " 4.17995898e-03 2.02103119e-03 3.00240851e-03 1.62479262e-03\n",
            " 1.36131593e-03 5.18260098e-03 1.97832023e-03 5.38777954e-03\n",
            " 3.73005694e-03 1.15343202e-03 1.05444040e-02 7.10757864e-03\n",
            " 3.04774112e-03 2.98094004e-03 6.21223053e-03 3.56121719e-03\n",
            " 4.59852317e-06 1.19466585e-02 8.23351803e-04 3.55180526e-03\n",
            " 1.32201615e-03 1.19269803e-02 9.28180453e-03 1.29244185e-05\n",
            " 1.03292753e-02 2.09676206e-03 1.92878109e-04 8.60120753e-03\n",
            " 1.27397835e-02 3.95455229e-03 3.04337023e-03 9.49132011e-03\n",
            " 1.66079392e-03 6.53588462e-04 2.23571207e-03 5.74440271e-04\n",
            " 1.69945455e-03 1.08664990e-03 3.46924741e-03 8.07912209e-03\n",
            " 5.69891309e-05 6.40218512e-04 1.02755507e-02 1.17796003e-03\n",
            " 1.17638442e-02 9.79529084e-03 1.16309585e-02 9.13878677e-03\n",
            " 1.23642792e-02 9.78940015e-03 8.79917134e-03 5.04411456e-03\n",
            " 7.82215728e-03 9.50049547e-03 7.69822145e-03 1.66079392e-03\n",
            " 9.81989275e-03 9.00757974e-03 2.21245873e-03 1.15477744e-02\n",
            " 3.54419352e-03 9.26320977e-03 4.38516221e-03 9.84520543e-03\n",
            " 1.74296352e-03 3.90958086e-03 1.09132405e-02 8.56074676e-03\n",
            " 1.27257086e-02 3.98476631e-03 8.55209733e-03 4.84505632e-04\n",
            " 2.40448982e-03 9.79024794e-03 3.50425552e-03 7.24772245e-03\n",
            " 9.71963212e-03 1.70307218e-04 4.60372419e-03 2.58129266e-03\n",
            " 3.42266052e-03 1.08138415e-02 8.43656089e-03 4.32174714e-03\n",
            " 5.29761438e-04 1.54512928e-03 1.27229543e-03 7.50978137e-03\n",
            " 4.53409093e-03 6.89569366e-04 3.83764172e-03 1.27692921e-02\n",
            " 3.57299706e-04 9.35604608e-03 1.66079392e-03 6.87242421e-03\n",
            " 1.15069835e-02 1.19747606e-02 5.91495715e-03 6.86374752e-03\n",
            " 7.72051139e-03 1.00354934e-02 9.37024346e-03 2.35062190e-03\n",
            " 3.76813444e-03 1.06953082e-03 8.75141130e-03 9.68447027e-03\n",
            " 8.96509626e-03 2.11234044e-04 1.03830687e-02 4.17995898e-03\n",
            " 6.81280668e-03 3.55180526e-03 9.48144881e-03 1.18007996e-03\n",
            " 2.56102199e-03 5.19725681e-04 8.40968288e-03 8.94004785e-03\n",
            " 5.34969341e-03 5.13689199e-03 1.41567490e-03 1.12424707e-02\n",
            " 1.24818206e-02 9.63545634e-03 6.71089230e-03 9.91660372e-03\n",
            " 1.02227795e-02 1.58951073e-04 6.74668177e-03 2.32104742e-03\n",
            " 4.39837627e-03 3.13287185e-03 5.44308650e-03 8.56455278e-03\n",
            " 1.15848953e-02 3.40828383e-03 6.96567546e-03 2.93257756e-03\n",
            " 9.22282475e-03 8.51684533e-03 1.88686036e-03 4.87741445e-04\n",
            " 2.63971945e-03 4.78422202e-03 9.48324518e-03 9.04452989e-03\n",
            " 4.19049854e-03 5.06454737e-04 3.13811063e-03 5.91722522e-03\n",
            " 4.84522122e-03 7.37608001e-03 5.72620677e-03 3.23934370e-04\n",
            " 2.80050890e-03 2.60830072e-03 7.08328743e-03 1.22815888e-02\n",
            " 9.17211235e-03 2.21245873e-03 1.43561874e-03 1.17619984e-02\n",
            " 2.21909009e-03 5.80763981e-03 9.86585074e-03 3.79624087e-03\n",
            " 1.26852467e-02 1.08259066e-02 4.47742035e-03 8.77100323e-04\n",
            " 1.25927736e-02 6.54723176e-03 4.58376275e-03 6.11342244e-03\n",
            " 3.51225982e-03 8.86383520e-03 5.83315490e-03 5.21596592e-03\n",
            " 2.81508816e-03 6.03422127e-03 1.06230234e-02 9.79419048e-04\n",
            " 7.16105976e-04 4.48869763e-03 8.23668016e-04 2.05967782e-04\n",
            " 1.07993709e-02 1.24198162e-02 1.13806616e-03 1.61227918e-03\n",
            " 3.09807447e-03 2.85803850e-03 7.55426087e-05 3.37517584e-03\n",
            " 6.10082307e-03 4.73592142e-03 1.71596137e-06 1.06923809e-02\n",
            " 6.38175115e-04 3.97694201e-07 2.48714920e-05 4.66883134e-05\n",
            " 1.06234507e-02 1.17889129e-02 1.31835426e-03 9.43224926e-04\n",
            " 1.20013334e-02 4.00586338e-03 3.86778276e-03 5.28019117e-03\n",
            " 1.13097764e-02 5.28019117e-03 1.07166928e-02 1.08798257e-03\n",
            " 7.19762836e-03 1.86071040e-03 3.80631699e-03 2.27824424e-04\n",
            " 3.94847291e-04 8.80939302e-03 3.57498014e-03 1.25323195e-02\n",
            " 4.36983068e-03 3.68470708e-03 2.25939792e-04 4.78022331e-03\n",
            " 5.95597993e-03 7.24467717e-03 6.43668088e-03 4.93421502e-03\n",
            " 5.40461683e-03 1.02832866e-02 1.07926082e-02 2.89561241e-03\n",
            " 1.18273363e-02 1.01899350e-02 7.53662803e-03 5.45747351e-03\n",
            " 5.59214818e-03 3.86778276e-03 7.60356694e-03 9.84040657e-03\n",
            " 1.21548891e-03 1.08561047e-03 3.29097732e-03 5.89179412e-03\n",
            " 4.03497564e-03 5.57935821e-04 1.12298273e-02 1.04393436e-02\n",
            " 8.06975550e-03 5.42816099e-03 1.88163213e-03 1.00919716e-03\n",
            " 8.89999640e-03 6.15270147e-03 6.68232413e-03 8.05776143e-03\n",
            " 1.25983141e-02 9.75432007e-03 2.65986028e-03 1.43301635e-03\n",
            " 1.23561728e-03 6.87417124e-03 9.24216735e-03 1.25610031e-02\n",
            " 6.61766155e-03 8.73058978e-03 4.51174633e-03 1.27627997e-02\n",
            " 1.00364682e-02 4.64630619e-03 8.32356838e-03 1.16641800e-02\n",
            " 3.19731878e-03 3.40808428e-03 8.11902349e-03 4.44070970e-04\n",
            " 1.01756099e-03 7.38816395e-03 7.83625510e-03 2.57560957e-03\n",
            " 9.78940015e-03 5.17095847e-03 7.52782390e-03 3.51496398e-04\n",
            " 5.51382389e-03 7.17297365e-03 4.33413187e-03 1.11228449e-02\n",
            " 6.07276939e-03 3.58182514e-03 7.50215555e-03 8.23283362e-03\n",
            " 9.67559008e-03 7.47943182e-03 4.87406410e-03 6.20004832e-03\n",
            " 6.20604290e-03 8.23351803e-04 3.60672553e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3610 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.11080124e-03 4.33293560e-03 4.33481558e-03 3.55095016e-03\n",
            " 6.89404431e-04 1.22071726e-02 8.57965395e-03 3.76072422e-03\n",
            " 7.64706877e-03 1.16682077e-02 8.45257003e-03 1.07702535e-02\n",
            " 7.74277362e-03 1.15784559e-02 1.16659469e-02 1.16601404e-02\n",
            " 5.43227536e-03 5.03911996e-03 7.82540690e-03 5.85583023e-03\n",
            " 8.69071104e-03 1.47630835e-03 9.04027404e-03 4.18122113e-03\n",
            " 5.66017470e-03 3.87288700e-03 1.21839882e-05 4.48264724e-03\n",
            " 1.05351576e-02 3.39784230e-03 1.17706290e-02 1.00255730e-04\n",
            " 7.51006122e-03 1.05351576e-02 1.00478970e-02 1.92787425e-03\n",
            " 4.18094297e-09 4.16885376e-03 1.62432801e-05 5.87755634e-03\n",
            " 1.23794495e-02 1.11197621e-02 3.03499118e-04 9.47165721e-08\n",
            " 1.20089409e-02 7.67311372e-03 7.45716776e-03 2.86180629e-03\n",
            " 7.09845630e-03 1.15000348e-02 9.78949865e-03 6.20179609e-03\n",
            " 9.35944958e-03 2.42673954e-03 1.03701884e-02 8.83029567e-03\n",
            " 1.22418009e-02 1.15013210e-02 1.08578730e-02 9.35097564e-04\n",
            " 7.49151334e-03 2.44623928e-03 3.40833411e-04 1.11042851e-03\n",
            " 7.77150984e-03 2.96298693e-03 9.75555001e-03 9.78949865e-03\n",
            " 1.13377596e-02 4.09901238e-04 8.11653609e-03 5.43814765e-03\n",
            " 4.45946398e-03 1.19310762e-02 4.61813320e-04 1.05409348e-02\n",
            " 8.86423431e-03 4.36006420e-03 4.39403170e-03 1.26123430e-03\n",
            " 6.04214410e-03 1.06453850e-02 6.79993456e-04 9.80088853e-04\n",
            " 1.02468756e-02 4.90638914e-03 5.77984610e-05 4.17399788e-03\n",
            " 1.12175328e-02 1.04628075e-02 1.02185681e-02 1.77748006e-03\n",
            " 1.00503766e-02 9.91104030e-03 8.29159165e-04 2.36571647e-03\n",
            " 1.10261704e-02 1.01816999e-02 7.51610727e-03 9.49973456e-03\n",
            " 4.49317462e-03 1.00478970e-02 3.75436439e-03 7.58089152e-05\n",
            " 8.67518481e-03 3.38386811e-03 3.75436439e-03 1.12697512e-02\n",
            " 9.49363154e-03 6.27195295e-03 1.11857835e-03 1.21727013e-02\n",
            " 7.42125494e-03 1.11948777e-02 1.32996214e-03 1.25290920e-02\n",
            " 3.28845477e-05 8.02349538e-03 5.44878802e-03 2.97841212e-03\n",
            " 1.08660838e-02 6.29570991e-03 9.10584709e-03 5.83776555e-03\n",
            " 8.18049857e-03 1.05756575e-02 9.90972304e-03 9.06878785e-03\n",
            " 4.18094297e-09 3.73634213e-03 7.88512216e-03 8.10074563e-03\n",
            " 1.02353090e-03 1.18883002e-02 3.77619031e-03 9.30433940e-03\n",
            " 2.07386288e-03 6.95079296e-03 2.38514344e-03 8.08631825e-03\n",
            " 4.32773069e-03 1.17367723e-02 8.43675068e-03 6.01909506e-03\n",
            " 4.78483840e-03 6.33016990e-03 3.11863330e-03 8.45257003e-03\n",
            " 1.22537405e-02 8.75880751e-03 4.89085187e-03 1.18178180e-02\n",
            " 4.36006420e-03 1.17706290e-02 9.12365167e-03 6.77459841e-03\n",
            " 1.09242814e-02 9.26877449e-03 5.38900118e-03 9.78744549e-03\n",
            " 6.93543584e-03 2.40569068e-03 1.18281839e-02 2.04079722e-04\n",
            " 3.66773457e-03 1.06475646e-02 1.13026696e-02 4.03961531e-03\n",
            " 1.03108346e-02 3.80678243e-03 7.50588885e-03 8.50117892e-03\n",
            " 9.76188010e-03 5.34580485e-04 2.84849126e-03 1.10615811e-02\n",
            " 6.38308880e-03 1.39214831e-06 1.20813130e-02 7.04212013e-05\n",
            " 7.45658537e-04 2.91054592e-03 7.74055476e-03 2.96819863e-03\n",
            " 8.64794694e-03 4.89164092e-03 4.41960438e-04 6.36659019e-03\n",
            " 4.89944197e-03 1.18733255e-02 1.24050997e-03 1.01238398e-02\n",
            " 8.63613961e-04 4.89745232e-03 1.22071726e-02 6.89548783e-03\n",
            " 8.28905663e-03 4.74171825e-03 5.82158135e-03 4.15285661e-03\n",
            " 4.91070646e-03 5.08994720e-03 3.09958191e-03 8.00187132e-03\n",
            " 4.36006420e-03 1.08207206e-02 8.34944995e-03 4.17631313e-03\n",
            " 1.27396750e-03 1.75734748e-03 9.45122717e-03 3.60012576e-03\n",
            " 9.40878044e-03 1.17463335e-02 1.43311208e-03 5.10430983e-03\n",
            " 1.17522792e-02 1.09481395e-04 7.35323857e-03 1.16415733e-16\n",
            " 3.43176525e-03 6.49945014e-03 1.23911179e-02 1.22201634e-02\n",
            " 1.94798169e-04 9.27737532e-03 9.48394032e-03 1.03108346e-02\n",
            " 7.49151334e-03 2.89484629e-03 3.80423051e-03 2.94037664e-03\n",
            " 1.11948777e-02 3.32252835e-03 3.37741767e-03 1.12472481e-02\n",
            " 6.32044936e-03 8.13280206e-03 2.07556225e-03 2.04841556e-04\n",
            " 8.58703575e-03 4.08895307e-03 6.84683313e-03 1.12981395e-02\n",
            " 3.57353800e-03 3.59431697e-04 7.67002785e-03 1.87702294e-03\n",
            " 4.15423371e-03 3.03013323e-03 8.95007565e-03 1.17372352e-02\n",
            " 1.74395455e-04 4.31648700e-03 3.05297491e-03 8.39252892e-03\n",
            " 5.39443029e-03 2.99656944e-03 8.51867328e-03 8.94762131e-03\n",
            " 6.53422991e-03 5.08356756e-03 1.07337508e-02 5.85583023e-03\n",
            " 9.95333084e-03 4.48047763e-03 1.20997276e-02 1.70466429e-04\n",
            " 9.01612457e-03 1.73127039e-03 8.33540016e-03 1.01013303e-02\n",
            " 7.25403790e-03 6.53267931e-03 4.17399788e-03 2.01603822e-03\n",
            " 3.00543542e-03 1.62219605e-03 1.36120972e-03 5.17374923e-03\n",
            " 1.97142635e-03 5.38900118e-03 3.73135650e-03 1.15228572e-03\n",
            " 1.05515948e-02 7.11014405e-03 3.04959757e-03 2.98022705e-03\n",
            " 6.19195686e-03 3.55924020e-03 4.56470564e-06 1.19563892e-02\n",
            " 8.16674362e-04 3.53888243e-03 1.31514628e-03 1.19345015e-02\n",
            " 9.25462573e-03 1.29202831e-05 1.03125737e-02 2.08568435e-03\n",
            " 1.92404790e-04 8.59486518e-03 3.95754185e-03 3.04485363e-03\n",
            " 9.47223967e-03 1.65361636e-03 6.52479126e-04 2.23241793e-03\n",
            " 5.72714393e-04 1.69293247e-03 1.08696196e-03 3.46739391e-03\n",
            " 8.07374955e-03 5.68312021e-05 6.38515078e-04 1.02454339e-02\n",
            " 1.17350789e-03 1.17560169e-02 9.77215149e-03 1.16100367e-02\n",
            " 9.13199025e-03 1.23581339e-02 9.78949865e-03 8.81097913e-03\n",
            " 5.03976640e-03 7.80870256e-03 9.48428984e-03 7.68923952e-03\n",
            " 1.65361636e-03 9.80656662e-03 9.00096861e-03 2.20491617e-03\n",
            " 1.15091461e-02 3.53012261e-03 9.23671016e-03 4.37613250e-03\n",
            " 9.83542464e-03 1.73946750e-03 3.89484101e-03 1.08834433e-02\n",
            " 8.55861115e-03 3.97032595e-03 8.55641230e-03 4.83943468e-04\n",
            " 2.38666628e-03 9.75733629e-03 3.50034171e-03 7.25852359e-03\n",
            " 9.70463988e-03 1.70466429e-04 4.59949747e-03 2.57320322e-03\n",
            " 3.42072813e-03 1.07879085e-02 8.43223752e-03 4.31972321e-03\n",
            " 5.27732248e-04 1.54201090e-03 1.27014288e-03 7.44933717e-03\n",
            " 4.52145511e-03 6.89404431e-04 3.82791453e-03 3.55574937e-04\n",
            " 9.34625927e-03 1.65361636e-03 6.85698494e-03 1.15141023e-02\n",
            " 1.19777263e-02 5.90441172e-03 6.80246936e-03 7.69946998e-03\n",
            " 1.00205599e-02 9.36394587e-03 2.34897169e-03 3.76200919e-03\n",
            " 1.06460468e-03 8.74967499e-03 9.66349743e-03 8.94029954e-03\n",
            " 2.11210194e-04 1.03721454e-02 4.17399788e-03 6.80089559e-03\n",
            " 3.53888243e-03 9.45118331e-03 1.18452323e-03 2.55025156e-03\n",
            " 5.18595698e-04 8.39259316e-03 8.93093333e-03 5.35783886e-03\n",
            " 5.11991663e-03 1.41744264e-03 1.12190745e-02 1.24521908e-02\n",
            " 9.61876584e-03 6.70543481e-03 9.87020380e-03 1.01981210e-02\n",
            " 1.58933223e-04 6.74534828e-03 2.31458880e-03 4.39399066e-03\n",
            " 3.12302821e-03 5.44878802e-03 8.54363484e-03 1.15748719e-02\n",
            " 3.38386811e-03 6.94925330e-03 2.90812207e-03 9.18726057e-03\n",
            " 8.52251939e-03 1.88522735e-03 4.84438947e-04 2.63220424e-03\n",
            " 4.76636898e-03 9.48702835e-03 9.03781063e-03 4.18876482e-03\n",
            " 5.03484877e-04 3.12763067e-03 5.90290768e-03 4.83085997e-03\n",
            " 7.36758294e-03 5.70411003e-03 3.22086486e-04 2.78916407e-03\n",
            " 2.59909746e-03 7.05737014e-03 1.22565221e-02 9.15484153e-03\n",
            " 2.20491617e-03 1.41999119e-03 1.17414975e-02 2.21748974e-03\n",
            " 5.80146728e-03 9.83076769e-03 3.79315917e-03 1.08037023e-02\n",
            " 4.47078598e-03 8.73034898e-04 6.54564984e-03 4.55828217e-03\n",
            " 6.10734930e-03 3.50141032e-03 8.86352823e-03 5.82639993e-03\n",
            " 5.17925251e-03 2.81441452e-03 6.04001917e-03 1.06099819e-02\n",
            " 9.79248077e-04 7.15728492e-04 4.48264724e-03 8.19596652e-04\n",
            " 2.05681911e-04 1.07785012e-02 1.23743945e-02 1.13768639e-03\n",
            " 1.61213677e-03 3.08907285e-03 2.86180629e-03 7.48373808e-05\n",
            " 3.37009575e-03 6.06141906e-03 4.73333045e-03 1.69574138e-06\n",
            " 1.06304542e-02 6.36279352e-04 3.91970198e-07 2.47561837e-05\n",
            " 4.63066059e-05 1.06282393e-02 1.17967359e-02 1.31274261e-03\n",
            " 9.41392883e-04 1.19460613e-02 4.00274559e-03 3.87288700e-03\n",
            " 5.28187431e-03 1.12977569e-02 5.28187431e-03 1.07196066e-02\n",
            " 1.08555076e-03 7.19463820e-03 1.86318585e-03 3.79835112e-03\n",
            " 2.25863409e-04 3.93427828e-04 8.73928419e-03 3.58400257e-03\n",
            " 1.25303566e-02 4.37009068e-03 3.67984130e-03 2.25954062e-04\n",
            " 4.76900082e-03 5.93864653e-03 7.22873821e-03 6.44023563e-03\n",
            " 4.93611327e-03 5.39443029e-03 1.01532581e-02 1.07858259e-02\n",
            " 2.88899481e-03 1.18365631e-02 1.01634499e-02 7.49746652e-03\n",
            " 5.45897642e-03 5.58557455e-03 3.87288700e-03 7.59874906e-03\n",
            " 9.79034645e-03 1.21581053e-03 1.08172777e-03 3.28156921e-03\n",
            " 5.88273770e-03 4.03183409e-03 5.55324963e-04 1.12190316e-02\n",
            " 1.04351941e-02 8.04242528e-03 5.43257773e-03 1.87771140e-03\n",
            " 1.00072722e-03 8.91434819e-03 6.13660083e-03 6.65424048e-03\n",
            " 8.06270459e-03 9.75832036e-03 2.65693703e-03 1.42411871e-03\n",
            " 1.23613706e-03 6.89569004e-03 9.24623288e-03 6.59299530e-03\n",
            " 8.72182233e-03 4.49596377e-03 1.00163424e-02 4.64987641e-03\n",
            " 8.30708537e-03 1.16622941e-02 3.18979592e-03 3.40739237e-03\n",
            " 8.12982441e-03 4.42751909e-04 1.01553924e-03 7.38011140e-03\n",
            " 7.81017855e-03 2.57327652e-03 9.78949865e-03 5.16969359e-03\n",
            " 7.52100408e-03 3.50168133e-04 5.49406640e-03 7.16565754e-03\n",
            " 4.29616738e-03 1.11072764e-02 6.07167664e-03 3.57915252e-03\n",
            " 7.48536767e-03 8.21323672e-03 9.68388556e-03 7.48095439e-03\n",
            " 4.86844104e-03 6.19078727e-03 6.18139671e-03 8.16674362e-04\n",
            " 3.60030607e-03]\n",
            "3620 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.09241995e-03 4.31801571e-03 4.31641660e-03 3.54812557e-03\n",
            " 6.88621936e-04 1.22058450e-02 8.54622186e-03 3.75871292e-03\n",
            " 7.62062589e-03 1.16561038e-02 8.43985394e-03 1.07765811e-02\n",
            " 7.73055700e-03 1.15259150e-02 1.16420871e-02 1.16556755e-02\n",
            " 5.42773834e-03 5.01829905e-03 7.80267485e-03 5.84632406e-03\n",
            " 8.65860913e-03 1.47339014e-03 9.03567294e-03 4.16187333e-03\n",
            " 5.66038483e-03 3.87085045e-03 1.21640784e-05 4.48325038e-03\n",
            " 1.05263870e-02 3.39695712e-03 1.17457766e-02 9.99708479e-05\n",
            " 7.46742880e-03 1.05263870e-02 1.00447392e-02 1.92141484e-03\n",
            " 4.10356325e-09 4.16741919e-03 1.62110677e-05 5.86261958e-03\n",
            " 1.10961351e-02 3.03490768e-04 9.42151904e-08 1.19954687e-02\n",
            " 7.64664248e-03 7.44860542e-03 2.86012094e-03 7.08344298e-03\n",
            " 1.14822332e-02 9.78700639e-03 6.17457544e-03 9.34238426e-03\n",
            " 2.41908077e-03 1.03769891e-02 8.83353488e-03 1.14800432e-02\n",
            " 1.08257739e-02 9.31510155e-04 7.48726093e-03 2.43841061e-03\n",
            " 3.38969256e-04 1.10669443e-03 7.74585056e-03 2.95341921e-03\n",
            " 9.74862181e-03 9.78700639e-03 1.13166866e-02 4.10072992e-04\n",
            " 8.08789514e-03 5.40493527e-03 4.45780088e-03 1.18954885e-02\n",
            " 4.59698657e-04 1.05281295e-02 8.84039435e-03 4.35339869e-03\n",
            " 4.37590606e-03 1.25744094e-03 6.01649813e-03 1.06299716e-02\n",
            " 6.78161273e-04 9.77364228e-04 1.02412251e-02 4.89224949e-03\n",
            " 5.77438452e-05 4.17005679e-03 1.12083776e-02 1.04327734e-02\n",
            " 1.02081987e-02 1.77514322e-03 1.00465493e-02 9.90068288e-03\n",
            " 8.24616827e-04 2.36615664e-03 1.10010104e-02 1.01692123e-02\n",
            " 7.51040924e-03 9.48650603e-03 4.48274656e-03 1.00447392e-02\n",
            " 3.74822482e-03 7.54335014e-05 8.68199112e-03 3.37959389e-03\n",
            " 3.74822482e-03 1.12270793e-02 9.48679582e-03 6.25972830e-03\n",
            " 1.11654669e-03 1.21467377e-02 7.40759137e-03 1.11607551e-02\n",
            " 1.32350187e-03 3.29308633e-05 8.02801594e-03 5.44929431e-03\n",
            " 2.97960349e-03 1.08541634e-02 6.29995250e-03 9.08256755e-03\n",
            " 5.84451782e-03 8.18044929e-03 1.05414499e-02 9.88058503e-03\n",
            " 9.04189692e-03 4.10356325e-09 3.73058703e-03 7.88445065e-03\n",
            " 8.09909034e-03 1.01824107e-03 1.18770665e-02 3.76587405e-03\n",
            " 9.29875889e-03 2.05606340e-03 6.89903613e-03 2.38451775e-03\n",
            " 8.07382226e-03 4.32412531e-03 1.17374110e-02 8.43053740e-03\n",
            " 6.02156130e-03 4.77257560e-03 6.30861298e-03 3.11826920e-03\n",
            " 8.43985394e-03 8.74085253e-03 4.89129512e-03 1.18091182e-02\n",
            " 4.35339869e-03 1.17457766e-02 9.13262758e-03 6.76056932e-03\n",
            " 1.09245353e-02 9.26064115e-03 5.38974743e-03 9.76804578e-03\n",
            " 6.92404221e-03 2.39656790e-03 1.18301799e-02 2.03576816e-04\n",
            " 3.65524205e-03 1.06117677e-02 1.12721979e-02 4.03899867e-03\n",
            " 1.02852670e-02 3.80495147e-03 7.49007269e-03 8.50441866e-03\n",
            " 9.75289294e-03 5.31572994e-04 2.84522053e-03 1.10404192e-02\n",
            " 6.38023026e-03 1.37768423e-06 1.20705021e-02 7.02496078e-05\n",
            " 7.44138570e-04 2.90096894e-03 7.74149459e-03 2.95709934e-03\n",
            " 8.63526839e-03 4.90014862e-03 4.40376985e-04 6.36185712e-03\n",
            " 4.89070951e-03 1.18589768e-02 1.23919330e-03 1.01020095e-02\n",
            " 8.60930412e-04 4.90311667e-03 1.22058450e-02 6.88880275e-03\n",
            " 8.27192175e-03 4.72234354e-03 5.81628118e-03 4.15193971e-03\n",
            " 4.90626875e-03 5.08270500e-03 3.09492935e-03 7.98357272e-03\n",
            " 4.35339869e-03 1.07947218e-02 8.31270494e-03 4.15440358e-03\n",
            " 1.27126876e-03 1.75203638e-03 9.43109980e-03 3.58802339e-03\n",
            " 9.39411081e-03 1.17403752e-02 1.42784294e-03 5.09914222e-03\n",
            " 1.17021074e-02 1.09064525e-04 7.35032308e-03 1.17034799e-16\n",
            " 3.40902391e-03 6.48986082e-03 1.22029654e-02 1.94637543e-04\n",
            " 9.26703693e-03 9.48198713e-03 1.02852670e-02 7.48726093e-03\n",
            " 2.89271455e-03 3.79100949e-03 2.94040444e-03 1.11607551e-02\n",
            " 3.31647364e-03 3.36089825e-03 1.12417599e-02 6.28604840e-03\n",
            " 8.12064173e-03 2.06470533e-03 2.04068532e-04 8.57172189e-03\n",
            " 4.08388165e-03 6.83141011e-03 1.13051219e-02 3.58064975e-03\n",
            " 3.58489936e-04 7.65940582e-03 1.87427029e-03 4.15093883e-03\n",
            " 3.02342035e-03 8.93315586e-03 1.17278598e-02 1.73662573e-04\n",
            " 4.30718223e-03 3.04887511e-03 8.39124230e-03 5.38430808e-03\n",
            " 2.99081366e-03 8.48780612e-03 8.91170487e-03 6.53863747e-03\n",
            " 5.07763536e-03 1.06885762e-02 5.84632406e-03 9.94457003e-03\n",
            " 4.47666240e-03 1.20637374e-02 1.69298140e-04 8.99731428e-03\n",
            " 1.72093273e-03 8.30650017e-03 1.00758281e-02 7.24812759e-03\n",
            " 6.53197599e-03 4.17005679e-03 2.01205566e-03 2.99212938e-03\n",
            " 1.62062559e-03 1.36117997e-03 5.15688643e-03 1.96908147e-03\n",
            " 5.38974743e-03 3.72873486e-03 1.14913229e-03 1.05317677e-02\n",
            " 7.10352864e-03 3.04335572e-03 2.96628588e-03 6.17856226e-03\n",
            " 3.55246747e-03 4.53916184e-06 1.19343991e-02 8.13978955e-04\n",
            " 3.53663845e-03 1.31102136e-03 1.19151942e-02 9.23914644e-03\n",
            " 1.27984479e-05 1.03066921e-02 2.08450185e-03 1.92220031e-04\n",
            " 8.58719111e-03 3.94867284e-03 3.03419923e-03 9.45572648e-03\n",
            " 1.65181939e-03 6.49822610e-04 2.23118556e-03 5.72508933e-04\n",
            " 1.68841989e-03 1.08459412e-03 3.45661826e-03 8.06608489e-03\n",
            " 5.67513936e-05 6.33567427e-04 1.02427335e-02 1.17228725e-03\n",
            " 1.17341695e-02 9.72288546e-03 1.16004405e-02 9.12030392e-03\n",
            " 9.78700639e-03 8.80529484e-03 5.03278608e-03 7.80820943e-03\n",
            " 9.47641244e-03 7.68688664e-03 1.65181939e-03 9.79252364e-03\n",
            " 8.98616279e-03 2.19562671e-03 1.14835388e-02 3.51641432e-03\n",
            " 9.23532741e-03 4.37087671e-03 9.78364519e-03 1.73714258e-03\n",
            " 3.87564339e-03 1.08764198e-02 8.54818236e-03 3.97394424e-03\n",
            " 8.54833884e-03 4.82006497e-04 2.38676565e-03 9.73375027e-03\n",
            " 3.48401280e-03 7.22626385e-03 9.70263111e-03 1.69298140e-04\n",
            " 4.58278227e-03 2.57297537e-03 3.40402260e-03 1.07223989e-02\n",
            " 8.42396948e-03 4.31308012e-03 5.24593408e-04 1.54166956e-03\n",
            " 1.26883285e-03 7.40706572e-03 4.50799703e-03 6.88621936e-04\n",
            " 3.81781011e-03 3.53687328e-04 9.35698939e-03 1.65181939e-03\n",
            " 6.86045632e-03 1.14831849e-02 1.19170940e-02 5.88791279e-03\n",
            " 6.79432932e-03 7.70372455e-03 1.00114236e-02 9.36391934e-03\n",
            " 2.34041179e-03 3.75028777e-03 1.06146899e-03 8.75061341e-03\n",
            " 9.64345879e-03 8.93494912e-03 2.11088329e-04 1.03479291e-02\n",
            " 4.17005679e-03 6.78342873e-03 3.53663845e-03 9.45892204e-03\n",
            " 1.18716111e-03 2.55159866e-03 5.15929237e-04 8.37051023e-03\n",
            " 8.90991154e-03 5.36065914e-03 5.11924361e-03 1.41304535e-03\n",
            " 1.12083342e-02 9.60390496e-03 6.69980584e-03 9.86387826e-03\n",
            " 1.02055881e-02 1.58886319e-04 6.74022753e-03 2.30741580e-03\n",
            " 4.36234797e-03 3.10413898e-03 5.44929431e-03 8.53037541e-03\n",
            " 1.15372807e-02 3.37959389e-03 6.94561039e-03 2.90143268e-03\n",
            " 9.17982896e-03 8.50764669e-03 1.88142060e-03 4.84489564e-04\n",
            " 2.62956997e-03 4.74912300e-03 9.48649553e-03 9.02819116e-03\n",
            " 4.18285427e-03 5.01540660e-04 3.11648492e-03 5.88458990e-03\n",
            " 4.83023798e-03 7.33508114e-03 5.68007312e-03 3.20407109e-04\n",
            " 2.77825533e-03 2.59042709e-03 7.03802795e-03 9.12863093e-03\n",
            " 2.19562671e-03 1.41673595e-03 1.17057837e-02 2.21313002e-03\n",
            " 5.78862284e-03 9.82733367e-03 3.79420260e-03 1.08051053e-02\n",
            " 4.45196628e-03 8.67739514e-04 6.53875233e-03 4.54221740e-03\n",
            " 6.09042817e-03 3.48450864e-03 8.83914400e-03 5.82209513e-03\n",
            " 5.17637210e-03 2.81295118e-03 6.02285269e-03 1.05782416e-02\n",
            " 9.74755734e-04 7.15334212e-04 4.48325038e-03 8.20482868e-04\n",
            " 2.05339299e-04 1.07183859e-02 1.12990903e-03 1.61227544e-03\n",
            " 3.08177836e-03 2.86012094e-03 7.47114615e-05 3.35830233e-03\n",
            " 6.04154098e-03 4.73189612e-03 1.69509415e-06 1.06258952e-02\n",
            " 6.34642565e-04 3.91700095e-07 2.45791812e-05 4.60004175e-05\n",
            " 1.06243405e-02 1.17918151e-02 1.31176589e-03 9.39990842e-04\n",
            " 1.19210994e-02 3.99812349e-03 3.87085045e-03 5.27836711e-03\n",
            " 1.12855471e-02 5.27836711e-03 1.07259097e-02 1.08362935e-03\n",
            " 7.18455045e-03 1.85676784e-03 3.77898431e-03 2.26371920e-04\n",
            " 3.91860957e-04 8.72421974e-03 3.57480356e-03 4.35447750e-03\n",
            " 3.67215280e-03 2.24815510e-04 4.76197938e-03 5.93312961e-03\n",
            " 7.21543237e-03 6.41795315e-03 4.93523444e-03 5.38430808e-03\n",
            " 1.01280482e-02 1.07645643e-02 2.88396055e-03 1.18230610e-02\n",
            " 1.01622858e-02 7.48410975e-03 5.44438308e-03 5.55591218e-03\n",
            " 3.87085045e-03 7.56361917e-03 9.78770132e-03 1.21252608e-03\n",
            " 1.07994754e-03 3.27731266e-03 5.87462008e-03 4.01663659e-03\n",
            " 5.55735677e-04 1.12019785e-02 1.04160027e-02 8.03473496e-03\n",
            " 5.42123508e-03 1.87052149e-03 9.99586300e-04 8.89721161e-03\n",
            " 6.10949035e-03 6.63941284e-03 8.05098209e-03 9.73103758e-03\n",
            " 2.65273222e-03 1.42179803e-03 1.23191133e-03 6.87613854e-03\n",
            " 9.24220815e-03 6.59323127e-03 8.71775871e-03 4.49563812e-03\n",
            " 1.00009363e-02 4.63281634e-03 8.30758302e-03 1.16508503e-02\n",
            " 3.17646711e-03 3.40666887e-03 8.10743615e-03 4.40766268e-04\n",
            " 1.01400735e-03 7.35309236e-03 7.79160252e-03 2.57159702e-03\n",
            " 9.78700639e-03 5.16249015e-03 7.51898104e-03 3.48706447e-04\n",
            " 5.49526925e-03 7.15545126e-03 4.28954235e-03 1.10908012e-02\n",
            " 6.07024344e-03 3.58052168e-03 7.45686755e-03 8.19358068e-03\n",
            " 9.66402303e-03 7.48298243e-03 4.85915121e-03 6.17382649e-03\n",
            " 6.17651531e-03 8.13978955e-04 3.59650136e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3630 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.07642525e-03 4.31506986e-03 4.30029142e-03 3.54503385e-03\n",
            " 6.87672982e-04 8.54822461e-03 3.75144742e-03 7.60653328e-03\n",
            " 1.16641364e-02 8.44313482e-03 1.07799931e-02 7.71643889e-03\n",
            " 1.14892987e-02 1.16396179e-02 1.16562499e-02 5.43327097e-03\n",
            " 5.00657551e-03 7.79302380e-03 5.84576648e-03 8.64190063e-03\n",
            " 1.47161845e-03 9.01779079e-03 4.16211435e-03 5.65079096e-03\n",
            " 3.86663535e-03 1.21158067e-05 4.47965251e-03 1.05206018e-02\n",
            " 3.39781364e-03 1.17289870e-02 9.97053625e-05 7.42770252e-03\n",
            " 1.05206018e-02 1.00436459e-02 1.92191900e-03 4.05798239e-09\n",
            " 4.15671423e-03 1.61435254e-05 5.85046810e-03 1.10887984e-02\n",
            " 3.03423721e-04 9.24315479e-08 7.62193284e-03 7.43585402e-03\n",
            " 2.85730542e-03 7.07525679e-03 1.14569786e-02 9.78406709e-03\n",
            " 6.15259841e-03 9.32080906e-03 2.41225205e-03 1.03672573e-02\n",
            " 8.82284853e-03 1.14510429e-02 1.08015518e-02 9.27163647e-04\n",
            " 7.47696541e-03 2.43841294e-03 3.37576393e-04 1.10245108e-03\n",
            " 7.71361973e-03 2.95612741e-03 9.74321824e-03 9.78406709e-03\n",
            " 1.13232500e-02 4.09561399e-04 8.07560808e-03 5.40633328e-03\n",
            " 4.46140997e-03 1.18751101e-02 4.57963612e-04 1.05164693e-02\n",
            " 8.84342327e-03 4.35231796e-03 4.36357804e-03 1.25372478e-03\n",
            " 6.00825695e-03 1.06239260e-02 6.75700155e-04 9.76627683e-04\n",
            " 1.02197043e-02 4.87720907e-03 5.75526069e-05 4.16507575e-03\n",
            " 1.11847544e-02 1.04188662e-02 1.01933526e-02 1.77334432e-03\n",
            " 1.00442772e-02 9.90513142e-03 8.23674768e-04 2.36381287e-03\n",
            " 1.09791523e-02 1.01374360e-02 7.50211367e-03 9.48368179e-03\n",
            " 4.46770144e-03 1.00436459e-02 3.74742749e-03 7.48380363e-05\n",
            " 8.68110373e-03 3.37143540e-03 3.74742749e-03 1.12034263e-02\n",
            " 9.48325797e-03 6.24404080e-03 1.11524483e-03 7.40454703e-03\n",
            " 1.11830085e-02 1.31622189e-03 3.29107645e-05 8.02671113e-03\n",
            " 5.44416025e-03 2.97881755e-03 1.08369044e-02 6.28179412e-03\n",
            " 9.07792331e-03 5.84301622e-03 8.17262091e-03 1.05376685e-02\n",
            " 9.86795936e-03 9.03509313e-03 4.05798239e-09 3.72852066e-03\n",
            " 7.88699168e-03 8.10246682e-03 1.01293463e-03 1.18798933e-02\n",
            " 3.76130772e-03 9.27874623e-03 2.04403120e-03 6.87158147e-03\n",
            " 2.38449712e-03 7.97477467e-03 4.32272945e-03 1.17150442e-02\n",
            " 8.42340201e-03 6.00900258e-03 4.77128491e-03 6.31054257e-03\n",
            " 3.11657110e-03 8.44313482e-03 8.70253995e-03 4.88958930e-03\n",
            " 1.17991997e-02 4.35231796e-03 1.17289870e-02 9.13350014e-03\n",
            " 6.73094921e-03 1.09176313e-02 9.25275151e-03 5.39069166e-03\n",
            " 9.75673717e-03 6.90792213e-03 2.38567355e-03 1.18127287e-02\n",
            " 2.02200097e-04 3.65126691e-03 1.06093253e-02 1.12701480e-02\n",
            " 4.03303689e-03 1.02681721e-02 3.79772204e-03 7.48178554e-03\n",
            " 8.50273693e-03 9.75319215e-03 5.31424148e-04 2.84595728e-03\n",
            " 1.10238817e-02 6.37315123e-03 1.36985670e-06 7.00961667e-05\n",
            " 7.40583119e-04 2.89356924e-03 7.71201753e-03 2.95422164e-03\n",
            " 8.64004978e-03 4.90062763e-03 4.37883058e-04 6.35479324e-03\n",
            " 4.88372352e-03 1.18485642e-02 1.23641849e-03 1.00938921e-02\n",
            " 8.58745244e-04 4.89427935e-03 6.88055093e-03 8.26611505e-03\n",
            " 4.71876698e-03 5.80985711e-03 4.14913884e-03 4.90279422e-03\n",
            " 5.07780481e-03 3.08339525e-03 7.97083277e-03 4.35231796e-03\n",
            " 1.07622415e-02 8.29371025e-03 4.14953803e-03 1.26689645e-03\n",
            " 1.75193191e-03 9.42118468e-03 3.58211383e-03 9.39192003e-03\n",
            " 1.17144892e-02 1.42380751e-03 5.09776791e-03 1.16683422e-02\n",
            " 1.08740964e-04 7.34631121e-03 1.17476754e-16 3.40709495e-03\n",
            " 6.48157466e-03 1.94475761e-04 9.25195845e-03 9.47285628e-03\n",
            " 1.02681721e-02 7.47696541e-03 2.89229101e-03 3.77983600e-03\n",
            " 2.93366146e-03 1.11830085e-02 3.31633138e-03 3.35182420e-03\n",
            " 1.12272465e-02 6.27632456e-03 8.11016732e-03 2.05562203e-03\n",
            " 2.03932431e-04 8.55921890e-03 4.07608511e-03 6.81559618e-03\n",
            " 1.13007920e-02 3.58266535e-03 3.57803865e-04 7.67100114e-03\n",
            " 1.87367737e-03 4.15032599e-03 3.02632905e-03 8.92538012e-03\n",
            " 1.17386702e-02 1.72903515e-04 4.30080394e-03 3.05027511e-03\n",
            " 8.39339668e-03 5.38721224e-03 2.99076827e-03 8.47264986e-03\n",
            " 8.91479729e-03 6.52836486e-03 5.06707667e-03 1.06610716e-02\n",
            " 5.84576648e-03 9.93582430e-03 4.47624705e-03 1.68772098e-04\n",
            " 9.00529574e-03 1.72095929e-03 8.28232612e-03 1.00719728e-02\n",
            " 7.23904545e-03 6.53163861e-03 4.16507575e-03 2.01171734e-03\n",
            " 2.98808642e-03 1.61882425e-03 1.36065182e-03 5.14925992e-03\n",
            " 1.96740853e-03 5.39069166e-03 3.71434791e-03 1.14533039e-03\n",
            " 1.05295626e-02 7.10797887e-03 3.04564239e-03 2.95844814e-03\n",
            " 6.16856628e-03 3.55445825e-03 4.52443336e-06 8.10265338e-04\n",
            " 3.52204088e-03 1.30953832e-03 1.19009219e-02 9.22833050e-03\n",
            " 1.27696986e-05 1.02978543e-02 2.08263926e-03 1.91931386e-04\n",
            " 8.58021592e-03 3.94008238e-03 3.03378847e-03 9.44480818e-03\n",
            " 1.64614492e-03 6.49237242e-04 2.22324162e-03 5.69982139e-04\n",
            " 1.68441485e-03 1.08127645e-03 3.45237780e-03 8.06089885e-03\n",
            " 5.66390155e-05 6.31381650e-04 1.02465308e-02 1.17312187e-03\n",
            " 1.17137504e-02 9.69352640e-03 1.15826445e-02 9.11605863e-03\n",
            " 9.78406709e-03 8.79798590e-03 5.02904265e-03 7.80825251e-03\n",
            " 9.49186433e-03 7.66059482e-03 1.64614492e-03 9.78627633e-03\n",
            " 8.97291487e-03 2.18379348e-03 1.14733624e-02 3.50318277e-03\n",
            " 9.21545559e-03 4.37225349e-03 9.76739455e-03 1.73715100e-03\n",
            " 3.86500631e-03 1.08712709e-02 8.54383905e-03 3.97494304e-03\n",
            " 8.53250000e-03 4.81340360e-04 2.38135634e-03 9.72219333e-03\n",
            " 3.48201225e-03 7.20282814e-03 9.65866110e-03 1.68772098e-04\n",
            " 4.57482518e-03 2.55443528e-03 3.39559313e-03 1.06742295e-02\n",
            " 8.41745344e-03 4.29937541e-03 5.23204859e-04 1.53500975e-03\n",
            " 1.26332325e-03 7.37234036e-03 4.50158720e-03 6.87672982e-04\n",
            " 3.81084347e-03 3.53889765e-04 9.33408551e-03 1.64614492e-03\n",
            " 6.86311935e-03 1.14688668e-02 5.87493787e-03 6.78508394e-03\n",
            " 7.67620191e-03 9.97991126e-03 9.35811601e-03 2.33972089e-03\n",
            " 3.74959005e-03 1.06018389e-03 8.75572270e-03 9.65093952e-03\n",
            " 8.92673973e-03 2.10724647e-04 1.03104128e-02 4.16507575e-03\n",
            " 6.77382537e-03 3.52204088e-03 9.45288994e-03 1.18753838e-03\n",
            " 2.54176111e-03 5.15669145e-04 8.35717651e-03 8.88516094e-03\n",
            " 5.36173144e-03 5.12715098e-03 1.41226753e-03 1.11766651e-02\n",
            " 9.58771334e-03 6.69715683e-03 9.83658918e-03 1.02129331e-02\n",
            " 1.58822321e-04 6.72388787e-03 2.30039365e-03 4.35176988e-03\n",
            " 3.10095557e-03 5.44416025e-03 8.51589652e-03 1.15239181e-02\n",
            " 3.37143540e-03 6.94871372e-03 2.90566870e-03 9.13461527e-03\n",
            " 8.50611193e-03 1.87953694e-03 4.83718160e-04 2.62557174e-03\n",
            " 4.73898214e-03 9.49081972e-03 9.02102147e-03 4.18351682e-03\n",
            " 5.02951361e-04 3.12027507e-03 5.87306135e-03 4.82674077e-03\n",
            " 7.31963523e-03 5.67560753e-03 3.18048760e-04 2.76737327e-03\n",
            " 2.58735013e-03 7.01552714e-03 9.12840782e-03 2.18379348e-03\n",
            " 1.41376653e-03 1.16785652e-02 2.20892830e-03 5.78328946e-03\n",
            " 9.82665055e-03 3.79453735e-03 1.07649819e-02 4.45100078e-03\n",
            " 8.66130011e-04 6.53603819e-03 4.53425920e-03 6.09455757e-03\n",
            " 3.47229567e-03 8.82412431e-03 5.80811190e-03 5.16885654e-03\n",
            " 2.81156498e-03 6.01714447e-03 1.05763903e-02 9.71581422e-04\n",
            " 7.16361539e-04 4.47965251e-03 8.20820456e-04 2.05080599e-04\n",
            " 1.06836418e-02 1.12580750e-03 1.60873733e-03 3.07860827e-03\n",
            " 2.85730542e-03 7.46569337e-05 3.35749703e-03 6.03333031e-03\n",
            " 4.72379743e-03 1.67838646e-06 1.06142468e-02 6.31700086e-04\n",
            " 3.91162654e-07 2.45590518e-05 4.58980644e-05 1.06248306e-02\n",
            " 1.17712377e-02 1.31003812e-03 9.37677641e-04 3.98858374e-03\n",
            " 3.86663535e-03 5.27513152e-03 1.12675282e-02 5.27513152e-03\n",
            " 1.07315308e-02 1.08191183e-03 7.16877772e-03 1.85597839e-03\n",
            " 3.76531823e-03 2.26496155e-04 3.90136292e-04 8.71020551e-03\n",
            " 3.57053168e-03 4.34511604e-03 3.67456099e-03 2.23826417e-04\n",
            " 4.74879883e-03 5.92160610e-03 7.22406341e-03 6.40591148e-03\n",
            " 4.93483097e-03 5.38721224e-03 1.00999653e-02 1.07475986e-02\n",
            " 2.87866991e-03 1.18294985e-02 1.01586341e-02 7.46879616e-03\n",
            " 5.43821577e-03 5.56367546e-03 3.86663535e-03 7.54358019e-03\n",
            " 9.78441602e-03 1.20889232e-03 1.07746359e-03 3.27188951e-03\n",
            " 5.87225445e-03 4.00806825e-03 5.56846843e-04 1.11950528e-02\n",
            " 1.04140214e-02 8.00891436e-03 5.41631972e-03 1.87045717e-03\n",
            " 9.96591564e-04 8.88795217e-03 6.08839021e-03 6.63405848e-03\n",
            " 8.05102241e-03 9.69616008e-03 2.65114366e-03 1.42146137e-03\n",
            " 1.22852761e-03 6.86959224e-03 9.23475301e-03 6.59555420e-03\n",
            " 8.70622071e-03 4.47686368e-03 9.97754312e-03 4.63179436e-03\n",
            " 8.30919179e-03 1.16444006e-02 3.16834010e-03 3.40491379e-03\n",
            " 8.10557481e-03 4.39696858e-04 1.01126389e-03 7.34230089e-03\n",
            " 7.77584099e-03 2.57243012e-03 9.78406709e-03 5.16163240e-03\n",
            " 7.51496995e-03 3.48235761e-04 5.47600344e-03 7.15019142e-03\n",
            " 4.27240192e-03 1.10902258e-02 6.07052826e-03 3.58393744e-03\n",
            " 7.41592281e-03 8.16484935e-03 9.62997587e-03 7.48455871e-03\n",
            " 4.85366559e-03 6.17500770e-03 6.16488824e-03 8.10265338e-04\n",
            " 3.58198072e-03]\n",
            "3640 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.06860113e-03 4.30926129e-03 4.31092892e-03 3.53278432e-03\n",
            " 6.86225973e-04 8.51773517e-03 3.72856967e-03 7.60044529e-03\n",
            " 1.16626083e-02 8.44097454e-03 1.07654751e-02 7.70624816e-03\n",
            " 1.14901915e-02 1.16255395e-02 1.16533718e-02 5.42778412e-03\n",
            " 5.00400071e-03 7.75718927e-03 5.84195005e-03 8.62161175e-03\n",
            " 1.46298136e-03 8.99038593e-03 4.16061234e-03 5.63687224e-03\n",
            " 3.86808980e-03 1.20025679e-05 4.48274469e-03 1.05116951e-02\n",
            " 3.39515100e-03 9.85981452e-05 7.41703701e-03 1.05116951e-02\n",
            " 9.99324058e-03 1.91734708e-03 4.00306668e-09 4.13859217e-03\n",
            " 1.60814777e-05 5.81145656e-03 1.10742762e-02 3.03101577e-04\n",
            " 9.06594717e-08 7.61705488e-03 7.42289177e-03 2.85793012e-03\n",
            " 7.07741223e-03 1.14333340e-02 9.77657464e-03 6.14828070e-03\n",
            " 9.29863308e-03 2.40372011e-03 1.03647272e-02 8.83711618e-03\n",
            " 1.14363756e-02 1.07919369e-02 9.20691658e-04 7.46758749e-03\n",
            " 2.43539673e-03 3.36022545e-04 1.10189056e-03 7.71694176e-03\n",
            " 2.94825063e-03 9.73565524e-03 9.77657464e-03 1.13112763e-02\n",
            " 4.09904719e-04 8.07388824e-03 5.39206862e-03 4.44486850e-03\n",
            " 4.55592691e-04 1.05276460e-02 8.82127092e-03 4.33479292e-03\n",
            " 4.34388277e-03 1.24979001e-03 5.98659320e-03 1.06329159e-02\n",
            " 6.74033708e-04 9.72362969e-04 1.01855263e-02 4.87722064e-03\n",
            " 5.70140675e-05 4.16330865e-03 1.11735918e-02 1.04004056e-02\n",
            " 1.01921467e-02 1.76917167e-03 9.99026369e-03 9.88447537e-03\n",
            " 8.21566100e-04 2.36716489e-03 1.09811980e-02 1.01405428e-02\n",
            " 7.49954235e-03 9.46921813e-03 4.45965884e-03 9.99324058e-03\n",
            " 3.73534275e-03 7.41964059e-05 8.67517038e-03 3.36824399e-03\n",
            " 3.73534275e-03 1.12020017e-02 9.47110889e-03 6.23654815e-03\n",
            " 1.11319721e-03 7.39420007e-03 1.11575647e-02 1.31167986e-03\n",
            " 3.28040297e-05 8.01252546e-03 5.44439844e-03 2.97430715e-03\n",
            " 1.08030427e-02 6.26733236e-03 9.06181537e-03 5.83738073e-03\n",
            " 8.17379412e-03 1.05368030e-02 9.87771702e-03 9.02072027e-03\n",
            " 4.00306668e-09 3.71218510e-03 7.85940997e-03 8.08970795e-03\n",
            " 1.01040185e-03 3.75393512e-03 9.24299961e-03 2.03443992e-03\n",
            " 6.86101251e-03 2.36927318e-03 7.97767906e-03 4.32105091e-03\n",
            " 1.17030271e-02 8.41641999e-03 5.99244320e-03 4.75056994e-03\n",
            " 6.30302489e-03 3.11434226e-03 8.44097454e-03 8.70313162e-03\n",
            " 4.88383613e-03 4.33479292e-03 1.15326806e-02 9.13327888e-03\n",
            " 6.72386446e-03 1.08920695e-02 9.21719566e-03 5.39113589e-03\n",
            " 9.73687638e-03 6.89235697e-03 2.38401408e-03 2.00909706e-04\n",
            " 3.64776107e-03 1.05727794e-02 1.12700516e-02 4.03208255e-03\n",
            " 1.02471561e-02 3.79822538e-03 7.42076880e-03 8.49857276e-03\n",
            " 9.74600905e-03 5.29003034e-04 2.84184984e-03 1.10348333e-02\n",
            " 6.36701357e-03 1.34258822e-06 6.97111968e-05 7.38517159e-04\n",
            " 2.88374239e-03 7.69519671e-03 2.94994988e-03 8.64423907e-03\n",
            " 4.88557032e-03 4.36650347e-04 6.34068946e-03 4.86839962e-03\n",
            " 1.23240656e-03 1.00892899e-02 8.54122121e-04 4.89620596e-03\n",
            " 6.86064548e-03 8.25780044e-03 4.72836345e-03 5.79591335e-03\n",
            " 4.13849857e-03 4.89404263e-03 5.06319635e-03 3.07805596e-03\n",
            " 7.96008586e-03 4.33479292e-03 1.07399133e-02 8.25687288e-03\n",
            " 4.13995954e-03 1.26377879e-03 1.75176062e-03 9.39504726e-03\n",
            " 3.56721559e-03 9.38162877e-03 1.16960625e-02 1.41841926e-03\n",
            " 5.09071232e-03 1.16624742e-02 1.08278826e-04 7.33251646e-03\n",
            " 1.16090105e-16 3.40066453e-03 6.47097748e-03 1.94248740e-04\n",
            " 9.25629223e-03 9.45462324e-03 1.02471561e-02 7.46758749e-03\n",
            " 2.89088262e-03 3.77534527e-03 2.93257680e-03 1.11575647e-02\n",
            " 3.31793782e-03 3.33767819e-03 1.12262397e-02 6.25932117e-03\n",
            " 8.08467925e-03 2.05282191e-03 2.03486647e-04 8.53459350e-03\n",
            " 4.04593477e-03 6.80097502e-03 1.12776562e-02 3.57974982e-03\n",
            " 3.57676222e-04 7.65687883e-03 1.87507402e-03 4.14064861e-03\n",
            " 3.02008014e-03 8.91298156e-03 1.72197201e-04 4.28865980e-03\n",
            " 3.04739974e-03 8.38172855e-03 5.37984206e-03 2.99159685e-03\n",
            " 8.46127666e-03 8.84658306e-03 6.53713903e-03 5.06157870e-03\n",
            " 1.06467052e-02 5.84195005e-03 9.93210968e-03 4.46992578e-03\n",
            " 1.68283753e-04 8.98719657e-03 1.71586270e-03 8.27090944e-03\n",
            " 1.00435905e-02 7.22851716e-03 6.51837827e-03 4.16330865e-03\n",
            " 2.00700772e-03 2.97666314e-03 1.61677649e-03 1.35993434e-03\n",
            " 5.13916481e-03 1.96105903e-03 5.39113589e-03 3.70550156e-03\n",
            " 1.14221168e-03 1.04823048e-02 7.11114326e-03 3.03413040e-03\n",
            " 2.95587509e-03 6.16127780e-03 3.54825037e-03 4.49579722e-06\n",
            " 8.07659414e-04 3.51511423e-03 1.30785750e-03 9.22632183e-03\n",
            " 1.26785313e-05 1.02873268e-02 2.07883115e-03 1.91414784e-04\n",
            " 8.58203378e-03 3.93188112e-03 3.02727878e-03 9.42807083e-03\n",
            " 1.64008401e-03 6.47668468e-04 2.21624212e-03 5.68887680e-04\n",
            " 1.67757311e-03 1.08063943e-03 3.44676067e-03 8.05087054e-03\n",
            " 5.66573741e-05 6.30506487e-04 1.02451311e-02 1.17067556e-03\n",
            " 1.16947556e-02 9.68798569e-03 1.15828343e-02 9.07501010e-03\n",
            " 9.77657464e-03 8.77499827e-03 5.02964023e-03 7.80352618e-03\n",
            " 9.48749483e-03 7.65685553e-03 1.64008401e-03 9.75345736e-03\n",
            " 8.96692216e-03 2.17511659e-03 1.14464687e-02 3.49968426e-03\n",
            " 9.19829370e-03 4.37174629e-03 9.75959625e-03 1.72965535e-03\n",
            " 3.84742542e-03 1.08552257e-02 8.53365525e-03 3.96769623e-03\n",
            " 8.52366656e-03 4.81637078e-04 2.37477350e-03 9.69613531e-03\n",
            " 3.46810117e-03 7.18171777e-03 9.65529040e-03 1.68283753e-04\n",
            " 4.56763260e-03 2.55746338e-03 3.38904957e-03 1.06609058e-02\n",
            " 8.40551841e-03 4.29016632e-03 5.19354652e-04 1.53101680e-03\n",
            " 1.26313248e-03 7.36748398e-03 4.49238046e-03 6.86225973e-04\n",
            " 3.78345479e-03 3.50287242e-04 9.32085154e-03 1.64008401e-03\n",
            " 6.86337207e-03 1.14437980e-02 5.85135778e-03 6.77416371e-03\n",
            " 7.66161859e-03 9.96547789e-03 9.35052554e-03 2.33511110e-03\n",
            " 3.74129101e-03 1.05733585e-03 8.75299817e-03 9.56735796e-03\n",
            " 8.91581372e-03 2.10514517e-04 1.03248858e-02 4.16330865e-03\n",
            " 6.76020488e-03 3.51511423e-03 9.43038942e-03 1.19164416e-03\n",
            " 2.52887990e-03 5.15657944e-04 8.33558016e-03 8.87608611e-03\n",
            " 5.36829422e-03 5.12385471e-03 1.40883858e-03 1.11582224e-02\n",
            " 9.57018027e-03 6.70015921e-03 9.82427827e-03 1.01972374e-02\n",
            " 1.58603517e-04 6.69617626e-03 2.29714834e-03 4.35415353e-03\n",
            " 3.09367714e-03 5.44439844e-03 8.50728996e-03 1.15204696e-02\n",
            " 3.36824399e-03 6.93498740e-03 2.89942027e-03 9.13013032e-03\n",
            " 8.49291995e-03 1.87649706e-03 4.82976171e-04 2.61700049e-03\n",
            " 4.72982746e-03 9.47894322e-03 9.00702537e-03 4.18333216e-03\n",
            " 5.02259329e-04 3.09918540e-03 5.87197853e-03 4.82071697e-03\n",
            " 7.29794765e-03 5.65466067e-03 3.17329650e-04 2.76162320e-03\n",
            " 2.58907748e-03 7.01220657e-03 9.09612051e-03 2.17511659e-03\n",
            " 1.40987948e-03 1.16735262e-02 2.20482307e-03 5.78134268e-03\n",
            " 9.81936188e-03 3.79349795e-03 1.07367988e-02 4.44814647e-03\n",
            " 8.62437735e-04 6.53381912e-03 4.52976810e-03 6.06887345e-03\n",
            " 3.46286969e-03 8.81808824e-03 5.80280429e-03 5.16937320e-03\n",
            " 2.80897725e-03 5.99555648e-03 1.05557139e-02 9.70653871e-04\n",
            " 7.15896876e-04 4.48274469e-03 8.18789281e-04 2.03242657e-04\n",
            " 1.06676598e-02 1.12303100e-03 1.60894508e-03 3.07427098e-03\n",
            " 2.85793012e-03 7.44626612e-05 3.35130115e-03 6.00715613e-03\n",
            " 4.72518693e-03 1.64683666e-06 1.06024329e-02 6.27755282e-04\n",
            " 3.91202848e-07 2.43383632e-05 4.56095168e-05 1.06211368e-02\n",
            " 1.30657130e-03 9.37180241e-04 3.98362221e-03 3.86808980e-03\n",
            " 5.26450356e-03 1.12465189e-02 5.26450356e-03 1.07401715e-02\n",
            " 1.08023729e-03 7.14601595e-03 1.85307497e-03 3.76714483e-03\n",
            " 2.26067139e-04 3.88772409e-04 8.68537167e-03 3.55747768e-03\n",
            " 4.32710733e-03 3.65829899e-03 2.22685653e-04 4.73969197e-03\n",
            " 5.92913855e-03 7.22156800e-03 6.38288863e-03 4.93174341e-03\n",
            " 5.37984206e-03 1.00830392e-02 1.07026701e-02 2.87560734e-03\n",
            " 1.01438263e-02 7.46081921e-03 5.43881499e-03 5.53978931e-03\n",
            " 3.86808980e-03 7.52683060e-03 9.76706599e-03 1.20032870e-03\n",
            " 1.07795795e-03 3.27119172e-03 5.86774950e-03 3.99941713e-03\n",
            " 5.55352679e-04 1.12091177e-02 1.04027226e-02 8.00216651e-03\n",
            " 5.40517572e-03 1.86785462e-03 9.91477629e-04 8.86305140e-03\n",
            " 6.07263031e-03 6.63767014e-03 8.04324620e-03 9.68291072e-03\n",
            " 2.64607169e-03 1.41672500e-03 1.22353232e-03 6.83510665e-03\n",
            " 9.23434269e-03 6.58587899e-03 8.67148091e-03 4.47268699e-03\n",
            " 9.96212615e-03 4.62128788e-03 8.28643004e-03 1.16484890e-02\n",
            " 3.15647938e-03 3.40273752e-03 8.08896110e-03 4.38859215e-04\n",
            " 1.01071490e-03 7.33245106e-03 7.76408158e-03 2.56718567e-03\n",
            " 9.77657464e-03 5.15545715e-03 7.50468720e-03 3.47656224e-04\n",
            " 5.48203147e-03 7.14508853e-03 4.26063747e-03 1.10852681e-02\n",
            " 6.05034471e-03 3.57877187e-03 7.42591813e-03 8.13577764e-03\n",
            " 9.60231202e-03 7.47724716e-03 4.84967209e-03 6.14612648e-03\n",
            " 6.16738634e-03 8.07659414e-04 3.57081082e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3650 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.06108383e-03 4.30489261e-03 4.29859122e-03 3.52935093e-03\n",
            " 6.85918060e-04 8.49148370e-03 3.72203028e-03 7.60069742e-03\n",
            " 8.43833760e-03 1.07677762e-02 7.69752471e-03 1.14780323e-02\n",
            " 5.42536864e-03 4.98002532e-03 7.75809191e-03 5.83359950e-03\n",
            " 8.61475306e-03 1.46048028e-03 8.98750496e-03 4.13417206e-03\n",
            " 5.63672105e-03 3.86592946e-03 1.20288002e-05 4.47994149e-03\n",
            " 1.05049601e-02 3.39115116e-03 9.86814489e-05 7.40823143e-03\n",
            " 1.05049601e-02 9.95153893e-03 1.91314341e-03 3.98520662e-09\n",
            " 4.13727178e-03 1.60133351e-05 5.81166279e-03 1.10825604e-02\n",
            " 3.02639271e-04 9.03017675e-08 7.57856555e-03 7.41581629e-03\n",
            " 2.85706373e-03 7.07617927e-03 1.14231855e-02 9.77455448e-03\n",
            " 6.12085882e-03 9.29259184e-03 2.40257734e-03 1.03679715e-02\n",
            " 8.82837053e-03 1.13978480e-02 1.07436106e-02 9.18762288e-04\n",
            " 7.46239590e-03 2.42949944e-03 3.35298437e-04 1.09215142e-03\n",
            " 7.69472452e-03 2.94746030e-03 9.73463170e-03 9.77455448e-03\n",
            " 1.13131480e-02 4.09473852e-04 8.05134642e-03 5.39462869e-03\n",
            " 4.44380328e-03 4.52432270e-04 1.05264211e-02 8.80226152e-03\n",
            " 4.33717498e-03 4.33408927e-03 1.25028681e-03 5.99177757e-03\n",
            " 1.05934238e-02 6.73474626e-04 9.70863169e-04 1.01915678e-02\n",
            " 4.86836235e-03 5.71530265e-05 4.15488628e-03 1.11695572e-02\n",
            " 1.03684885e-02 1.01858908e-02 1.76662628e-03 9.99513040e-03\n",
            " 9.86082189e-03 8.21622119e-04 2.35570246e-03 1.09662259e-02\n",
            " 1.01167559e-02 7.49498197e-03 9.45760712e-03 4.44249706e-03\n",
            " 9.95153893e-03 3.73524254e-03 7.40387470e-05 8.66230923e-03\n",
            " 3.36794152e-03 3.73524254e-03 1.11968738e-02 9.43859390e-03\n",
            " 6.23283169e-03 1.11140349e-03 7.38123921e-03 1.11514034e-02\n",
            " 1.30672758e-03 3.27436384e-05 8.01162641e-03 5.44279623e-03\n",
            " 2.97449225e-03 1.08110520e-02 6.25607145e-03 9.05824973e-03\n",
            " 5.83573532e-03 8.14950141e-03 1.05198673e-02 9.86829732e-03\n",
            " 9.00403223e-03 3.98520662e-09 3.71387160e-03 7.85284847e-03\n",
            " 8.08743938e-03 1.00839814e-03 3.74250609e-03 9.22549852e-03\n",
            " 2.01751855e-03 6.84692920e-03 2.36851052e-03 7.96630400e-03\n",
            " 4.31929733e-03 8.40452935e-03 5.99084747e-03 4.75986156e-03\n",
            " 6.29914355e-03 3.11298411e-03 8.43833760e-03 8.67089141e-03\n",
            " 4.86383984e-03 4.33717498e-03 1.15180574e-02 9.13669968e-03\n",
            " 6.70321079e-03 1.08965943e-02 9.22393269e-03 5.39868986e-03\n",
            " 9.68460673e-03 6.87764764e-03 2.37408661e-03 2.00207164e-04\n",
            " 3.63852650e-03 1.05381875e-02 1.12548030e-02 4.02677794e-03\n",
            " 1.02432688e-02 3.79241590e-03 7.35995636e-03 8.47018257e-03\n",
            " 9.71025028e-03 5.27774609e-04 2.83865910e-03 1.10249208e-02\n",
            " 6.36652596e-03 1.33927285e-06 6.95658112e-05 7.33222717e-04\n",
            " 2.88169787e-03 7.68255886e-03 2.94705777e-03 8.60957798e-03\n",
            " 4.86524178e-03 4.35966182e-04 6.34504860e-03 4.86349241e-03\n",
            " 1.22434978e-03 1.00717122e-02 8.54312247e-04 4.89108205e-03\n",
            " 6.83455960e-03 8.25253453e-03 4.71080677e-03 5.79458466e-03\n",
            " 4.13816675e-03 4.87638472e-03 5.05995403e-03 3.06983196e-03\n",
            " 7.93022356e-03 4.33717498e-03 1.07324157e-02 8.24055153e-03\n",
            " 4.12515459e-03 1.26301897e-03 1.74537769e-03 9.39237895e-03\n",
            " 3.55576940e-03 9.37325687e-03 1.41611226e-03 5.09037448e-03\n",
            " 1.08016830e-04 7.33776149e-03 1.16388930e-16 3.39821908e-03\n",
            " 6.46860488e-03 1.94098661e-04 9.23083866e-03 9.44273536e-03\n",
            " 1.02432688e-02 7.46239590e-03 2.88345650e-03 3.76623457e-03\n",
            " 2.93534406e-03 1.11514034e-02 3.31337456e-03 3.33423686e-03\n",
            " 1.11888741e-02 6.23937974e-03 8.08203763e-03 2.04255561e-03\n",
            " 2.01842615e-04 8.52321390e-03 4.04176615e-03 6.78351311e-03\n",
            " 1.12852840e-02 3.58141804e-03 3.54629712e-04 7.66089969e-03\n",
            " 1.86830052e-03 4.13939773e-03 3.01825944e-03 8.90344488e-03\n",
            " 1.71389564e-04 4.28292784e-03 3.04802957e-03 8.35851632e-03\n",
            " 5.37349053e-03 2.98319805e-03 8.44303643e-03 8.84135594e-03\n",
            " 6.52954589e-03 5.04015808e-03 1.06408917e-02 5.83359950e-03\n",
            " 9.91554309e-03 4.46450341e-03 1.67912022e-04 8.96617455e-03\n",
            " 1.71116235e-03 8.24736335e-03 1.00331288e-02 7.21700669e-03\n",
            " 6.51464145e-03 4.15488628e-03 2.00338299e-03 2.97491589e-03\n",
            " 1.61496070e-03 1.35951002e-03 5.12429429e-03 1.95950609e-03\n",
            " 5.39868986e-03 3.70541307e-03 1.13940099e-03 1.04742945e-02\n",
            " 7.10881884e-03 3.03743994e-03 2.95758110e-03 6.15686613e-03\n",
            " 3.54658305e-03 4.48963441e-06 8.07425186e-04 3.50984021e-03\n",
            " 1.30150643e-03 9.20550581e-03 1.25188579e-05 1.02699502e-02\n",
            " 2.07545692e-03 1.91372536e-04 8.56537002e-03 3.92819959e-03\n",
            " 3.00835667e-03 9.40813968e-03 1.63697525e-03 6.44402644e-04\n",
            " 2.21046642e-03 5.69324827e-04 1.67226688e-03 1.07713360e-03\n",
            " 3.43787345e-03 8.03946261e-03 5.66115003e-05 6.27085030e-04\n",
            " 1.02441911e-02 1.17199487e-03 9.66550914e-03 9.06801639e-03\n",
            " 9.77455448e-03 8.78066372e-03 5.01638020e-03 7.80307637e-03\n",
            " 9.44989772e-03 7.61903464e-03 1.63697525e-03 9.75817535e-03\n",
            " 8.96673574e-03 2.16904863e-03 1.14320929e-02 3.48727397e-03\n",
            " 9.18851737e-03 4.36400090e-03 9.75916625e-03 1.72693487e-03\n",
            " 3.82478115e-03 1.08503326e-02 8.52431638e-03 3.96535181e-03\n",
            " 8.51111789e-03 4.82276993e-04 2.37546537e-03 9.69398155e-03\n",
            " 3.46274998e-03 7.16576329e-03 9.65665678e-03 1.67912022e-04\n",
            " 4.55771189e-03 2.55198784e-03 3.36737166e-03 1.06421745e-02\n",
            " 8.39777888e-03 4.27883074e-03 5.17869603e-04 1.53047810e-03\n",
            " 1.26061301e-03 7.35517073e-03 4.48076085e-03 6.85918060e-04\n",
            " 3.77796584e-03 3.49439917e-04 9.31358305e-03 1.63697525e-03\n",
            " 6.85990779e-03 1.14395552e-02 5.84985605e-03 6.75631608e-03\n",
            " 7.63835306e-03 9.91904549e-03 9.33629857e-03 2.33516944e-03\n",
            " 3.73221169e-03 1.05291722e-03 8.75145094e-03 9.55555053e-03\n",
            " 8.87239455e-03 2.09762907e-04 1.02882544e-02 4.15488628e-03\n",
            " 6.76368592e-03 3.50984021e-03 9.42597680e-03 1.19281852e-03\n",
            " 2.53044052e-03 5.12169797e-04 8.31147028e-03 8.85187836e-03\n",
            " 5.37091443e-03 5.12519283e-03 1.40384580e-03 1.11389231e-02\n",
            " 9.56100939e-03 6.70217024e-03 9.80511911e-03 1.02030574e-02\n",
            " 1.58647635e-04 6.70354818e-03 2.29506676e-03 4.33919046e-03\n",
            " 3.08836762e-03 5.44279623e-03 8.46859658e-03 1.14666462e-02\n",
            " 3.36794152e-03 6.93112755e-03 2.89803197e-03 9.10489542e-03\n",
            " 8.44886191e-03 1.87325620e-03 4.83206302e-04 2.61198225e-03\n",
            " 4.72325529e-03 9.46241974e-03 9.00205090e-03 4.16745676e-03\n",
            " 5.00128886e-04 3.09856967e-03 5.85253840e-03 4.81581144e-03\n",
            " 7.27740266e-03 5.64143530e-03 3.16832971e-04 2.75364331e-03\n",
            " 2.56151272e-03 6.97475679e-03 9.09634000e-03 2.16904863e-03\n",
            " 1.40367707e-03 2.20176272e-03 5.76515970e-03 9.81200998e-03\n",
            " 3.78944833e-03 1.07211452e-02 4.44242298e-03 8.58256037e-04\n",
            " 6.52784314e-03 4.52790580e-03 6.05945467e-03 3.44675467e-03\n",
            " 8.79293415e-03 5.79264076e-03 5.15644401e-03 2.80604705e-03\n",
            " 5.97793948e-03 1.05285009e-02 9.67452219e-04 7.14424490e-04\n",
            " 4.47994149e-03 8.17974074e-04 2.02675196e-04 1.06029703e-02\n",
            " 1.11937648e-03 1.60587082e-03 3.07094797e-03 2.85706373e-03\n",
            " 7.42075486e-05 3.33747564e-03 5.98608556e-03 4.72155725e-03\n",
            " 1.63944455e-06 1.05851541e-02 6.26894440e-04 3.91681727e-07\n",
            " 2.41140354e-05 4.53790144e-05 1.06100913e-02 1.30449595e-03\n",
            " 9.35765096e-04 3.94501648e-03 3.86592946e-03 5.26007338e-03\n",
            " 1.12397372e-02 5.26007338e-03 1.07392139e-02 1.07909630e-03\n",
            " 7.14565422e-03 1.84975340e-03 3.75318421e-03 2.26192390e-04\n",
            " 3.88021034e-04 8.67273048e-03 3.54831856e-03 4.31355569e-03\n",
            " 3.64919004e-03 2.22003195e-04 4.73982967e-03 5.91527219e-03\n",
            " 7.21246756e-03 6.37253984e-03 4.92247681e-03 5.37349053e-03\n",
            " 1.00598231e-02 1.07073151e-02 2.87329623e-03 1.01342914e-02\n",
            " 7.46966421e-03 5.42950812e-03 5.52710208e-03 3.86592946e-03\n",
            " 7.51430365e-03 9.74059866e-03 1.19943203e-03 1.07660068e-03\n",
            " 3.26798063e-03 5.86278704e-03 3.98939194e-03 5.56146653e-04\n",
            " 1.12150278e-02 1.03901553e-02 7.97545861e-03 5.38936974e-03\n",
            " 1.86930354e-03 9.89777586e-04 8.85582390e-03 6.07611843e-03\n",
            " 6.60962062e-03 8.03575195e-03 9.67960455e-03 2.63930778e-03\n",
            " 1.41167081e-03 1.22104073e-03 6.83970061e-03 9.18994246e-03\n",
            " 6.58373570e-03 8.65785664e-03 4.46664864e-03 9.93954498e-03\n",
            " 4.61128826e-03 8.27189363e-03 3.15467907e-03 3.40147004e-03\n",
            " 8.07921163e-03 4.35156725e-04 1.00917782e-03 7.31024842e-03\n",
            " 7.74621669e-03 2.56716851e-03 9.77455448e-03 5.15226710e-03\n",
            " 7.50495152e-03 3.46078708e-04 5.47913127e-03 7.13702382e-03\n",
            " 4.25250477e-03 1.10705059e-02 6.04653701e-03 3.57581392e-03\n",
            " 7.39670046e-03 8.12181316e-03 9.59691428e-03 7.47647696e-03\n",
            " 4.85008512e-03 6.14333700e-03 6.14811907e-03 8.07425186e-04\n",
            " 3.56940723e-03]\n",
            "3660 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.04869407e-03 4.30079857e-03 4.29462099e-03 3.52524925e-03\n",
            " 6.85787530e-04 8.48529620e-03 3.71230859e-03 7.59116420e-03\n",
            " 8.43162651e-03 1.07591462e-02 7.69819653e-03 5.41677502e-03\n",
            " 4.97124844e-03 7.74181332e-03 5.83148002e-03 8.58951007e-03\n",
            " 1.46131707e-03 8.98395271e-03 4.12618081e-03 5.62554729e-03\n",
            " 3.86247197e-03 1.19849787e-05 4.47319924e-03 1.04919579e-02\n",
            " 3.38723952e-03 9.78582083e-05 7.40354414e-03 1.04919579e-02\n",
            " 9.94610574e-03 1.90892636e-03 3.94359962e-09 4.13481773e-03\n",
            " 1.59222628e-05 5.79812487e-03 1.10830736e-02 3.01659428e-04\n",
            " 8.90468400e-08 7.57646574e-03 7.40685431e-03 2.85397470e-03\n",
            " 7.06238247e-03 9.77013323e-03 6.10805395e-03 9.28914930e-03\n",
            " 2.39862839e-03 1.03501729e-02 8.83337579e-03 1.07346416e-02\n",
            " 9.16610059e-04 7.45969407e-03 2.42294563e-03 3.33768697e-04\n",
            " 1.08914975e-03 7.67680914e-03 2.92936618e-03 9.72013185e-03\n",
            " 9.77013323e-03 4.09985054e-04 8.02349399e-03 5.36329148e-03\n",
            " 4.43159199e-03 4.51805300e-04 1.05161301e-02 8.78319727e-03\n",
            " 4.33399352e-03 4.31765757e-03 1.24841076e-03 5.98328064e-03\n",
            " 1.05952404e-02 6.71989374e-04 9.67718695e-04 1.01740471e-02\n",
            " 4.85686605e-03 5.69931222e-05 4.14841791e-03 1.11516679e-02\n",
            " 1.03300261e-02 1.01439703e-02 1.76277430e-03 9.98389394e-03\n",
            " 9.84835657e-03 8.19215019e-04 2.35221635e-03 1.09179680e-02\n",
            " 1.01080623e-02 7.49085392e-03 9.44297783e-03 4.43357089e-03\n",
            " 9.94610574e-03 3.73445130e-03 7.38094067e-05 8.65957920e-03\n",
            " 3.36059902e-03 3.73445130e-03 1.11870102e-02 9.44965943e-03\n",
            " 6.22368406e-03 1.11004117e-03 7.37650472e-03 1.11395299e-02\n",
            " 1.30074413e-03 3.25203922e-05 8.00730266e-03 5.44018434e-03\n",
            " 2.96914854e-03 1.08025453e-02 6.23437696e-03 9.03216607e-03\n",
            " 5.82920963e-03 8.14445908e-03 1.05070226e-02 9.85044935e-03\n",
            " 8.99718449e-03 3.94359962e-09 3.70551507e-03 7.83744880e-03\n",
            " 8.07986804e-03 1.00607258e-03 3.72945819e-03 9.19004409e-03\n",
            " 2.00443473e-03 6.84216367e-03 2.36874011e-03 7.95481491e-03\n",
            " 4.31954199e-03 8.39357039e-03 5.97888947e-03 4.74162823e-03\n",
            " 6.30237285e-03 3.11109802e-03 8.43162651e-03 8.64459614e-03\n",
            " 4.85950493e-03 4.33399352e-03 9.13048300e-03 6.70925725e-03\n",
            " 1.08839815e-02 9.20736247e-03 5.39310759e-03 9.68651555e-03\n",
            " 6.86353224e-03 2.36467190e-03 2.00101823e-04 3.62752533e-03\n",
            " 1.05371588e-02 4.02307522e-03 1.02273345e-02 3.79585863e-03\n",
            " 7.34627923e-03 8.45957063e-03 9.70369530e-03 5.27853016e-04\n",
            " 2.82969459e-03 1.10042925e-02 6.35892080e-03 1.31723095e-06\n",
            " 6.92006256e-05 7.30182447e-04 2.87424139e-03 7.66936896e-03\n",
            " 2.94102071e-03 8.59953542e-03 4.86465174e-03 4.35188112e-04\n",
            " 6.33665334e-03 4.85471073e-03 1.22379371e-03 1.00513462e-02\n",
            " 8.52721062e-04 4.88376286e-03 6.81452697e-03 8.23574795e-03\n",
            " 4.71303224e-03 5.78920001e-03 4.13594592e-03 4.86919329e-03\n",
            " 5.05698766e-03 3.06057975e-03 7.91238443e-03 4.33399352e-03\n",
            " 1.07120863e-02 8.21733799e-03 4.11269293e-03 1.26136215e-03\n",
            " 1.74447304e-03 9.37083190e-03 3.54665189e-03 9.35903080e-03\n",
            " 1.41472666e-03 5.07381054e-03 1.07755821e-04 7.34363018e-03\n",
            " 1.13898120e-16 3.38751945e-03 6.46120847e-03 1.93022203e-04\n",
            " 9.20278237e-03 9.43122501e-03 1.02273345e-02 7.45969407e-03\n",
            " 2.87911796e-03 3.75564008e-03 2.93135328e-03 1.11395299e-02\n",
            " 3.31280570e-03 3.32066321e-03 1.11891353e-02 6.21333773e-03\n",
            " 8.07319567e-03 2.03893805e-03 2.01610123e-04 8.50923282e-03\n",
            " 4.02481126e-03 6.76671856e-03 3.57232557e-03 3.54231831e-04\n",
            " 7.65154085e-03 1.86688862e-03 4.14359741e-03 3.01439104e-03\n",
            " 8.89765067e-03 1.70634403e-04 4.26879162e-03 3.04397115e-03\n",
            " 8.36017914e-03 5.36981994e-03 2.98027562e-03 8.42129577e-03\n",
            " 8.79680356e-03 6.54288395e-03 5.03076029e-03 1.06294076e-02\n",
            " 5.83148002e-03 9.90562953e-03 4.45220372e-03 1.67445309e-04\n",
            " 8.96021066e-03 1.70489900e-03 8.23677780e-03 1.00227717e-02\n",
            " 7.19427458e-03 6.49262804e-03 4.14841791e-03 1.99713943e-03\n",
            " 2.96743375e-03 1.61346917e-03 1.35886264e-03 5.11377625e-03\n",
            " 1.95110843e-03 5.39310759e-03 3.69366162e-03 1.13378571e-03\n",
            " 1.04762736e-02 7.10719003e-03 3.03615702e-03 2.95092275e-03\n",
            " 6.14845152e-03 3.54513948e-03 4.45116971e-06 8.05460579e-04\n",
            " 3.51005998e-03 1.29541458e-03 9.15865552e-03 1.24821370e-05\n",
            " 1.02489191e-02 2.07174722e-03 1.90917123e-04 8.55176552e-03\n",
            " 3.92394503e-03 3.00288338e-03 9.38490082e-03 1.63228646e-03\n",
            " 6.43000712e-04 2.20750438e-03 5.69157283e-04 1.66932700e-03\n",
            " 1.07410360e-03 3.43322808e-03 8.02146747e-03 5.65399396e-05\n",
            " 6.24295934e-04 1.02301748e-02 1.16805721e-03 9.62547048e-03\n",
            " 9.04394840e-03 9.77013323e-03 8.77405165e-03 4.99939601e-03\n",
            " 7.78131256e-03 9.43592843e-03 7.60706318e-03 1.63228646e-03\n",
            " 9.72982767e-03 8.97955646e-03 2.16665107e-03 3.47616663e-03\n",
            " 9.17648452e-03 4.36185013e-03 9.72470985e-03 1.72407276e-03\n",
            " 3.81227445e-03 1.08362295e-02 8.52110803e-03 3.95259201e-03\n",
            " 8.50001606e-03 4.80922951e-04 2.36752250e-03 9.69000992e-03\n",
            " 3.45015141e-03 7.13583308e-03 9.63905320e-03 1.67445309e-04\n",
            " 4.54894238e-03 2.54528925e-03 3.35374455e-03 1.06167897e-02\n",
            " 8.39037159e-03 4.26978316e-03 5.14984007e-04 1.52654329e-03\n",
            " 1.25867084e-03 7.34465332e-03 4.47685451e-03 6.85787530e-04\n",
            " 3.76483670e-03 3.48375937e-04 9.30978068e-03 1.63228646e-03\n",
            " 6.85711222e-03 5.83456330e-03 6.75173766e-03 7.62710602e-03\n",
            " 9.90567897e-03 9.32700311e-03 2.32871611e-03 3.73098801e-03\n",
            " 1.04989100e-03 8.74595256e-03 9.54283827e-03 8.86532635e-03\n",
            " 2.09464134e-04 1.03046794e-02 4.14841791e-03 6.76057415e-03\n",
            " 3.51005998e-03 9.41626873e-03 1.19113692e-03 2.52652461e-03\n",
            " 5.11654275e-04 8.29736537e-03 8.82824146e-03 5.36538833e-03\n",
            " 5.12011366e-03 1.40554484e-03 1.11294402e-02 9.52590021e-03\n",
            " 6.70035010e-03 9.80527224e-03 1.01891342e-02 1.58398135e-04\n",
            " 6.68859677e-03 2.28987435e-03 4.32862342e-03 3.08334783e-03\n",
            " 5.44018434e-03 8.44872313e-03 3.36059902e-03 6.93490934e-03\n",
            " 2.88663703e-03 9.08304707e-03 8.44576320e-03 1.87004570e-03\n",
            " 4.81947801e-04 2.60962956e-03 4.71993457e-03 9.44479520e-03\n",
            " 8.99102447e-03 4.15454306e-03 4.98050606e-04 3.08855312e-03\n",
            " 5.81801262e-03 4.80682053e-03 7.25438776e-03 5.61789731e-03\n",
            " 3.15983213e-04 2.73506850e-03 2.55511430e-03 6.96244150e-03\n",
            " 9.05817214e-03 2.16665107e-03 1.40151933e-03 2.19863945e-03\n",
            " 5.76098047e-03 9.80825876e-03 3.78861364e-03 1.06943461e-02\n",
            " 4.41854809e-03 8.53344416e-04 6.52254948e-03 4.50857040e-03\n",
            " 6.05462114e-03 3.43138959e-03 8.78203000e-03 5.78179188e-03\n",
            " 5.15080708e-03 2.80287028e-03 5.96815863e-03 1.05071732e-02\n",
            " 9.58304445e-04 7.13562456e-04 4.47319924e-03 8.15251200e-04\n",
            " 2.02487740e-04 1.05689619e-02 1.11229773e-03 1.60365883e-03\n",
            " 3.04541210e-03 2.85397470e-03 7.38235219e-05 3.33313539e-03\n",
            " 5.98610703e-03 4.71895223e-03 1.62315779e-06 1.05683373e-02\n",
            " 6.25105418e-04 3.89972172e-07 2.39680280e-05 4.52808129e-05\n",
            " 1.06007262e-02 1.30327280e-03 9.34141131e-04 3.94635987e-03\n",
            " 3.86247197e-03 5.25377070e-03 1.12372083e-02 5.25377070e-03\n",
            " 1.07317767e-02 1.07827594e-03 7.12469802e-03 1.84872332e-03\n",
            " 3.74850129e-03 2.24809155e-04 3.87398393e-04 8.66175619e-03\n",
            " 3.54977431e-03 4.31528183e-03 3.65158890e-03 2.20448622e-04\n",
            " 4.74239461e-03 5.91988785e-03 7.21506812e-03 6.35681451e-03\n",
            " 4.91825419e-03 5.36981994e-03 1.00274933e-02 1.06638352e-02\n",
            " 2.86426395e-03 1.01039262e-02 7.46246510e-03 5.42375605e-03\n",
            " 5.51362225e-03 3.86247197e-03 7.49603183e-03 9.72588833e-03\n",
            " 1.19508147e-03 1.07310853e-03 3.25779053e-03 5.85871706e-03\n",
            " 3.98360436e-03 5.54146407e-04 1.12018615e-02 1.03852847e-02\n",
            " 7.96478012e-03 5.37014501e-03 1.86534225e-03 9.85225193e-04\n",
            " 8.84368997e-03 6.06297936e-03 6.60871904e-03 8.01460177e-03\n",
            " 9.65927082e-03 2.63283158e-03 1.41014764e-03 1.21842157e-03\n",
            " 6.82375733e-03 9.17217062e-03 6.58048107e-03 8.64316504e-03\n",
            " 4.46548643e-03 9.92895042e-03 4.60635655e-03 8.26117744e-03\n",
            " 3.14504428e-03 3.39944700e-03 8.06368145e-03 4.34827363e-04\n",
            " 1.00737791e-03 7.28781078e-03 7.74320509e-03 2.56662553e-03\n",
            " 9.77013323e-03 5.14919739e-03 7.50381276e-03 3.44653813e-04\n",
            " 5.47313898e-03 7.12951221e-03 4.24397898e-03 1.10687507e-02\n",
            " 6.05684829e-03 3.57200686e-03 7.39607976e-03 8.08260855e-03\n",
            " 9.58379653e-03 7.46962376e-03 4.83786202e-03 6.12357501e-03\n",
            " 6.14134382e-03 8.05460579e-04 3.56292797e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3670 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.04784893e-03 4.29606739e-03 4.29334169e-03 3.52520330e-03\n",
            " 6.86422688e-04 8.46561158e-03 3.70533678e-03 7.60226319e-03\n",
            " 8.43932927e-03 1.07631883e-02 7.66646903e-03 5.42023542e-03\n",
            " 4.95622983e-03 7.71564357e-03 5.74599801e-03 8.58312274e-03\n",
            " 1.45637669e-03 8.98423247e-03 4.12526945e-03 5.62334632e-03\n",
            " 3.85939240e-03 1.19527339e-05 4.46602421e-03 1.04891243e-02\n",
            " 3.37737806e-03 9.70389710e-05 7.39418046e-03 1.04891243e-02\n",
            " 9.93690175e-03 1.91259454e-03 3.90341194e-09 4.12844096e-03\n",
            " 1.59068850e-05 5.77957550e-03 3.01404027e-04 8.84438937e-08\n",
            " 7.56963260e-03 7.40931723e-03 2.84831737e-03 7.05867578e-03\n",
            " 9.76306545e-03 6.11152553e-03 9.26708288e-03 2.39352320e-03\n",
            " 1.03405710e-02 8.82696704e-03 1.07362048e-02 9.12528456e-04\n",
            " 7.46720757e-03 2.42329853e-03 3.32087145e-04 1.09044795e-03\n",
            " 7.66050096e-03 2.92482898e-03 9.71717862e-03 9.76306545e-03\n",
            " 4.10369714e-04 8.01091263e-03 5.35514524e-03 4.41328306e-03\n",
            " 4.49622832e-04 1.04985967e-02 8.77296902e-03 4.30452349e-03\n",
            " 4.30898664e-03 1.24292526e-03 5.95403165e-03 1.05966242e-02\n",
            " 6.70483299e-04 9.65180905e-04 1.01694823e-02 4.85799734e-03\n",
            " 5.68606435e-05 4.13453583e-03 1.03278952e-02 1.01092847e-02\n",
            " 1.76128714e-03 9.97447387e-03 9.84557146e-03 8.15551102e-04\n",
            " 2.35392546e-03 1.09112226e-02 1.00859778e-02 7.48998107e-03\n",
            " 9.44018802e-03 4.41971472e-03 9.93690175e-03 3.71046884e-03\n",
            " 7.33582512e-05 8.65324715e-03 3.36128564e-03 3.71046884e-03\n",
            " 9.44339406e-03 6.22228547e-03 1.10945835e-03 7.37168648e-03\n",
            " 1.29841861e-03 3.24589908e-05 8.00094868e-03 5.43684869e-03\n",
            " 2.97146001e-03 1.07816205e-02 6.23614981e-03 9.02570106e-03\n",
            " 5.83515182e-03 8.12647528e-03 1.05018079e-02 9.84600784e-03\n",
            " 8.97227996e-03 3.90341194e-09 3.70282836e-03 7.83722776e-03\n",
            " 8.09387734e-03 1.00308036e-03 3.71496769e-03 9.18372106e-03\n",
            " 2.00430041e-03 6.82679456e-03 2.36335417e-03 7.95430322e-03\n",
            " 4.31238589e-03 8.38571278e-03 5.97626848e-03 4.74475964e-03\n",
            " 6.27415830e-03 3.10952251e-03 8.43932927e-03 8.63781431e-03\n",
            " 4.84837346e-03 4.30452349e-03 9.06339422e-03 6.69524684e-03\n",
            " 1.08821784e-02 9.20530042e-03 5.38952974e-03 9.66292443e-03\n",
            " 6.86287468e-03 2.35212574e-03 2.00020740e-04 3.61077002e-03\n",
            " 1.04889572e-02 4.02526298e-03 1.02085826e-02 3.79278178e-03\n",
            " 7.31569037e-03 8.46085886e-03 9.68285086e-03 5.26394319e-04\n",
            " 2.82583666e-03 1.09751145e-02 6.35243669e-03 1.30604569e-06\n",
            " 6.89265380e-05 7.28280384e-04 2.86921140e-03 7.67146046e-03\n",
            " 2.94362001e-03 8.58349075e-03 4.86001301e-03 4.34682134e-04\n",
            " 6.32315759e-03 4.85006019e-03 1.22072080e-03 1.00383206e-02\n",
            " 8.50212858e-04 4.88477693e-03 6.81419729e-03 8.22390235e-03\n",
            " 4.71354512e-03 5.78370076e-03 4.13734113e-03 4.86263245e-03\n",
            " 5.04500208e-03 3.05746082e-03 7.90530008e-03 4.30452349e-03\n",
            " 1.07039396e-02 8.17684408e-03 4.11710412e-03 1.25726398e-03\n",
            " 1.74427582e-03 9.37071438e-03 3.53267211e-03 9.33283383e-03\n",
            " 1.40510062e-03 5.07380825e-03 1.06635033e-04 7.31402130e-03\n",
            " 1.14246789e-16 3.37875780e-03 6.45306944e-03 1.92769631e-04\n",
            " 9.18857354e-03 9.42165743e-03 1.02085826e-02 7.46720757e-03\n",
            " 2.87759727e-03 3.75461966e-03 2.92421800e-03 3.30528835e-03\n",
            " 3.31316848e-03 6.20316751e-03 8.05821145e-03 2.03853396e-03\n",
            " 2.01340090e-04 8.50098756e-03 4.01511759e-03 6.76775082e-03\n",
            " 3.57637324e-03 3.53621115e-04 7.63897118e-03 1.86588344e-03\n",
            " 4.13455161e-03 3.01065009e-03 8.88173957e-03 1.70365758e-04\n",
            " 4.26508906e-03 3.04208930e-03 8.35094423e-03 5.31522742e-03\n",
            " 2.98219050e-03 8.40809620e-03 8.78669617e-03 6.55140011e-03\n",
            " 5.02812173e-03 1.06204442e-02 5.74599801e-03 9.84006649e-03\n",
            " 4.44599366e-03 1.66608268e-04 8.94930792e-03 1.70220998e-03\n",
            " 8.21805390e-03 1.00212692e-02 7.18543467e-03 6.48957353e-03\n",
            " 4.13453583e-03 2.00012973e-03 2.95292676e-03 1.61125159e-03\n",
            " 1.35795665e-03 5.11361694e-03 1.95375897e-03 5.38952974e-03\n",
            " 3.68459085e-03 1.13550222e-03 1.04638191e-02 7.10391548e-03\n",
            " 3.03437423e-03 2.94840130e-03 6.13952602e-03 3.53136392e-03\n",
            " 4.43985645e-06 8.04152501e-04 3.50270078e-03 1.29623065e-03\n",
            " 9.14362823e-03 1.24371666e-05 1.02434733e-02 2.07137483e-03\n",
            " 1.90382393e-04 8.54260881e-03 3.91642508e-03 3.00411265e-03\n",
            " 9.38207867e-03 1.62724780e-03 6.40804630e-04 2.20301938e-03\n",
            " 5.67487269e-04 1.65551579e-03 1.07306335e-03 3.42404193e-03\n",
            " 8.01854231e-03 5.63514038e-05 6.22117953e-04 1.02270203e-02\n",
            " 1.16458997e-03 9.61716977e-03 9.01748609e-03 9.76306545e-03\n",
            " 8.75776485e-03 5.00120344e-03 7.77282038e-03 9.42869083e-03\n",
            " 7.60603060e-03 1.62724780e-03 9.71983149e-03 8.96471167e-03\n",
            " 2.16368944e-03 3.47110871e-03 9.14501128e-03 4.34813335e-03\n",
            " 9.71952781e-03 1.71798814e-03 3.80471262e-03 1.08156386e-02\n",
            " 8.50980309e-03 3.95255660e-03 8.49814867e-03 4.79912829e-04\n",
            " 2.36175156e-03 9.66835328e-03 3.44276977e-03 7.11809385e-03\n",
            " 9.64296500e-03 1.66608268e-04 4.55032946e-03 2.54127495e-03\n",
            " 3.34946963e-03 1.06017828e-02 8.37975543e-03 4.26305008e-03\n",
            " 5.12143838e-04 1.52682452e-03 1.25574572e-03 7.30840115e-03\n",
            " 4.46144650e-03 6.86422688e-04 3.76424997e-03 3.45719660e-04\n",
            " 9.30153960e-03 1.62724780e-03 6.85290207e-03 5.81671827e-03\n",
            " 6.75330011e-03 7.62530728e-03 9.90380578e-03 9.31006005e-03\n",
            " 2.32095250e-03 3.72649809e-03 1.04653079e-03 8.74336749e-03\n",
            " 9.51550511e-03 8.85281878e-03 2.09581032e-04 1.02961060e-02\n",
            " 4.13453583e-03 6.74325933e-03 3.50270078e-03 9.39695525e-03\n",
            " 1.18549616e-03 2.52280369e-03 5.11076120e-04 8.29587581e-03\n",
            " 8.82257443e-03 5.34606881e-03 5.10981391e-03 1.40424773e-03\n",
            " 9.51814818e-03 6.69789013e-03 9.80201626e-03 1.01769248e-02\n",
            " 1.58309441e-04 6.67395970e-03 2.29115950e-03 4.32486004e-03\n",
            " 3.07631757e-03 5.43684869e-03 8.43487708e-03 3.36128564e-03\n",
            " 6.93667136e-03 2.88077015e-03 9.06713519e-03 8.41954591e-03\n",
            " 1.86755182e-03 4.81247312e-04 2.60583679e-03 4.71000257e-03\n",
            " 9.44775843e-03 8.98245651e-03 4.15199357e-03 4.97490934e-04\n",
            " 3.07739383e-03 5.80973908e-03 4.80714872e-03 7.24189693e-03\n",
            " 5.61057930e-03 3.14637863e-04 2.73116673e-03 2.55482795e-03\n",
            " 6.95387380e-03 9.06167064e-03 2.16368944e-03 1.39730607e-03\n",
            " 2.19558381e-03 5.75020176e-03 9.77790493e-03 3.77892383e-03\n",
            " 1.06922527e-02 4.41381728e-03 8.52184589e-04 6.52579922e-03\n",
            " 4.50725139e-03 6.05004336e-03 3.42249950e-03 8.78096564e-03\n",
            " 5.77698922e-03 5.12394424e-03 2.79969344e-03 5.96066201e-03\n",
            " 1.04822418e-02 9.53055854e-04 7.10867017e-04 4.46602421e-03\n",
            " 8.14251594e-04 2.01825776e-04 1.05667196e-02 1.11121306e-03\n",
            " 1.60090245e-03 3.03800180e-03 2.84831737e-03 7.38024251e-05\n",
            " 3.32597580e-03 5.96761529e-03 4.70099880e-03 1.60023432e-06\n",
            " 1.05652062e-02 6.22033205e-04 3.90089430e-07 2.38795391e-05\n",
            " 4.51809867e-05 1.05936790e-02 1.29918587e-03 9.31777379e-04\n",
            " 3.94015006e-03 3.85939240e-03 5.24638215e-03 5.24638215e-03\n",
            " 1.06987413e-02 1.07676420e-03 7.11742900e-03 1.84007057e-03\n",
            " 3.74364367e-03 2.25044280e-04 3.86680591e-04 8.63191502e-03\n",
            " 3.53761095e-03 4.29384695e-03 3.64702683e-03 2.19626057e-04\n",
            " 4.72859147e-03 5.92851351e-03 7.19399679e-03 6.34763329e-03\n",
            " 4.91038580e-03 5.31522742e-03 1.00354033e-02 1.06363895e-02\n",
            " 2.86177467e-03 1.01043203e-02 7.44964918e-03 5.42164570e-03\n",
            " 5.51141422e-03 3.85939240e-03 7.48937567e-03 9.67824240e-03\n",
            " 1.19284441e-03 1.07214081e-03 3.25483346e-03 5.85160740e-03\n",
            " 3.96861654e-03 5.54291992e-04 1.03894808e-02 7.95777922e-03\n",
            " 5.36582537e-03 1.86322241e-03 9.81965173e-04 8.83154576e-03\n",
            " 6.06202232e-03 6.60263360e-03 8.01058360e-03 9.65829412e-03\n",
            " 2.63166178e-03 1.40999300e-03 1.21462675e-03 6.81338107e-03\n",
            " 9.17458586e-03 6.56447811e-03 8.62945961e-03 4.45754920e-03\n",
            " 9.91852461e-03 4.60601750e-03 8.24913849e-03 3.13504785e-03\n",
            " 3.39694985e-03 8.04810484e-03 4.33528026e-04 1.00486212e-03\n",
            " 7.25578910e-03 7.72825913e-03 2.56453722e-03 9.76306545e-03\n",
            " 5.14502955e-03 7.49756595e-03 3.44389330e-04 5.45917141e-03\n",
            " 7.11638266e-03 4.22530240e-03 6.03836800e-03 3.56199440e-03\n",
            " 7.39542710e-03 8.05392982e-03 9.57364282e-03 7.47375435e-03\n",
            " 4.83759841e-03 6.10024092e-03 6.11967302e-03 8.04152501e-04\n",
            " 3.55017513e-03]\n",
            "3680 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.04048315e-03 4.29264302e-03 4.29258109e-03 3.50960038e-03\n",
            " 6.85972281e-04 8.46549938e-03 3.70262325e-03 7.59374780e-03\n",
            " 8.41362885e-03 7.65275645e-03 5.40464390e-03 4.93970686e-03\n",
            " 7.71393872e-03 5.74884067e-03 8.57591181e-03 1.45201874e-03\n",
            " 8.94943229e-03 4.11574207e-03 5.61858215e-03 3.85851280e-03\n",
            " 1.18907344e-05 4.46227792e-03 1.04745619e-02 3.37582046e-03\n",
            " 9.69043564e-05 7.38681842e-03 1.04745619e-02 9.90728377e-03\n",
            " 1.90241223e-03 3.89330474e-09 4.12218068e-03 1.55550002e-05\n",
            " 5.77501230e-03 3.00161151e-04 8.83496740e-08 7.56472585e-03\n",
            " 7.40476024e-03 2.84722973e-03 7.04991905e-03 9.76133305e-03\n",
            " 6.10215840e-03 9.25043921e-03 2.39117447e-03 1.03137712e-02\n",
            " 8.79271159e-03 9.05573866e-04 7.46510716e-03 2.40601411e-03\n",
            " 3.30537077e-04 1.08789216e-03 7.64869610e-03 2.92235095e-03\n",
            " 9.68001273e-03 9.76133305e-03 4.10059912e-04 7.98713114e-03\n",
            " 5.34118014e-03 4.39378600e-03 4.47871707e-04 1.04871821e-02\n",
            " 8.76437512e-03 4.30295088e-03 4.29708532e-03 1.23855617e-03\n",
            " 5.94279058e-03 1.05808861e-02 6.66769657e-04 9.64586964e-04\n",
            " 1.01539713e-02 4.84178812e-03 5.65871202e-05 4.13278768e-03\n",
            " 1.03228089e-02 1.00913751e-02 1.75592985e-03 9.95978798e-03\n",
            " 9.83868716e-03 8.12068124e-04 2.35159494e-03 1.00777261e-02\n",
            " 7.48467933e-03 9.38632036e-03 4.41045096e-03 9.90728377e-03\n",
            " 3.71116923e-03 7.29866794e-05 8.63796173e-03 3.33750112e-03\n",
            " 3.71116923e-03 9.42783929e-03 6.21528139e-03 1.10830992e-03\n",
            " 7.36882618e-03 1.29726904e-03 3.20045562e-05 7.96421439e-03\n",
            " 5.43287614e-03 2.95936304e-03 6.22996917e-03 9.01620435e-03\n",
            " 5.79538139e-03 8.08895152e-03 1.05010594e-02 9.84205492e-03\n",
            " 8.97050809e-03 3.89330474e-09 3.69774013e-03 7.83632235e-03\n",
            " 8.09515068e-03 1.00159210e-03 3.71449819e-03 9.17221166e-03\n",
            " 2.00311300e-03 6.81279952e-03 2.36018542e-03 7.94366555e-03\n",
            " 4.31224792e-03 8.38388194e-03 5.97116430e-03 4.73097238e-03\n",
            " 6.26859537e-03 3.10866963e-03 8.41362885e-03 8.62946571e-03\n",
            " 4.84043233e-03 4.30295088e-03 9.03722506e-03 6.67672223e-03\n",
            " 9.19554862e-03 5.39168813e-03 9.65827552e-03 6.83939746e-03\n",
            " 2.35237457e-03 1.99994205e-04 3.60710341e-03 1.04535549e-02\n",
            " 4.02075997e-03 1.02042191e-02 3.79440912e-03 7.30918487e-03\n",
            " 8.44925390e-03 9.65859714e-03 5.26057027e-04 2.81773650e-03\n",
            " 6.34837696e-03 1.30252921e-06 6.81402235e-05 7.26554465e-04\n",
            " 2.86837915e-03 7.65101813e-03 2.94100535e-03 8.58330798e-03\n",
            " 4.83575942e-03 4.33658798e-04 6.31624154e-03 4.85003649e-03\n",
            " 1.21608781e-03 1.00084942e-02 8.48391396e-04 4.86867290e-03\n",
            " 6.80796993e-03 8.21945233e-03 4.70905246e-03 5.77587385e-03\n",
            " 4.11977116e-03 4.85900774e-03 5.03751567e-03 3.04870963e-03\n",
            " 7.88498986e-03 4.30295088e-03 8.14051188e-03 4.11107860e-03\n",
            " 1.25479915e-03 1.73641167e-03 9.33185462e-03 3.53201055e-03\n",
            " 9.30750442e-03 1.40174187e-03 5.04953516e-03 1.06207863e-04\n",
            " 7.30840558e-03 1.07477146e-16 3.37497815e-03 6.44336734e-03\n",
            " 1.91279018e-04 9.17519556e-03 9.38462924e-03 1.02042191e-02\n",
            " 7.46510716e-03 2.87201020e-03 3.74176484e-03 2.92382193e-03\n",
            " 3.29569959e-03 3.30853627e-03 6.19956731e-03 8.05008263e-03\n",
            " 2.03599662e-03 2.00868736e-04 8.48930993e-03 4.00957156e-03\n",
            " 6.76399187e-03 3.54124383e-03 3.53117724e-04 7.61459055e-03\n",
            " 1.86413784e-03 4.13383920e-03 3.00259154e-03 8.87715783e-03\n",
            " 1.69631920e-04 4.26218588e-03 3.03244772e-03 8.34187231e-03\n",
            " 5.31660223e-03 2.97395855e-03 8.39753250e-03 8.78334264e-03\n",
            " 6.54858087e-03 5.00362391e-03 1.06014207e-02 5.74884067e-03\n",
            " 9.83373733e-03 4.42885131e-03 1.66525238e-04 8.94246740e-03\n",
            " 1.69922090e-03 8.20465670e-03 1.00188502e-02 7.18404646e-03\n",
            " 6.46792796e-03 4.13278768e-03 1.99038561e-03 2.94806341e-03\n",
            " 1.61063284e-03 1.35770136e-03 5.10550946e-03 1.93933435e-03\n",
            " 5.39168813e-03 3.68271942e-03 1.12821663e-03 1.04395344e-02\n",
            " 7.09094863e-03 3.02858469e-03 2.94205094e-03 6.13177284e-03\n",
            " 3.52832354e-03 4.38671754e-06 8.03524875e-04 3.50294360e-03\n",
            " 1.29454291e-03 9.14359014e-03 1.24127488e-05 1.01859700e-02\n",
            " 2.06813034e-03 1.90040558e-04 8.54618410e-03 3.91396428e-03\n",
            " 3.00450622e-03 9.34137140e-03 1.61609651e-03 6.40261569e-04\n",
            " 2.19922933e-03 5.65921017e-04 1.65023665e-03 1.07066237e-03\n",
            " 3.42085102e-03 8.00102277e-03 5.62397746e-05 6.20073807e-04\n",
            " 1.01777599e-02 1.15432103e-03 9.58802353e-03 8.99879680e-03\n",
            " 9.76133305e-03 8.74477367e-03 5.00105103e-03 7.74419073e-03\n",
            " 9.38210537e-03 7.58126330e-03 1.61609651e-03 9.69813437e-03\n",
            " 8.94708924e-03 2.15717829e-03 3.46381182e-03 9.12466955e-03\n",
            " 4.34654513e-03 9.69803555e-03 1.71458779e-03 3.80219259e-03\n",
            " 8.49940254e-03 3.92688166e-03 8.49150948e-03 4.80234171e-04\n",
            " 2.35275849e-03 9.65438286e-03 3.44164946e-03 7.10724870e-03\n",
            " 9.62869232e-03 1.66525238e-04 4.54614728e-03 2.53380141e-03\n",
            " 3.34484657e-03 1.05822214e-02 8.37484889e-03 4.25673041e-03\n",
            " 5.09603704e-04 1.52491961e-03 1.25443151e-03 7.29166027e-03\n",
            " 4.45237779e-03 6.85972281e-04 3.73993040e-03 3.45472051e-04\n",
            " 9.29751730e-03 1.61609651e-03 6.83057051e-03 5.81420502e-03\n",
            " 6.73647134e-03 7.62358954e-03 9.90129732e-03 9.31198213e-03\n",
            " 2.31893695e-03 3.72141677e-03 1.04078868e-03 8.73535179e-03\n",
            " 9.49346551e-03 8.85580627e-03 2.09253401e-04 1.02763817e-02\n",
            " 4.13278768e-03 6.73266415e-03 3.50294360e-03 9.37732619e-03\n",
            " 1.17942817e-03 2.51717849e-03 5.10177952e-04 8.28654731e-03\n",
            " 8.81532611e-03 5.32876307e-03 5.09407472e-03 1.40412687e-03\n",
            " 9.50993179e-03 6.69898164e-03 9.77686848e-03 1.01390073e-02\n",
            " 1.58129639e-04 6.67288524e-03 2.28089886e-03 4.31245405e-03\n",
            " 3.07136059e-03 5.43287614e-03 8.42654181e-03 3.33750112e-03\n",
            " 6.92946284e-03 2.85381877e-03 9.04757714e-03 8.41703090e-03\n",
            " 1.86660166e-03 4.75860212e-04 2.60089846e-03 4.70296323e-03\n",
            " 9.44223954e-03 8.96342935e-03 4.14032036e-03 4.94844188e-04\n",
            " 3.07626609e-03 5.80179595e-03 4.79228139e-03 7.23189015e-03\n",
            " 5.60372721e-03 3.13834343e-04 2.72604789e-03 2.54575639e-03\n",
            " 6.95264122e-03 9.02958474e-03 2.15717829e-03 1.39578059e-03\n",
            " 2.19369840e-03 5.74786594e-03 9.74874714e-03 3.77863494e-03\n",
            " 4.41202920e-03 8.49878338e-04 6.51446618e-03 4.50351435e-03\n",
            " 6.04541382e-03 3.42052776e-03 8.78093131e-03 5.76960190e-03\n",
            " 5.12187675e-03 2.79802862e-03 5.95732058e-03 1.04743471e-02\n",
            " 9.50427091e-04 7.09943130e-04 4.46227792e-03 8.06018794e-04\n",
            " 2.01063691e-04 1.05671284e-02 1.10768104e-03 1.59749143e-03\n",
            " 3.03293831e-03 2.84722973e-03 7.29962337e-05 3.32443739e-03\n",
            " 5.95682890e-03 4.68296674e-03 1.58593827e-06 1.05452047e-02\n",
            " 6.19377626e-04 3.87943848e-07 2.38393096e-05 4.50518217e-05\n",
            " 1.05902016e-02 1.29415725e-03 9.30986124e-04 3.94138517e-03\n",
            " 3.85851280e-03 5.24301381e-03 5.24301381e-03 1.07530521e-03\n",
            " 7.10841779e-03 1.83714015e-03 3.73615601e-03 2.21438553e-04\n",
            " 3.84284305e-04 8.63972247e-03 3.52881191e-03 4.28760886e-03\n",
            " 3.64901904e-03 2.19215236e-04 4.71680225e-03 5.92672575e-03\n",
            " 7.18656005e-03 6.34493876e-03 4.90652163e-03 5.31660223e-03\n",
            " 1.00555477e-02 1.06353089e-02 2.84939649e-03 1.00726142e-02\n",
            " 7.44220870e-03 5.41500466e-03 5.50672788e-03 3.85851280e-03\n",
            " 7.49110256e-03 9.65326115e-03 1.19046578e-03 1.06953659e-03\n",
            " 3.25044671e-03 5.84875371e-03 3.96465550e-03 5.47195904e-04\n",
            " 1.03766027e-02 7.94951616e-03 5.36429931e-03 1.84951506e-03\n",
            " 9.73604202e-04 8.83074649e-03 6.05358477e-03 6.59510326e-03\n",
            " 7.99076893e-03 9.64713386e-03 2.61965648e-03 1.40582351e-03\n",
            " 1.21333074e-03 6.80525062e-03 9.16806695e-03 6.53557108e-03\n",
            " 8.62721043e-03 4.44438393e-03 9.91758669e-03 4.60395273e-03\n",
            " 8.21544705e-03 3.12382855e-03 3.39580583e-03 8.02622757e-03\n",
            " 4.32142913e-04 1.00400186e-03 7.24259635e-03 7.72437133e-03\n",
            " 2.55557639e-03 9.76133305e-03 5.13797049e-03 7.49118722e-03\n",
            " 3.42842502e-04 5.44461038e-03 7.11292768e-03 4.21161539e-03\n",
            " 6.03153382e-03 3.55963451e-03 7.38757882e-03 8.05069706e-03\n",
            " 9.55996831e-03 7.46856375e-03 4.83273381e-03 6.09640989e-03\n",
            " 6.10760872e-03 8.03524875e-04 3.54164013e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3690 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.03099125e-03 4.28645325e-03 4.28397882e-03 3.50861345e-03\n",
            " 6.85254645e-04 8.45843521e-03 3.69348700e-03 7.58012932e-03\n",
            " 8.41095625e-03 7.64563459e-03 5.40241398e-03 4.92477772e-03\n",
            " 7.71694464e-03 5.74385120e-03 8.55350599e-03 1.45002243e-03\n",
            " 8.94433003e-03 4.11924488e-03 5.62130124e-03 3.85809312e-03\n",
            " 1.18733177e-05 4.45851703e-03 3.36936222e-03 9.66733620e-05\n",
            " 7.40188240e-03 1.03620219e-02 9.91387259e-03 1.89628676e-03\n",
            " 3.87116107e-09 4.12165203e-03 1.56095913e-05 5.76499453e-03\n",
            " 2.99807494e-04 8.84177602e-08 7.55827403e-03 7.39637683e-03\n",
            " 2.84709273e-03 7.04600034e-03 9.75780965e-03 6.09222547e-03\n",
            " 9.24319583e-03 2.38997120e-03 1.03161236e-02 8.79271667e-03\n",
            " 9.02142809e-04 7.46893915e-03 2.40605645e-03 3.28497436e-04\n",
            " 1.08350880e-03 7.62397405e-03 2.91535144e-03 9.68203922e-03\n",
            " 9.75780965e-03 4.09983001e-04 7.98032809e-03 5.32894671e-03\n",
            " 4.38890008e-03 4.47479988e-04 8.74298265e-03 4.29710193e-03\n",
            " 4.26065349e-03 1.23849967e-03 5.93995157e-03 6.65678492e-04\n",
            " 9.62711019e-04 1.01240990e-02 4.84299631e-03 5.65150005e-05\n",
            " 4.12993271e-03 1.03068294e-02 1.00856856e-02 1.75387363e-03\n",
            " 9.95141670e-03 9.82673315e-03 8.08799730e-04 2.34958255e-03\n",
            " 1.00628319e-02 7.48415426e-03 9.38025468e-03 4.40183875e-03\n",
            " 9.91387259e-03 3.71078320e-03 7.28132233e-05 8.63383939e-03\n",
            " 3.33998508e-03 3.71078320e-03 9.43180834e-03 6.21189724e-03\n",
            " 1.10787817e-03 7.35499102e-03 1.29418870e-03 3.20206239e-05\n",
            " 7.96458112e-03 5.43325433e-03 2.95664138e-03 6.21645059e-03\n",
            " 9.01168776e-03 5.79640184e-03 8.08277969e-03 9.81176565e-03\n",
            " 8.94815716e-03 3.87116107e-09 3.68719327e-03 7.82164191e-03\n",
            " 8.08531604e-03 1.00168875e-03 3.71093938e-03 9.17413819e-03\n",
            " 1.99207783e-03 6.79674840e-03 2.35720496e-03 7.92869197e-03\n",
            " 4.31368043e-03 8.36392077e-03 5.97351476e-03 4.72043242e-03\n",
            " 6.26441914e-03 3.10639475e-03 8.41095625e-03 8.61955034e-03\n",
            " 4.83091336e-03 4.29710193e-03 9.03932716e-03 6.67106704e-03\n",
            " 9.19457172e-03 5.39451796e-03 9.65119522e-03 6.83553028e-03\n",
            " 2.34733006e-03 1.99682769e-04 3.59598213e-03 1.04451170e-02\n",
            " 4.01427511e-03 1.01874121e-02 3.79523025e-03 7.29693659e-03\n",
            " 8.44592561e-03 9.62944874e-03 5.23929210e-04 2.81737174e-03\n",
            " 6.34733071e-03 1.29270510e-06 6.80036276e-05 7.24346532e-04\n",
            " 2.86368007e-03 7.65952962e-03 2.93276883e-03 8.58558710e-03\n",
            " 4.84112812e-03 4.32711225e-04 6.31779088e-03 4.85201189e-03\n",
            " 1.21571435e-03 9.99799800e-03 8.44850221e-04 4.87261948e-03\n",
            " 6.80504368e-03 8.21281668e-03 4.70570853e-03 5.76570055e-03\n",
            " 4.12038263e-03 4.85051565e-03 5.03345046e-03 3.04675128e-03\n",
            " 7.87470693e-03 4.29710193e-03 8.11482774e-03 4.09469609e-03\n",
            " 1.25395263e-03 1.73385927e-03 9.32998418e-03 3.52866841e-03\n",
            " 9.31113999e-03 1.39895995e-03 5.04718756e-03 1.05706985e-04\n",
            " 7.30078246e-03 1.07688026e-16 3.36105651e-03 6.43889063e-03\n",
            " 1.91337640e-04 9.16150412e-03 9.36836552e-03 1.01874121e-02\n",
            " 7.46893915e-03 2.86686730e-03 3.73169328e-03 2.92271887e-03\n",
            " 3.29285568e-03 3.30528698e-03 6.19750349e-03 8.04559007e-03\n",
            " 2.02968159e-03 2.00229610e-04 8.46685612e-03 4.00332792e-03\n",
            " 6.75712719e-03 3.54362475e-03 3.51593794e-04 7.61633330e-03\n",
            " 1.86336701e-03 4.13039069e-03 3.00196644e-03 8.86954063e-03\n",
            " 1.69035840e-04 4.25749196e-03 3.03111185e-03 8.32859200e-03\n",
            " 5.31219099e-03 2.97328119e-03 8.38219070e-03 8.78232857e-03\n",
            " 6.54440334e-03 4.99502625e-03 5.74385120e-03 9.82216363e-03\n",
            " 4.42585332e-03 1.66281587e-04 8.94198072e-03 1.69354882e-03\n",
            " 8.18803864e-03 1.00048870e-02 7.17496461e-03 6.46710575e-03\n",
            " 4.12993271e-03 1.99084595e-03 2.94619936e-03 1.61073622e-03\n",
            " 1.35705067e-03 5.09643619e-03 1.93413001e-03 5.39451796e-03\n",
            " 3.67447951e-03 1.12874222e-03 1.04042336e-02 7.07859466e-03\n",
            " 3.02724476e-03 2.94017511e-03 6.11401493e-03 3.52458959e-03\n",
            " 4.38059501e-06 8.01701555e-04 3.49761416e-03 1.29261287e-03\n",
            " 9.13726178e-03 1.23866838e-05 1.01683679e-02 2.06655465e-03\n",
            " 1.89979412e-04 8.54432145e-03 3.90735590e-03 3.00243434e-03\n",
            " 9.33022560e-03 1.61423668e-03 6.38227805e-04 2.19628024e-03\n",
            " 5.63267162e-04 1.64684834e-03 1.06862739e-03 3.41708132e-03\n",
            " 7.98541853e-03 5.61614753e-05 6.18877719e-04 1.01714107e-02\n",
            " 1.15186041e-03 9.56791182e-03 8.97732682e-03 9.75780965e-03\n",
            " 8.72580512e-03 4.99793164e-03 7.74268437e-03 9.36872224e-03\n",
            " 7.55130177e-03 1.61423668e-03 9.68854190e-03 8.95550504e-03\n",
            " 2.15316405e-03 3.45327227e-03 9.09821049e-03 4.34501917e-03\n",
            " 9.69477140e-03 1.71079784e-03 3.78816655e-03 8.49061615e-03\n",
            " 3.92368556e-03 8.49352203e-03 4.78865907e-04 2.34234438e-03\n",
            " 9.65255524e-03 3.43438589e-03 7.09725197e-03 9.62004215e-03\n",
            " 1.66281587e-04 4.53850232e-03 2.52432891e-03 3.33593313e-03\n",
            " 8.37094837e-03 4.25252501e-03 5.07584584e-04 1.52507258e-03\n",
            " 1.25391909e-03 7.28104960e-03 4.44513188e-03 6.85254645e-04\n",
            " 3.73711722e-03 3.44605894e-04 9.28666046e-03 1.61423668e-03\n",
            " 6.83036059e-03 5.81123527e-03 6.73352473e-03 7.61596693e-03\n",
            " 9.88579093e-03 9.30918092e-03 2.31395288e-03 3.71723167e-03\n",
            " 1.03717614e-03 8.73318967e-03 9.48235689e-03 8.83861130e-03\n",
            " 2.09023228e-04 1.02701365e-02 4.12993271e-03 6.72881337e-03\n",
            " 3.49761416e-03 9.36990817e-03 1.17852986e-03 2.51539233e-03\n",
            " 5.09638907e-04 8.27723363e-03 8.80678818e-03 5.32518201e-03\n",
            " 5.08243446e-03 1.40405764e-03 9.50916656e-03 6.70143276e-03\n",
            " 9.74565583e-03 1.01338846e-02 1.58086585e-04 6.65369417e-03\n",
            " 2.27331914e-03 4.29172802e-03 3.06410687e-03 5.43325433e-03\n",
            " 8.41016988e-03 3.33998508e-03 6.91731058e-03 2.85348037e-03\n",
            " 9.02061784e-03 8.40999408e-03 1.86529300e-03 4.75962469e-04\n",
            " 2.59584902e-03 4.69656248e-03 9.44176127e-03 8.95206543e-03\n",
            " 4.13147287e-03 4.93226231e-04 3.06938053e-03 5.78864350e-03\n",
            " 4.78490313e-03 7.21983194e-03 5.58457883e-03 3.12937756e-04\n",
            " 2.72128494e-03 2.53845625e-03 6.94738236e-03 9.01584728e-03\n",
            " 2.15316405e-03 1.38835624e-03 2.19295850e-03 5.74617027e-03\n",
            " 9.74858029e-03 3.77953399e-03 4.40975357e-03 8.47418483e-04\n",
            " 6.50693410e-03 4.48560304e-03 6.04084269e-03 3.41456772e-03\n",
            " 8.78120205e-03 5.75993288e-03 5.11652688e-03 2.79651322e-03\n",
            " 5.95281868e-03 1.04511611e-02 9.48895490e-04 7.09272238e-04\n",
            " 4.45851703e-03 8.05727451e-04 2.00479240e-04 1.10517953e-03\n",
            " 1.59725604e-03 3.03352491e-03 2.84709273e-03 7.28076511e-05\n",
            " 3.32099550e-03 5.95623627e-03 4.68424897e-03 1.57717213e-06\n",
            " 6.15526600e-04 3.83490940e-07 2.37512252e-05 4.48230067e-05\n",
            " 1.29242821e-03 9.29905883e-04 3.93508816e-03 3.85809312e-03\n",
            " 5.24114797e-03 5.24114797e-03 1.07463063e-03 7.10568528e-03\n",
            " 1.83594963e-03 3.72981962e-03 2.21682946e-04 3.83908056e-04\n",
            " 8.60519068e-03 3.52956920e-03 4.27924760e-03 3.64057697e-03\n",
            " 2.18585177e-04 4.71213922e-03 5.92506119e-03 7.17923051e-03\n",
            " 6.33841421e-03 4.90195116e-03 5.31219099e-03 1.00153501e-02\n",
            " 2.84678642e-03 1.00661266e-02 7.42805651e-03 5.39512000e-03\n",
            " 5.49996024e-03 3.85809312e-03 7.49190847e-03 9.62111967e-03\n",
            " 1.18855656e-03 1.06603292e-03 3.24169392e-03 5.84524654e-03\n",
            " 3.94804256e-03 5.46875458e-04 1.03577442e-02 7.92947505e-03\n",
            " 5.36397009e-03 1.84821883e-03 9.71982170e-04 8.82936680e-03\n",
            " 6.03723549e-03 6.57867567e-03 7.99715606e-03 9.63997024e-03\n",
            " 2.62035033e-03 1.40376640e-03 1.20945392e-03 6.79749825e-03\n",
            " 9.14120462e-03 6.53278213e-03 8.62211402e-03 4.42575192e-03\n",
            " 9.91129183e-03 4.60168417e-03 8.21125263e-03 3.11456334e-03\n",
            " 3.39305141e-03 8.01205601e-03 4.29844766e-04 1.00285594e-03\n",
            " 7.22900769e-03 7.72790575e-03 2.55454236e-03 9.75780965e-03\n",
            " 5.13388767e-03 7.48937847e-03 3.42206397e-04 5.44303205e-03\n",
            " 7.09097356e-03 4.20082096e-03 6.03922373e-03 3.56021066e-03\n",
            " 7.37181426e-03 8.02791426e-03 9.54942225e-03 7.47113348e-03\n",
            " 4.83027824e-03 6.08896117e-03 6.09566502e-03 8.01701555e-04\n",
            " 3.54111606e-03]\n",
            "3700 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.02094591e-03 4.28060516e-03 4.28717011e-03 3.49934169e-03\n",
            " 6.84708981e-04 8.43225222e-03 3.68391824e-03 7.58201030e-03\n",
            " 8.39856964e-03 7.63912427e-03 5.39458888e-03 4.90724919e-03\n",
            " 7.70967476e-03 5.73705572e-03 8.53064765e-03 1.44758717e-03\n",
            " 8.93245316e-03 4.11814663e-03 5.61508013e-03 3.85843664e-03\n",
            " 1.18451748e-05 4.45637823e-03 3.36887707e-03 9.62590850e-05\n",
            " 7.38131740e-03 9.91235233e-03 1.89204410e-03 3.84934229e-09\n",
            " 4.11904786e-03 1.55082915e-05 5.75580147e-03 2.99169173e-04\n",
            " 8.83647004e-08 7.54593420e-03 7.39551103e-03 2.84781679e-03\n",
            " 7.02891225e-03 9.75510752e-03 6.09265141e-03 9.21652295e-03\n",
            " 2.38603966e-03 8.76022119e-03 8.95933094e-04 7.46795345e-03\n",
            " 2.40390038e-03 3.27242307e-04 1.08012310e-03 7.61758331e-03\n",
            " 2.91375101e-03 9.66682611e-03 9.75510752e-03 4.09851322e-04\n",
            " 7.97791004e-03 5.31889688e-03 4.38239326e-03 4.45829063e-04\n",
            " 8.72734606e-03 4.29891458e-03 4.24916589e-03 1.23431765e-03\n",
            " 5.93535240e-03 6.63277123e-04 9.60221165e-04 1.01206643e-02\n",
            " 4.84098514e-03 5.63956145e-05 4.13187414e-03 1.00688170e-02\n",
            " 1.74808517e-03 9.93978683e-03 9.80986564e-03 8.07019659e-04\n",
            " 2.34997592e-03 1.00554317e-02 7.47058458e-03 9.36358168e-03\n",
            " 4.39416182e-03 9.91235233e-03 3.71085427e-03 7.24192647e-05\n",
            " 8.61325216e-03 3.33493189e-03 3.71085427e-03 9.41983771e-03\n",
            " 6.20588551e-03 1.10691962e-03 7.34606446e-03 1.29324586e-03\n",
            " 3.18985799e-05 7.93879989e-03 5.43168483e-03 2.95519495e-03\n",
            " 6.22125999e-03 8.99324743e-03 5.78572172e-03 8.06871788e-03\n",
            " 9.79232573e-03 8.93642899e-03 3.84934229e-09 3.67779002e-03\n",
            " 7.80812367e-03 8.08913753e-03 9.96455096e-04 3.70671376e-03\n",
            " 9.18054080e-03 1.98601971e-03 6.77190817e-03 2.36039011e-03\n",
            " 7.92443059e-03 4.31196855e-03 8.34697326e-03 5.97134070e-03\n",
            " 4.71613991e-03 6.26309601e-03 3.10422759e-03 8.39856964e-03\n",
            " 8.60603646e-03 4.82309828e-03 4.29891458e-03 9.03275436e-03\n",
            " 6.65501983e-03 9.18080055e-03 5.40122085e-03 9.63135058e-03\n",
            " 6.82806985e-03 2.34740390e-03 1.99385934e-04 3.59265581e-03\n",
            " 4.00297771e-03 3.79797010e-03 7.24570621e-03 8.44015698e-03\n",
            " 9.61287406e-03 5.21510481e-04 2.81337504e-03 6.34437407e-03\n",
            " 1.28828139e-06 6.77324635e-05 7.21454226e-04 2.85741139e-03\n",
            " 7.64662858e-03 2.92219204e-03 8.58207823e-03 4.82811550e-03\n",
            " 4.33179225e-04 6.30773265e-03 4.84463083e-03 1.21417883e-03\n",
            " 9.98531118e-03 8.37112894e-04 4.87351001e-03 6.80858118e-03\n",
            " 8.19891901e-03 4.70503509e-03 5.75677062e-03 4.11117137e-03\n",
            " 4.84615853e-03 5.01982570e-03 3.04541298e-03 7.85860985e-03\n",
            " 4.29891458e-03 8.09069546e-03 4.09334120e-03 1.25267982e-03\n",
            " 1.72721425e-03 9.31094923e-03 3.51412028e-03 9.29031355e-03\n",
            " 1.39459972e-03 5.04215616e-03 1.05361529e-04 7.29531455e-03\n",
            " 1.06265645e-16 3.35880847e-03 6.43504108e-03 1.90902845e-04\n",
            " 9.16266406e-03 9.34059817e-03 7.46795345e-03 2.86480465e-03\n",
            " 3.72460401e-03 2.92589922e-03 3.28294071e-03 3.29844604e-03\n",
            " 6.19192693e-03 8.03936708e-03 2.02999453e-03 1.98878782e-04\n",
            " 8.44804998e-03 3.99487618e-03 6.75347900e-03 3.53882378e-03\n",
            " 3.50892499e-04 7.60168202e-03 1.86248749e-03 4.11887319e-03\n",
            " 3.00161824e-03 8.85430166e-03 1.68324683e-04 4.24820543e-03\n",
            " 3.02506950e-03 8.33059133e-03 5.30566950e-03 2.97001254e-03\n",
            " 8.37016008e-03 8.77835968e-03 6.54325137e-03 4.98477481e-03\n",
            " 5.73705572e-03 9.81387618e-03 4.42122585e-03 1.65797491e-04\n",
            " 8.93111791e-03 1.68904360e-03 8.18430403e-03 9.96827742e-03\n",
            " 7.16719502e-03 6.46103686e-03 4.13187414e-03 1.98569306e-03\n",
            " 2.93305111e-03 1.61092922e-03 1.35646278e-03 5.08937307e-03\n",
            " 1.93130664e-03 5.40122085e-03 3.66710362e-03 1.12608815e-03\n",
            " 7.05742478e-03 3.01792181e-03 2.93428847e-03 6.08970534e-03\n",
            " 3.52129053e-03 4.35731783e-06 8.01513361e-04 3.48220106e-03\n",
            " 1.29241073e-03 9.14084678e-03 1.23122807e-05 1.01613363e-02\n",
            " 2.06584480e-03 1.89661230e-04 8.54363718e-03 3.89639385e-03\n",
            " 2.99821546e-03 9.31622403e-03 1.61113501e-03 6.38386501e-04\n",
            " 2.19024657e-03 5.62134450e-04 1.64315548e-03 1.06894420e-03\n",
            " 3.40697209e-03 7.98025340e-03 5.61064869e-05 6.17543653e-04\n",
            " 1.01556870e-02 1.14831375e-03 9.55071230e-03 8.97127950e-03\n",
            " 9.75510752e-03 8.70132801e-03 4.99412286e-03 7.73051478e-03\n",
            " 9.34622920e-03 7.54230851e-03 1.61113501e-03 9.67719969e-03\n",
            " 8.92688872e-03 2.14289306e-03 3.44910664e-03 9.08378818e-03\n",
            " 4.34848089e-03 9.68732106e-03 1.70762668e-03 3.79049006e-03\n",
            " 8.47841788e-03 3.91809318e-03 8.47566207e-03 4.77122874e-04\n",
            " 2.33636881e-03 9.61193292e-03 3.43147874e-03 7.08360422e-03\n",
            " 9.62019284e-03 1.65797491e-04 4.54021706e-03 2.52156716e-03\n",
            " 3.32492759e-03 8.36751430e-03 4.24721505e-03 5.04758629e-04\n",
            " 1.52327830e-03 1.25416898e-03 7.25274789e-03 4.43250923e-03\n",
            " 6.84708981e-04 3.72996844e-03 3.44372483e-04 9.29341627e-03\n",
            " 1.61113501e-03 6.82304206e-03 5.80202441e-03 6.72890096e-03\n",
            " 7.62343597e-03 9.87686375e-03 9.30833320e-03 2.30982235e-03\n",
            " 3.71382588e-03 1.03639714e-03 8.71482733e-03 9.48964916e-03\n",
            " 8.79746870e-03 2.08878246e-04 4.13187414e-03 6.72107452e-03\n",
            " 3.48220106e-03 9.35539705e-03 1.17786513e-03 2.50981677e-03\n",
            " 5.08144642e-04 8.27262982e-03 8.80280335e-03 5.32095232e-03\n",
            " 5.07302482e-03 1.40280578e-03 9.50350495e-03 6.70636106e-03\n",
            " 9.72687469e-03 1.01283292e-02 1.57963055e-04 6.64442474e-03\n",
            " 2.27125689e-03 4.28885236e-03 3.05020258e-03 5.43168483e-03\n",
            " 8.39933622e-03 3.33493189e-03 6.92098273e-03 2.85305014e-03\n",
            " 9.00523025e-03 8.40150733e-03 1.86378213e-03 4.74799289e-04\n",
            " 2.58620654e-03 4.69497321e-03 9.44791073e-03 8.92085589e-03\n",
            " 4.12384906e-03 4.92353555e-04 3.06583176e-03 5.78058103e-03\n",
            " 4.77494019e-03 7.21224334e-03 5.58622701e-03 3.12208103e-04\n",
            " 2.72070374e-03 2.52866920e-03 6.94263231e-03 9.00667468e-03\n",
            " 2.14289306e-03 1.38519640e-03 2.19211852e-03 5.73977964e-03\n",
            " 9.73510869e-03 3.78190659e-03 4.40624611e-03 8.44866081e-04\n",
            " 6.49764593e-03 4.46217247e-03 6.01508793e-03 3.40867277e-03\n",
            " 8.78317029e-03 5.74885838e-03 5.11631061e-03 2.79543373e-03\n",
            " 5.94141951e-03 9.45193313e-04 7.09287983e-04 4.45637823e-03\n",
            " 8.04076781e-04 1.98885474e-04 1.10208449e-03 1.59604555e-03\n",
            " 3.02734722e-03 2.84781679e-03 7.25638682e-05 3.31826770e-03\n",
            " 5.93771607e-03 4.68151772e-03 1.56967039e-06 6.14354900e-04\n",
            " 3.83654535e-07 2.36467811e-05 4.47471234e-05 1.29030384e-03\n",
            " 9.30088134e-04 3.92731151e-03 3.85843664e-03 5.23836084e-03\n",
            " 5.23836084e-03 1.07354950e-03 7.10534918e-03 1.83294541e-03\n",
            " 3.72019678e-03 2.21041270e-04 3.82884188e-04 8.59542326e-03\n",
            " 3.51745737e-03 4.25963528e-03 3.64017980e-03 2.17825209e-04\n",
            " 4.69382281e-03 5.92416786e-03 7.16902844e-03 6.32905369e-03\n",
            " 4.90243680e-03 5.30566950e-03 1.00034951e-02 2.84207792e-03\n",
            " 1.00450271e-02 7.41769482e-03 5.38316516e-03 5.47509756e-03\n",
            " 3.85843664e-03 7.49329856e-03 9.60113713e-03 1.18380274e-03\n",
            " 1.06114792e-03 3.24061820e-03 5.83926511e-03 3.94278756e-03\n",
            " 5.43687883e-04 7.92240435e-03 5.36120112e-03 1.84019323e-03\n",
            " 9.69421317e-04 8.81335372e-03 6.03221132e-03 6.56724291e-03\n",
            " 7.99772268e-03 9.63156556e-03 2.61627048e-03 1.40012444e-03\n",
            " 1.20525981e-03 6.76956239e-03 9.12343293e-03 6.51899271e-03\n",
            " 8.60334456e-03 4.42455655e-03 9.89799289e-03 4.60032465e-03\n",
            " 8.19957464e-03 3.10873127e-03 3.39059987e-03 7.99097463e-03\n",
            " 4.26843623e-04 1.00307203e-03 7.23515670e-03 7.72466265e-03\n",
            " 2.55002766e-03 9.75510752e-03 5.13272787e-03 7.47364283e-03\n",
            " 3.41265672e-04 5.44257316e-03 7.07720432e-03 4.19624933e-03\n",
            " 6.02434040e-03 3.56093936e-03 7.36316530e-03 8.00438672e-03\n",
            " 9.54396687e-03 7.46500891e-03 4.82841186e-03 6.08409757e-03\n",
            " 6.09414430e-03 8.01513361e-04 3.53875263e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3710 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.01366865e-03 4.27365979e-03 4.28871046e-03 3.48801927e-03\n",
            " 6.84218536e-04 8.40686525e-03 3.67776766e-03 7.56123946e-03\n",
            " 8.37435637e-03 7.63424159e-03 5.38074286e-03 4.90377650e-03\n",
            " 7.70092942e-03 5.73247390e-03 8.51277641e-03 1.44511682e-03\n",
            " 8.89923359e-03 4.10519633e-03 5.60956574e-03 3.85382533e-03\n",
            " 1.18407184e-05 4.45030874e-03 3.36758100e-03 9.55516192e-05\n",
            " 7.38592627e-03 9.91553411e-03 1.88638197e-03 3.80245852e-09\n",
            " 4.11618060e-03 1.52438043e-05 5.74862748e-03 2.98185207e-04\n",
            " 8.81974664e-08 7.54707799e-03 7.39059078e-03 2.84389354e-03\n",
            " 7.02886091e-03 9.75189633e-03 6.08286716e-03 9.21738007e-03\n",
            " 2.38738362e-03 8.75527987e-03 8.93247815e-04 7.46646840e-03\n",
            " 2.39270710e-03 3.25982307e-04 1.07895831e-03 7.60026968e-03\n",
            " 2.91010069e-03 9.63578029e-03 9.75189633e-03 4.09986057e-04\n",
            " 7.98326889e-03 5.30865531e-03 4.36958477e-03 4.45886630e-04\n",
            " 8.72163647e-03 4.29390334e-03 4.22969117e-03 1.22991236e-03\n",
            " 5.91746040e-03 6.62318745e-04 9.59483603e-04 4.83625064e-03\n",
            " 5.63999906e-05 4.13417161e-03 1.74415601e-03 9.93396473e-03\n",
            " 9.78769616e-03 8.04411971e-04 2.34858864e-03 7.47103958e-03\n",
            " 9.32595993e-03 4.39020667e-03 9.91553411e-03 3.70837308e-03\n",
            " 7.22604385e-05 8.61413080e-03 3.31089299e-03 3.70837308e-03\n",
            " 9.42050714e-03 6.20646129e-03 1.10707649e-03 7.34223769e-03\n",
            " 1.29187375e-03 3.14974879e-05 7.91871096e-03 5.43577725e-03\n",
            " 2.94543095e-03 6.20685020e-03 8.98232611e-03 5.75340815e-03\n",
            " 8.05727087e-03 9.79696245e-03 8.93311265e-03 3.80245852e-09\n",
            " 3.66391715e-03 7.79697238e-03 8.08145818e-03 9.96103024e-04\n",
            " 3.70527963e-03 9.17870427e-03 1.98168928e-03 6.76144649e-03\n",
            " 2.35569060e-03 7.91125405e-03 4.30809498e-03 8.35038042e-03\n",
            " 5.96559604e-03 4.69239105e-03 6.26138024e-03 3.10389193e-03\n",
            " 8.37435637e-03 8.57616633e-03 4.81472247e-03 4.29390334e-03\n",
            " 9.00869178e-03 6.65336075e-03 9.15766104e-03 5.39862792e-03\n",
            " 9.61590486e-03 6.79343688e-03 2.34711275e-03 1.99259467e-04\n",
            " 3.58466888e-03 3.99333221e-03 3.79453112e-03 7.22229425e-03\n",
            " 8.44188357e-03 9.59958583e-03 5.20565143e-04 2.80271721e-03\n",
            " 6.33840960e-03 1.28769661e-06 6.73706285e-05 7.19829383e-04\n",
            " 2.85326737e-03 7.61681714e-03 2.92226922e-03 8.57845291e-03\n",
            " 4.81099341e-03 4.32811085e-04 6.30504996e-03 4.84356534e-03\n",
            " 1.21441121e-03 8.33528941e-04 4.86124448e-03 6.80384453e-03\n",
            " 8.18327169e-03 4.70616707e-03 5.75172594e-03 4.10092131e-03\n",
            " 4.84981887e-03 5.01478859e-03 3.03346016e-03 7.85424751e-03\n",
            " 4.29390334e-03 8.06623727e-03 4.09149286e-03 1.24934036e-03\n",
            " 1.72472989e-03 9.28697586e-03 3.50329840e-03 9.28876493e-03\n",
            " 1.39115649e-03 5.02402947e-03 1.04982067e-04 7.28536440e-03\n",
            " 1.00441047e-16 3.35664269e-03 6.43082372e-03 1.89677329e-04\n",
            " 9.14900806e-03 9.30543031e-03 7.46646840e-03 2.86249704e-03\n",
            " 3.71952479e-03 2.92741732e-03 3.28416097e-03 3.28900235e-03\n",
            " 6.16943476e-03 8.02853384e-03 2.02998072e-03 1.98298247e-04\n",
            " 8.42625744e-03 3.98922376e-03 6.74694894e-03 3.50954553e-03\n",
            " 3.50397452e-04 7.57715105e-03 1.86224266e-03 4.12047944e-03\n",
            " 2.99334328e-03 8.85499320e-03 1.67604809e-04 4.24267298e-03\n",
            " 3.02216080e-03 8.32856278e-03 5.30040950e-03 2.96131970e-03\n",
            " 8.35313279e-03 8.76023567e-03 6.54104886e-03 4.96827987e-03\n",
            " 5.73247390e-03 9.79611956e-03 4.40727633e-03 1.65039730e-04\n",
            " 8.90654036e-03 1.68368883e-03 8.16645204e-03 7.15860623e-03\n",
            " 6.43699431e-03 4.13417161e-03 1.98086602e-03 2.92494275e-03\n",
            " 1.61095910e-03 1.35650394e-03 5.08214460e-03 1.91933736e-03\n",
            " 5.39862792e-03 3.66256572e-03 1.12066387e-03 7.05563943e-03\n",
            " 3.02192555e-03 2.93520523e-03 6.08143858e-03 3.52077139e-03\n",
            " 4.30392533e-06 7.98382382e-04 3.48221654e-03 1.29152904e-03\n",
            " 9.11509100e-03 1.22866481e-05 2.06356013e-03 1.89293459e-04\n",
            " 8.54081223e-03 3.88905915e-03 2.99741633e-03 9.27484674e-03\n",
            " 1.59824972e-03 6.37765925e-04 2.18913994e-03 5.60433373e-04\n",
            " 1.63924091e-03 1.06664175e-03 3.40541839e-03 7.96384893e-03\n",
            " 5.59283766e-05 6.16951417e-04 1.14018770e-03 9.53086428e-03\n",
            " 8.94817113e-03 9.75189633e-03 8.70663545e-03 4.98305293e-03\n",
            " 7.70417902e-03 9.32082111e-03 7.53458399e-03 1.59824972e-03\n",
            " 9.64218043e-03 8.92622806e-03 2.13741632e-03 3.43950836e-03\n",
            " 9.07068017e-03 4.34839437e-03 9.66863236e-03 1.70396584e-03\n",
            " 3.77853006e-03 8.47606466e-03 3.89609557e-03 8.46990326e-03\n",
            " 4.76046528e-04 2.32290193e-03 9.61414787e-03 3.42783487e-03\n",
            " 7.07611783e-03 9.61115451e-03 1.65039730e-04 4.53411943e-03\n",
            " 2.50949428e-03 3.31514402e-03 8.36330039e-03 4.24176234e-03\n",
            " 5.03975164e-04 1.52139100e-03 1.25222037e-03 7.23752375e-03\n",
            " 4.42399210e-03 6.84218536e-04 3.70968187e-03 3.43589618e-04\n",
            " 9.29291784e-03 1.59824972e-03 6.80686800e-03 5.79969499e-03\n",
            " 6.71974473e-03 7.61835444e-03 9.86812010e-03 9.30718638e-03\n",
            " 2.30935535e-03 3.70651307e-03 1.03431118e-03 8.71043383e-03\n",
            " 9.46609609e-03 8.78447348e-03 2.08613894e-04 4.13417161e-03\n",
            " 6.72382526e-03 3.48221654e-03 9.34489483e-03 1.17824712e-03\n",
            " 2.50702550e-03 5.08488512e-04 8.26222738e-03 8.79369566e-03\n",
            " 5.32239224e-03 5.07564451e-03 1.40417775e-03 9.48908448e-03\n",
            " 6.70968583e-03 9.72317471e-03 1.57868221e-04 6.63653860e-03\n",
            " 2.26446836e-03 4.28909326e-03 3.04242324e-03 5.43577725e-03\n",
            " 8.38224283e-03 3.31089299e-03 6.91279687e-03 2.82410243e-03\n",
            " 8.95216461e-03 8.39742783e-03 1.86104858e-03 4.70596880e-04\n",
            " 2.58331485e-03 4.69422884e-03 9.44925051e-03 8.90815749e-03\n",
            " 4.12083311e-03 4.89415845e-04 3.06182626e-03 5.77443641e-03\n",
            " 4.75948358e-03 7.20399756e-03 5.56514452e-03 3.11070176e-04\n",
            " 2.71342537e-03 2.52597274e-03 6.93492876e-03 8.97586340e-03\n",
            " 2.13741632e-03 1.38263201e-03 2.19316090e-03 5.73143544e-03\n",
            " 9.70887808e-03 3.78070969e-03 4.39436739e-03 8.42698318e-04\n",
            " 6.49312176e-03 4.45373515e-03 6.01432278e-03 3.40503112e-03\n",
            " 8.76286391e-03 5.73967997e-03 5.11032454e-03 2.79539022e-03\n",
            " 5.93657239e-03 9.40439666e-04 7.09098077e-04 4.45030874e-03\n",
            " 7.96547778e-04 1.98517867e-04 1.09991496e-03 1.59269967e-03\n",
            " 3.01619098e-03 2.84389354e-03 7.18883910e-05 3.31153156e-03\n",
            " 5.92510191e-03 4.66759600e-03 1.55855747e-06 6.12774229e-04\n",
            " 3.77919642e-07 2.35500235e-05 4.46539973e-05 1.28610716e-03\n",
            " 9.30115528e-04 3.92622834e-03 3.85382533e-03 5.23769022e-03\n",
            " 5.23769022e-03 1.07046506e-03 7.09880799e-03 1.83192261e-03\n",
            " 3.71605444e-03 2.17888264e-04 3.80862673e-04 8.56462130e-03\n",
            " 3.51837800e-03 4.25616873e-03 3.63581277e-03 2.16836782e-04\n",
            " 4.69264514e-03 5.91986891e-03 7.16171866e-03 6.32034297e-03\n",
            " 4.90409441e-03 5.30040950e-03 2.83064980e-03 7.41078376e-03\n",
            " 5.37996706e-03 5.46017465e-03 3.85382533e-03 7.48947726e-03\n",
            " 9.57582076e-03 1.18158956e-03 1.05894114e-03 3.23183465e-03\n",
            " 5.83540892e-03 3.93987286e-03 5.39602001e-04 7.91582374e-03\n",
            " 5.35224769e-03 1.82696781e-03 9.62795181e-04 8.81182239e-03\n",
            " 6.02603200e-03 6.56419121e-03 7.97407530e-03 9.62692427e-03\n",
            " 2.60280692e-03 1.39875033e-03 1.20176437e-03 6.75651191e-03\n",
            " 9.12043387e-03 6.49740005e-03 8.59056943e-03 4.42322496e-03\n",
            " 9.89202104e-03 4.59634519e-03 8.17321642e-03 3.09677042e-03\n",
            " 3.39025039e-03 7.98215548e-03 4.25990988e-04 1.00307923e-03\n",
            " 7.23554717e-03 7.71786762e-03 2.54400130e-03 9.75189633e-03\n",
            " 5.12566530e-03 7.47335268e-03 3.39887301e-04 5.44388101e-03\n",
            " 7.05799714e-03 4.17888850e-03 6.02843645e-03 3.55557304e-03\n",
            " 7.36778221e-03 7.98255358e-03 9.52500190e-03 7.46191927e-03\n",
            " 4.82307587e-03 6.08358128e-03 6.08854410e-03 7.98382382e-04\n",
            " 3.53518934e-03]\n",
            "3720 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.01156316e-03 4.26559162e-03 4.28351393e-03 3.48028181e-03\n",
            " 6.84553881e-04 8.39400307e-03 3.67720956e-03 7.56358822e-03\n",
            " 8.37142371e-03 7.64110027e-03 5.38004742e-03 4.87685542e-03\n",
            " 7.70270553e-03 5.71027407e-03 8.51397515e-03 1.44204627e-03\n",
            " 8.89881557e-03 4.10760356e-03 5.60386059e-03 3.85429719e-03\n",
            " 1.17568989e-05 4.44668457e-03 3.34850667e-03 9.39771863e-05\n",
            " 7.38050902e-03 1.87816314e-03 3.70626286e-09 4.10484212e-03\n",
            " 1.52131638e-05 5.74180306e-03 2.96227109e-04 8.60398773e-08\n",
            " 7.53228438e-03 7.38098982e-03 2.84378602e-03 7.02749895e-03\n",
            " 6.07581841e-03 9.21089904e-03 2.38595362e-03 8.75449349e-03\n",
            " 8.89685828e-04 7.46568678e-03 2.39011990e-03 3.24353181e-04\n",
            " 1.07649960e-03 7.59828390e-03 2.90711000e-03 9.62832020e-03\n",
            " 9.57198093e-03 4.09364637e-04 7.97807736e-03 5.28740182e-03\n",
            " 4.37370395e-03 4.42459026e-04 8.70690407e-03 4.28233404e-03\n",
            " 4.22216613e-03 1.22776439e-03 5.89323161e-03 6.60959896e-04\n",
            " 9.58122214e-04 4.83244230e-03 5.60082152e-05 4.13269948e-03\n",
            " 1.74425263e-03 8.04408406e-04 2.34647648e-03 7.46613350e-03\n",
            " 9.32364037e-03 4.37839326e-03 3.70007262e-03 7.21854799e-05\n",
            " 8.57688337e-03 3.28726056e-03 3.70007262e-03 9.37192913e-03\n",
            " 6.20710426e-03 1.10618954e-03 7.32306674e-03 1.28630381e-03\n",
            " 3.15271696e-05 7.91864135e-03 5.43454541e-03 2.93887924e-03\n",
            " 6.19437115e-03 8.97643450e-03 5.75148180e-03 8.05535765e-03\n",
            " 8.92235567e-03 3.70626286e-09 3.65712564e-03 7.75136816e-03\n",
            " 8.08211528e-03 9.93533132e-04 3.69861091e-03 9.17207055e-03\n",
            " 1.97762345e-03 6.74746716e-03 2.35342960e-03 7.89982025e-03\n",
            " 4.30296766e-03 8.34850434e-03 5.96081880e-03 4.68686557e-03\n",
            " 6.24013255e-03 3.08304525e-03 8.37142371e-03 8.54864366e-03\n",
            " 4.78919374e-03 4.28233404e-03 9.01031304e-03 6.61433953e-03\n",
            " 9.16139167e-03 5.39851028e-03 9.58934158e-03 6.79419986e-03\n",
            " 2.34574160e-03 1.98624038e-04 3.57715806e-03 3.99478982e-03\n",
            " 3.78804967e-03 7.23464670e-03 8.42735135e-03 9.59224469e-03\n",
            " 5.19082333e-04 2.80015730e-03 6.33764926e-03 1.28105428e-06\n",
            " 6.72611526e-05 7.17882992e-04 2.84635100e-03 7.61032565e-03\n",
            " 2.90277377e-03 8.54827615e-03 4.78694753e-03 4.32320057e-04\n",
            " 6.28384986e-03 4.83952026e-03 1.20443396e-03 8.32040150e-04\n",
            " 4.86083505e-03 6.79085575e-03 8.17903076e-03 4.70680835e-03\n",
            " 5.73269694e-03 4.09634021e-03 4.84885397e-03 5.00271187e-03\n",
            " 3.02411346e-03 7.83266595e-03 4.28233404e-03 8.05221609e-03\n",
            " 4.06506421e-03 1.24698610e-03 1.71473685e-03 9.28843746e-03\n",
            " 3.50331952e-03 9.28492089e-03 1.38499495e-03 5.02231875e-03\n",
            " 1.04815528e-04 7.27277546e-03 1.00395476e-16 3.35749191e-03\n",
            " 6.43049185e-03 1.89618043e-04 9.14611532e-03 9.30513832e-03\n",
            " 7.46568678e-03 2.85739326e-03 3.72058277e-03 2.92361690e-03\n",
            " 3.27458728e-03 3.27259888e-03 6.15742869e-03 8.02323986e-03\n",
            " 2.02363271e-03 1.96453878e-04 8.42225422e-03 3.98247591e-03\n",
            " 6.73766290e-03 3.50973376e-03 3.48731516e-04 7.57450240e-03\n",
            " 1.85999970e-03 4.11680566e-03 2.99007071e-03 8.85671866e-03\n",
            " 1.67331951e-04 4.23539948e-03 3.01685302e-03 8.32437624e-03\n",
            " 5.27891402e-03 2.96023779e-03 8.33321218e-03 8.71285892e-03\n",
            " 6.53648565e-03 4.96778291e-03 5.71027407e-03 4.40066208e-03\n",
            " 1.63781593e-04 8.91141463e-03 1.67806350e-03 8.15879344e-03\n",
            " 7.15900310e-03 6.43454535e-03 4.13269948e-03 1.98011987e-03\n",
            " 2.91368240e-03 1.60909333e-03 1.34555870e-03 5.07310415e-03\n",
            " 1.91380321e-03 5.39851028e-03 3.65899870e-03 1.11961127e-03\n",
            " 7.05654820e-03 3.01693246e-03 2.93276951e-03 6.07915612e-03\n",
            " 3.51573412e-03 4.28645708e-06 7.92971247e-04 3.48351520e-03\n",
            " 1.29022489e-03 9.11485389e-03 1.21853726e-05 2.05819046e-03\n",
            " 1.88957774e-04 8.53921814e-03 3.88463027e-03 2.98010160e-03\n",
            " 9.26962362e-03 1.59311409e-03 6.37774011e-04 2.18294231e-03\n",
            " 5.60248074e-04 1.64119664e-03 1.06592880e-03 3.38686301e-03\n",
            " 7.95857524e-03 5.58136906e-05 6.13136652e-04 1.13995644e-03\n",
            " 9.52192318e-03 8.93507811e-03 9.57198093e-03 8.69730707e-03\n",
            " 4.97370527e-03 7.70435886e-03 9.28142756e-03 7.52107817e-03\n",
            " 1.59311409e-03 9.55826880e-03 8.92473746e-03 2.12849445e-03\n",
            " 3.43928031e-03 9.06360050e-03 4.35198435e-03 9.66641494e-03\n",
            " 1.70435236e-03 3.77163092e-03 8.48186788e-03 3.89610863e-03\n",
            " 8.45463701e-03 4.74699699e-04 2.31307099e-03 9.61611041e-03\n",
            " 3.41875242e-03 7.06017845e-03 9.61054056e-03 1.63781593e-04\n",
            " 4.52465093e-03 2.51228626e-03 3.30371416e-03 8.35101273e-03\n",
            " 4.23099785e-03 5.01260729e-04 1.52084445e-03 1.25139466e-03\n",
            " 7.23767550e-03 4.42000443e-03 6.84553881e-04 3.70502871e-03\n",
            " 3.42435317e-04 9.27435084e-03 1.59311409e-03 6.80465668e-03\n",
            " 5.80294053e-03 6.68070468e-03 7.59928615e-03 9.29658471e-03\n",
            " 2.29860505e-03 3.70361146e-03 1.02519620e-03 8.71438469e-03\n",
            " 9.45638026e-03 8.75891025e-03 2.08395084e-04 4.13269948e-03\n",
            " 6.71619707e-03 3.48351520e-03 9.32016613e-03 1.17857639e-03\n",
            " 2.50615162e-03 5.03734043e-04 8.25256029e-03 8.78552814e-03\n",
            " 5.31972743e-03 5.06051534e-03 1.39615797e-03 9.46372965e-03\n",
            " 6.70538883e-03 9.71282004e-03 1.57685630e-04 6.62413314e-03\n",
            " 2.26417205e-03 4.28690892e-03 3.03952378e-03 5.43454541e-03\n",
            " 8.35774353e-03 3.28726056e-03 6.90815901e-03 2.81723211e-03\n",
            " 8.95950727e-03 8.39481834e-03 1.86101284e-03 4.70686331e-04\n",
            " 2.57871608e-03 4.69411856e-03 9.44873946e-03 8.89315684e-03\n",
            " 4.10735373e-03 4.86008302e-04 3.05629671e-03 5.75786613e-03\n",
            " 4.74927760e-03 7.19930551e-03 5.56499971e-03 3.10756250e-04\n",
            " 2.70747981e-03 2.49793741e-03 6.92120673e-03 8.98149684e-03\n",
            " 2.12849445e-03 1.37481738e-03 2.18815901e-03 5.70286075e-03\n",
            " 9.70746047e-03 3.77729269e-03 4.38701428e-03 8.41833727e-04\n",
            " 6.49629183e-03 4.45426709e-03 5.99527725e-03 3.40408143e-03\n",
            " 8.74872026e-03 5.74618131e-03 5.09950409e-03 2.79353209e-03\n",
            " 5.92993798e-03 9.37160650e-04 7.07356320e-04 4.44668457e-03\n",
            " 7.96167467e-04 1.97372765e-04 1.09670585e-03 1.59256234e-03\n",
            " 3.01145477e-03 2.84378602e-03 7.18814511e-05 3.30852373e-03\n",
            " 5.91234884e-03 4.66691088e-03 1.54452963e-06 6.11936451e-04\n",
            " 3.77555005e-07 2.32793624e-05 4.45134853e-05 1.28579838e-03\n",
            " 9.29910234e-04 3.90323068e-03 3.85429719e-03 5.22171922e-03\n",
            " 5.22171922e-03 1.06960227e-03 7.09693400e-03 1.82598547e-03\n",
            " 3.71041178e-03 2.18017325e-04 3.80340694e-04 8.55875000e-03\n",
            " 3.51369353e-03 4.24581724e-03 3.61705112e-03 2.15806586e-04\n",
            " 4.69320831e-03 5.91153864e-03 7.14762944e-03 6.30491183e-03\n",
            " 4.89504522e-03 5.27891402e-03 2.83245272e-03 7.41018024e-03\n",
            " 5.37024652e-03 5.45757669e-03 3.85429719e-03 7.47188031e-03\n",
            " 9.54923296e-03 1.17512515e-03 1.05890441e-03 3.23379122e-03\n",
            " 5.82975859e-03 3.93413992e-03 5.40130509e-04 7.90135307e-03\n",
            " 5.34440173e-03 1.82513351e-03 9.62451733e-04 8.79916695e-03\n",
            " 6.02309048e-03 6.53509204e-03 7.95662375e-03 9.61783065e-03\n",
            " 2.59871726e-03 1.39114483e-03 1.20086297e-03 6.74230069e-03\n",
            " 9.11041686e-03 6.49689478e-03 8.58028417e-03 4.41418836e-03\n",
            " 4.58653791e-03 8.17199686e-03 3.08530733e-03 3.36289587e-03\n",
            " 7.97423267e-03 4.23845256e-04 1.00282106e-03 7.21725319e-03\n",
            " 7.69322176e-03 2.54391845e-03 5.12395888e-03 7.46416996e-03\n",
            " 3.38727832e-04 5.43596215e-03 7.05081441e-03 4.17796473e-03\n",
            " 6.02785259e-03 3.54904701e-03 7.33922014e-03 7.95751639e-03\n",
            " 9.51092884e-03 7.46973442e-03 4.81520274e-03 6.06856616e-03\n",
            " 6.07362237e-03 7.92971247e-04 3.53465113e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3730 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.00906448e-03 4.26079266e-03 4.27771055e-03 3.46988062e-03\n",
            " 6.83860839e-04 8.39122573e-03 3.67558687e-03 7.55404831e-03\n",
            " 8.35756905e-03 7.63520315e-03 5.37224394e-03 4.86841318e-03\n",
            " 7.70381411e-03 5.70669740e-03 8.50538787e-03 1.43726927e-03\n",
            " 8.88665679e-03 4.10585546e-03 5.60109343e-03 3.85688269e-03\n",
            " 1.17207486e-05 4.44728993e-03 3.34837020e-03 9.40700442e-05\n",
            " 7.34670876e-03 1.87145325e-03 3.68052980e-09 4.09420519e-03\n",
            " 1.50502737e-05 5.73567332e-03 2.95029044e-04 8.49093457e-08\n",
            " 7.52446947e-03 7.36237271e-03 2.84565527e-03 7.00538193e-03\n",
            " 6.07390927e-03 9.18855030e-03 2.38025242e-03 8.71978809e-03\n",
            " 8.83498604e-04 7.46534755e-03 2.38096290e-03 3.23390334e-04\n",
            " 1.07256641e-03 7.58878356e-03 2.90441767e-03 9.48566132e-03\n",
            " 4.08920149e-04 7.96182865e-03 5.26750235e-03 4.36810794e-03\n",
            " 4.40808457e-04 8.69544168e-03 4.27194525e-03 4.21005181e-03\n",
            " 1.22484081e-03 5.87532551e-03 6.59862385e-04 9.57007018e-04\n",
            " 4.82981079e-03 5.58623381e-05 4.12967593e-03 1.73941150e-03\n",
            " 8.02423127e-04 2.34438885e-03 7.45508698e-03 9.30503540e-03\n",
            " 4.37154444e-03 3.69119210e-03 7.14834053e-05 8.56511878e-03\n",
            " 3.28121209e-03 3.69119210e-03 9.35033798e-03 6.19749645e-03\n",
            " 1.10517350e-03 7.30970500e-03 1.28327784e-03 3.13415311e-05\n",
            " 7.89704305e-03 5.43519097e-03 2.93331693e-03 6.19897095e-03\n",
            " 8.96724065e-03 5.73061137e-03 8.05635213e-03 8.91257543e-03\n",
            " 3.68052980e-09 3.64952705e-03 7.74856257e-03 8.08136091e-03\n",
            " 9.89759579e-04 3.69847970e-03 9.17023124e-03 1.97760069e-03\n",
            " 6.72890259e-03 2.34882094e-03 7.89396351e-03 4.30150316e-03\n",
            " 8.34283743e-03 5.95718695e-03 4.67492750e-03 6.23784700e-03\n",
            " 3.07264375e-03 8.35756905e-03 8.54194519e-03 4.78181187e-03\n",
            " 4.27194525e-03 9.00112816e-03 6.60456996e-03 9.15263644e-03\n",
            " 5.40168146e-03 6.77989309e-03 2.34375534e-03 1.98552215e-04\n",
            " 3.57331087e-03 3.98853297e-03 3.78416244e-03 7.21517001e-03\n",
            " 8.41652679e-03 5.18384123e-04 2.79853696e-03 6.33601393e-03\n",
            " 1.27500567e-06 6.69442173e-05 7.17887314e-04 2.84115127e-03\n",
            " 7.60199679e-03 2.89707705e-03 8.54883891e-03 4.75148782e-03\n",
            " 4.31890879e-04 6.26531824e-03 4.83583204e-03 1.20006825e-03\n",
            " 8.28642716e-04 4.85261259e-03 6.79668867e-03 8.17451731e-03\n",
            " 4.70784707e-03 5.72459387e-03 4.08868421e-03 4.83979185e-03\n",
            " 4.99605015e-03 3.02194992e-03 7.82116995e-03 4.27194525e-03\n",
            " 8.02800801e-03 4.05840833e-03 1.24559344e-03 1.71000519e-03\n",
            " 9.25821132e-03 3.49780001e-03 9.27448410e-03 1.38157428e-03\n",
            " 5.01394851e-03 1.04425748e-04 7.25140677e-03 9.78860071e-17\n",
            " 3.35480968e-03 6.42988321e-03 1.89050111e-04 9.14453648e-03\n",
            " 9.28280038e-03 7.46534755e-03 2.85906075e-03 3.70680957e-03\n",
            " 2.92238220e-03 3.27333654e-03 3.26428436e-03 6.15182725e-03\n",
            " 8.01946818e-03 2.01877972e-03 1.96132062e-04 8.40527061e-03\n",
            " 3.97906594e-03 6.73749135e-03 3.49456921e-03 3.48138433e-04\n",
            " 7.56655946e-03 1.86226686e-03 4.11694367e-03 2.98310068e-03\n",
            " 8.84481519e-03 1.66820824e-04 4.23061725e-03 3.00754422e-03\n",
            " 8.32061974e-03 5.27766566e-03 2.95594695e-03 8.31656008e-03\n",
            " 8.71059827e-03 6.53329911e-03 4.94738042e-03 5.70669740e-03\n",
            " 4.39361740e-03 1.63267479e-04 8.91456613e-03 1.67593444e-03\n",
            " 8.14104087e-03 7.15437107e-03 6.42639211e-03 4.12967593e-03\n",
            " 1.97298318e-03 2.90530034e-03 1.60795958e-03 1.34017548e-03\n",
            " 5.06531265e-03 1.90402331e-03 5.40168146e-03 3.65523146e-03\n",
            " 1.11480005e-03 7.05227783e-03 3.01372298e-03 2.92496891e-03\n",
            " 6.07742910e-03 3.50701942e-03 4.25489457e-06 7.91965509e-04\n",
            " 3.47877549e-03 1.28899113e-03 9.11842500e-03 1.21328895e-05\n",
            " 2.05551859e-03 1.88710592e-04 8.54416930e-03 3.88014533e-03\n",
            " 2.97543183e-03 9.23811693e-03 1.58753049e-03 6.37331727e-04\n",
            " 2.18033116e-03 5.59850454e-04 1.63553760e-03 1.06573060e-03\n",
            " 3.37882084e-03 7.94593310e-03 5.57755738e-05 6.11863621e-04\n",
            " 1.13509049e-03 9.49383000e-03 8.93101948e-03 8.67606627e-03\n",
            " 4.97593250e-03 7.69381631e-03 9.25090918e-03 7.51240495e-03\n",
            " 1.58753049e-03 9.55005417e-03 8.88809945e-03 2.12334353e-03\n",
            " 3.43535202e-03 9.05442465e-03 4.35184876e-03 1.70237149e-03\n",
            " 3.76536445e-03 8.47447756e-03 3.88454526e-03 8.43712005e-03\n",
            " 4.73880356e-04 2.30608961e-03 3.41568784e-03 7.05426160e-03\n",
            " 1.63267479e-04 4.50160645e-03 2.51058352e-03 3.29869062e-03\n",
            " 8.34741551e-03 4.22832199e-03 5.00298064e-04 1.51907791e-03\n",
            " 1.25077891e-03 7.22839206e-03 4.41146015e-03 6.83860839e-04\n",
            " 3.69409855e-03 3.42127585e-04 9.27290418e-03 1.58753049e-03\n",
            " 6.79012070e-03 5.79852980e-03 6.68369772e-03 7.59478911e-03\n",
            " 9.29186970e-03 2.29732593e-03 3.69815989e-03 1.02236331e-03\n",
            " 8.70274468e-03 9.44998397e-03 8.75290371e-03 2.08117946e-04\n",
            " 4.12967593e-03 6.69792509e-03 3.47877549e-03 9.30627275e-03\n",
            " 1.17912931e-03 2.49689867e-03 5.02037879e-04 8.24685231e-03\n",
            " 8.78854377e-03 5.32337657e-03 5.04805717e-03 1.39476848e-03\n",
            " 9.45643094e-03 6.70385904e-03 1.57504328e-04 6.62104660e-03\n",
            " 2.25981032e-03 4.27788085e-03 3.03398321e-03 5.43519097e-03\n",
            " 8.35017141e-03 3.28121209e-03 6.90837656e-03 2.81003714e-03\n",
            " 8.94166143e-03 8.38006292e-03 1.86009311e-03 4.68605549e-04\n",
            " 2.57493332e-03 4.69086592e-03 9.44604739e-03 8.86857820e-03\n",
            " 4.09855017e-03 4.84944675e-04 3.05545233e-03 5.75430176e-03\n",
            " 4.73887706e-03 7.17990357e-03 5.55948024e-03 3.09697928e-04\n",
            " 2.70284991e-03 2.49194346e-03 6.90655771e-03 8.97279810e-03\n",
            " 2.12334353e-03 1.37074843e-03 2.18495189e-03 5.69324089e-03\n",
            " 3.77802875e-03 4.37795785e-03 8.40677255e-04 6.48683142e-03\n",
            " 4.45324175e-03 5.98657335e-03 3.40063231e-03 8.74762812e-03\n",
            " 5.74285311e-03 5.08310533e-03 2.79091888e-03 5.92057825e-03\n",
            " 9.35936233e-04 7.07268417e-04 4.44728993e-03 7.92688620e-04\n",
            " 1.96787325e-04 1.09289966e-03 1.59176099e-03 3.01203577e-03\n",
            " 2.84565527e-03 7.15181130e-05 3.30367240e-03 5.90509583e-03\n",
            " 4.65968589e-03 1.53054187e-06 6.11212044e-04 3.75956939e-07\n",
            " 2.31523572e-05 4.44165944e-05 1.28246822e-03 9.29253406e-04\n",
            " 3.89455790e-03 3.85688269e-03 5.21365443e-03 5.21365443e-03\n",
            " 1.06878198e-03 7.08981096e-03 1.82301325e-03 3.70500478e-03\n",
            " 2.16599828e-04 3.78219545e-04 8.54355432e-03 3.49941682e-03\n",
            " 4.22748587e-03 3.61961055e-03 2.15102762e-04 4.68590080e-03\n",
            " 5.91386204e-03 7.14528326e-03 6.29522363e-03 4.89499902e-03\n",
            " 5.27766566e-03 2.82509009e-03 7.41146261e-03 5.35524314e-03\n",
            " 5.44347138e-03 3.85688269e-03 7.46614791e-03 9.53426936e-03\n",
            " 1.17366248e-03 1.05844883e-03 3.23254999e-03 5.83096634e-03\n",
            " 3.92981593e-03 5.36792142e-04 7.89387062e-03 5.34412621e-03\n",
            " 1.81763630e-03 9.59110553e-04 8.79218989e-03 6.01658107e-03\n",
            " 6.52968557e-03 7.94293086e-03 2.59428752e-03 1.38774047e-03\n",
            " 1.19608711e-03 6.72940135e-03 9.10218188e-03 6.48169712e-03\n",
            " 8.56956361e-03 4.40746201e-03 4.58407945e-03 8.14908793e-03\n",
            " 3.07706647e-03 3.34936088e-03 7.96064059e-03 4.22988319e-04\n",
            " 1.00210073e-03 7.21559498e-03 7.67635451e-03 2.53836511e-03\n",
            " 5.11834833e-03 7.45815579e-03 3.37675535e-04 5.43466522e-03\n",
            " 7.04296238e-03 4.16688046e-03 6.00285283e-03 3.54850034e-03\n",
            " 7.32979317e-03 7.94480993e-03 9.49544942e-03 7.47134946e-03\n",
            " 4.80312739e-03 6.07009787e-03 6.06990613e-03 7.91965509e-04\n",
            " 3.52463419e-03]\n",
            "3740 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[3.00135380e-03 4.24976255e-03 4.27908620e-03 3.46391184e-03\n",
            " 6.83389448e-04 8.37290551e-03 3.67094984e-03 7.54542772e-03\n",
            " 8.35644441e-03 7.62752380e-03 5.36888836e-03 4.84246859e-03\n",
            " 7.69734382e-03 5.71472925e-03 8.48475584e-03 1.43213272e-03\n",
            " 8.88413012e-03 4.09860946e-03 5.59769371e-03 3.85905993e-03\n",
            " 1.16876370e-05 4.44561496e-03 3.34488679e-03 9.34649125e-05\n",
            " 7.33020447e-03 1.86929970e-03 3.60889323e-09 4.08266233e-03\n",
            " 1.50423723e-05 5.72615767e-03 2.94319250e-04 8.33813569e-08\n",
            " 7.51923949e-03 7.34285679e-03 2.84750597e-03 7.00074770e-03\n",
            " 6.05601705e-03 9.18319641e-03 2.37063292e-03 8.72323782e-03\n",
            " 8.80892059e-04 7.46557296e-03 2.37958236e-03 3.21548034e-04\n",
            " 1.07136761e-03 7.58379173e-03 2.89232788e-03 4.08589331e-04\n",
            " 7.94650208e-03 5.24012626e-03 4.36570108e-03 4.38730399e-04\n",
            " 8.68399474e-03 4.25814933e-03 4.20413400e-03 1.22062133e-03\n",
            " 5.84588911e-03 6.58785325e-04 9.54657314e-04 4.82412047e-03\n",
            " 5.57162720e-05 4.12686856e-03 1.73537960e-03 8.00772737e-04\n",
            " 2.34175150e-03 7.45725949e-03 9.30436362e-03 4.36669774e-03\n",
            " 3.67865676e-03 7.09919939e-05 8.54406777e-03 3.26787384e-03\n",
            " 3.67865676e-03 6.20171433e-03 1.10462830e-03 7.29429145e-03\n",
            " 1.27876255e-03 3.12691352e-05 7.89408885e-03 5.43227918e-03\n",
            " 2.93222461e-03 6.19573150e-03 8.96250857e-03 5.73141405e-03\n",
            " 8.04267268e-03 8.90019089e-03 3.60889323e-09 3.63993751e-03\n",
            " 7.73771783e-03 8.07954410e-03 9.89630135e-04 3.69249498e-03\n",
            " 9.15099919e-03 1.97371322e-03 6.71501113e-03 2.33928381e-03\n",
            " 7.88452134e-03 4.29647807e-03 8.34012504e-03 5.95285036e-03\n",
            " 4.67302699e-03 6.24260077e-03 3.05996715e-03 8.35644441e-03\n",
            " 8.49954529e-03 4.76981561e-03 4.25814933e-03 9.00577142e-03\n",
            " 6.58962883e-03 9.14033737e-03 5.39993974e-03 6.75799379e-03\n",
            " 2.33943998e-03 1.98439233e-04 3.56698673e-03 3.98399142e-03\n",
            " 3.78073066e-03 7.20858315e-03 8.41343781e-03 5.18090201e-04\n",
            " 2.79943845e-03 6.33275615e-03 1.27460332e-06 6.69301753e-05\n",
            " 7.16126183e-04 2.83467336e-03 7.60218450e-03 2.89137040e-03\n",
            " 8.54078467e-03 4.74110958e-03 4.31085051e-04 6.25050147e-03\n",
            " 4.82965393e-03 1.19644009e-03 8.24765926e-04 4.85187184e-03\n",
            " 6.79207398e-03 8.16275572e-03 4.70304103e-03 5.70710172e-03\n",
            " 4.08848362e-03 4.82780526e-03 4.98506993e-03 3.01147561e-03\n",
            " 7.80075000e-03 4.25814933e-03 8.00802957e-03 4.05463642e-03\n",
            " 1.24153925e-03 1.70484983e-03 9.24382134e-03 3.48518582e-03\n",
            " 9.27254355e-03 1.37782310e-03 5.00976362e-03 1.03778856e-04\n",
            " 7.24535289e-03 9.79710652e-17 3.34345829e-03 6.42997961e-03\n",
            " 1.89078816e-04 9.12954779e-03 9.27820656e-03 7.46557296e-03\n",
            " 2.85590789e-03 3.69778142e-03 2.92131612e-03 3.26782314e-03\n",
            " 3.24804478e-03 6.12847672e-03 8.01342450e-03 2.01162886e-03\n",
            " 1.95376254e-04 8.38286306e-03 3.97582275e-03 6.73128883e-03\n",
            " 3.49311233e-03 3.47643802e-04 7.56678941e-03 1.86320168e-03\n",
            " 4.11619054e-03 2.98197946e-03 8.83847845e-03 1.66420142e-04\n",
            " 4.22730987e-03 3.00359364e-03 8.30761962e-03 5.28019562e-03\n",
            " 2.95772758e-03 8.28796985e-03 8.66616903e-03 6.53295834e-03\n",
            " 4.93679777e-03 5.71472925e-03 4.38849820e-03 1.62161139e-04\n",
            " 8.90254021e-03 1.67123049e-03 8.13141723e-03 7.15167518e-03\n",
            " 6.42645522e-03 4.12686856e-03 1.97386642e-03 2.89237725e-03\n",
            " 1.60674895e-03 1.33383804e-03 5.06167327e-03 1.89988132e-03\n",
            " 5.39993974e-03 3.64583381e-03 1.11263024e-03 7.05253195e-03\n",
            " 3.00973865e-03 2.91704358e-03 6.06461366e-03 3.49926116e-03\n",
            " 4.24324176e-06 7.89027135e-04 3.48234301e-03 1.28743211e-03\n",
            " 9.09804448e-03 1.20461885e-05 2.05290101e-03 1.88530397e-04\n",
            " 8.54630475e-03 3.87086710e-03 2.96635330e-03 9.22549580e-03\n",
            " 1.58284528e-03 6.37193095e-04 2.17484997e-03 5.59638669e-04\n",
            " 1.63006884e-03 1.06397007e-03 3.36748093e-03 7.93876595e-03\n",
            " 5.57040083e-05 6.09870327e-04 1.13136018e-03 8.90958146e-03\n",
            " 8.67380579e-03 4.97579554e-03 7.68864096e-03 9.23299704e-03\n",
            " 7.50255006e-03 1.58284528e-03 8.87460723e-03 2.11279663e-03\n",
            " 3.43132169e-03 9.04767376e-03 4.35694241e-03 1.69954122e-03\n",
            " 3.75873156e-03 8.46504004e-03 3.88323097e-03 8.42510989e-03\n",
            " 4.73421757e-04 2.30288239e-03 3.40479530e-03 7.02811530e-03\n",
            " 1.62161139e-04 4.49847028e-03 2.50697411e-03 3.28510134e-03\n",
            " 8.33901090e-03 4.21916974e-03 4.97051911e-04 1.51767096e-03\n",
            " 1.24929552e-03 7.22546489e-03 4.41355484e-03 6.83389448e-04\n",
            " 3.67753173e-03 3.39773023e-04 9.26322643e-03 1.58284528e-03\n",
            " 6.78777177e-03 5.79699197e-03 6.67985882e-03 7.57996225e-03\n",
            " 9.29920430e-03 2.29157133e-03 3.68860221e-03 1.01679226e-03\n",
            " 8.70676423e-03 8.74786057e-03 2.07891231e-04 4.12686856e-03\n",
            " 6.68889898e-03 3.48234301e-03 1.17899974e-03 2.48842847e-03\n",
            " 4.99468826e-04 8.24015756e-03 8.78665085e-03 5.32508840e-03\n",
            " 5.04090552e-03 1.38833162e-03 6.70467924e-03 1.57351758e-04\n",
            " 6.61057819e-03 2.25888468e-03 4.27890503e-03 3.02946615e-03\n",
            " 5.43227918e-03 8.32695627e-03 3.26787384e-03 6.89686143e-03\n",
            " 2.80396088e-03 8.90653373e-03 8.36197236e-03 1.85779241e-03\n",
            " 4.68758015e-04 2.56767151e-03 4.69019209e-03 8.86158693e-03\n",
            " 4.09102041e-03 4.81961483e-04 3.04069682e-03 5.74089010e-03\n",
            " 4.73606985e-03 7.16577485e-03 5.54219171e-03 3.08315198e-04\n",
            " 2.69149601e-03 2.47543206e-03 6.90255400e-03 8.96238052e-03\n",
            " 2.11279663e-03 1.36760402e-03 2.18254301e-03 5.67488836e-03\n",
            " 3.77987352e-03 4.36084759e-03 8.38904714e-04 6.47282428e-03\n",
            " 4.45875198e-03 5.96809303e-03 3.39502911e-03 8.71762225e-03\n",
            " 5.73799136e-03 5.07373411e-03 2.78804964e-03 5.91129144e-03\n",
            " 9.29851014e-04 7.06341975e-04 4.44561496e-03 7.92722793e-04\n",
            " 1.95588875e-04 1.08668522e-03 1.58953305e-03 3.00121086e-03\n",
            " 2.84750597e-03 7.13766697e-05 3.29319942e-03 5.89128746e-03\n",
            " 4.65570038e-03 1.51427111e-06 6.09666520e-04 3.71980505e-07\n",
            " 2.31037174e-05 4.41937760e-05 1.28156197e-03 9.28411117e-04\n",
            " 3.88297859e-03 3.85905993e-03 5.20429785e-03 5.20429785e-03\n",
            " 1.06852421e-03 7.08270418e-03 1.81689741e-03 3.70485627e-03\n",
            " 2.16690800e-04 3.77539038e-04 8.51707886e-03 3.48790893e-03\n",
            " 4.21601571e-03 3.61107399e-03 2.13730612e-04 4.68237042e-03\n",
            " 5.90576990e-03 7.14178481e-03 6.28540392e-03 4.89111113e-03\n",
            " 5.28019562e-03 2.82670628e-03 7.41092634e-03 5.34302519e-03\n",
            " 5.43473220e-03 3.85905993e-03 7.46195745e-03 1.16981957e-03\n",
            " 1.05645547e-03 3.22633391e-03 5.83367395e-03 3.92432685e-03\n",
            " 5.35941339e-04 7.89179349e-03 5.33699099e-03 1.81514620e-03\n",
            " 9.57113025e-04 8.79251008e-03 6.01220824e-03 6.52137976e-03\n",
            " 7.94450852e-03 2.59193537e-03 1.37911446e-03 1.19394034e-03\n",
            " 6.70711488e-03 9.09910057e-03 6.47629300e-03 8.55902624e-03\n",
            " 4.40623727e-03 4.56620611e-03 8.14203753e-03 3.06584477e-03\n",
            " 3.33332686e-03 7.94553068e-03 4.21637509e-04 1.00117273e-03\n",
            " 7.20760969e-03 7.66704311e-03 2.53680609e-03 5.11432103e-03\n",
            " 7.44572395e-03 3.37224142e-04 5.41201963e-03 7.03037057e-03\n",
            " 4.15022964e-03 5.99419912e-03 3.54556504e-03 7.32222406e-03\n",
            " 7.92459437e-03 7.47370177e-03 4.79389172e-03 6.06830281e-03\n",
            " 6.06640261e-03 7.89027135e-04 3.51503597e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3750 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.99942966e-03 4.25002023e-03 4.27608938e-03 3.45002923e-03\n",
            " 6.83222699e-04 8.37072866e-03 3.66597367e-03 7.54651163e-03\n",
            " 8.33119566e-03 7.62300192e-03 5.34711204e-03 4.82752821e-03\n",
            " 7.69628839e-03 5.70349179e-03 8.47499410e-03 1.43125460e-03\n",
            " 8.84336332e-03 4.09525812e-03 5.59398072e-03 3.85801270e-03\n",
            " 1.16801656e-05 4.44638512e-03 3.34618270e-03 9.33614529e-05\n",
            " 7.31092967e-03 1.86196638e-03 3.59566496e-09 4.07319158e-03\n",
            " 1.46931221e-05 5.72069775e-03 2.93075900e-04 8.37392370e-08\n",
            " 7.51039252e-03 7.33920798e-03 2.84471488e-03 6.99897837e-03\n",
            " 6.05865037e-03 2.36423830e-03 8.70560430e-03 8.73698228e-04\n",
            " 7.45709791e-03 2.36935363e-03 3.20885507e-04 1.07049241e-03\n",
            " 7.58111212e-03 2.88823765e-03 4.08602454e-04 7.93861574e-03\n",
            " 5.23595025e-03 4.34904403e-03 4.36881942e-04 8.67032383e-03\n",
            " 4.25724313e-03 4.19722572e-03 1.21385692e-03 5.83548414e-03\n",
            " 6.57509448e-04 9.53247990e-04 4.82209496e-03 5.57030685e-05\n",
            " 4.12637188e-03 1.73420135e-03 7.97455137e-04 2.34141899e-03\n",
            " 7.45317538e-03 4.35957345e-03 3.67802286e-03 7.06783113e-05\n",
            " 8.53489170e-03 3.24663009e-03 3.67802286e-03 6.19197623e-03\n",
            " 1.10339104e-03 7.28249560e-03 1.27825812e-03 3.07987121e-05\n",
            " 7.85594648e-03 5.42950520e-03 2.92041601e-03 6.19250772e-03\n",
            " 8.96042982e-03 5.69135546e-03 8.03610247e-03 8.89627993e-03\n",
            " 3.59566496e-09 3.63723969e-03 7.71119973e-03 8.08111581e-03\n",
            " 9.85885359e-04 3.69186341e-03 1.97211440e-03 6.71308608e-03\n",
            " 2.33432849e-03 7.87937367e-03 4.29471399e-03 8.34207256e-03\n",
            " 5.95056502e-03 4.65826304e-03 6.23804891e-03 3.05945114e-03\n",
            " 8.33119566e-03 8.49075343e-03 4.75812376e-03 4.25724313e-03\n",
            " 8.97802899e-03 6.58319402e-03 9.13905030e-03 5.39952504e-03\n",
            " 6.73736595e-03 2.33802809e-03 1.98396071e-04 3.56653387e-03\n",
            " 3.98525926e-03 3.77923530e-03 7.17948677e-03 8.41131078e-03\n",
            " 5.18274628e-04 2.79077328e-03 6.32778328e-03 1.27652942e-06\n",
            " 6.63819148e-05 7.15390499e-04 2.83379165e-03 7.57775134e-03\n",
            " 2.88872887e-03 8.52116033e-03 4.71292843e-03 4.31165633e-04\n",
            " 6.23848773e-03 4.82309912e-03 1.19516130e-03 8.24270599e-04\n",
            " 4.83418090e-03 6.78801649e-03 8.15451554e-03 4.70725415e-03\n",
            " 5.70312025e-03 4.06819165e-03 4.83063840e-03 4.97602593e-03\n",
            " 3.01037912e-03 7.79116258e-03 4.25724313e-03 7.99287557e-03\n",
            " 4.05444085e-03 1.24112838e-03 1.69901396e-03 3.47838795e-03\n",
            " 1.37478521e-03 4.99142116e-03 1.03524850e-04 7.23625588e-03\n",
            " 9.17170118e-17 3.34439293e-03 6.42734867e-03 1.87484958e-04\n",
            " 9.11834880e-03 7.45709791e-03 2.85636124e-03 3.69442257e-03\n",
            " 2.92178543e-03 3.26406380e-03 3.24502977e-03 6.12682972e-03\n",
            " 8.00859467e-03 2.00957701e-03 1.94461251e-04 8.38171825e-03\n",
            " 3.97279978e-03 6.72878713e-03 3.45868125e-03 3.45987184e-04\n",
            " 7.53940592e-03 1.86086883e-03 4.11565674e-03 2.96978955e-03\n",
            " 8.82776832e-03 1.66212412e-04 4.21999393e-03 2.99422468e-03\n",
            " 8.30533730e-03 5.27162105e-03 2.94754447e-03 8.28636497e-03\n",
            " 8.65382424e-03 6.53485213e-03 4.91568125e-03 5.70349179e-03\n",
            " 4.37470336e-03 1.62073579e-04 8.90238250e-03 1.66773483e-03\n",
            " 8.12985585e-03 7.14820069e-03 6.39484644e-03 4.12637188e-03\n",
            " 1.96239361e-03 2.88988369e-03 1.60627157e-03 1.33376168e-03\n",
            " 5.05321587e-03 1.88204321e-03 5.39952504e-03 3.64458436e-03\n",
            " 1.10678373e-03 7.05769023e-03 3.00258242e-03 2.91528437e-03\n",
            " 6.06350186e-03 3.49558210e-03 4.19639144e-06 7.87891253e-04\n",
            " 3.48246572e-03 1.28542615e-03 9.09555450e-03 1.19804448e-05\n",
            " 2.05070785e-03 1.88229668e-04 8.54535715e-03 3.86894775e-03\n",
            " 2.96091422e-03 1.57191649e-03 6.36731792e-04 2.17351136e-03\n",
            " 5.58857618e-04 1.62691706e-03 1.06365748e-03 3.35717557e-03\n",
            " 7.93893445e-03 5.56820817e-05 6.07404316e-04 1.12245549e-03\n",
            " 8.89281389e-03 8.65896089e-03 4.97552560e-03 7.66214317e-03\n",
            " 7.50266004e-03 1.57191649e-03 8.86185379e-03 2.10791643e-03\n",
            " 3.42639431e-03 9.04410533e-03 4.35530529e-03 1.69685194e-03\n",
            " 3.75814156e-03 8.45882961e-03 3.85603927e-03 8.41396353e-03\n",
            " 4.73734968e-04 2.29597817e-03 3.40269845e-03 7.02533609e-03\n",
            " 1.62073579e-04 4.49581320e-03 2.50683362e-03 3.27819578e-03\n",
            " 8.33695987e-03 4.21732100e-03 4.95676732e-04 1.51659222e-03\n",
            " 1.25004602e-03 7.22053344e-03 4.40161990e-03 6.83222699e-04\n",
            " 3.65941309e-03 3.39453009e-04 1.57191649e-03 6.76346441e-03\n",
            " 5.78453723e-03 6.68299615e-03 7.56945889e-03 2.28942999e-03\n",
            " 3.68442668e-03 1.00967364e-03 8.69990197e-03 8.74492941e-03\n",
            " 2.07775810e-04 4.12637188e-03 6.68600700e-03 3.48246572e-03\n",
            " 1.17635809e-03 2.48267095e-03 4.97013865e-04 8.23784085e-03\n",
            " 8.78146160e-03 5.31699643e-03 5.02642177e-03 1.38550510e-03\n",
            " 6.70375782e-03 1.57284130e-04 6.60960853e-03 2.24941468e-03\n",
            " 4.27483501e-03 3.03123180e-03 5.42950520e-03 8.32818568e-03\n",
            " 3.24663009e-03 6.89609692e-03 2.77795404e-03 8.89224769e-03\n",
            " 8.35681749e-03 1.85562854e-03 4.63817623e-04 2.56304393e-03\n",
            " 4.68745980e-03 8.85722197e-03 4.08633061e-03 4.79334326e-04\n",
            " 3.03673269e-03 5.73613321e-03 4.71731591e-03 7.15948796e-03\n",
            " 5.54034391e-03 3.07740487e-04 2.68830211e-03 2.46995123e-03\n",
            " 6.90271809e-03 8.92828354e-03 2.10791643e-03 1.36595293e-03\n",
            " 2.18072246e-03 5.66484782e-03 3.77907023e-03 4.35354262e-03\n",
            " 8.38118515e-04 6.46835202e-03 4.45403715e-03 5.94451845e-03\n",
            " 3.38858185e-03 8.71239160e-03 5.73824394e-03 5.07309945e-03\n",
            " 2.78621553e-03 5.90361302e-03 9.29396546e-04 7.05374879e-04\n",
            " 4.44638512e-03 7.84479949e-04 1.94759929e-04 1.08478326e-03\n",
            " 1.59068979e-03 2.99628246e-03 2.84471488e-03 7.06100826e-05\n",
            " 3.29219383e-03 5.89220450e-03 4.63754696e-03 1.51152403e-06\n",
            " 6.08327887e-04 3.67208297e-07 2.29213574e-05 4.42018458e-05\n",
            " 1.27650767e-03 9.28215892e-04 3.86895592e-03 3.85801270e-03\n",
            " 5.20280250e-03 5.20280250e-03 1.06752582e-03 7.08287023e-03\n",
            " 1.81340578e-03 3.70108267e-03 2.13254623e-04 3.75290081e-04\n",
            " 8.53044442e-03 3.47870915e-03 4.20994620e-03 3.61256490e-03\n",
            " 2.13358718e-04 4.67178719e-03 5.90505019e-03 7.13986055e-03\n",
            " 6.27589289e-03 4.88561937e-03 5.27162105e-03 2.81428456e-03\n",
            " 7.41229446e-03 5.34516738e-03 5.42156666e-03 3.85801270e-03\n",
            " 7.45013959e-03 1.16790154e-03 1.05631232e-03 3.22091003e-03\n",
            " 5.82901052e-03 3.91609408e-03 5.29679420e-04 7.88874340e-03\n",
            " 5.33459208e-03 1.80259244e-03 9.50104602e-04 8.77991103e-03\n",
            " 6.00944011e-03 6.50108597e-03 7.91911574e-03 2.57777517e-03\n",
            " 1.37709559e-03 1.19091076e-03 6.69420044e-03 9.10093458e-03\n",
            " 6.45237070e-03 8.55943472e-03 4.40655429e-03 4.55970464e-03\n",
            " 8.11111633e-03 3.06236197e-03 3.33272181e-03 7.92896591e-03\n",
            " 4.20886571e-04 1.00099982e-03 7.21603045e-03 7.65984103e-03\n",
            " 2.52716719e-03 5.10264419e-03 7.43004476e-03 3.34816529e-04\n",
            " 5.41372354e-03 7.02793843e-03 4.14511663e-03 5.97773235e-03\n",
            " 3.54451609e-03 7.30650554e-03 7.91797133e-03 7.46734487e-03\n",
            " 4.79186711e-03 6.06119264e-03 6.06457166e-03 7.87891253e-04\n",
            " 3.50565791e-03]\n",
            "3760 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1240\n",
            "           1       0.85      0.97      0.91       153\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.99457746e-03 4.24884524e-03 4.27231353e-03 3.44261764e-03\n",
            " 6.82955939e-04 8.35280990e-03 3.65714885e-03 7.53434860e-03\n",
            " 8.31775922e-03 7.60864389e-03 5.33229803e-03 4.82401629e-03\n",
            " 7.69638147e-03 5.70171788e-03 8.45181736e-03 1.42764295e-03\n",
            " 8.83419809e-03 4.08845169e-03 5.58830300e-03 3.85575664e-03\n",
            " 1.16679323e-05 4.44346163e-03 3.34151674e-03 9.29146908e-05\n",
            " 7.29686125e-03 1.85967963e-03 3.57828298e-09 4.06769001e-03\n",
            " 1.45875420e-05 5.72182086e-03 2.92457680e-04 8.23601245e-08\n",
            " 7.50492406e-03 7.33238038e-03 2.84336106e-03 6.98028791e-03\n",
            " 6.05678211e-03 2.35908087e-03 8.69415468e-03 8.70392641e-04\n",
            " 7.45782184e-03 2.35265002e-03 3.19419433e-04 1.06965500e-03\n",
            " 7.56715058e-03 2.88112897e-03 4.09111293e-04 7.93868132e-03\n",
            " 5.21910532e-03 4.33632394e-03 4.36344843e-04 8.67251820e-03\n",
            " 4.25529079e-03 4.18130864e-03 1.21114322e-03 5.82798124e-03\n",
            " 6.56155902e-04 9.49147181e-04 4.81293843e-03 5.56555146e-05\n",
            " 4.12289345e-03 1.72777461e-03 7.94092143e-04 2.34255441e-03\n",
            " 7.44842189e-03 4.36042895e-03 3.67568418e-03 7.04489807e-05\n",
            " 8.52293458e-03 3.23475906e-03 3.67568418e-03 6.19293829e-03\n",
            " 1.10259561e-03 7.27698741e-03 1.27572856e-03 3.05561627e-05\n",
            " 7.84609878e-03 5.42702171e-03 2.91582480e-03 6.18965876e-03\n",
            " 5.67900907e-03 8.02752040e-03 3.57828298e-09 3.62529132e-03\n",
            " 7.70293465e-03 8.07208987e-03 9.82632500e-04 3.68963769e-03\n",
            " 1.96502972e-03 6.71636721e-03 2.32654071e-03 7.87392089e-03\n",
            " 4.29408563e-03 8.31198707e-03 5.94429745e-03 4.64818819e-03\n",
            " 6.24323121e-03 3.05780393e-03 8.31775922e-03 8.49447242e-03\n",
            " 4.76036688e-03 4.25529079e-03 6.57002684e-03 5.40026004e-03\n",
            " 6.72571848e-03 2.33785691e-03 1.98270375e-04 3.56009194e-03\n",
            " 3.98343256e-03 3.77376427e-03 7.16884652e-03 8.40606958e-03\n",
            " 5.18409685e-04 2.77725452e-03 6.32111481e-03 1.28225994e-06\n",
            " 6.63680740e-05 7.13360269e-04 2.82424686e-03 7.56843498e-03\n",
            " 2.88494358e-03 8.50586938e-03 4.71161586e-03 4.30803400e-04\n",
            " 6.23185791e-03 4.81643637e-03 1.19422849e-03 8.22011667e-04\n",
            " 4.82343074e-03 6.77771964e-03 8.13948225e-03 4.70692184e-03\n",
            " 5.69880614e-03 4.06411809e-03 4.82311585e-03 4.97053740e-03\n",
            " 2.99780104e-03 7.78909518e-03 4.25529079e-03 7.98229085e-03\n",
            " 4.05555514e-03 1.23923285e-03 1.69708165e-03 3.46609083e-03\n",
            " 1.37156579e-03 4.97494572e-03 1.03457421e-04 7.23714262e-03\n",
            " 8.92705618e-17 3.34264637e-03 6.42377114e-03 1.86367688e-04\n",
            " 7.45782184e-03 2.85104069e-03 3.68929583e-03 2.92554639e-03\n",
            " 3.26119226e-03 3.24079197e-03 6.12591227e-03 7.99851066e-03\n",
            " 2.00192260e-03 1.93772935e-04 8.37253863e-03 3.96797083e-03\n",
            " 6.71175091e-03 3.44668253e-03 3.44590972e-04 7.53063538e-03\n",
            " 1.86069896e-03 4.10854548e-03 2.95840885e-03 8.81725869e-03\n",
            " 1.65738154e-04 4.21106765e-03 2.99004336e-03 8.27659869e-03\n",
            " 5.26838043e-03 2.94457916e-03 8.28067883e-03 8.64117246e-03\n",
            " 6.54470679e-03 4.90671659e-03 5.70171788e-03 4.36773907e-03\n",
            " 1.61889983e-04 1.66023890e-03 8.11575255e-03 7.13908030e-03\n",
            " 6.37598118e-03 4.12289345e-03 1.95843206e-03 2.86840618e-03\n",
            " 1.60512011e-03 1.33383343e-03 5.05290465e-03 1.87744508e-03\n",
            " 5.40026004e-03 3.63831812e-03 1.09726607e-03 7.04765181e-03\n",
            " 3.00307100e-03 2.91108193e-03 6.04952292e-03 3.49004793e-03\n",
            " 4.16885868e-06 7.86321086e-04 3.47759712e-03 1.28082572e-03\n",
            " 1.19591299e-05 2.04640464e-03 1.88003628e-04 8.52410565e-03\n",
            " 3.86798237e-03 2.95365646e-03 1.56835923e-03 6.33695651e-04\n",
            " 2.16887652e-03 5.58301439e-04 1.62495197e-03 1.06189885e-03\n",
            " 3.35565834e-03 7.93494103e-03 5.56131898e-05 6.06441204e-04\n",
            " 1.11673731e-03 8.86427891e-03 8.66098267e-03 4.95755948e-03\n",
            " 7.63905728e-03 7.50411183e-03 1.56835923e-03 8.85216220e-03\n",
            " 2.10601309e-03 3.41593285e-03 4.35389323e-03 1.69549520e-03\n",
            " 3.74745328e-03 8.45500567e-03 3.84628090e-03 8.41160784e-03\n",
            " 4.73922030e-04 2.28980363e-03 3.38498895e-03 7.00942391e-03\n",
            " 1.61889983e-04 4.49531311e-03 2.49461552e-03 3.27506873e-03\n",
            " 8.32891799e-03 4.21601877e-03 4.94431018e-04 1.51613890e-03\n",
            " 1.24810546e-03 7.22026208e-03 4.40240767e-03 6.82955939e-04\n",
            " 3.64831068e-03 3.38574806e-04 1.56835923e-03 6.75198184e-03\n",
            " 5.77455297e-03 6.68374820e-03 7.56224389e-03 2.28452706e-03\n",
            " 3.67790482e-03 1.00428247e-03 8.69067271e-03 8.73387752e-03\n",
            " 2.07567123e-04 4.12289345e-03 6.67255367e-03 3.47759712e-03\n",
            " 1.17450529e-03 2.47549783e-03 4.97080740e-04 8.22477381e-03\n",
            " 8.75750260e-03 5.31065342e-03 5.02266525e-03 1.38309088e-03\n",
            " 6.70232622e-03 1.57080180e-04 6.60116872e-03 2.24531355e-03\n",
            " 4.27502777e-03 3.02427710e-03 5.42702171e-03 8.31165915e-03\n",
            " 3.23475906e-03 6.88885618e-03 2.76752544e-03 8.86792396e-03\n",
            " 8.35447156e-03 1.85325856e-03 4.62180218e-04 2.54377864e-03\n",
            " 4.68497718e-03 8.84991332e-03 4.07487965e-03 4.77100684e-04\n",
            " 3.02495140e-03 5.71404040e-03 4.70209839e-03 7.15462922e-03\n",
            " 5.52839226e-03 3.07365042e-04 2.67374776e-03 2.46308090e-03\n",
            " 6.89744019e-03 2.10601309e-03 1.36518891e-03 2.17998905e-03\n",
            " 5.66292240e-03 3.77826366e-03 4.34190806e-03 8.31508768e-04\n",
            " 6.45707115e-03 4.43027219e-03 5.93969699e-03 3.38174159e-03\n",
            " 8.71511398e-03 5.73062074e-03 5.07081597e-03 2.78389973e-03\n",
            " 5.89910173e-03 9.26412446e-04 7.05167133e-04 4.44346163e-03\n",
            " 7.80254102e-04 1.93087421e-04 1.08392699e-03 1.58917789e-03\n",
            " 2.97542097e-03 2.84336106e-03 7.02463312e-05 3.28489736e-03\n",
            " 5.87127206e-03 4.62322852e-03 1.49868241e-06 6.07821638e-04\n",
            " 3.66318236e-07 2.28391080e-05 4.41201013e-05 1.27373974e-03\n",
            " 9.28133310e-04 3.86445035e-03 3.85575664e-03 5.19894060e-03\n",
            " 5.19894060e-03 1.06648588e-03 7.06153249e-03 1.81250453e-03\n",
            " 3.70367688e-03 2.11555483e-04 3.74740336e-04 8.53114322e-03\n",
            " 3.45286370e-03 4.20872505e-03 3.60515881e-03 2.12751077e-04\n",
            " 4.67410726e-03 5.90007148e-03 7.12574248e-03 6.27822337e-03\n",
            " 4.88486035e-03 5.26838043e-03 2.80752524e-03 7.40923889e-03\n",
            " 5.32468734e-03 5.42111690e-03 3.85575664e-03 7.43311827e-03\n",
            " 1.16567082e-03 1.05341449e-03 3.20505499e-03 5.82728215e-03\n",
            " 3.90372594e-03 5.27247348e-04 7.87620433e-03 5.31240496e-03\n",
            " 1.79810065e-03 9.45201028e-04 8.76409860e-03 6.00290629e-03\n",
            " 6.48129019e-03 7.90086609e-03 2.56849635e-03 1.37611106e-03\n",
            " 1.18894647e-03 6.68329993e-03 6.44607235e-03 8.56399931e-03\n",
            " 4.40272564e-03 4.54894131e-03 8.10291890e-03 3.05525678e-03\n",
            " 3.33284156e-03 7.92586507e-03 4.20155963e-04 1.00091687e-03\n",
            " 7.21542841e-03 7.65122097e-03 2.52232812e-03 5.10118024e-03\n",
            " 7.42686112e-03 3.34282729e-04 5.40868966e-03 7.01863203e-03\n",
            " 4.13473394e-03 5.97690254e-03 3.54293252e-03 7.31234817e-03\n",
            " 7.86810431e-03 7.44841145e-03 4.78686337e-03 6.04410444e-03\n",
            " 6.06340933e-03 7.86321086e-04 3.50280941e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3770 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.68135079e-03 4.15682157e-03 3.99498281e-03 3.19939443e-03\n",
            " 7.10613851e-04 1.35163077e-02 4.32829925e-03 6.65460498e-03\n",
            " 7.64133101e-03 7.81783982e-03 4.85137781e-03 7.33155070e-03\n",
            " 6.88466017e-03 5.42310537e-03 1.09089339e-02 1.39231775e-03\n",
            " 4.28819188e-03 5.75526928e-03 4.23302011e-03 1.39411538e-05\n",
            " 4.54734668e-03 3.15830014e-03 1.29891397e-04 9.12050998e-03\n",
            " 1.81749201e-03 8.81765993e-09 4.45805888e-03 1.24099438e-05\n",
            " 5.84415934e-03 3.47447344e-04 7.53368151e-07 7.30228351e-03\n",
            " 7.12948575e-03 3.18464875e-03 1.02897945e-02 5.78528032e-03\n",
            " 2.91356897e-03 8.77104852e-03 1.06978533e-03 7.52156303e-03\n",
            " 2.95727398e-03 2.76215935e-04 1.09886290e-03 9.50023374e-03\n",
            " 2.41905511e-03 4.08724416e-04 8.19983830e-03 6.71215105e-03\n",
            " 4.97796880e-03 3.83946909e-04 9.18405786e-03 3.69193349e-03\n",
            " 3.28341757e-03 1.00142765e-03 8.28590576e-03 5.94963757e-04\n",
            " 9.45663835e-04 5.21237433e-03 6.25868570e-05 4.24510990e-03\n",
            " 2.09335777e-03 1.83252179e-03 2.29954651e-03 7.79426032e-03\n",
            " 4.93587271e-03 3.24597055e-03 1.02036478e-04 9.92090312e-03\n",
            " 2.98274102e-03 3.24597055e-03 6.60620996e-03 1.20460177e-03\n",
            " 7.16112654e-03 1.59776959e-03 4.47155387e-05 9.65922390e-03\n",
            " 3.39427479e-03 2.81713773e-03 5.70236232e-03 4.94639605e-03\n",
            " 7.70967868e-03 8.81765993e-09 6.16294155e-03 6.42905817e-03\n",
            " 7.52684589e-03 1.24781365e-03 4.02120501e-03 1.95703345e-03\n",
            " 5.99972850e-03 2.03600430e-03 8.66061448e-03 4.62520027e-03\n",
            " 7.12306446e-03 6.06798927e-03 6.06810639e-03 5.34591979e-03\n",
            " 3.02433717e-03 7.64133101e-03 8.27425711e-03 4.41664060e-03\n",
            " 3.69193349e-03 7.58770802e-03 5.50250251e-03 6.14161914e-03\n",
            " 1.97005218e-03 1.91524967e-04 4.20429777e-03 6.64524224e-03\n",
            " 3.83571683e-03 8.71960240e-03 8.02407740e-03 6.67566158e-04\n",
            " 3.23587928e-03 6.32595483e-03 7.92792025e-07 6.54419028e-05\n",
            " 6.62623780e-04 3.01498274e-03 7.01314076e-03 2.74226849e-03\n",
            " 8.71637799e-03 6.22406783e-03 3.60023816e-04 7.49632281e-03\n",
            " 5.15388294e-03 1.72215141e-03 1.04577691e-03 4.64297873e-03\n",
            " 5.85932026e-03 9.63671674e-03 5.24177098e-03 7.02201010e-03\n",
            " 4.27558679e-03 5.01349663e-03 6.02170617e-03 3.15040925e-03\n",
            " 7.61495291e-03 3.69193349e-03 9.39607570e-03 3.56168662e-03\n",
            " 1.10309164e-03 1.43888142e-03 6.36716488e-03 2.31610142e-03\n",
            " 5.55958276e-03 2.19071531e-04 7.71650076e-03 5.75503245e-17\n",
            " 3.92368197e-03 7.05442539e-03 2.56831192e-04 7.52156303e-03\n",
            " 2.32142855e-03 3.68537041e-03 3.12814553e-03 3.11209041e-03\n",
            " 3.11921646e-03 5.59842663e-03 6.73772711e-03 1.87065844e-03\n",
            " 2.37842333e-04 7.71219221e-03 3.76661766e-03 7.37199321e-03\n",
            " 3.56903409e-03 2.93066876e-04 7.07544045e-03 1.65815776e-03\n",
            " 4.07820163e-03 2.45482442e-03 1.71240959e-04 5.03265141e-03\n",
            " 3.43189708e-03 7.06516178e-03 4.51862212e-03 2.63876205e-03\n",
            " 8.01258536e-03 6.78085669e-03 6.17611434e-03 5.32032337e-03\n",
            " 5.42310537e-03 4.18660614e-03 2.31192942e-04 2.11198163e-03\n",
            " 7.80209123e-03 8.42755320e-03 6.86570399e-03 4.24510990e-03\n",
            " 1.74388364e-03 2.51923491e-03 1.57308687e-03 1.35259546e-03\n",
            " 5.03570927e-03 2.40401908e-03 5.50250251e-03 3.72181462e-03\n",
            " 2.15897412e-03 6.26902091e-03 3.54569764e-03 3.03231416e-03\n",
            " 5.67012384e-03 3.27981136e-03 3.18574076e-06 1.22427942e-03\n",
            " 3.04826598e-03 1.34269170e-03 1.32433950e-05 2.16631071e-03\n",
            " 2.16114825e-04 9.92647186e-03 3.65861792e-03 2.56971453e-03\n",
            " 1.32408712e-03 5.73083417e-04 2.48385599e-03 1.10097913e-03\n",
            " 1.76581070e-03 1.10397169e-03 3.82739602e-03 7.96298394e-03\n",
            " 5.77465633e-05 6.60100988e-04 1.42082897e-03 9.99468268e-03\n",
            " 6.06679134e-03 9.15591216e-03 7.01741587e-03 1.32408712e-03\n",
            " 2.69627932e-03 3.79752346e-03 4.28399943e-03 2.00852447e-03\n",
            " 4.79563204e-03 1.04340825e-02 3.65161932e-03 7.74585514e-03\n",
            " 3.70399825e-04 3.88480693e-03 3.16027923e-03 7.52679580e-03\n",
            " 2.31192942e-04 4.23099357e-03 6.02057530e-03 3.44931502e-03\n",
            " 7.81271755e-03 3.96430416e-03 5.37348322e-04 1.64206577e-03\n",
            " 1.28282463e-03 9.81447801e-03 4.38483326e-03 7.10613851e-04\n",
            " 3.53105813e-03 2.91761070e-04 1.32408712e-03 6.13990895e-03\n",
            " 5.19470220e-03 6.49621832e-03 6.43190278e-03 2.35327423e-03\n",
            " 3.41147713e-03 1.99412715e-03 7.94824867e-03 2.12675794e-04\n",
            " 4.24510990e-03 7.64895744e-03 3.04826598e-03 1.27024465e-03\n",
            " 4.91572171e-03 6.57705230e-04 7.51596996e-03 5.45753301e-03\n",
            " 5.29061461e-03 1.20047694e-03 5.91393726e-03 1.77014990e-04\n",
            " 6.07184740e-03 2.22293897e-03 4.50285528e-03 2.83889020e-03\n",
            " 3.39427479e-03 7.99524556e-03 2.98274102e-03 6.13390413e-03\n",
            " 4.02042597e-03 1.08414635e-02 2.11983712e-03 4.32238355e-04\n",
            " 2.56351380e-03 4.52496040e-03 4.00207754e-03 6.55802702e-04\n",
            " 2.49739412e-03 7.23320046e-03 5.90675648e-03 6.62505680e-03\n",
            " 9.30931677e-03 5.01635766e-04 3.46836410e-03 2.40694410e-03\n",
            " 6.40753704e-03 2.69627932e-03 1.00498629e-03 2.09490724e-03\n",
            " 5.10397363e-03 3.84809322e-03 3.89971776e-03 1.24334647e-03\n",
            " 6.93891512e-03 3.98967903e-03 6.77098045e-03 3.15566082e-03\n",
            " 6.59445485e-03 4.73223984e-03 3.01339891e-03 6.52175647e-03\n",
            " 9.49087207e-04 5.88197267e-04 4.54734668e-03 7.55803713e-04\n",
            " 3.21142182e-04 1.04735117e-03 1.89361867e-03 7.10876553e-03\n",
            " 3.18464875e-03 7.71915550e-05 6.28154520e-03 5.79788104e-03\n",
            " 6.66405869e-03 3.49677382e-06 5.93789953e-04 6.23603468e-06\n",
            " 1.86267384e-05 4.16002181e-05 1.16603128e-03 9.88075697e-04\n",
            " 4.31352267e-03 4.23302011e-03 5.35255316e-03 5.35255316e-03\n",
            " 1.10835678e-03 8.48408077e-03 2.14097889e-03 3.75882316e-03\n",
            " 2.26056526e-04 4.03317871e-04 1.50502366e-02 5.79687473e-03\n",
            " 5.38304582e-03 2.68362886e-03 1.68966343e-04 6.01742143e-03\n",
            " 5.60799889e-03 5.95939792e-03 6.31203292e-03 5.37928577e-03\n",
            " 4.51862212e-03 2.93392986e-03 5.89763430e-03 5.80676563e-03\n",
            " 8.62074314e-03 4.23302011e-03 7.15996058e-03 1.30581559e-03\n",
            " 1.33150444e-03 4.85889003e-03 5.20417861e-03 3.52581476e-03\n",
            " 7.11655154e-04 8.15005816e-03 5.71042858e-03 2.01328400e-03\n",
            " 1.19618951e-03 5.16298388e-03 6.06802603e-03 7.30581798e-03\n",
            " 3.11876965e-03 1.29179106e-03 1.57449166e-03 6.45346885e-03\n",
            " 7.00714951e-03 7.54506200e-03 3.86877022e-03 4.10480548e-03\n",
            " 8.80915134e-03 3.29936661e-03 3.35955858e-03 9.68580456e-03\n",
            " 3.53184808e-04 1.06275402e-03 7.25066049e-03 8.08145968e-03\n",
            " 2.49837951e-03 5.95551675e-03 8.15664995e-03 2.96176859e-04\n",
            " 4.81835845e-03 6.52384782e-03 1.09376017e-02 8.11466565e-03\n",
            " 3.00895333e-03 7.36355441e-03 8.16442024e-03 6.29832415e-03\n",
            " 4.54980876e-03 5.73709459e-03 5.97011278e-03 1.22427942e-03\n",
            " 5.79457680e-03]\n",
            "3780 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.68609392e-03 4.14465232e-03 3.99319628e-03 3.19571234e-03\n",
            " 7.09166757e-04 4.31498508e-03 6.65528299e-03 7.64268162e-03\n",
            " 7.78934510e-03 4.85402983e-03 7.33364481e-03 6.88325879e-03\n",
            " 5.42046017e-03 1.38529379e-03 4.28663531e-03 5.74753280e-03\n",
            " 4.23443249e-03 1.38898897e-05 4.54768777e-03 3.14867566e-03\n",
            " 1.28981471e-04 9.09010224e-03 1.81417994e-03 8.66706624e-09\n",
            " 4.44395207e-03 1.24285478e-05 5.83535175e-03 3.46311808e-04\n",
            " 7.46487520e-07 7.29171063e-03 7.11281006e-03 3.18567618e-03\n",
            " 5.78761973e-03 2.90577014e-03 8.74692592e-03 1.06396520e-03\n",
            " 7.50964836e-03 2.94535329e-03 2.75007884e-04 1.09789440e-03\n",
            " 9.48657338e-03 2.39918890e-03 4.08296686e-04 8.18165030e-03\n",
            " 6.68231294e-03 4.96525215e-03 3.83498587e-04 9.16844906e-03\n",
            " 3.68540991e-03 3.28049301e-03 1.00025122e-03 8.22417095e-03\n",
            " 5.94526310e-04 9.42790590e-04 5.21153199e-03 6.23294943e-05\n",
            " 4.24351613e-03 2.08769747e-03 1.82585203e-03 2.29900106e-03\n",
            " 7.76716733e-03 4.92493685e-03 3.23947507e-03 1.01700553e-04\n",
            " 2.96472748e-03 3.23947507e-03 6.59776663e-03 1.20295257e-03\n",
            " 7.15583322e-03 1.59261733e-03 4.45754548e-05 9.65678405e-03\n",
            " 3.39877498e-03 2.81770062e-03 5.70413896e-03 4.94370252e-03\n",
            " 7.70489490e-03 8.66706624e-09 6.13517837e-03 6.39881334e-03\n",
            " 7.51668530e-03 1.24257994e-03 4.01089052e-03 1.95692091e-03\n",
            " 5.96375749e-03 2.03356781e-03 8.65947188e-03 4.61688009e-03\n",
            " 7.12222467e-03 6.06277637e-03 6.06246471e-03 5.33984635e-03\n",
            " 3.02317984e-03 7.64268162e-03 8.26430487e-03 4.40869298e-03\n",
            " 3.68540991e-03 7.58418839e-03 5.49709262e-03 6.14179281e-03\n",
            " 1.97027750e-03 1.90914181e-04 4.19585509e-03 6.63142998e-03\n",
            " 3.82663576e-03 8.69839269e-03 8.01150517e-03 6.63811826e-04\n",
            " 3.22892577e-03 6.31871613e-03 7.87774962e-07 6.52745127e-05\n",
            " 6.61028076e-04 3.00925316e-03 7.01397971e-03 2.72727749e-03\n",
            " 8.71792196e-03 6.20409875e-03 3.58847048e-04 7.48212843e-03\n",
            " 5.13884567e-03 1.71456915e-03 1.04170696e-03 4.64231135e-03\n",
            " 5.85942037e-03 9.61851330e-03 5.24062987e-03 7.00555902e-03\n",
            " 4.27347102e-03 4.99578141e-03 6.00579372e-03 3.13883341e-03\n",
            " 7.60759861e-03 3.68540991e-03 9.35311025e-03 3.55794208e-03\n",
            " 1.10159361e-03 1.43986450e-03 6.31921212e-03 2.30069197e-03\n",
            " 5.55264646e-03 2.18135047e-04 7.72092975e-03 5.74548070e-17\n",
            " 3.91679530e-03 7.04375533e-03 2.56220922e-04 7.50964836e-03\n",
            " 2.32047971e-03 3.68019930e-03 3.12044978e-03 3.10953470e-03\n",
            " 3.10443282e-03 5.59532607e-03 6.73330839e-03 1.87087468e-03\n",
            " 2.36674769e-04 7.69821917e-03 3.76305376e-03 7.36173920e-03\n",
            " 3.57160732e-03 2.93052287e-04 7.07403685e-03 1.65645252e-03\n",
            " 4.06138699e-03 2.44818887e-03 1.70729786e-04 5.02672374e-03\n",
            " 3.42485464e-03 7.05850294e-03 4.51273293e-03 2.63262109e-03\n",
            " 8.00520329e-03 6.75614744e-03 6.18046287e-03 5.31819169e-03\n",
            " 5.42046017e-03 4.18515686e-03 2.29229188e-04 2.10890548e-03\n",
            " 7.79032004e-03 8.41417300e-03 6.86053644e-03 4.24351613e-03\n",
            " 1.74615667e-03 2.50975141e-03 1.57192183e-03 1.35215565e-03\n",
            " 5.02849687e-03 2.39893231e-03 5.49709262e-03 3.71686934e-03\n",
            " 2.14608697e-03 6.26283816e-03 3.53507337e-03 3.02824155e-03\n",
            " 5.66337324e-03 3.27446542e-03 3.18140724e-06 1.22092742e-03\n",
            " 3.05369674e-03 1.34072392e-03 1.31909773e-05 2.16083428e-03\n",
            " 2.15816484e-04 3.64964475e-03 2.56814531e-03 1.32336277e-03\n",
            " 5.70570602e-04 2.47662452e-03 1.09611315e-03 1.75647886e-03\n",
            " 1.10042022e-03 3.82353218e-03 7.95578027e-03 5.77100292e-05\n",
            " 6.57827986e-04 1.41533594e-03 6.05316900e-03 9.14843911e-03\n",
            " 7.00854122e-03 1.32336277e-03 2.68777086e-03 3.79337617e-03\n",
            " 4.27667817e-03 2.00430353e-03 4.77210619e-03 3.65095389e-03\n",
            " 7.74110847e-03 3.69122800e-04 3.88179384e-03 3.14292727e-03\n",
            " 7.50215653e-03 2.29229188e-04 4.22299646e-03 6.00652003e-03\n",
            " 3.45148514e-03 7.80628282e-03 3.95497438e-03 5.34544855e-04\n",
            " 1.63990543e-03 1.28285807e-03 9.80496293e-03 4.36672521e-03\n",
            " 7.09166757e-04 3.52591970e-03 2.90091158e-04 1.32336277e-03\n",
            " 6.13443877e-03 5.19711652e-03 6.49434629e-03 6.42834893e-03\n",
            " 2.34644239e-03 3.39924146e-03 1.98966488e-03 7.93020894e-03\n",
            " 2.12154987e-04 4.24351613e-03 7.63724991e-03 3.05369674e-03\n",
            " 1.27015481e-03 4.89641884e-03 6.57386885e-04 7.51297868e-03\n",
            " 5.45659081e-03 5.26885148e-03 1.19870592e-03 5.91377094e-03\n",
            " 1.76566308e-04 6.05784983e-03 2.22275992e-03 4.49395072e-03\n",
            " 2.83569911e-03 3.39877498e-03 7.98910191e-03 2.96472748e-03\n",
            " 6.13383550e-03 4.02171376e-03 2.11408796e-03 4.32194310e-04\n",
            " 2.55881529e-03 4.52270097e-03 3.99609669e-03 6.52910998e-04\n",
            " 2.48189206e-03 7.20805524e-03 5.90982449e-03 6.61574031e-03\n",
            " 9.28751433e-03 4.99339046e-04 3.46333419e-03 2.40087435e-03\n",
            " 6.40591352e-03 2.68777086e-03 1.00193895e-03 2.08912308e-03\n",
            " 5.09439130e-03 3.84758152e-03 3.88588224e-03 1.23776254e-03\n",
            " 6.93246470e-03 3.99188993e-03 6.76518149e-03 3.14732464e-03\n",
            " 6.58826008e-03 4.71460956e-03 3.00774521e-03 6.51065033e-03\n",
            " 9.47579712e-04 5.87260748e-04 4.54768777e-03 7.55391037e-04\n",
            " 3.19673400e-04 1.04611460e-03 1.89363396e-03 7.08274656e-03\n",
            " 3.18567618e-03 7.71758658e-05 6.24348269e-03 5.76964540e-03\n",
            " 6.66533928e-03 3.45677274e-06 5.90322457e-04 6.14179368e-06\n",
            " 1.85938833e-05 4.14021843e-05 1.16412599e-03 9.87290027e-04\n",
            " 4.30936372e-03 4.23443249e-03 5.34437075e-03 5.34437075e-03\n",
            " 1.10673921e-03 8.47482249e-03 2.13751106e-03 3.75358498e-03\n",
            " 2.26394945e-04 4.02792886e-04 5.78743820e-03 5.36529229e-03\n",
            " 2.66996841e-03 1.68692456e-04 6.01221341e-03 5.59900201e-03\n",
            " 5.94663456e-03 6.29163477e-03 5.37493882e-03 4.51273293e-03\n",
            " 2.92811604e-03 5.88960930e-03 5.78448050e-03 8.55510688e-03\n",
            " 4.23443249e-03 7.13497618e-03 1.30391212e-03 1.33178526e-03\n",
            " 4.84810769e-03 5.21027381e-03 3.51568778e-03 7.10470116e-04\n",
            " 8.14504465e-03 5.70335890e-03 2.00926612e-03 1.19296530e-03\n",
            " 5.15572069e-03 6.06620816e-03 7.30543715e-03 3.11735491e-03\n",
            " 1.28912728e-03 1.56809701e-03 6.42267608e-03 6.99180756e-03\n",
            " 7.54370582e-03 3.86018833e-03 4.09788708e-03 8.80549297e-03\n",
            " 3.29303535e-03 3.35818770e-03 9.66844429e-03 3.52310290e-04\n",
            " 1.06194384e-03 7.25113010e-03 8.06271747e-03 2.49477549e-03\n",
            " 5.95389905e-03 8.15383568e-03 2.95792193e-04 4.80995448e-03\n",
            " 6.50920887e-03 8.10141676e-03 3.00488614e-03 7.35946864e-03\n",
            " 8.15293260e-03 6.28848150e-03 4.54173302e-03 5.72267105e-03\n",
            " 5.96049317e-03 1.22092742e-03 5.79492989e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3790 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.68364344e-03 4.14562458e-03 3.98855259e-03 3.18596384e-03\n",
            " 7.09573752e-04 4.31649864e-03 6.65218436e-03 7.63074868e-03\n",
            " 7.77600173e-03 4.85143741e-03 7.30942220e-03 6.88124614e-03\n",
            " 5.41894967e-03 1.38396256e-03 4.27128167e-03 5.74414584e-03\n",
            " 4.23490500e-03 1.38801986e-05 4.54336707e-03 3.15023639e-03\n",
            " 1.28754757e-04 1.81128942e-03 8.53010481e-09 4.43764239e-03\n",
            " 1.22922299e-05 5.81734608e-03 3.44985582e-04 7.35994247e-07\n",
            " 7.28017068e-03 7.09705276e-03 3.18641778e-03 5.78310201e-03\n",
            " 2.90429876e-03 8.73248591e-03 1.05839168e-03 7.51412076e-03\n",
            " 2.93210808e-03 2.73876956e-04 1.09521483e-03 2.39431894e-03\n",
            " 4.08606898e-04 8.16103950e-03 6.67007930e-03 4.95335895e-03\n",
            " 3.82539871e-04 3.67856109e-03 3.27286034e-03 9.96633090e-04\n",
            " 8.18648417e-03 5.93483417e-04 9.40056898e-04 5.19947344e-03\n",
            " 6.23414930e-05 4.24086175e-03 2.08668594e-03 1.82153245e-03\n",
            " 2.29471483e-03 7.76927949e-03 4.92164758e-03 3.23258389e-03\n",
            " 1.01234841e-04 2.95874671e-03 3.23258389e-03 6.58989431e-03\n",
            " 1.20402074e-03 7.15213027e-03 1.59129712e-03 4.43126184e-05\n",
            " 3.39653244e-03 2.81268536e-03 5.71702004e-03 4.93404111e-03\n",
            " 7.69665138e-03 8.53010481e-09 6.13448240e-03 6.39705679e-03\n",
            " 7.51425937e-03 1.23631752e-03 4.00732617e-03 1.94595332e-03\n",
            " 5.94493901e-03 2.03301354e-03 8.64031937e-03 4.61390232e-03\n",
            " 7.13238093e-03 6.06113847e-03 6.05206911e-03 5.32294118e-03\n",
            " 3.01900608e-03 7.63074868e-03 8.24822090e-03 4.40509932e-03\n",
            " 3.67856109e-03 7.57503248e-03 5.49459939e-03 6.13118189e-03\n",
            " 1.97165150e-03 1.90668456e-04 4.18633107e-03 6.62330079e-03\n",
            " 3.82729708e-03 8.68874658e-03 8.01077786e-03 6.63268134e-04\n",
            " 3.21767629e-03 6.31547627e-03 7.85401224e-07 6.48562924e-05\n",
            " 6.60703624e-04 3.00500286e-03 6.99908592e-03 2.72549110e-03\n",
            " 8.71921752e-03 6.18156645e-03 3.57730518e-04 7.45751670e-03\n",
            " 5.12836389e-03 1.70939508e-03 1.04169875e-03 4.63419295e-03\n",
            " 5.85734784e-03 5.22893376e-03 6.99691216e-03 4.26548354e-03\n",
            " 4.98739452e-03 5.98915850e-03 3.13415870e-03 7.59974821e-03\n",
            " 3.67856109e-03 3.55688157e-03 1.09814994e-03 1.43893999e-03\n",
            " 6.30239725e-03 2.29464574e-03 5.53774398e-03 2.17297046e-04\n",
            " 7.70419401e-03 5.57672077e-17 3.91292121e-03 7.03785472e-03\n",
            " 2.54677983e-04 7.51412076e-03 2.31582782e-03 3.67519461e-03\n",
            " 3.12019671e-03 3.10787626e-03 3.08719187e-03 5.57500267e-03\n",
            " 6.73031574e-03 1.86721132e-03 2.36081358e-04 7.68463644e-03\n",
            " 3.76126437e-03 7.35448991e-03 3.55718888e-03 2.92210821e-04\n",
            " 7.05487241e-03 1.65328142e-03 4.06157014e-03 2.44446614e-03\n",
            " 1.70169499e-04 5.02074340e-03 3.41697129e-03 7.06476378e-03\n",
            " 4.51040813e-03 2.62315912e-03 7.98974654e-03 6.73347809e-03\n",
            " 6.18706944e-03 5.29945732e-03 5.41894967e-03 4.17808627e-03\n",
            " 2.28019826e-04 2.10312353e-03 7.77115981e-03 8.41049431e-03\n",
            " 6.84286954e-03 4.24086175e-03 1.74277223e-03 2.50318048e-03\n",
            " 1.57218761e-03 1.35012867e-03 5.01583027e-03 2.39285660e-03\n",
            " 5.49459939e-03 3.70558777e-03 2.13660178e-03 6.24995578e-03\n",
            " 3.52340364e-03 3.02683130e-03 5.66348173e-03 3.26216284e-03\n",
            " 3.14814878e-06 1.21697069e-03 3.05351049e-03 1.33862916e-03\n",
            " 1.31663635e-05 2.15951549e-03 2.15651563e-04 3.64014351e-03\n",
            " 2.56902542e-03 1.31593899e-03 5.70108172e-04 2.46771684e-03\n",
            " 1.09360833e-03 1.75262996e-03 1.09839889e-03 3.81822672e-03\n",
            " 7.94571166e-03 5.76273938e-05 6.54509799e-04 1.40598018e-03\n",
            " 6.04389731e-03 7.00882966e-03 1.31593899e-03 2.67984624e-03\n",
            " 3.78489156e-03 4.27490655e-03 2.00361112e-03 4.76784591e-03\n",
            " 3.63669591e-03 7.72880935e-03 3.68899880e-04 3.87491553e-03\n",
            " 3.13309981e-03 7.47307212e-03 2.28019826e-04 4.21486928e-03\n",
            " 6.00026851e-03 3.44542374e-03 7.80085004e-03 3.94843043e-03\n",
            " 5.30162539e-04 1.63753143e-03 1.28139097e-03 4.36332085e-03\n",
            " 7.09573752e-04 3.50773693e-03 2.89471834e-04 1.31593899e-03\n",
            " 6.12706898e-03 5.18672664e-03 6.47424473e-03 6.42852271e-03\n",
            " 2.34280401e-03 3.39349627e-03 1.98367866e-03 7.92654330e-03\n",
            " 2.12346895e-04 4.24086175e-03 7.62126708e-03 3.05351049e-03\n",
            " 1.27127739e-03 4.89307200e-03 6.57468522e-04 7.49826792e-03\n",
            " 5.46066543e-03 5.25754482e-03 1.19603240e-03 5.90759078e-03\n",
            " 1.76720891e-04 6.06156486e-03 2.21803675e-03 4.48174757e-03\n",
            " 2.82866989e-03 3.39653244e-03 7.99231595e-03 2.95874671e-03\n",
            " 6.13416585e-03 4.00846606e-03 2.11277183e-03 4.29639528e-04\n",
            " 2.55305658e-03 4.51526417e-03 3.98954182e-03 6.51541916e-04\n",
            " 2.47880821e-03 7.19150839e-03 5.89890843e-03 6.60316077e-03\n",
            " 4.96926652e-04 3.45720959e-03 2.40225089e-03 6.38834381e-03\n",
            " 2.67984624e-03 1.00277731e-03 2.08706780e-03 5.08415994e-03\n",
            " 3.84811559e-03 3.87077056e-03 1.23537599e-03 6.92471826e-03\n",
            " 3.98743629e-03 6.74560142e-03 3.14090619e-03 6.58750951e-03\n",
            " 4.70361394e-03 3.00395532e-03 6.48422232e-03 9.42198493e-04\n",
            " 5.86948983e-04 4.54336707e-03 7.52147485e-04 3.18621695e-04\n",
            " 1.04242519e-03 1.89103605e-03 7.07325617e-03 3.18641778e-03\n",
            " 7.66823387e-05 6.22945660e-03 5.77296191e-03 6.65773751e-03\n",
            " 3.43426493e-06 5.87767299e-04 6.12784206e-06 1.85085325e-05\n",
            " 4.13558631e-05 1.15973258e-03 9.86407902e-04 4.30592042e-03\n",
            " 4.23490500e-03 5.34083067e-03 5.34083067e-03 1.10625273e-03\n",
            " 8.46741077e-03 2.13173217e-03 3.73768636e-03 2.24730602e-04\n",
            " 4.00454241e-04 5.75416525e-03 5.34978530e-03 2.66968842e-03\n",
            " 1.68129069e-04 5.99946805e-03 5.59585950e-03 5.94783848e-03\n",
            " 6.27400707e-03 5.37277539e-03 4.51040813e-03 2.92260602e-03\n",
            " 5.88273673e-03 5.77450138e-03 8.52763425e-03 4.23490500e-03\n",
            " 7.10953149e-03 1.29784210e-03 1.32635581e-03 4.83902745e-03\n",
            " 5.21019146e-03 3.50484295e-03 7.06274731e-04 8.14289247e-03\n",
            " 5.69093601e-03 1.99925455e-03 1.18676074e-03 5.16157811e-03\n",
            " 6.05273875e-03 7.29467702e-03 3.11020289e-03 1.28659484e-03\n",
            " 1.56290780e-03 6.40304738e-03 6.98169958e-03 7.52499246e-03\n",
            " 3.85883703e-03 4.08994627e-03 8.78760435e-03 3.28200200e-03\n",
            " 3.35332601e-03 3.52169510e-04 1.06097028e-03 7.24657441e-03\n",
            " 8.05981901e-03 2.48882091e-03 5.95293193e-03 8.14365814e-03\n",
            " 2.94220290e-04 4.81248772e-03 6.49052023e-03 8.07737320e-03\n",
            " 3.00394846e-03 7.35981931e-03 8.12274150e-03 6.30245578e-03\n",
            " 4.54252685e-03 5.71543124e-03 5.95493407e-03 1.21697069e-03\n",
            " 5.78593259e-03]\n",
            "3800 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.68167156e-03 4.13745107e-03 3.98960757e-03 3.18201956e-03\n",
            " 7.09293589e-04 4.30653280e-03 6.65519668e-03 7.62727318e-03\n",
            " 7.77259229e-03 4.85588791e-03 7.28280118e-03 6.87355595e-03\n",
            " 5.41916107e-03 1.38167345e-03 4.25643459e-03 5.73593955e-03\n",
            " 4.23249719e-03 1.38107352e-05 4.54478300e-03 3.15103384e-03\n",
            " 1.28095888e-04 1.80838126e-03 8.40266754e-09 4.43167458e-03\n",
            " 1.21867883e-05 5.79835552e-03 3.43916058e-04 7.29775033e-07\n",
            " 7.27912243e-03 7.08563189e-03 3.18461710e-03 5.77324870e-03\n",
            " 2.89367537e-03 1.05359087e-03 7.49604990e-03 2.91991310e-03\n",
            " 2.72976079e-04 1.09019658e-03 2.38464314e-03 4.08996464e-04\n",
            " 8.16955364e-03 6.65343003e-03 4.94532666e-03 3.80829723e-04\n",
            " 3.67765798e-03 3.26504562e-03 9.94539418e-04 5.93896366e-04\n",
            " 9.37832656e-04 5.19362768e-03 6.19587057e-05 4.23327642e-03\n",
            " 2.07964068e-03 1.81836945e-03 2.29338887e-03 7.75230805e-03\n",
            " 4.91265430e-03 3.23136393e-03 1.00825691e-04 2.94812618e-03\n",
            " 3.23136393e-03 6.57987191e-03 1.20251636e-03 7.14445077e-03\n",
            " 1.58916477e-03 4.40789277e-05 3.39362786e-03 2.80820930e-03\n",
            " 5.71170803e-03 4.92465184e-03 7.68855973e-03 8.40266754e-09\n",
            " 6.12654616e-03 6.39468244e-03 7.50901885e-03 1.22963951e-03\n",
            " 4.00411006e-03 1.94265721e-03 5.92213426e-03 2.03204890e-03\n",
            " 4.61187167e-03 7.13781273e-03 6.05080674e-03 6.04562920e-03\n",
            " 5.31687756e-03 3.01943292e-03 7.62727318e-03 4.38761654e-03\n",
            " 3.67765798e-03 7.56504300e-03 5.49156042e-03 6.11683420e-03\n",
            " 1.96718374e-03 1.90203768e-04 4.17858718e-03 6.61501174e-03\n",
            " 3.82250166e-03 8.01302935e-03 6.63098921e-04 3.21332847e-03\n",
            " 6.30803900e-03 7.84100058e-07 6.45790246e-05 6.57254797e-04\n",
            " 2.99902702e-03 6.97894829e-03 2.72473481e-03 6.15973939e-03\n",
            " 3.57035373e-04 7.43675133e-03 5.11799272e-03 1.70713993e-03\n",
            " 1.03986138e-03 4.63421847e-03 5.85054531e-03 5.22192433e-03\n",
            " 6.99089995e-03 4.26070306e-03 4.98148594e-03 5.97218107e-03\n",
            " 3.12171147e-03 7.57865620e-03 3.67765798e-03 3.55880276e-03\n",
            " 1.09551713e-03 1.43725683e-03 6.28142429e-03 2.28434133e-03\n",
            " 5.53084825e-03 2.16580695e-04 7.69924788e-03 5.48483423e-17\n",
            " 3.90989965e-03 7.03321154e-03 2.53739225e-04 7.49604990e-03\n",
            " 2.31732148e-03 3.66489949e-03 3.11319037e-03 3.10802131e-03\n",
            " 3.07673526e-03 5.55099050e-03 6.72705198e-03 1.86437704e-03\n",
            " 2.34817819e-04 7.67641100e-03 3.75845762e-03 7.34741897e-03\n",
            " 3.55022542e-03 2.91315658e-04 7.05389073e-03 1.65334096e-03\n",
            " 4.06023227e-03 2.43946965e-03 1.69751910e-04 5.01171598e-03\n",
            " 3.41483277e-03 7.06886739e-03 4.51077769e-03 2.62231657e-03\n",
            " 7.97444229e-03 6.70871961e-03 6.19340168e-03 5.29432913e-03\n",
            " 5.41916107e-03 4.17769005e-03 2.26696144e-04 2.09212972e-03\n",
            " 7.77060628e-03 6.83316664e-03 4.23327642e-03 1.73945774e-03\n",
            " 2.49470424e-03 1.57151657e-03 1.35118281e-03 5.00791770e-03\n",
            " 2.38813119e-03 5.49156042e-03 3.69985271e-03 2.12512914e-03\n",
            " 6.23719572e-03 3.51421539e-03 3.02498488e-03 5.65927519e-03\n",
            " 3.25502800e-03 3.13016321e-06 1.21286515e-03 3.04946907e-03\n",
            " 1.33846543e-03 1.30472499e-05 2.15609039e-03 2.15111504e-04\n",
            " 3.63886686e-03 2.55926910e-03 1.31196807e-03 5.69652664e-04\n",
            " 2.46291549e-03 1.09116775e-03 1.74424209e-03 1.09534887e-03\n",
            " 3.80320429e-03 7.93363529e-03 5.75660068e-05 6.52113072e-04\n",
            " 1.40102582e-03 6.03637591e-03 7.00494876e-03 1.31196807e-03\n",
            " 2.67176290e-03 3.77918540e-03 4.27551192e-03 2.00302374e-03\n",
            " 4.75012605e-03 3.62952848e-03 7.71988003e-03 3.68379007e-04\n",
            " 3.87216078e-03 3.12895046e-03 7.46487523e-03 2.26696144e-04\n",
            " 4.21330978e-03 5.98206008e-03 3.43063344e-03 7.80737765e-03\n",
            " 3.94262268e-03 5.27791718e-04 1.63241615e-03 1.27601869e-03\n",
            " 4.35216332e-03 7.09293589e-04 3.49900031e-03 2.88691198e-04\n",
            " 1.31196807e-03 6.12013762e-03 5.17908571e-03 6.46981801e-03\n",
            " 6.41815148e-03 2.33710307e-03 3.38530276e-03 1.97920849e-03\n",
            " 7.90512357e-03 2.12006235e-04 4.23327642e-03 7.61874709e-03\n",
            " 3.04946907e-03 1.27238304e-03 4.88043185e-03 6.53525270e-04\n",
            " 7.49901810e-03 5.46087577e-03 5.24062269e-03 1.18980599e-03\n",
            " 5.91290203e-03 1.76597873e-04 6.05919068e-03 2.21544965e-03\n",
            " 4.47805323e-03 2.82278929e-03 3.39362786e-03 7.98962879e-03\n",
            " 2.94812618e-03 6.12652883e-03 3.99342221e-03 2.10889588e-03\n",
            " 4.28556891e-04 2.54804816e-03 4.51247574e-03 3.98553467e-03\n",
            " 6.48359303e-04 2.47571937e-03 7.18542956e-03 5.89013208e-03\n",
            " 6.59155943e-03 4.94818886e-04 3.44651271e-03 2.39217953e-03\n",
            " 6.37688045e-03 2.67176290e-03 9.99676296e-04 2.08412940e-03\n",
            " 5.06910121e-03 3.84973281e-03 3.86186058e-03 1.23152639e-03\n",
            " 6.91060704e-03 3.98452405e-03 6.72632552e-03 3.13939612e-03\n",
            " 6.57616827e-03 4.68969293e-03 3.00263762e-03 6.46973097e-03\n",
            " 9.37100301e-04 5.86624735e-04 4.54478300e-03 7.50661058e-04\n",
            " 3.16756609e-04 1.03989124e-03 1.89064405e-03 7.06099247e-03\n",
            " 3.18461710e-03 7.64593918e-05 6.20585311e-03 5.74972687e-03\n",
            " 6.65101934e-03 3.39978949e-06 5.85729338e-04 6.12901017e-06\n",
            " 1.83761309e-05 4.12872312e-05 1.15881356e-03 9.84422713e-04\n",
            " 4.28254281e-03 4.23249719e-03 5.34314345e-03 5.34314345e-03\n",
            " 1.10608074e-03 2.12567782e-03 3.73058906e-03 2.23814431e-04\n",
            " 3.99095039e-04 5.73664355e-03 5.33171260e-03 2.66394459e-03\n",
            " 1.67227555e-04 5.98383131e-03 5.60185863e-03 5.94463710e-03\n",
            " 6.25452205e-03 5.37536189e-03 4.51077769e-03 2.90853099e-03\n",
            " 5.88272318e-03 5.75616536e-03 4.23249719e-03 7.09483684e-03\n",
            " 1.29583789e-03 1.32507371e-03 4.82785658e-03 5.20977785e-03\n",
            " 3.49965768e-03 7.04159197e-04 8.14786864e-03 5.68508986e-03\n",
            " 1.99419334e-03 1.18173269e-03 5.15903911e-03 6.02886131e-03\n",
            " 7.28768008e-03 3.10273666e-03 1.28497247e-03 1.55914980e-03\n",
            " 6.37608683e-03 6.97421926e-03 7.50437078e-03 3.85474034e-03\n",
            " 4.07447469e-03 3.27535415e-03 3.35550789e-03 3.50630898e-04\n",
            " 1.05861655e-03 7.25092617e-03 8.04060248e-03 2.48425480e-03\n",
            " 5.94719953e-03 8.13955456e-03 2.92353271e-04 4.80948189e-03\n",
            " 6.48217539e-03 8.06879779e-03 3.00482341e-03 7.35163969e-03\n",
            " 8.10808287e-03 6.30879725e-03 4.53979394e-03 5.69785082e-03\n",
            " 5.94659519e-03 1.21286515e-03 5.77390685e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3810 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.67535846e-03 4.12620144e-03 3.98474942e-03 3.17324144e-03\n",
            " 7.08718150e-04 4.30107388e-03 6.64652307e-03 7.62718719e-03\n",
            " 7.76254448e-03 4.85605263e-03 7.27137591e-03 6.86499303e-03\n",
            " 5.41732259e-03 1.37674231e-03 4.24310879e-03 5.72967646e-03\n",
            " 4.23488105e-03 1.37321844e-05 4.54349956e-03 3.14323355e-03\n",
            " 1.27423911e-04 1.80291489e-03 8.29828721e-09 4.42843275e-03\n",
            " 1.21618672e-05 5.78716585e-03 3.42965869e-04 7.17549749e-07\n",
            " 7.26598508e-03 7.07886497e-03 3.18658741e-03 5.76282982e-03\n",
            " 2.88919802e-03 1.05059924e-03 7.49228845e-03 2.91733436e-03\n",
            " 2.71607770e-04 1.08533476e-03 2.38166971e-03 4.08836043e-04\n",
            " 6.63232559e-03 4.94800766e-03 3.79848057e-04 3.67328690e-03\n",
            " 3.25331242e-03 9.93575712e-04 5.91687389e-04 9.36971594e-04\n",
            " 5.18459641e-03 6.16460924e-05 4.23096028e-03 2.07480733e-03\n",
            " 1.81642301e-03 2.28952868e-03 7.73662599e-03 4.90830801e-03\n",
            " 3.22773939e-03 1.00394725e-04 2.94717169e-03 3.22773939e-03\n",
            " 6.57082439e-03 1.20199510e-03 7.13579227e-03 1.58626152e-03\n",
            " 4.40425760e-05 3.39103504e-03 2.80516741e-03 5.70957700e-03\n",
            " 4.92298165e-03 7.67401066e-03 8.29828721e-09 6.12885551e-03\n",
            " 6.39126465e-03 7.51386479e-03 1.22755457e-03 3.99556040e-03\n",
            " 1.93845480e-03 5.91319791e-03 2.02906949e-03 4.61019874e-03\n",
            " 7.13067151e-03 6.04372758e-03 6.04739557e-03 5.31426194e-03\n",
            " 3.01882129e-03 7.62718719e-03 4.38533768e-03 3.67328690e-03\n",
            " 7.55609088e-03 5.49194700e-03 6.11385429e-03 1.96264651e-03\n",
            " 1.89544291e-04 4.16890586e-03 6.60646057e-03 3.81990460e-03\n",
            " 6.61384220e-04 3.21135232e-03 6.30749601e-03 7.79568801e-07\n",
            " 6.44449283e-05 6.54457986e-04 2.98585394e-03 6.97261167e-03\n",
            " 2.72127232e-03 6.15464070e-03 3.55795689e-04 7.41937368e-03\n",
            " 5.11038271e-03 1.69817496e-03 1.03435527e-03 4.63108387e-03\n",
            " 5.84048333e-03 5.22015319e-03 6.97625491e-03 4.25581511e-03\n",
            " 4.97211624e-03 5.96709969e-03 3.11925421e-03 7.56809422e-03\n",
            " 3.67328690e-03 3.55137356e-03 1.09243157e-03 1.43519641e-03\n",
            " 6.27936576e-03 2.28086114e-03 5.52940424e-03 2.16004214e-04\n",
            " 7.68994382e-03 5.48358008e-17 3.90524422e-03 7.02737565e-03\n",
            " 2.53372761e-04 7.49228845e-03 2.31350162e-03 3.65423475e-03\n",
            " 3.10543965e-03 3.10000344e-03 3.06652110e-03 5.53354472e-03\n",
            " 6.73012405e-03 1.86219674e-03 2.34310358e-04 7.66875732e-03\n",
            " 3.75868977e-03 7.33860312e-03 3.54868320e-03 2.90584451e-04\n",
            " 7.05237069e-03 1.65082061e-03 4.05762112e-03 2.43887516e-03\n",
            " 1.69005964e-04 5.00555385e-03 3.40656194e-03 7.06054250e-03\n",
            " 4.51019893e-03 2.62177918e-03 6.68931147e-03 6.19118870e-03\n",
            " 5.28659773e-03 5.41732259e-03 4.17263163e-03 2.25731199e-04\n",
            " 2.09010532e-03 7.74711802e-03 6.83263896e-03 4.23096028e-03\n",
            " 1.73647378e-03 2.48554505e-03 1.57237478e-03 1.35103160e-03\n",
            " 4.99960543e-03 2.38219250e-03 5.49194700e-03 3.69438112e-03\n",
            " 2.12235891e-03 6.23050434e-03 3.50343370e-03 3.02024989e-03\n",
            " 5.64314660e-03 3.24987160e-03 3.11944149e-06 1.21013347e-03\n",
            " 3.04283770e-03 1.33651508e-03 1.30221140e-05 2.14941274e-03\n",
            " 2.14769658e-04 3.63431130e-03 2.55592483e-03 1.31033709e-03\n",
            " 5.68664247e-04 2.46084952e-03 1.08888645e-03 1.74079525e-03\n",
            " 1.09400155e-03 3.79579417e-03 5.75515274e-05 6.50726155e-04\n",
            " 1.39767279e-03 6.02931414e-03 6.99208839e-03 1.31033709e-03\n",
            " 2.66340942e-03 3.76965560e-03 4.26955979e-03 2.00040702e-03\n",
            " 4.75011233e-03 3.62725741e-03 7.71408332e-03 3.67644372e-04\n",
            " 3.86476568e-03 3.12108962e-03 7.44105745e-03 2.25731199e-04\n",
            " 4.21040483e-03 5.97565422e-03 3.42085281e-03 7.80984943e-03\n",
            " 3.93054715e-03 5.24752322e-04 1.63170029e-03 1.27562488e-03\n",
            " 4.34757261e-03 7.08718150e-04 3.49163377e-03 2.88283493e-04\n",
            " 1.31033709e-03 6.12006646e-03 5.17626240e-03 6.46059743e-03\n",
            " 6.41509937e-03 2.33017897e-03 3.38301633e-03 1.97849976e-03\n",
            " 7.90220637e-03 2.11831383e-04 4.23096028e-03 7.61246260e-03\n",
            " 3.04283770e-03 1.26940594e-03 4.87185715e-03 6.52993981e-04\n",
            " 7.48270261e-03 5.45183142e-03 5.23925916e-03 1.19017544e-03\n",
            " 5.91543803e-03 1.76578171e-04 6.04586571e-03 2.21535444e-03\n",
            " 4.46863484e-03 2.80933744e-03 3.39103504e-03 2.94717169e-03\n",
            " 6.12353527e-03 3.99553033e-03 2.10828607e-03 4.28431528e-04\n",
            " 2.54232378e-03 4.51031197e-03 3.97642071e-03 6.48775391e-04\n",
            " 2.47099883e-03 7.17865582e-03 5.88740768e-03 6.57631909e-03\n",
            " 4.93181904e-04 3.43848284e-03 2.38403711e-03 6.35183562e-03\n",
            " 2.66340942e-03 9.97417805e-04 2.08408343e-03 5.06486003e-03\n",
            " 3.84932497e-03 3.85214159e-03 1.23057840e-03 6.90348876e-03\n",
            " 3.97665812e-03 6.71046609e-03 3.13908969e-03 6.57352725e-03\n",
            " 4.67356877e-03 3.00100825e-03 6.45924997e-03 9.33506799e-04\n",
            " 5.86436869e-04 4.54349956e-03 7.50498311e-04 3.15953494e-04\n",
            " 1.03462027e-03 1.88936620e-03 7.05056767e-03 3.18658741e-03\n",
            " 7.63131803e-05 6.20008542e-03 5.74328538e-03 6.65276783e-03\n",
            " 3.38141727e-06 5.84413793e-04 6.13179690e-06 1.83428743e-05\n",
            " 4.11922956e-05 1.15714434e-03 9.83985290e-04 4.27945428e-03\n",
            " 4.23488105e-03 5.33990458e-03 5.33990458e-03 1.10550544e-03\n",
            " 2.12102108e-03 3.72268344e-03 2.23755886e-04 3.98355975e-04\n",
            " 5.72630327e-03 5.32201695e-03 2.65763590e-03 1.66470620e-04\n",
            " 5.97678763e-03 5.59974460e-03 5.93372051e-03 6.24417880e-03\n",
            " 5.37488204e-03 4.51019893e-03 2.90927887e-03 5.87058835e-03\n",
            " 5.74430949e-03 4.23488105e-03 7.07798353e-03 1.29222709e-03\n",
            " 1.32138890e-03 4.82487533e-03 5.21102629e-03 3.49295426e-03\n",
            " 7.03073257e-04 5.67585951e-03 1.99134774e-03 1.18107568e-03\n",
            " 5.15332426e-03 6.02871447e-03 7.28367624e-03 3.10301977e-03\n",
            " 1.28034586e-03 1.55373810e-03 6.35613626e-03 6.97332574e-03\n",
            " 7.49719858e-03 3.84525877e-03 4.06830721e-03 3.26743660e-03\n",
            " 3.35489320e-03 3.49267637e-04 1.05813644e-03 7.24644865e-03\n",
            " 2.48210281e-03 5.94475971e-03 2.92010128e-04 4.80776496e-03\n",
            " 6.47116563e-03 3.00440920e-03 7.34951747e-03 6.30540657e-03\n",
            " 4.52941326e-03 5.68954097e-03 5.93261961e-03 1.21013347e-03\n",
            " 5.75948011e-03]\n",
            "3820 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.67213543e-03 4.12301933e-03 3.98340508e-03 3.17131622e-03\n",
            " 7.08723442e-04 4.29882757e-03 6.63504085e-03 4.85230362e-03\n",
            " 7.26205040e-03 6.86719541e-03 5.41298573e-03 1.37324147e-03\n",
            " 4.24546052e-03 5.72314685e-03 4.23169423e-03 1.37271127e-05\n",
            " 4.54022884e-03 3.14023615e-03 1.27391354e-04 1.80214619e-03\n",
            " 8.28484122e-09 4.42022100e-03 1.21264120e-05 5.78936294e-03\n",
            " 3.42325599e-04 7.19289031e-07 7.26300960e-03 7.07330831e-03\n",
            " 3.18402249e-03 5.75456130e-03 2.88623823e-03 1.04834911e-03\n",
            " 7.49295357e-03 2.91053679e-03 2.70504910e-04 1.08258810e-03\n",
            " 2.37978984e-03 4.08794008e-04 6.62732577e-03 4.94537537e-03\n",
            " 3.79082338e-04 3.67157276e-03 3.24768814e-03 9.92494835e-04\n",
            " 5.89502634e-04 9.36244183e-04 5.17883565e-03 6.16292385e-05\n",
            " 4.22848688e-03 2.07275792e-03 1.81423053e-03 2.28794753e-03\n",
            " 4.90600047e-03 3.22616749e-03 1.00012042e-04 2.94399599e-03\n",
            " 3.22616749e-03 6.56927417e-03 1.20228069e-03 7.11908629e-03\n",
            " 1.58438298e-03 4.39048575e-05 3.38984725e-03 2.80250086e-03\n",
            " 5.70549044e-03 4.91771729e-03 8.28484122e-09 6.12989053e-03\n",
            " 6.38778971e-03 7.50713518e-03 1.22536352e-03 3.99459520e-03\n",
            " 1.93467420e-03 5.90733233e-03 2.02324143e-03 4.61008716e-03\n",
            " 7.12434704e-03 6.03666289e-03 6.04457243e-03 5.30692668e-03\n",
            " 3.01706195e-03 7.60167640e-03 4.37723553e-03 3.67157276e-03\n",
            " 7.55208438e-03 5.49129589e-03 6.11174095e-03 1.95861823e-03\n",
            " 1.89442126e-04 4.16432851e-03 6.59671927e-03 3.81915088e-03\n",
            " 6.61390693e-04 3.20850490e-03 6.30478139e-03 7.77860308e-07\n",
            " 6.43274696e-05 6.53276718e-04 2.98410001e-03 6.96678985e-03\n",
            " 2.71814661e-03 6.14689533e-03 3.55590528e-04 7.41328674e-03\n",
            " 5.11110195e-03 1.69767172e-03 1.03224852e-03 4.62754106e-03\n",
            " 5.83250161e-03 5.22052992e-03 6.97020670e-03 4.25315476e-03\n",
            " 4.97042302e-03 5.96485985e-03 3.11192841e-03 7.55141566e-03\n",
            " 3.67157276e-03 3.54904635e-03 1.09202620e-03 1.43384005e-03\n",
            " 6.27727155e-03 2.27978016e-03 5.52386605e-03 2.15659790e-04\n",
            " 5.41722343e-17 3.90349287e-03 7.02969106e-03 2.53130094e-04\n",
            " 7.49295357e-03 2.30968654e-03 3.64368191e-03 3.10469286e-03\n",
            " 3.09999514e-03 3.06552111e-03 5.52891846e-03 6.71592957e-03\n",
            " 1.85881194e-03 2.34058172e-04 3.75800792e-03 7.33226690e-03\n",
            " 3.54221287e-03 2.90471285e-04 7.04582778e-03 1.64872176e-03\n",
            " 4.05733779e-03 2.43784325e-03 1.68434163e-04 5.00279642e-03\n",
            " 3.40346909e-03 7.05252258e-03 4.50491301e-03 2.61963370e-03\n",
            " 6.68010903e-03 6.18860617e-03 5.27780016e-03 5.41298573e-03\n",
            " 4.16882425e-03 2.25562306e-04 2.08596993e-03 6.82797135e-03\n",
            " 4.22848688e-03 1.73436545e-03 2.48252962e-03 1.57256256e-03\n",
            " 1.35024589e-03 4.99657597e-03 2.37589716e-03 5.49129589e-03\n",
            " 3.68976512e-03 2.11779384e-03 6.22224857e-03 3.50006110e-03\n",
            " 3.01466994e-03 5.63137261e-03 3.24686697e-03 3.11151409e-06\n",
            " 1.20904791e-03 3.03757371e-03 1.33597990e-03 1.30135249e-05\n",
            " 2.14786038e-03 2.14552203e-04 3.62892290e-03 2.55233573e-03\n",
            " 1.30670004e-03 5.67614434e-04 2.45983443e-03 1.08887254e-03\n",
            " 1.73417226e-03 1.09296100e-03 3.79634164e-03 5.74899732e-05\n",
            " 6.49927800e-04 1.39494554e-03 6.02741558e-03 6.97725042e-03\n",
            " 1.30670004e-03 2.66254215e-03 3.76218993e-03 4.26663903e-03\n",
            " 1.99770598e-03 4.75003735e-03 3.62078324e-03 3.66905026e-04\n",
            " 3.85715429e-03 3.11667742e-03 7.42735794e-03 2.25562306e-04\n",
            " 4.20720188e-03 5.97197614e-03 3.41787207e-03 3.92472781e-03\n",
            " 5.23862802e-04 1.62928735e-03 1.27479331e-03 4.34134397e-03\n",
            " 7.08723442e-04 3.48977238e-03 2.87900084e-04 1.30670004e-03\n",
            " 6.11446730e-03 5.17427024e-03 6.44601311e-03 6.40874009e-03\n",
            " 2.32950307e-03 3.37408746e-03 1.97587875e-03 2.11813962e-04\n",
            " 4.22848688e-03 7.60188074e-03 3.03757371e-03 1.26945470e-03\n",
            " 4.86585345e-03 6.52627511e-04 7.46960403e-03 5.45080510e-03\n",
            " 5.24199656e-03 1.18923292e-03 5.91582773e-03 1.76576486e-04\n",
            " 6.04176609e-03 2.21308704e-03 4.46681055e-03 2.80403062e-03\n",
            " 3.38984725e-03 2.94399599e-03 6.11472585e-03 3.99376577e-03\n",
            " 2.10809754e-03 4.27396140e-04 2.53965406e-03 4.50494854e-03\n",
            " 3.97270331e-03 6.48131168e-04 2.46909002e-03 7.17317262e-03\n",
            " 5.87952229e-03 6.56876250e-03 4.92068321e-04 3.43342282e-03\n",
            " 2.38159085e-03 6.33593130e-03 2.66254215e-03 9.96732855e-04\n",
            " 2.08415922e-03 5.05982922e-03 3.84679312e-03 3.84850617e-03\n",
            " 1.22939133e-03 6.89225656e-03 3.97793591e-03 6.70575905e-03\n",
            " 3.13636097e-03 6.57286758e-03 4.66347048e-03 3.00155554e-03\n",
            " 6.45774869e-03 9.32444278e-04 5.86221732e-04 4.54022884e-03\n",
            " 7.49550571e-04 3.15734826e-04 1.03307774e-03 1.88732754e-03\n",
            " 7.05582076e-03 3.18402249e-03 7.61039813e-05 6.19761743e-03\n",
            " 5.73009460e-03 6.65113646e-03 3.36830897e-06 5.83508902e-04\n",
            " 6.08898712e-06 1.83054496e-05 4.10252437e-05 1.15430751e-03\n",
            " 9.83315950e-04 4.27602198e-03 4.23169423e-03 5.33563847e-03\n",
            " 5.33563847e-03 1.10489774e-03 2.11968686e-03 3.71797206e-03\n",
            " 2.23202834e-04 3.97438094e-04 5.72280820e-03 5.31468337e-03\n",
            " 2.65447008e-03 1.66203988e-04 5.97035764e-03 5.59217959e-03\n",
            " 5.92840284e-03 6.24261959e-03 5.37273385e-03 4.50491301e-03\n",
            " 2.90676025e-03 5.87042955e-03 5.73234913e-03 4.23169423e-03\n",
            " 7.07669833e-03 1.29143463e-03 1.32139790e-03 4.81965825e-03\n",
            " 5.20759628e-03 3.49074675e-03 7.00926913e-04 5.67486952e-03\n",
            " 1.98923895e-03 1.17895450e-03 5.15251671e-03 6.02288533e-03\n",
            " 7.28347658e-03 3.10174164e-03 1.27872736e-03 1.55045167e-03\n",
            " 6.35088475e-03 6.96888755e-03 7.48782195e-03 3.83980050e-03\n",
            " 4.06273363e-03 3.26378099e-03 3.35294262e-03 3.48137454e-04\n",
            " 1.05737094e-03 7.22322691e-03 2.47872263e-03 5.94086965e-03\n",
            " 2.91574441e-04 4.80802124e-03 6.46645239e-03 3.00222982e-03\n",
            " 7.35080958e-03 6.29985875e-03 4.52312907e-03 5.68743147e-03\n",
            " 5.92320391e-03 1.20904791e-03 5.75783853e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3830 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.66788081e-03 4.12137696e-03 3.98312349e-03 3.16662812e-03\n",
            " 7.08239959e-04 4.29148847e-03 6.62249074e-03 4.84913821e-03\n",
            " 7.22925924e-03 6.86234348e-03 5.41195531e-03 1.36949639e-03\n",
            " 4.24347745e-03 5.71966901e-03 4.22283280e-03 1.37096640e-05\n",
            " 4.53168088e-03 3.13734006e-03 1.27123338e-04 1.80138097e-03\n",
            " 8.20608116e-09 4.41759934e-03 1.20473066e-05 5.78692923e-03\n",
            " 3.42367670e-04 7.16322731e-07 7.25561742e-03 7.07193123e-03\n",
            " 3.17685470e-03 5.74578365e-03 2.88247947e-03 1.04376010e-03\n",
            " 2.90827529e-03 2.69382232e-04 1.08003630e-03 2.37473093e-03\n",
            " 4.08072046e-04 6.59914682e-03 4.94517350e-03 3.77477539e-04\n",
            " 3.66795669e-03 3.24078489e-03 9.91427441e-04 5.88703300e-04\n",
            " 9.35106778e-04 5.16784585e-03 6.14727259e-05 4.22602063e-03\n",
            " 2.07102800e-03 1.81301035e-03 2.29064165e-03 4.90438177e-03\n",
            " 3.22305648e-03 9.98416523e-05 2.93855532e-03 3.22305648e-03\n",
            " 6.56795258e-03 1.20190994e-03 7.10544389e-03 1.58344547e-03\n",
            " 4.38316888e-05 3.38584103e-03 2.80069411e-03 5.71178921e-03\n",
            " 4.91394454e-03 8.20608116e-09 6.11853091e-03 6.38377579e-03\n",
            " 1.22224828e-03 3.99196932e-03 1.92645517e-03 5.90171623e-03\n",
            " 2.01877555e-03 4.61121139e-03 7.12001278e-03 6.03218821e-03\n",
            " 6.03994998e-03 5.30526251e-03 3.01725472e-03 4.36717078e-03\n",
            " 3.66795669e-03 5.48838515e-03 6.10859417e-03 1.95552118e-03\n",
            " 1.88912305e-04 4.16164080e-03 6.59368438e-03 3.81618183e-03\n",
            " 6.60259484e-04 3.20652783e-03 6.30223311e-03 7.74245832e-07\n",
            " 6.41370573e-05 6.51231147e-04 2.98004305e-03 6.95844324e-03\n",
            " 2.71435196e-03 6.14432196e-03 3.55004320e-04 7.40323670e-03\n",
            " 5.11416359e-03 1.69908740e-03 1.03084790e-03 4.62611382e-03\n",
            " 5.82729464e-03 5.21095110e-03 6.96154082e-03 4.24924422e-03\n",
            " 4.96384505e-03 5.95629036e-03 3.10436745e-03 3.66795669e-03\n",
            " 3.54544840e-03 1.09058728e-03 1.43131452e-03 6.27022795e-03\n",
            " 2.27776827e-03 5.51748601e-03 2.15319478e-04 5.35585228e-17\n",
            " 3.89866295e-03 7.01679423e-03 2.52529163e-04 2.31001421e-03\n",
            " 3.63925555e-03 3.10453045e-03 3.09614318e-03 3.05762528e-03\n",
            " 5.51979287e-03 6.71421567e-03 1.85360082e-03 2.33694960e-04\n",
            " 3.76189665e-03 7.32256241e-03 3.53519133e-03 2.90027967e-04\n",
            " 7.04141837e-03 1.64955489e-03 4.05116492e-03 2.43567381e-03\n",
            " 1.67914364e-04 5.00175954e-03 3.40349241e-03 7.04696304e-03\n",
            " 4.50280148e-03 2.62039022e-03 6.66118600e-03 6.17412049e-03\n",
            " 5.27273494e-03 5.41195531e-03 4.16596740e-03 2.24638147e-04\n",
            " 2.08164717e-03 6.82340323e-03 4.22602063e-03 1.73300757e-03\n",
            " 2.47656590e-03 1.57258880e-03 1.35028488e-03 4.99256511e-03\n",
            " 2.36562744e-03 5.48838515e-03 3.68243426e-03 2.11548058e-03\n",
            " 6.21963112e-03 3.49574469e-03 3.01024877e-03 5.62604591e-03\n",
            " 3.24198934e-03 3.09754798e-06 1.20624393e-03 3.03608867e-03\n",
            " 1.33555765e-03 1.29592324e-05 2.14412782e-03 2.14364263e-04\n",
            " 3.62160678e-03 2.54442027e-03 1.30204317e-03 5.65643421e-04\n",
            " 2.45438089e-03 1.08908494e-03 1.73190357e-03 1.09255151e-03\n",
            " 3.78804011e-03 5.74106817e-05 6.46960923e-04 1.39196914e-03\n",
            " 6.02437235e-03 6.96930178e-03 1.30204317e-03 2.65698487e-03\n",
            " 3.75842681e-03 4.26896866e-03 1.99699149e-03 4.74418812e-03\n",
            " 3.61516649e-03 3.66292045e-04 3.84765808e-03 3.11087649e-03\n",
            " 2.24638147e-04 4.20953962e-03 5.97403258e-03 3.40999174e-03\n",
            " 3.92144167e-03 5.21273411e-04 1.62758215e-03 1.27246777e-03\n",
            " 4.33906026e-03 7.08239959e-04 3.48692660e-03 2.87021230e-04\n",
            " 1.30204317e-03 6.10927003e-03 5.17116207e-03 6.43997801e-03\n",
            " 6.39923200e-03 2.33038472e-03 3.37098369e-03 1.97077782e-03\n",
            " 2.11432408e-04 4.22602063e-03 3.03608867e-03 1.26925169e-03\n",
            " 4.86128432e-03 6.50072050e-04 5.45052316e-03 5.24438402e-03\n",
            " 1.18612434e-03 5.91447091e-03 1.76652532e-04 6.03496086e-03\n",
            " 2.20859281e-03 4.46670233e-03 2.80351056e-03 3.38584103e-03\n",
            " 2.93855532e-03 6.10229083e-03 3.99203032e-03 2.10722823e-03\n",
            " 4.26591000e-04 2.53810734e-03 4.50208340e-03 3.96895883e-03\n",
            " 6.45825520e-04 2.46591373e-03 7.16181166e-03 5.86292856e-03\n",
            " 6.56050573e-03 4.90691770e-04 3.42928582e-03 2.37263641e-03\n",
            " 6.33025404e-03 2.65698487e-03 9.94499175e-04 2.08391180e-03\n",
            " 5.04877323e-03 3.84106738e-03 3.84642451e-03 1.22771984e-03\n",
            " 6.89359721e-03 3.97347661e-03 6.69371376e-03 3.13512713e-03\n",
            " 6.56700620e-03 4.66012203e-03 3.00104088e-03 6.44842750e-03\n",
            " 9.28642014e-04 5.85670706e-04 4.53168088e-03 7.48618296e-04\n",
            " 3.14977372e-04 1.03183087e-03 1.88598560e-03 7.05560862e-03\n",
            " 3.17685470e-03 7.59099942e-05 6.18637225e-03 5.71254692e-03\n",
            " 6.64257524e-03 3.35277270e-06 5.82252788e-04 6.05141433e-06\n",
            " 1.82034534e-05 4.08214679e-05 1.15376705e-03 9.81922890e-04\n",
            " 4.26330037e-03 4.22283280e-03 5.33683763e-03 5.33683763e-03\n",
            " 1.10404357e-03 2.11272562e-03 3.71357822e-03 2.22679470e-04\n",
            " 3.96768208e-04 5.70483248e-03 5.31047410e-03 2.64750722e-03\n",
            " 1.65454220e-04 5.96565113e-03 5.58970381e-03 5.92730168e-03\n",
            " 6.23827114e-03 5.36904532e-03 4.50280148e-03 2.90599562e-03\n",
            " 5.86796808e-03 5.73613861e-03 4.22283280e-03 7.06784477e-03\n",
            " 1.28877702e-03 1.32007788e-03 4.81859214e-03 5.20682880e-03\n",
            " 3.49180223e-03 6.99573601e-04 5.67088825e-03 1.98522298e-03\n",
            " 1.17471912e-03 5.15104311e-03 6.01822861e-03 7.27031005e-03\n",
            " 3.09686309e-03 1.27684923e-03 1.54798423e-03 6.33274480e-03\n",
            " 6.96720060e-03 3.83791720e-03 4.05524785e-03 3.26031351e-03\n",
            " 3.35309446e-03 3.47093397e-04 1.05576925e-03 7.21993813e-03\n",
            " 2.47397071e-03 5.93258383e-03 2.90843076e-04 4.80994785e-03\n",
            " 6.46191548e-03 3.00214828e-03 7.34615807e-03 6.29292623e-03\n",
            " 4.51619119e-03 5.68457287e-03 5.92009747e-03 1.20624393e-03\n",
            " 5.75484516e-03]\n",
            "3840 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.66515695e-03 4.11649368e-03 3.97317562e-03 3.15884192e-03\n",
            " 7.07720049e-04 4.28725897e-03 6.61521403e-03 4.84141745e-03\n",
            " 6.86132655e-03 5.41060836e-03 1.36796826e-03 4.24076006e-03\n",
            " 5.71861883e-03 4.22314154e-03 1.36562922e-05 4.53068364e-03\n",
            " 3.13665902e-03 1.26659463e-04 1.79919780e-03 8.17945795e-09\n",
            " 4.41034769e-03 1.19463648e-05 5.78288248e-03 3.41500425e-04\n",
            " 7.08296620e-07 7.05753717e-03 3.17713431e-03 5.73462880e-03\n",
            " 2.87863001e-03 1.04021384e-03 2.89929353e-03 2.68903533e-04\n",
            " 1.07892686e-03 2.37515013e-03 4.07950344e-04 6.56899694e-03\n",
            " 4.93869895e-03 3.74415615e-04 3.66267964e-03 3.23403941e-03\n",
            " 9.90282084e-04 5.87623728e-04 9.34032047e-04 5.16508164e-03\n",
            " 6.12456393e-05 4.22341108e-03 2.06959939e-03 1.80987634e-03\n",
            " 2.28906637e-03 4.90038540e-03 3.21844179e-03 9.96334217e-05\n",
            " 2.92974852e-03 3.21844179e-03 6.56306848e-03 1.20114755e-03\n",
            " 1.57785410e-03 4.37356325e-05 3.38391412e-03 2.79816070e-03\n",
            " 5.70794550e-03 4.90954873e-03 8.17945795e-09 6.12319475e-03\n",
            " 6.38180127e-03 1.22116169e-03 3.98979599e-03 1.92047153e-03\n",
            " 5.89804676e-03 2.01428040e-03 4.61077176e-03 6.03082767e-03\n",
            " 6.02984935e-03 5.30666289e-03 3.01650176e-03 4.35189120e-03\n",
            " 3.66267964e-03 5.49585873e-03 6.09891574e-03 1.95369795e-03\n",
            " 1.88008010e-04 4.15560786e-03 6.59012008e-03 3.81535736e-03\n",
            " 6.60171918e-04 3.19942467e-03 6.30029818e-03 7.73006505e-07\n",
            " 6.40097574e-05 6.48758394e-04 2.97687607e-03 6.95438182e-03\n",
            " 2.71080556e-03 6.13432614e-03 3.54374684e-04 5.10652162e-03\n",
            " 1.69803065e-03 1.02879673e-03 4.62045967e-03 5.81839101e-03\n",
            " 5.20628183e-03 6.95349796e-03 4.24200191e-03 4.96025543e-03\n",
            " 5.95178112e-03 3.09976212e-03 3.66267964e-03 3.53579608e-03\n",
            " 1.08941917e-03 1.42346781e-03 6.26797305e-03 2.27451099e-03\n",
            " 5.50383641e-03 2.15017514e-04 5.29306619e-17 3.89571156e-03\n",
            " 7.01762430e-03 2.51932147e-04 2.30295783e-03 3.63321279e-03\n",
            " 3.10096967e-03 3.09054010e-03 3.05380449e-03 5.51534593e-03\n",
            " 6.71211483e-03 1.84544280e-03 2.31968211e-04 3.76169795e-03\n",
            " 3.53086682e-03 2.89629917e-04 7.03778743e-03 1.64768260e-03\n",
            " 4.04960190e-03 2.43388493e-03 1.67539361e-04 4.99432150e-03\n",
            " 3.39745753e-03 7.03187903e-03 4.50213821e-03 2.61608173e-03\n",
            " 6.66061246e-03 6.17442765e-03 5.26474030e-03 5.41060836e-03\n",
            " 4.15436772e-03 2.24306691e-04 2.07435386e-03 6.81357982e-03\n",
            " 4.22341108e-03 1.73014812e-03 2.47350727e-03 1.57234682e-03\n",
            " 1.35000666e-03 4.98587301e-03 2.36191568e-03 5.49585873e-03\n",
            " 3.67689032e-03 2.10732151e-03 6.21072037e-03 3.49156254e-03\n",
            " 3.00646727e-03 5.61786861e-03 3.23995984e-03 3.08672966e-06\n",
            " 1.20514154e-03 3.03207029e-03 1.33319341e-03 1.28279554e-05\n",
            " 2.14124189e-03 2.14282325e-04 3.61750388e-03 2.52689723e-03\n",
            " 1.29985085e-03 5.63659955e-04 2.44874302e-03 1.08798956e-03\n",
            " 1.73328521e-03 1.09029106e-03 3.77127141e-03 5.73262958e-05\n",
            " 6.44143508e-04 1.38987054e-03 6.01725312e-03 6.96495935e-03\n",
            " 1.29985085e-03 2.65114161e-03 3.75247141e-03 4.27091253e-03\n",
            " 1.99527615e-03 4.73849138e-03 3.61000353e-03 3.65760335e-04\n",
            " 3.83766722e-03 3.10049222e-03 2.24306691e-04 4.20677303e-03\n",
            " 5.96823081e-03 3.40046198e-03 3.91525622e-03 5.18836399e-04\n",
            " 1.62776424e-03 1.27138085e-03 4.33804101e-03 7.07720049e-04\n",
            " 3.47803339e-03 2.86760952e-04 1.29985085e-03 6.10020412e-03\n",
            " 5.16623147e-03 6.43280620e-03 6.39554309e-03 2.32492408e-03\n",
            " 3.36751379e-03 1.95951055e-03 2.11291384e-04 4.22341108e-03\n",
            " 3.03207029e-03 1.27060877e-03 4.85561556e-03 6.43686237e-04\n",
            " 5.45549249e-03 5.24441411e-03 1.18154027e-03 5.91466053e-03\n",
            " 1.76553488e-04 6.02826272e-03 2.20365164e-03 4.46270721e-03\n",
            " 2.80074036e-03 3.38391412e-03 2.92974852e-03 6.09249307e-03\n",
            " 3.98651141e-03 2.10517976e-03 4.25970431e-04 2.53613703e-03\n",
            " 4.50070451e-03 3.94951494e-03 6.43597952e-04 2.46576866e-03\n",
            " 5.84150448e-03 6.54840634e-03 4.89408195e-04 3.41856370e-03\n",
            " 2.35804117e-03 6.32622684e-03 2.65114161e-03 9.90286771e-04\n",
            " 2.08264959e-03 5.02714331e-03 3.84081702e-03 3.84015379e-03\n",
            " 1.22345476e-03 6.88933703e-03 3.97100998e-03 6.68213155e-03\n",
            " 3.13309168e-03 6.56370990e-03 4.65952530e-03 2.99920622e-03\n",
            " 6.44516236e-03 9.27556617e-04 5.85426033e-04 4.53068364e-03\n",
            " 7.46421726e-04 3.13869549e-04 1.03020566e-03 1.88462062e-03\n",
            " 7.04574460e-03 3.17713431e-03 7.56690543e-05 6.17754183e-03\n",
            " 5.70552538e-03 6.62976538e-03 3.33775277e-06 5.81017170e-04\n",
            " 6.04947948e-06 1.80180065e-05 4.07150642e-05 1.15246654e-03\n",
            " 9.81506969e-04 4.23146237e-03 4.22314154e-03 5.33480428e-03\n",
            " 5.33480428e-03 1.10381120e-03 2.10517954e-03 3.70629722e-03\n",
            " 2.22044890e-04 3.96042184e-04 5.69279153e-03 5.30958260e-03\n",
            " 2.64311407e-03 1.65006190e-04 5.96221098e-03 5.58726697e-03\n",
            " 5.92048086e-03 6.23324004e-03 5.36878510e-03 4.50213821e-03\n",
            " 2.90449473e-03 5.86579457e-03 5.72742323e-03 4.22314154e-03\n",
            " 7.05622687e-03 1.28677906e-03 1.31858133e-03 4.80879989e-03\n",
            " 5.20622413e-03 3.49034431e-03 6.97631324e-04 5.65963389e-03\n",
            " 1.97982158e-03 1.17318208e-03 5.14705303e-03 6.00104235e-03\n",
            " 3.08328812e-03 1.27556593e-03 1.54482391e-03 6.32704513e-03\n",
            " 6.96167503e-03 3.83319077e-03 4.04519609e-03 3.25372857e-03\n",
            " 3.35230949e-03 3.45256828e-04 1.05530915e-03 2.46929070e-03\n",
            " 5.92938710e-03 2.88880216e-04 4.81066366e-03 6.45939452e-03\n",
            " 2.99893572e-03 6.28927032e-03 4.51142956e-03 5.67904414e-03\n",
            " 5.91931080e-03 1.20514154e-03 5.75021474e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3850 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.66422713e-03 4.11426548e-03 3.96651232e-03 3.14973243e-03\n",
            " 7.06718320e-04 4.28426150e-03 6.61516349e-03 4.83320755e-03\n",
            " 6.85930351e-03 5.40971280e-03 1.36812019e-03 4.23416797e-03\n",
            " 5.71488319e-03 4.22260810e-03 1.36201251e-05 4.52946611e-03\n",
            " 3.13076434e-03 1.26354743e-04 1.79594814e-03 8.10636569e-09\n",
            " 4.40722866e-03 1.18197402e-05 5.78284197e-03 3.39745985e-04\n",
            " 6.98208462e-07 3.17713698e-03 5.72492318e-03 2.87385216e-03\n",
            " 1.03762800e-03 2.89126245e-03 2.67777158e-04 1.07804219e-03\n",
            " 2.37157037e-03 4.07751995e-04 6.54501791e-03 4.92806649e-03\n",
            " 3.73550021e-04 3.65554910e-03 3.23082844e-03 9.87113857e-04\n",
            " 5.87515047e-04 9.32688114e-04 5.16087183e-03 6.11236517e-05\n",
            " 4.22071722e-03 2.06704241e-03 1.80647775e-03 2.28325297e-03\n",
            " 4.89909634e-03 3.21216932e-03 9.94724099e-05 2.91937223e-03\n",
            " 3.21216932e-03 6.56390523e-03 1.20031758e-03 1.57646121e-03\n",
            " 4.34136849e-05 3.38416489e-03 2.79232606e-03 5.70583001e-03\n",
            " 4.89252099e-03 8.10636569e-09 6.11396762e-03 6.36346267e-03\n",
            " 1.21831104e-03 3.98340222e-03 1.91623381e-03 5.88788114e-03\n",
            " 2.01411673e-03 4.61037195e-03 6.02826640e-03 6.01847054e-03\n",
            " 5.31028238e-03 3.01592984e-03 4.35117309e-03 3.65554910e-03\n",
            " 5.49117295e-03 6.08278143e-03 1.95290425e-03 1.87392356e-04\n",
            " 4.15130707e-03 6.58486605e-03 3.81102290e-03 6.59497912e-04\n",
            " 3.19281507e-03 6.29437814e-03 7.73659928e-07 6.37885896e-05\n",
            " 6.47596238e-04 2.97459996e-03 2.70994881e-03 6.12768183e-03\n",
            " 3.54257169e-04 5.09385572e-03 1.69448270e-03 1.02616896e-03\n",
            " 4.60936044e-03 5.81290864e-03 5.20148885e-03 4.23572437e-03\n",
            " 4.94992356e-03 5.94873764e-03 3.09334356e-03 3.65554910e-03\n",
            " 3.53324775e-03 1.08696611e-03 1.42272804e-03 6.25372178e-03\n",
            " 2.27158750e-03 5.49137392e-03 2.14605323e-04 5.13455897e-17\n",
            " 3.89033225e-03 2.50912203e-04 2.30340346e-03 3.63092577e-03\n",
            " 3.10042607e-03 3.09055786e-03 3.04567631e-03 5.50657734e-03\n",
            " 6.70579159e-03 1.84108021e-03 2.30945110e-04 3.75851950e-03\n",
            " 3.51395180e-03 2.89333404e-04 1.64585774e-03 4.04628843e-03\n",
            " 2.42690010e-03 1.66985260e-04 4.99148530e-03 3.39220525e-03\n",
            " 4.50012151e-03 2.60995898e-03 6.65220032e-03 6.17491898e-03\n",
            " 5.25012197e-03 5.40971280e-03 4.14458578e-03 2.23779927e-04\n",
            " 2.07186432e-03 6.79841637e-03 4.22071722e-03 1.72484137e-03\n",
            " 2.46794549e-03 1.57076051e-03 1.34984780e-03 4.98235878e-03\n",
            " 2.35363251e-03 5.49117295e-03 3.67259223e-03 2.10195592e-03\n",
            " 6.21299097e-03 3.49062343e-03 3.00540424e-03 5.61083922e-03\n",
            " 3.23614797e-03 3.06764479e-06 1.20200042e-03 3.02881933e-03\n",
            " 1.33146651e-03 1.27998611e-05 2.13924202e-03 2.14147774e-04\n",
            " 3.61484422e-03 2.52473516e-03 1.29502152e-03 5.62679663e-04\n",
            " 2.44700626e-03 1.08671549e-03 1.73128708e-03 1.08811924e-03\n",
            " 3.76949409e-03 5.72172570e-05 6.43137652e-04 1.38522550e-03\n",
            " 6.00913832e-03 1.29502152e-03 2.64649088e-03 3.74935897e-03\n",
            " 4.27310770e-03 1.99458880e-03 4.73525230e-03 3.59820343e-03\n",
            " 3.65726580e-04 3.82991162e-03 3.09092254e-03 2.23779927e-04\n",
            " 4.20607751e-03 5.96131296e-03 3.39661445e-03 3.91111153e-03\n",
            " 5.17384420e-04 1.62702613e-03 1.27001697e-03 4.33499567e-03\n",
            " 7.06718320e-04 3.47156228e-03 2.86234302e-04 1.29502152e-03\n",
            " 6.09001527e-03 5.16744174e-03 6.42691069e-03 6.38499397e-03\n",
            " 2.32165672e-03 3.36347631e-03 1.95183996e-03 2.11145901e-04\n",
            " 4.22071722e-03 3.02881933e-03 1.26907949e-03 4.84646149e-03\n",
            " 6.43483114e-04 5.45018132e-03 5.24244572e-03 1.17923434e-03\n",
            " 5.91463999e-03 1.76305269e-04 6.02786291e-03 2.19997654e-03\n",
            " 4.45575908e-03 2.79958996e-03 3.38416489e-03 2.91937223e-03\n",
            " 6.08796079e-03 3.96623355e-03 2.10299905e-03 4.23850036e-04\n",
            " 2.53482511e-03 4.49954540e-03 3.94154239e-03 6.42233017e-04\n",
            " 2.46073055e-03 5.82803769e-03 6.54295527e-03 4.88483460e-04\n",
            " 3.40837096e-03 2.35430926e-03 6.31671581e-03 2.64649088e-03\n",
            " 9.87994774e-04 2.08140772e-03 5.02237877e-03 3.83959139e-03\n",
            " 3.83381628e-03 1.22027029e-03 6.88914889e-03 3.97145569e-03\n",
            " 6.68136190e-03 3.12893886e-03 6.55676284e-03 4.65084181e-03\n",
            " 2.99493810e-03 6.43877746e-03 9.23972161e-04 5.85182760e-04\n",
            " 4.52946611e-03 7.42058456e-04 3.13225042e-04 1.02841745e-03\n",
            " 1.88206114e-03 3.17713698e-03 7.53003242e-05 6.17595091e-03\n",
            " 5.69808900e-03 6.61145517e-03 3.31764128e-06 5.80353314e-04\n",
            " 6.03462179e-06 1.79692709e-05 4.05933618e-05 1.14979574e-03\n",
            " 9.81347078e-04 4.23372984e-03 4.22260810e-03 5.33017225e-03\n",
            " 5.33017225e-03 1.10247849e-03 2.10375731e-03 3.70333068e-03\n",
            " 2.20302786e-04 3.95266681e-04 5.68639002e-03 5.30512599e-03\n",
            " 2.63932406e-03 1.64481563e-04 5.96363974e-03 5.58249434e-03\n",
            " 5.91338705e-03 6.22041119e-03 5.36763213e-03 4.50012151e-03\n",
            " 2.89748119e-03 5.86425243e-03 5.72126490e-03 4.22260810e-03\n",
            " 1.28446797e-03 1.31766654e-03 4.80075264e-03 5.20666263e-03\n",
            " 3.48323081e-03 6.94352873e-04 5.65307149e-03 1.97311616e-03\n",
            " 1.16856596e-03 5.14417490e-03 6.00414215e-03 3.07788457e-03\n",
            " 1.27457702e-03 1.54198647e-03 6.31610468e-03 3.82289497e-03\n",
            " 4.04315307e-03 3.24885819e-03 3.35179815e-03 3.44594837e-04\n",
            " 1.05516758e-03 2.46459015e-03 5.92502678e-03 2.88293175e-04\n",
            " 4.80523442e-03 6.45265454e-03 2.99807997e-03 6.28401477e-03\n",
            " 4.50834926e-03 5.67507033e-03 5.91362335e-03 1.20200042e-03\n",
            " 5.74555022e-03]\n",
            "3860 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.66279980e-03 4.11223147e-03 3.96545893e-03 3.14635322e-03\n",
            " 7.06121403e-04 4.27527748e-03 4.82717787e-03 5.40738150e-03\n",
            " 1.36566388e-03 4.23113540e-03 5.71135142e-03 4.21961625e-03\n",
            " 1.35805068e-05 4.52726078e-03 3.12840866e-03 1.26100728e-04\n",
            " 1.79141376e-03 8.05475828e-09 4.40231533e-03 1.17299557e-05\n",
            " 5.77266658e-03 3.39567037e-04 6.95668953e-07 3.17477898e-03\n",
            " 5.71554143e-03 2.87148315e-03 1.03451598e-03 2.88380716e-03\n",
            " 2.67414993e-04 1.07592549e-03 2.36688023e-03 4.07646571e-04\n",
            " 6.53099685e-03 4.92140882e-03 3.72789951e-04 3.64600277e-03\n",
            " 3.22558884e-03 9.84216854e-04 5.86510606e-04 9.30967463e-04\n",
            " 5.15804094e-03 6.09605503e-05 4.21223109e-03 2.06385427e-03\n",
            " 1.80084004e-03 2.28166927e-03 4.89752617e-03 3.20367819e-03\n",
            " 9.94045584e-05 2.91191690e-03 3.20367819e-03 1.20002665e-03\n",
            " 1.57670718e-03 4.32336936e-05 3.38387138e-03 2.78825799e-03\n",
            " 5.70072147e-03 4.88433100e-03 8.05475828e-09 6.10208722e-03\n",
            " 6.35669380e-03 1.21649756e-03 3.97910714e-03 1.91490864e-03\n",
            " 5.88496395e-03 2.00682586e-03 4.60729004e-03 6.02428682e-03\n",
            " 6.00984561e-03 5.30376396e-03 3.01443723e-03 4.34999241e-03\n",
            " 3.64600277e-03 5.49309056e-03 6.07260069e-03 1.95244666e-03\n",
            " 1.87210729e-04 4.14711021e-03 3.80803890e-03 6.58286683e-04\n",
            " 3.18767935e-03 6.29132258e-03 7.69647470e-07 6.36037783e-05\n",
            " 6.46859625e-04 2.97190631e-03 2.70765360e-03 6.12416383e-03\n",
            " 3.53799514e-04 5.09210580e-03 1.69493682e-03 1.02502868e-03\n",
            " 4.60261294e-03 5.80988472e-03 5.19648030e-03 4.22940298e-03\n",
            " 4.95013868e-03 5.94271836e-03 3.09148390e-03 3.64600277e-03\n",
            " 3.53269447e-03 1.08476585e-03 1.42004379e-03 6.23924022e-03\n",
            " 2.26739378e-03 5.48347528e-03 2.14252066e-04 5.03256052e-17\n",
            " 3.88498070e-03 2.50147741e-04 2.30069047e-03 3.62462374e-03\n",
            " 3.10158027e-03 3.08755328e-03 3.04057131e-03 5.50201214e-03\n",
            " 1.83777257e-03 2.30456983e-04 3.75227058e-03 3.50498835e-03\n",
            " 2.88895510e-04 1.64263702e-03 4.04397157e-03 2.42421102e-03\n",
            " 1.66451167e-04 4.98798912e-03 3.38859666e-03 4.49551668e-03\n",
            " 2.60661610e-03 6.17460865e-03 5.24275361e-03 5.40738150e-03\n",
            " 4.14016571e-03 2.23184493e-04 2.06692046e-03 4.21223109e-03\n",
            " 1.72076967e-03 2.46205364e-03 1.56976382e-03 1.34932087e-03\n",
            " 4.97448215e-03 2.34733262e-03 5.49309056e-03 3.67107492e-03\n",
            " 2.09393385e-03 6.19830921e-03 3.48443531e-03 3.00094158e-03\n",
            " 5.60994283e-03 3.23492724e-03 3.05001990e-06 1.20007766e-03\n",
            " 3.02613185e-03 1.33044183e-03 1.27491411e-05 2.13894447e-03\n",
            " 2.13894495e-04 3.61063035e-03 2.52044238e-03 1.29197211e-03\n",
            " 5.62329417e-04 2.44343439e-03 1.08429165e-03 1.73066129e-03\n",
            " 1.08706928e-03 3.76503558e-03 5.71680955e-05 6.41648099e-04\n",
            " 1.37903532e-03 6.00504040e-03 1.29197211e-03 2.64086480e-03\n",
            " 3.74786698e-03 4.26996382e-03 1.99171518e-03 4.73083445e-03\n",
            " 3.59183772e-03 3.65717040e-04 3.82458459e-03 3.08748501e-03\n",
            " 2.23184493e-04 4.20104867e-03 5.96089970e-03 3.39530762e-03\n",
            " 3.90712637e-03 5.15581344e-04 1.62515226e-03 1.26800150e-03\n",
            " 4.33678725e-03 7.06121403e-04 3.45761992e-03 2.84711906e-04\n",
            " 1.29197211e-03 6.08285958e-03 5.16130681e-03 6.43035267e-03\n",
            " 6.38164603e-03 2.32009292e-03 3.35500581e-03 1.94970018e-03\n",
            " 2.11015116e-04 4.21223109e-03 3.02613185e-03 1.26901843e-03\n",
            " 4.84400777e-03 6.41975484e-04 5.44942346e-03 5.24269669e-03\n",
            " 1.17816829e-03 5.91238948e-03 1.76175229e-04 6.02217205e-03\n",
            " 2.19681212e-03 4.45527504e-03 2.79491522e-03 3.38387138e-03\n",
            " 2.91191690e-03 6.08067375e-03 3.95579188e-03 2.10229581e-03\n",
            " 4.22625663e-04 2.53092403e-03 4.49771833e-03 3.94022201e-03\n",
            " 6.40084574e-04 2.44937753e-03 5.82196033e-03 6.53937092e-03\n",
            " 4.87447119e-04 3.40786455e-03 2.35125093e-03 6.31461522e-03\n",
            " 2.64086480e-03 9.87729013e-04 2.08016564e-03 5.01640993e-03\n",
            " 3.83710088e-03 3.82470687e-03 1.21789081e-03 3.96839756e-03\n",
            " 3.12860349e-03 6.55245637e-03 4.64767824e-03 2.99119250e-03\n",
            " 6.43003089e-03 9.22381334e-04 5.84984487e-04 4.52726078e-03\n",
            " 7.39690610e-04 3.12361227e-04 1.02747341e-03 1.88055459e-03\n",
            " 3.17477898e-03 7.49869269e-05 6.15469880e-03 5.69880567e-03\n",
            " 3.31835196e-06 5.80085341e-04 6.02284286e-06 1.79368035e-05\n",
            " 4.04856879e-05 1.14900854e-03 9.79189328e-04 4.22955070e-03\n",
            " 4.21961625e-03 5.32389417e-03 5.32389417e-03 1.10063044e-03\n",
            " 2.09869649e-03 3.69940784e-03 2.19341376e-04 3.94343861e-04\n",
            " 5.68063604e-03 5.29633821e-03 2.63617383e-03 1.63987537e-04\n",
            " 5.95895788e-03 5.57777544e-03 5.91166292e-03 6.21655901e-03\n",
            " 5.36692713e-03 4.49551668e-03 2.89349316e-03 5.85924904e-03\n",
            " 5.71053665e-03 4.21961625e-03 1.28285594e-03 1.31455681e-03\n",
            " 4.79530741e-03 5.20326734e-03 3.48036539e-03 6.91691003e-04\n",
            " 5.64630406e-03 1.96720208e-03 1.16410652e-03 5.13845557e-03\n",
            " 5.99619085e-03 3.07187829e-03 1.27248483e-03 1.54066074e-03\n",
            " 6.30182193e-03 3.82097730e-03 4.02597319e-03 3.24552576e-03\n",
            " 3.35016260e-03 3.44070507e-04 1.05280529e-03 2.46001636e-03\n",
            " 5.92239280e-03 2.87070304e-04 4.80640302e-03 6.45045573e-03\n",
            " 2.99575703e-03 6.28275216e-03 4.50705073e-03 5.67092077e-03\n",
            " 5.91391881e-03 1.20007766e-03 5.74275109e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3870 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.66006219e-03 4.11101551e-03 3.96293431e-03 3.14204929e-03\n",
            " 7.05676525e-04 4.27381598e-03 4.83225355e-03 5.40505987e-03\n",
            " 1.36380184e-03 4.22675199e-03 5.70805979e-03 4.22188648e-03\n",
            " 1.35209667e-05 4.52562404e-03 3.11380365e-03 1.25534934e-04\n",
            " 1.78715642e-03 7.90237261e-09 4.39780017e-03 1.17107648e-05\n",
            " 5.76248409e-03 3.37419667e-04 6.82696289e-07 3.17633353e-03\n",
            " 5.70450504e-03 2.86704720e-03 1.03157879e-03 2.87951701e-03\n",
            " 2.66084565e-04 1.07385117e-03 2.36156507e-03 4.07236737e-04\n",
            " 4.92233314e-03 3.71594294e-04 3.64052499e-03 3.21681670e-03\n",
            " 9.81325320e-04 5.85236397e-04 9.29445951e-04 5.15141482e-03\n",
            " 6.06859516e-05 4.21025639e-03 2.06232868e-03 1.79916956e-03\n",
            " 2.27939930e-03 4.88992087e-03 3.19863621e-03 9.93586719e-05\n",
            " 2.90057933e-03 3.19863621e-03 1.19990088e-03 1.57380920e-03\n",
            " 4.31929236e-05 3.38155386e-03 2.78403489e-03 5.69222706e-03\n",
            " 4.88388157e-03 7.90237261e-09 6.09569513e-03 1.21425431e-03\n",
            " 3.97299920e-03 1.90714586e-03 5.87375696e-03 2.00599814e-03\n",
            " 4.60532750e-03 6.02040914e-03 6.01059029e-03 5.30775860e-03\n",
            " 3.01433822e-03 4.34394803e-03 3.64052499e-03 5.48926292e-03\n",
            " 6.06379009e-03 1.94740830e-03 1.86700991e-04 4.14029261e-03\n",
            " 3.80472240e-03 6.57640755e-04 3.18881806e-03 6.28574726e-03\n",
            " 7.68701086e-07 6.34940516e-05 6.46263317e-04 2.96579924e-03\n",
            " 2.70360043e-03 6.11896495e-03 3.53741596e-04 5.08398220e-03\n",
            " 1.68707795e-03 1.02263435e-03 4.60295465e-03 5.79829483e-03\n",
            " 5.19492449e-03 4.22672108e-03 4.93520398e-03 5.92962834e-03\n",
            " 3.08309891e-03 3.64052499e-03 3.52107382e-03 1.08273848e-03\n",
            " 1.42056542e-03 6.23008405e-03 2.26138299e-03 5.48116285e-03\n",
            " 2.14141296e-04 5.02358614e-17 3.88384752e-03 2.49940842e-04\n",
            " 2.30323253e-03 3.61766234e-03 3.10314688e-03 3.08752876e-03\n",
            " 3.02512131e-03 5.48352790e-03 1.83326612e-03 2.29396261e-04\n",
            " 3.75072641e-03 3.50436764e-03 2.88403570e-04 1.63954583e-03\n",
            " 4.04385779e-03 2.42284221e-03 1.65828020e-04 4.98242568e-03\n",
            " 3.38851731e-03 4.49584074e-03 2.60616772e-03 6.17374617e-03\n",
            " 5.23890047e-03 5.40505987e-03 4.13611811e-03 2.22082784e-04\n",
            " 2.06180826e-03 4.21025639e-03 1.71938328e-03 2.45165350e-03\n",
            " 1.56897882e-03 1.34959413e-03 4.96802979e-03 2.34285972e-03\n",
            " 5.48926292e-03 3.66531862e-03 2.09073591e-03 6.19451734e-03\n",
            " 3.47907663e-03 2.99932140e-03 5.60585089e-03 3.22819670e-03\n",
            " 3.04010975e-06 1.19347419e-03 3.02802541e-03 1.32910536e-03\n",
            " 1.26660531e-05 2.13831491e-03 2.13772960e-04 3.60520315e-03\n",
            " 2.51429767e-03 1.28991755e-03 5.61584654e-04 2.43968774e-03\n",
            " 1.08151231e-03 1.72784733e-03 1.08460009e-03 3.75932932e-03\n",
            " 5.71446577e-05 6.39763705e-04 1.37555384e-03 6.00260711e-03\n",
            " 1.28991755e-03 2.63284397e-03 3.74542384e-03 4.27151097e-03\n",
            " 1.99025379e-03 4.72569112e-03 3.58984499e-03 3.65504122e-04\n",
            " 3.81989070e-03 3.07805384e-03 2.22082784e-04 4.20111409e-03\n",
            " 5.96176244e-03 3.38610179e-03 3.90078335e-03 5.13618572e-04\n",
            " 1.62437922e-03 1.26736985e-03 4.33569137e-03 7.05676525e-04\n",
            " 3.45064110e-03 2.83816138e-04 1.28991755e-03 6.08161025e-03\n",
            " 5.15613744e-03 2.31410425e-03 3.35109335e-03 1.94309271e-03\n",
            " 2.10651294e-04 4.21025639e-03 3.02802541e-03 1.26877545e-03\n",
            " 4.84321553e-03 6.40679854e-04 5.44811339e-03 5.23856514e-03\n",
            " 1.17403724e-03 5.91105371e-03 1.75963497e-04 6.01732021e-03\n",
            " 2.19605588e-03 4.45476715e-03 2.78931735e-03 3.38155386e-03\n",
            " 2.90057933e-03 6.07338129e-03 3.95392131e-03 2.09934829e-03\n",
            " 4.22238741e-04 2.52656353e-03 4.49793745e-03 3.93288489e-03\n",
            " 6.37949778e-04 2.44334378e-03 5.81495246e-03 4.85491957e-04\n",
            " 3.39974964e-03 2.34321424e-03 2.63284397e-03 9.86451548e-04\n",
            " 2.07730573e-03 5.00623010e-03 3.83760389e-03 3.81605387e-03\n",
            " 1.21675547e-03 3.96527109e-03 3.12385560e-03 4.63427983e-03\n",
            " 2.98869194e-03 9.18271207e-04 5.84735906e-04 4.52562404e-03\n",
            " 7.39560686e-04 3.11198758e-04 1.02343750e-03 1.88001048e-03\n",
            " 3.17633353e-03 7.48714462e-05 6.14972014e-03 5.69543295e-03\n",
            " 3.30474003e-06 5.78678678e-04 6.03181993e-06 1.79131663e-05\n",
            " 4.03684667e-05 1.14819790e-03 9.78360421e-04 4.22610156e-03\n",
            " 4.22188648e-03 5.32177485e-03 5.32177485e-03 1.10005555e-03\n",
            " 2.09578361e-03 3.69360729e-03 2.19234093e-04 3.93923290e-04\n",
            " 5.67518711e-03 5.28964050e-03 2.62931323e-03 1.63225260e-04\n",
            " 5.96034081e-03 5.57046961e-03 5.90115665e-03 6.20011309e-03\n",
            " 5.36654247e-03 4.49584074e-03 2.89263127e-03 5.84634953e-03\n",
            " 5.70645611e-03 4.22188648e-03 1.27861242e-03 1.31256291e-03\n",
            " 4.79559344e-03 5.20387549e-03 3.47604555e-03 6.90269737e-04\n",
            " 5.64029082e-03 1.96531039e-03 1.16350054e-03 5.13316971e-03\n",
            " 5.99221425e-03 3.07109224e-03 1.26945578e-03 1.53618833e-03\n",
            " 3.81575026e-03 4.02141880e-03 3.23850303e-03 3.35014582e-03\n",
            " 3.43429984e-04 1.05188770e-03 2.45944652e-03 5.91790062e-03\n",
            " 2.86473545e-04 4.80647770e-03 2.99263733e-03 6.28385803e-03\n",
            " 4.50353281e-03 5.66713193e-03 5.90116068e-03 1.19347419e-03\n",
            " 5.73273681e-03]\n",
            "3880 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.66137934e-03 4.11211150e-03 3.96319661e-03 3.13766751e-03\n",
            " 7.05362292e-04 4.27333902e-03 4.82273422e-03 5.40471333e-03\n",
            " 1.36350752e-03 4.22637511e-03 5.70391287e-03 4.21890222e-03\n",
            " 1.34834466e-05 4.52009365e-03 3.11202874e-03 1.25243116e-04\n",
            " 1.78504987e-03 7.84548656e-09 4.39235608e-03 1.16373187e-05\n",
            " 5.75406361e-03 3.36840067e-04 6.76306502e-07 3.17364776e-03\n",
            " 5.70712401e-03 2.86521265e-03 1.02852279e-03 2.87158474e-03\n",
            " 2.65696726e-04 1.07351469e-03 2.34922866e-03 4.04692415e-04\n",
            " 4.92128260e-03 3.71548108e-04 3.63798536e-03 3.21443477e-03\n",
            " 9.78794995e-04 5.84681813e-04 9.26162538e-04 5.15028590e-03\n",
            " 6.05096892e-05 4.21075812e-03 2.06184621e-03 1.79322113e-03\n",
            " 2.28089121e-03 4.88439469e-03 3.19609519e-03 9.89345218e-05\n",
            " 2.88716402e-03 3.19609519e-03 1.19862238e-03 1.57327716e-03\n",
            " 4.30383064e-05 3.38343441e-03 2.78243280e-03 5.68788380e-03\n",
            " 4.87426882e-03 7.84548656e-09 1.21048496e-03 3.96980712e-03\n",
            " 1.90700010e-03 5.85738609e-03 2.00223849e-03 4.60217573e-03\n",
            " 6.01565731e-03 6.00192389e-03 5.30472426e-03 3.01389800e-03\n",
            " 4.34427376e-03 3.63798536e-03 5.48470644e-03 6.05878886e-03\n",
            " 1.94768990e-03 1.86346288e-04 4.14216003e-03 3.80651942e-03\n",
            " 6.56849261e-04 3.18483493e-03 7.67902432e-07 6.33255019e-05\n",
            " 6.45915315e-04 2.96477117e-03 2.70298035e-03 3.53853872e-04\n",
            " 5.07749632e-03 1.68627625e-03 1.02181958e-03 4.59858003e-03\n",
            " 5.79987108e-03 5.19039468e-03 4.22241936e-03 4.93003064e-03\n",
            " 5.92259517e-03 3.07994506e-03 3.63798536e-03 3.51775509e-03\n",
            " 1.08194344e-03 1.41842472e-03 2.25303227e-03 5.47709126e-03\n",
            " 2.14031728e-04 4.93855383e-17 3.88629332e-03 2.49651103e-04\n",
            " 2.30184369e-03 3.61363295e-03 3.10160933e-03 3.08780552e-03\n",
            " 3.01874231e-03 5.48135968e-03 1.82885027e-03 2.28706899e-04\n",
            " 3.75274818e-03 3.49517671e-03 2.88443673e-04 1.63872391e-03\n",
            " 4.04324768e-03 2.41501492e-03 1.65825414e-04 4.98197672e-03\n",
            " 3.38413151e-03 4.49470760e-03 2.60328346e-03 5.23670235e-03\n",
            " 5.40471333e-03 4.13060550e-03 2.21373563e-04 2.06055427e-03\n",
            " 4.21075812e-03 1.71602486e-03 2.44584929e-03 1.56785369e-03\n",
            " 1.34941221e-03 4.95874893e-03 2.33622104e-03 5.48470644e-03\n",
            " 3.66398812e-03 2.08177405e-03 3.47660707e-03 2.99651534e-03\n",
            " 5.60844930e-03 3.22133882e-03 3.02680521e-06 1.19161048e-03\n",
            " 3.02667014e-03 1.32883714e-03 1.26501864e-05 2.13883420e-03\n",
            " 2.13637226e-04 3.60004065e-03 2.51373770e-03 1.28788869e-03\n",
            " 5.60802587e-04 2.43237525e-03 1.07932095e-03 1.72812320e-03\n",
            " 1.08475072e-03 3.75678446e-03 5.70558039e-05 6.39507036e-04\n",
            " 1.36916040e-03 6.00595157e-03 1.28788869e-03 2.62904377e-03\n",
            " 3.74331184e-03 4.27090829e-03 1.98906465e-03 4.70505925e-03\n",
            " 3.58502546e-03 3.65259920e-04 3.81165841e-03 3.07434005e-03\n",
            " 2.21373563e-04 4.19198970e-03 5.96034983e-03 3.38602856e-03\n",
            " 3.89923917e-03 5.11527680e-04 1.62287184e-03 1.26668722e-03\n",
            " 4.32738676e-03 7.05362292e-04 3.44654626e-03 2.82792827e-04\n",
            " 1.28788869e-03 5.15497378e-03 2.30994189e-03 3.34343100e-03\n",
            " 1.93572416e-03 2.10623504e-04 4.21075812e-03 3.02667014e-03\n",
            " 1.26746499e-03 4.82824014e-03 6.40644736e-04 5.44363690e-03\n",
            " 5.22509301e-03 1.17284796e-03 5.90818238e-03 1.75701347e-04\n",
            " 6.01863241e-03 2.19236097e-03 4.45124907e-03 2.78686015e-03\n",
            " 3.38343441e-03 2.88716402e-03 6.07085368e-03 3.94477145e-03\n",
            " 2.09515032e-03 4.21243948e-04 2.52482347e-03 4.49831981e-03\n",
            " 3.93253656e-03 6.35415379e-04 2.43314432e-03 5.81379164e-03\n",
            " 4.84807799e-04 3.40131256e-03 2.33953598e-03 2.62904377e-03\n",
            " 9.86114194e-04 2.07477994e-03 5.00447720e-03 3.83722891e-03\n",
            " 3.80943799e-03 1.21597930e-03 3.96308040e-03 3.11959746e-03\n",
            " 4.62795040e-03 2.98464321e-03 9.17401890e-04 5.84388407e-04\n",
            " 4.52009365e-03 7.37619118e-04 3.10186348e-04 1.02236745e-03\n",
            " 1.87997115e-03 3.17364776e-03 7.46526882e-05 5.68406631e-03\n",
            " 3.28501794e-06 5.77795233e-04 5.99397859e-06 1.78870179e-05\n",
            " 4.03731087e-05 1.14753931e-03 9.78152524e-04 4.22153966e-03\n",
            " 4.21890222e-03 5.31975242e-03 5.31975242e-03 1.09911508e-03\n",
            " 2.09391123e-03 3.69269838e-03 2.18502842e-04 3.93395850e-04\n",
            " 5.66850164e-03 5.28205243e-03 2.61894330e-03 1.62494303e-04\n",
            " 5.95612548e-03 5.56506443e-03 5.88880551e-03 5.36540000e-03\n",
            " 4.49470760e-03 2.88762626e-03 5.83689198e-03 5.70269823e-03\n",
            " 4.21890222e-03 1.27634933e-03 1.31059509e-03 4.79401576e-03\n",
            " 5.20028791e-03 3.47447093e-03 6.88438719e-04 5.64058410e-03\n",
            " 1.95998384e-03 1.16046514e-03 5.13108061e-03 5.98288717e-03\n",
            " 3.06996712e-03 1.26844478e-03 1.53398033e-03 3.81559279e-03\n",
            " 4.01398771e-03 3.22912773e-03 3.34949142e-03 3.43587798e-04\n",
            " 1.05166618e-03 2.45569429e-03 5.91299220e-03 2.85493255e-04\n",
            " 4.80362357e-03 2.98999460e-03 4.50330262e-03 5.65811471e-03\n",
            " 5.90217939e-03 1.19161048e-03 5.72254010e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3890 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.65787731e-03 4.10958079e-03 3.96493334e-03 3.13594567e-03\n",
            " 7.05393219e-04 4.26034950e-03 4.82061559e-03 5.40360540e-03\n",
            " 1.36116415e-03 4.22049970e-03 5.67496533e-03 4.21890269e-03\n",
            " 1.34301680e-05 4.52080797e-03 3.11332052e-03 1.24633033e-04\n",
            " 1.78303138e-03 7.80258112e-09 4.38497412e-03 1.15904819e-05\n",
            " 5.74199455e-03 3.36168710e-04 6.71951457e-07 3.17372374e-03\n",
            " 5.69770540e-03 2.85967410e-03 1.02492913e-03 2.86370559e-03\n",
            " 2.65308660e-04 1.07278717e-03 2.34895004e-03 4.04648451e-04\n",
            " 4.91132024e-03 3.70486629e-04 3.63581016e-03 3.21111085e-03\n",
            " 9.76978773e-04 5.83991672e-04 9.24892745e-04 5.14835310e-03\n",
            " 6.02615537e-05 4.20633721e-03 2.05910039e-03 1.79151156e-03\n",
            " 2.28039477e-03 4.88125117e-03 3.19509297e-03 9.86448609e-05\n",
            " 2.87642233e-03 3.19509297e-03 1.19831105e-03 1.57165740e-03\n",
            " 4.28774866e-05 3.38394870e-03 2.77715497e-03 5.67266637e-03\n",
            " 4.86755292e-03 7.80258112e-09 1.20834507e-03 3.96636203e-03\n",
            " 1.90460517e-03 5.85581346e-03 2.00019834e-03 4.60169124e-03\n",
            " 5.30186342e-03 3.01342395e-03 4.33520011e-03 3.63581016e-03\n",
            " 5.48730549e-03 1.94725904e-03 1.86087770e-04 4.14039411e-03\n",
            " 3.80443043e-03 6.56256876e-04 3.17789926e-03 7.64830511e-07\n",
            " 6.31268395e-05 6.45261962e-04 2.96131988e-03 2.70004662e-03\n",
            " 3.53564373e-04 5.07356768e-03 1.68570044e-03 1.01950967e-03\n",
            " 4.59669304e-03 5.80134977e-03 5.18498539e-03 4.21514631e-03\n",
            " 4.93017295e-03 3.07241662e-03 3.63581016e-03 3.51506904e-03\n",
            " 1.07952431e-03 1.41653236e-03 2.25158923e-03 5.46845748e-03\n",
            " 2.13617743e-04 4.85956265e-17 3.88295487e-03 2.48911688e-04\n",
            " 2.30027301e-03 3.60967281e-03 3.10013520e-03 3.08485889e-03\n",
            " 3.01815473e-03 5.47792473e-03 1.82625579e-03 2.28006138e-04\n",
            " 3.74484351e-03 3.48718057e-03 2.87879150e-04 1.63860436e-03\n",
            " 4.03742451e-03 2.41309475e-03 1.65507476e-04 4.97486360e-03\n",
            " 3.38045811e-03 4.49293738e-03 2.60117848e-03 5.23235900e-03\n",
            " 5.40360540e-03 4.12885674e-03 2.20999921e-04 2.05552451e-03\n",
            " 4.20633721e-03 1.71595628e-03 2.44447477e-03 1.56841376e-03\n",
            " 1.34929695e-03 4.95686639e-03 2.33192945e-03 5.48730549e-03\n",
            " 3.65873821e-03 2.07417922e-03 3.47328023e-03 2.99392984e-03\n",
            " 5.60375473e-03 3.21778304e-03 3.01697887e-06 1.18876587e-03\n",
            " 3.02501468e-03 1.32802493e-03 1.26073586e-05 2.13612958e-03\n",
            " 2.12842967e-04 3.59633919e-03 2.50454330e-03 1.28588176e-03\n",
            " 5.60200005e-04 2.43142141e-03 1.07692993e-03 1.72700928e-03\n",
            " 1.08333185e-03 3.75046664e-03 5.70271844e-05 6.38794362e-04\n",
            " 1.36670905e-03 1.28588176e-03 2.62314555e-03 3.73925751e-03\n",
            " 4.27239390e-03 1.98798507e-03 4.70436629e-03 3.57964364e-03\n",
            " 3.65065738e-04 3.79826101e-03 3.07228386e-03 2.20999921e-04\n",
            " 4.19026850e-03 3.38164708e-03 3.89841658e-03 5.11413681e-04\n",
            " 1.61869947e-03 1.26486429e-03 4.32466500e-03 7.05393219e-04\n",
            " 3.43489573e-03 2.82503562e-04 1.28588176e-03 5.14293460e-03\n",
            " 2.30747750e-03 3.33925806e-03 1.93252360e-03 2.10588637e-04\n",
            " 4.20633721e-03 3.02501468e-03 1.26766661e-03 4.81765421e-03\n",
            " 6.38771334e-04 5.44481251e-03 5.22285402e-03 1.16973891e-03\n",
            " 5.90777017e-03 1.75685836e-04 2.18798212e-03 4.45295042e-03\n",
            " 2.78359208e-03 3.38394870e-03 2.87642233e-03 3.93822121e-03\n",
            " 2.09396348e-03 4.20036651e-04 2.51609546e-03 4.49484010e-03\n",
            " 3.92478037e-03 6.33246424e-04 2.43356194e-03 5.80347993e-03\n",
            " 4.83579041e-04 3.39412620e-03 2.33271584e-03 2.62314555e-03\n",
            " 9.84300972e-04 2.07475366e-03 4.99723332e-03 3.83725122e-03\n",
            " 3.80795136e-03 1.21313689e-03 3.96205001e-03 3.11482412e-03\n",
            " 4.62304888e-03 2.98078045e-03 9.16878077e-04 5.84088144e-04\n",
            " 4.52080797e-03 7.35044632e-04 3.09588051e-04 1.02166282e-03\n",
            " 1.87985032e-03 3.17372374e-03 7.44006892e-05 5.68193004e-03\n",
            " 3.26507547e-06 5.75865874e-04 5.98150275e-06 1.78019706e-05\n",
            " 4.02823998e-05 1.14537475e-03 9.76860407e-04 4.21249507e-03\n",
            " 4.21890269e-03 5.31874330e-03 5.31874330e-03 1.09875735e-03\n",
            " 2.09106184e-03 3.68607457e-03 2.17571184e-04 3.92682761e-04\n",
            " 5.66255802e-03 5.27652408e-03 2.61778109e-03 1.62334983e-04\n",
            " 5.56177890e-03 5.87925951e-03 5.36518381e-03 4.49293738e-03\n",
            " 2.88217886e-03 5.83180996e-03 5.69112175e-03 4.21890269e-03\n",
            " 1.27630560e-03 1.30956945e-03 4.77952815e-03 5.20035453e-03\n",
            " 3.47363752e-03 6.86781485e-04 5.63622765e-03 1.95582307e-03\n",
            " 1.15874402e-03 5.12234320e-03 3.06217149e-03 1.26823374e-03\n",
            " 1.53137498e-03 3.81172843e-03 4.00933608e-03 3.22714071e-03\n",
            " 3.34894468e-03 3.43011731e-04 1.05057171e-03 2.45267472e-03\n",
            " 5.91384603e-03 2.84885342e-04 4.79632599e-03 2.98900349e-03\n",
            " 4.50045764e-03 5.65346726e-03 5.90108695e-03 1.18876587e-03\n",
            " 5.71538349e-03]\n",
            "3900 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.65446300e-03 4.10700351e-03 3.96195179e-03 3.13036091e-03\n",
            " 7.05259341e-04 4.25349401e-03 4.81894961e-03 5.40081950e-03\n",
            " 1.35868301e-03 4.21178513e-03 5.67174259e-03 4.21518686e-03\n",
            " 1.33712393e-05 4.51818719e-03 3.10798080e-03 1.24182025e-04\n",
            " 1.78136415e-03 7.74761398e-09 4.38688776e-03 1.15577036e-05\n",
            " 3.35118263e-04 6.66633486e-07 3.17028016e-03 5.69486058e-03\n",
            " 2.85738733e-03 1.02131803e-03 2.86297028e-03 2.64609986e-04\n",
            " 1.07209249e-03 2.34492397e-03 4.04331152e-04 4.91088665e-03\n",
            " 3.69744432e-04 3.63467637e-03 3.20493952e-03 9.75457737e-04\n",
            " 5.83128070e-04 9.24250588e-04 5.14793589e-03 5.99868109e-05\n",
            " 4.20488288e-03 2.05890254e-03 1.79008133e-03 2.28053216e-03\n",
            " 4.87892410e-03 3.19444687e-03 9.81504135e-05 2.87079704e-03\n",
            " 3.19444687e-03 1.19792884e-03 1.57181424e-03 4.27878270e-05\n",
            " 3.38245515e-03 2.77553623e-03 5.66429657e-03 4.86310926e-03\n",
            " 7.74761398e-09 1.20631431e-03 3.96194448e-03 1.90139196e-03\n",
            " 2.00020719e-03 4.59951950e-03 5.30016686e-03 3.01097763e-03\n",
            " 4.33253388e-03 3.63467637e-03 5.47940615e-03 1.94580067e-03\n",
            " 1.85755275e-04 4.13778978e-03 3.80438576e-03 6.55323728e-04\n",
            " 3.17463375e-03 7.62425646e-07 6.29620454e-05 6.45014391e-04\n",
            " 2.95948822e-03 2.69929348e-03 3.52962336e-04 5.07330888e-03\n",
            " 1.68131375e-03 1.01885446e-03 4.59293807e-03 5.18238376e-03\n",
            " 4.21197816e-03 4.92611593e-03 3.07043857e-03 3.63467637e-03\n",
            " 3.51393788e-03 1.07789914e-03 1.41386577e-03 2.24936273e-03\n",
            " 5.46760058e-03 2.13294543e-04 4.81056062e-17 3.87688599e-03\n",
            " 2.48611028e-04 2.29917870e-03 3.60697699e-03 3.09738395e-03\n",
            " 3.08107033e-03 3.01135472e-03 5.46972887e-03 1.82542997e-03\n",
            " 2.27728416e-04 3.74320927e-03 3.48332664e-03 2.87321650e-04\n",
            " 1.63583031e-03 4.03100818e-03 2.41015330e-03 1.65284528e-04\n",
            " 4.96677637e-03 3.37983622e-03 4.49114992e-03 2.60041206e-03\n",
            " 5.22383530e-03 5.40081950e-03 4.12445818e-03 2.20484851e-04\n",
            " 2.05068878e-03 4.20488288e-03 1.71374661e-03 2.43997789e-03\n",
            " 1.56827690e-03 1.34820587e-03 4.95092332e-03 2.33014833e-03\n",
            " 5.47940615e-03 3.65689855e-03 2.07333738e-03 3.46913686e-03\n",
            " 2.99408005e-03 5.60016076e-03 3.20993217e-03 3.00497956e-06\n",
            " 1.18792992e-03 3.02281550e-03 1.32800141e-03 1.25611622e-05\n",
            " 2.13546182e-03 2.12643529e-04 3.59527490e-03 2.50364230e-03\n",
            " 1.28487693e-03 5.59082118e-04 2.42845175e-03 1.07360129e-03\n",
            " 1.72595393e-03 1.08244725e-03 3.74513728e-03 5.69734763e-05\n",
            " 6.38540058e-04 1.36038664e-03 1.28487693e-03 2.61942891e-03\n",
            " 3.73575527e-03 4.27181915e-03 1.98594731e-03 4.69775398e-03\n",
            " 3.57718967e-03 3.64267785e-04 3.79088304e-03 3.07049948e-03\n",
            " 2.20484851e-04 4.18891490e-03 3.37403304e-03 3.89250513e-03\n",
            " 5.10182740e-04 1.61849179e-03 1.26427816e-03 4.32147890e-03\n",
            " 7.05259341e-04 3.42716817e-03 2.81893270e-04 1.28487693e-03\n",
            " 5.13723727e-03 2.30381196e-03 3.33845451e-03 1.93053330e-03\n",
            " 2.10411304e-04 4.20488288e-03 3.02281550e-03 1.26548313e-03\n",
            " 4.80967898e-03 6.38101975e-04 5.43461405e-03 5.21803456e-03\n",
            " 1.16940415e-03 1.75634632e-04 2.18562110e-03 4.44921361e-03\n",
            " 2.77850098e-03 3.38245515e-03 2.87079704e-03 3.93437011e-03\n",
            " 2.09207239e-03 4.19419880e-04 2.51336414e-03 4.49424492e-03\n",
            " 3.92148917e-03 6.31822516e-04 2.42979811e-03 4.82973742e-04\n",
            " 3.38955238e-03 2.33030591e-03 2.61942891e-03 9.82876880e-04\n",
            " 2.07183465e-03 4.98982892e-03 3.83526837e-03 3.80092093e-03\n",
            " 1.21328105e-03 3.95766234e-03 3.11152601e-03 4.61196291e-03\n",
            " 2.97876979e-03 9.14571188e-04 5.84032199e-04 4.51818719e-03\n",
            " 7.33194138e-04 3.09003143e-04 1.02002093e-03 1.88015053e-03\n",
            " 3.17028016e-03 7.42689112e-05 5.67636165e-03 3.24244340e-06\n",
            " 5.74049304e-04 5.97763158e-06 1.77657837e-05 4.02754499e-05\n",
            " 1.14494488e-03 9.76658442e-04 4.20463341e-03 4.21518686e-03\n",
            " 5.31655143e-03 5.31655143e-03 1.09713134e-03 2.08855047e-03\n",
            " 3.68139961e-03 2.17071710e-04 3.92186971e-04 5.65734845e-03\n",
            " 5.27058166e-03 2.61328252e-03 1.62093535e-04 5.56243258e-03\n",
            " 5.36595922e-03 4.49114992e-03 2.87964690e-03 5.69370707e-03\n",
            " 4.21518686e-03 1.27435032e-03 1.30679666e-03 4.77507037e-03\n",
            " 5.19863047e-03 3.47082082e-03 6.85190122e-04 5.62509363e-03\n",
            " 1.95198501e-03 1.15652696e-03 5.11109195e-03 3.06018497e-03\n",
            " 1.26607691e-03 1.52990770e-03 3.80998256e-03 4.00746102e-03\n",
            " 3.22192591e-03 3.34614960e-03 3.42263086e-04 1.05034857e-03\n",
            " 2.45245022e-03 2.84072425e-04 4.78604646e-03 2.98617424e-03\n",
            " 4.49788668e-03 5.64407508e-03 1.18792992e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3910 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.64614824e-03 4.09744612e-03 3.96044347e-03 3.12789364e-03\n",
            " 7.04889862e-04 4.25009075e-03 4.81611259e-03 5.40240644e-03\n",
            " 1.35701733e-03 4.20372805e-03 4.21301623e-03 1.33370034e-05\n",
            " 4.51808006e-03 3.10516267e-03 1.23510216e-04 1.78009635e-03\n",
            " 7.71911344e-09 4.38300171e-03 1.15533473e-05 3.34803550e-04\n",
            " 6.62196457e-07 3.16889586e-03 2.85095066e-03 1.01910837e-03\n",
            " 2.85425324e-03 2.63607293e-04 1.07039653e-03 2.33960477e-03\n",
            " 4.04344852e-04 4.91118212e-03 3.69320284e-04 3.63249543e-03\n",
            " 3.20149469e-03 9.75467994e-04 5.81838119e-04 9.21800855e-04\n",
            " 5.13716507e-03 5.98370397e-05 4.20088593e-03 2.05663103e-03\n",
            " 1.78816933e-03 2.27608870e-03 4.87887108e-03 3.19313896e-03\n",
            " 9.77681607e-05 2.86537032e-03 3.19313896e-03 1.19681570e-03\n",
            " 1.56930383e-03 4.27402527e-05 3.38051535e-03 2.77562966e-03\n",
            " 4.86286136e-03 7.71911344e-09 1.20517098e-03 3.95516493e-03\n",
            " 1.89568162e-03 1.99686015e-03 4.60019895e-03 5.30306336e-03\n",
            " 3.01033014e-03 4.33034724e-03 3.63249543e-03 5.47659836e-03\n",
            " 1.94433886e-03 1.85237246e-04 4.13646288e-03 3.80146299e-03\n",
            " 6.54983907e-04 3.17245389e-03 7.59796755e-07 6.28529554e-05\n",
            " 6.43989886e-04 2.95811875e-03 2.69642384e-03 3.52752891e-04\n",
            " 5.06558631e-03 1.68224226e-03 1.01699832e-03 4.59357906e-03\n",
            " 5.17269805e-03 4.21022803e-03 4.92745265e-03 3.06585368e-03\n",
            " 3.63249543e-03 3.51104497e-03 1.07702912e-03 1.41321467e-03\n",
            " 2.24427157e-03 5.46619775e-03 2.12898785e-04 4.80072094e-17\n",
            " 3.86926723e-03 2.48492928e-04 2.29441928e-03 3.60199561e-03\n",
            " 3.09233858e-03 3.07949611e-03 3.00987129e-03 5.46087576e-03\n",
            " 1.82323838e-03 2.26970556e-04 3.73852766e-03 3.48435601e-03\n",
            " 2.87112215e-04 1.63327893e-03 4.02725699e-03 2.40715267e-03\n",
            " 1.65101990e-04 4.95806275e-03 3.37653449e-03 4.49109238e-03\n",
            " 2.59950275e-03 5.21534629e-03 5.40240644e-03 4.12239302e-03\n",
            " 2.20300898e-04 2.04857575e-03 4.20088593e-03 1.71323218e-03\n",
            " 2.43770046e-03 1.56790800e-03 1.34792159e-03 4.94730191e-03\n",
            " 2.33095254e-03 5.47659836e-03 3.65460235e-03 2.06436230e-03\n",
            " 3.46530390e-03 2.99119866e-03 3.20265879e-03 3.00264311e-06\n",
            " 1.18688998e-03 3.02441606e-03 1.32681480e-03 1.25402555e-05\n",
            " 2.13452292e-03 2.11889813e-04 3.59317706e-03 2.50038302e-03\n",
            " 1.28486814e-03 5.57779346e-04 2.42563121e-03 1.07208302e-03\n",
            " 1.72413987e-03 1.07983711e-03 3.74316602e-03 5.69441707e-05\n",
            " 6.37983015e-04 1.35981018e-03 1.28486814e-03 2.61556581e-03\n",
            " 3.72598315e-03 4.27155053e-03 1.98591851e-03 4.69135818e-03\n",
            " 3.57760356e-03 3.63996198e-04 3.78638234e-03 3.06511908e-03\n",
            " 2.20300898e-04 4.18247404e-03 3.36735028e-03 3.88650408e-03\n",
            " 5.09901905e-04 1.61418072e-03 1.26216488e-03 4.31834533e-03\n",
            " 7.04889862e-04 3.42393934e-03 2.81322844e-04 1.28486814e-03\n",
            " 5.12646999e-03 2.30016151e-03 3.33267334e-03 1.92754478e-03\n",
            " 2.10350792e-04 4.20088593e-03 3.02441606e-03 1.26540253e-03\n",
            " 4.80595369e-03 6.38048657e-04 5.42963287e-03 5.21342722e-03\n",
            " 1.16774031e-03 1.75666116e-04 2.18557243e-03 4.44418270e-03\n",
            " 2.76935369e-03 3.38051535e-03 2.86537032e-03 3.93488093e-03\n",
            " 2.09078372e-03 4.19573023e-04 2.50983220e-03 4.49244010e-03\n",
            " 3.91138067e-03 6.30658067e-04 2.42733662e-03 4.82535567e-04\n",
            " 3.38010250e-03 2.32463822e-03 2.61556581e-03 9.82057391e-04\n",
            " 2.07147754e-03 4.99008681e-03 3.83508836e-03 3.79629618e-03\n",
            " 1.21128933e-03 3.95239307e-03 3.10919357e-03 4.61063275e-03\n",
            " 2.97470556e-03 9.12844470e-04 5.83751151e-04 4.51808006e-03\n",
            " 7.32873680e-04 3.08102116e-04 1.01879632e-03 1.87891841e-03\n",
            " 3.16889586e-03 7.42223220e-05 3.20977029e-06 5.72081759e-04\n",
            " 5.98327568e-06 1.77344697e-05 4.01651716e-05 1.14343667e-03\n",
            " 9.75518978e-04 4.20370035e-03 4.21301623e-03 5.31509318e-03\n",
            " 5.31509318e-03 1.09661167e-03 2.08759950e-03 3.67545076e-03\n",
            " 2.17025709e-04 3.91569070e-04 5.26307354e-03 2.60748092e-03\n",
            " 1.61749433e-04 5.36532134e-03 4.49109238e-03 2.87874882e-03\n",
            " 4.21301623e-03 1.27357645e-03 1.30675324e-03 4.76775222e-03\n",
            " 5.19814312e-03 3.46745720e-03 6.84924190e-04 1.95115951e-03\n",
            " 1.15541680e-03 5.10891370e-03 3.05874727e-03 1.26536688e-03\n",
            " 1.52786732e-03 3.80258207e-03 4.00095726e-03 3.21892277e-03\n",
            " 3.34545306e-03 3.41827143e-04 1.04939048e-03 2.45208036e-03\n",
            " 2.84005436e-04 4.77957674e-03 2.98485998e-03 4.49641068e-03\n",
            " 1.18688998e-03]\n",
            "3920 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.64539765e-03 4.09418416e-03 3.95966618e-03 3.12789961e-03\n",
            " 7.03413236e-04 4.24904007e-03 4.81541504e-03 1.35777339e-03\n",
            " 4.20038877e-03 4.20763403e-03 1.33298265e-05 4.51039251e-03\n",
            " 3.10341775e-03 1.23422527e-04 1.77931399e-03 7.69107029e-09\n",
            " 4.38286303e-03 1.15295996e-05 3.34411468e-04 6.63514185e-07\n",
            " 3.16081301e-03 2.84946304e-03 1.01966221e-03 2.85160448e-03\n",
            " 2.63351827e-04 1.07106328e-03 2.33756965e-03 4.03803845e-04\n",
            " 4.90873825e-03 3.69582985e-04 3.63150686e-03 3.20292833e-03\n",
            " 9.74756661e-04 5.81620948e-04 9.21294294e-04 5.13345422e-03\n",
            " 5.98202559e-05 4.18518116e-03 2.05627261e-03 1.78787139e-03\n",
            " 2.27634475e-03 4.86485430e-03 3.19277775e-03 9.78362922e-05\n",
            " 2.86174934e-03 3.19277775e-03 1.19629157e-03 1.56834544e-03\n",
            " 4.26639196e-05 3.38321717e-03 2.77396899e-03 4.85993831e-03\n",
            " 7.69107029e-09 1.20438804e-03 3.95223283e-03 1.89428153e-03\n",
            " 1.99807744e-03 4.59389166e-03 5.30087869e-03 3.00522762e-03\n",
            " 4.32896057e-03 3.63150686e-03 1.94276374e-03 1.85175086e-04\n",
            " 4.13259982e-03 3.79677738e-03 6.55022213e-04 3.17079942e-03\n",
            " 7.59474935e-07 6.28641427e-05 6.43750800e-04 2.95643095e-03\n",
            " 2.69623733e-03 3.52820299e-04 5.06245394e-03 1.68383188e-03\n",
            " 1.01662359e-03 4.58727327e-03 5.17463093e-03 4.20863664e-03\n",
            " 4.92395472e-03 3.06324359e-03 3.63150686e-03 3.51021595e-03\n",
            " 1.07636829e-03 1.41389942e-03 2.24497509e-03 2.13033646e-04\n",
            " 4.76649115e-17 3.86936496e-03 2.48163963e-04 2.29743533e-03\n",
            " 3.60184938e-03 3.09015642e-03 3.07087416e-03 3.00632584e-03\n",
            " 1.82325837e-03 2.27094388e-04 3.73693113e-03 3.48027796e-03\n",
            " 2.87041556e-04 1.63204803e-03 4.02682941e-03 2.40453306e-03\n",
            " 1.65014475e-04 4.95485098e-03 3.38000970e-03 4.44620706e-03\n",
            " 2.59678750e-03 5.21429277e-03 4.11827279e-03 2.19947649e-04\n",
            " 2.04829391e-03 4.18518116e-03 1.71231702e-03 2.43676306e-03\n",
            " 1.56444393e-03 1.34588561e-03 4.94789807e-03 2.33218993e-03\n",
            " 3.65266376e-03 2.06352972e-03 3.46615521e-03 2.99163545e-03\n",
            " 3.19787014e-03 2.99626209e-06 1.18564453e-03 3.02363974e-03\n",
            " 1.32679647e-03 1.25394315e-05 2.13397810e-03 2.11515603e-04\n",
            " 3.59155197e-03 2.49830208e-03 1.28340542e-03 5.57970048e-04\n",
            " 2.42528875e-03 1.07182915e-03 1.72376749e-03 1.07916401e-03\n",
            " 3.74169590e-03 5.68026719e-05 6.37661977e-04 1.35884029e-03\n",
            " 1.28340542e-03 2.61564539e-03 3.72607606e-03 4.27027953e-03\n",
            " 1.98021243e-03 4.69200768e-03 3.57528022e-03 3.64042646e-04\n",
            " 3.78390739e-03 3.06240776e-03 2.19947649e-04 4.18356257e-03\n",
            " 3.36399098e-03 3.88362494e-03 5.09608267e-04 1.61364931e-03\n",
            " 1.26134631e-03 4.31786100e-03 7.03413236e-04 3.42076073e-03\n",
            " 2.81164415e-04 1.28340542e-03 5.12764697e-03 2.29929626e-03\n",
            " 3.33220112e-03 1.92678907e-03 2.10128621e-04 4.18518116e-03\n",
            " 3.02363974e-03 1.25490318e-03 4.80707127e-03 6.38677236e-04\n",
            " 5.21464400e-03 1.16665986e-03 1.75625595e-04 2.18512178e-03\n",
            " 4.44400989e-03 2.76844750e-03 3.38321717e-03 2.86174934e-03\n",
            " 3.93428073e-03 2.09013543e-03 4.18934183e-04 2.51096366e-03\n",
            " 4.49258913e-03 3.91142392e-03 6.30506012e-04 2.42600199e-03\n",
            " 4.82332647e-04 3.37986258e-03 2.32237913e-03 2.61564539e-03\n",
            " 9.81707081e-04 2.06427122e-03 4.98648661e-03 3.81999635e-03\n",
            " 3.79135707e-03 1.21162342e-03 3.95288743e-03 3.10806426e-03\n",
            " 4.61139961e-03 2.97051722e-03 9.10969855e-04 5.80129930e-04\n",
            " 4.51039251e-03 7.31787884e-04 3.08591970e-04 1.01768440e-03\n",
            " 1.87717065e-03 3.16081301e-03 7.41521656e-05 3.21895623e-06\n",
            " 5.72093460e-04 5.98080477e-06 1.77118175e-05 4.01852969e-05\n",
            " 1.14259089e-03 9.71011086e-04 4.20662234e-03 4.20763403e-03\n",
            " 1.09516511e-03 2.08660055e-03 3.67491466e-03 2.16717704e-04\n",
            " 3.91456840e-04 5.26125409e-03 2.60967093e-03 1.61574373e-04\n",
            " 4.44620706e-03 2.87568689e-03 4.20763403e-03 1.27289061e-03\n",
            " 1.30665672e-03 4.77074127e-03 5.19557284e-03 3.46133311e-03\n",
            " 6.84358698e-04 1.94891970e-03 1.15563646e-03 5.10778541e-03\n",
            " 3.05684273e-03 1.26438942e-03 1.52666712e-03 3.80353847e-03\n",
            " 4.00103664e-03 3.21607701e-03 3.33981420e-03 3.41652090e-04\n",
            " 1.04457205e-03 2.45021908e-03 2.83707315e-04 4.78138900e-03\n",
            " 2.97567862e-03 4.49534920e-03 1.18564453e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3930 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.64374638e-03 4.09427971e-03 3.95604756e-03 3.12602120e-03\n",
            " 7.03601490e-04 4.24445180e-03 4.81467227e-03 1.35739385e-03\n",
            " 4.20206178e-03 4.20952787e-03 1.33104637e-05 4.50567194e-03\n",
            " 3.10454095e-03 1.23415356e-04 1.77933598e-03 7.69015382e-09\n",
            " 4.38074349e-03 1.15055381e-05 3.33790213e-04 6.61133209e-07\n",
            " 3.16265017e-03 2.84972478e-03 1.01796256e-03 2.84887831e-03\n",
            " 2.63135597e-04 1.07079254e-03 2.33456384e-03 4.03630936e-04\n",
            " 4.90444246e-03 3.69426481e-04 3.63300891e-03 3.20202768e-03\n",
            " 9.73500287e-04 5.81380779e-04 9.20328152e-04 5.97088938e-05\n",
            " 4.18455017e-03 2.05602482e-03 1.78941592e-03 2.27144636e-03\n",
            " 4.86208575e-03 3.19375957e-03 9.79228750e-05 2.85697232e-03\n",
            " 3.19375957e-03 1.19652410e-03 1.56550776e-03 4.25443315e-05\n",
            " 3.38226813e-03 2.77373847e-03 4.85279114e-03 7.69015382e-09\n",
            " 1.20318842e-03 3.95076560e-03 1.89385447e-03 2.00377028e-03\n",
            " 4.59631882e-03 3.00520299e-03 4.32997317e-03 3.63300891e-03\n",
            " 1.94241120e-03 1.84957108e-04 4.12889381e-03 3.79513089e-03\n",
            " 6.54696620e-04 3.17013112e-03 7.58912578e-07 6.26710269e-05\n",
            " 6.43573370e-04 2.95555200e-03 2.69609564e-03 3.52970706e-04\n",
            " 1.68126058e-03 1.01515611e-03 4.58841265e-03 4.20556129e-03\n",
            " 4.91652790e-03 3.06017523e-03 3.63300891e-03 3.51172475e-03\n",
            " 1.07633095e-03 1.41291820e-03 2.24446058e-03 2.12638150e-04\n",
            " 4.73812975e-17 3.87178062e-03 2.47780373e-04 2.29789852e-03\n",
            " 3.59813590e-03 3.08881418e-03 3.07012044e-03 3.00380298e-03\n",
            " 1.82349089e-03 2.26634114e-04 3.73500000e-03 3.47624258e-03\n",
            " 2.87130626e-04 1.63221205e-03 4.02767118e-03 2.40231711e-03\n",
            " 1.64883998e-04 4.95296061e-03 3.37712446e-03 4.44703259e-03\n",
            " 2.59347681e-03 4.11783482e-03 2.19942182e-04 2.04770899e-03\n",
            " 4.18455017e-03 1.71238004e-03 2.43484407e-03 1.56466481e-03\n",
            " 1.34594163e-03 4.94817581e-03 2.32997550e-03 3.64995390e-03\n",
            " 2.06361004e-03 3.46452567e-03 2.98971755e-03 3.19412833e-03\n",
            " 2.99079204e-06 1.18641174e-03 3.02203467e-03 1.32580515e-03\n",
            " 1.25335593e-05 2.13291986e-03 2.11598801e-04 3.59214080e-03\n",
            " 2.49800819e-03 1.28183956e-03 5.57008338e-04 2.42587201e-03\n",
            " 1.07133076e-03 1.72032616e-03 1.07845953e-03 3.74048383e-03\n",
            " 5.68138174e-05 6.36683517e-04 1.35596432e-03 1.28183956e-03\n",
            " 2.61336029e-03 3.72820612e-03 4.27215490e-03 1.98028444e-03\n",
            " 4.69117510e-03 3.57283710e-03 3.63959585e-04 3.78295295e-03\n",
            " 3.05986576e-03 2.19942182e-04 4.17814537e-03 3.36206263e-03\n",
            " 3.88152390e-03 5.09240782e-04 1.61374895e-03 1.26301757e-03\n",
            " 4.31084985e-03 7.03601490e-04 3.41583665e-03 2.81558499e-04\n",
            " 1.28183956e-03 2.29959275e-03 3.32810755e-03 1.92511452e-03\n",
            " 2.10068085e-04 4.18455017e-03 3.02203467e-03 1.25554161e-03\n",
            " 4.79817770e-03 6.38272003e-04 1.16676704e-03 1.75556948e-04\n",
            " 2.18246213e-03 4.44360510e-03 2.76661670e-03 3.38226813e-03\n",
            " 2.85697232e-03 3.93399013e-03 2.08984073e-03 4.18318406e-04\n",
            " 2.51159720e-03 4.49006535e-03 3.90199954e-03 6.31252756e-04\n",
            " 2.42658755e-03 4.82007743e-04 3.38059379e-03 2.31814278e-03\n",
            " 2.61336029e-03 9.80756240e-04 2.06290303e-03 4.98525910e-03\n",
            " 3.81988112e-03 3.78739273e-03 1.21090896e-03 3.95384461e-03\n",
            " 3.10508269e-03 4.61080114e-03 2.96912021e-03 9.09471490e-04\n",
            " 5.80339811e-04 4.50567194e-03 7.30262669e-04 3.07909364e-04\n",
            " 1.01693661e-03 1.87930020e-03 3.16265017e-03 7.40463827e-05\n",
            " 3.22374249e-06 5.70600069e-04 5.98789566e-06 1.77111872e-05\n",
            " 4.01783767e-05 1.14040871e-03 9.70869894e-04 4.20737130e-03\n",
            " 4.20952787e-03 1.09538546e-03 2.08645566e-03 3.66761443e-03\n",
            " 2.16308554e-04 3.90774713e-04 2.60923114e-03 1.61527807e-04\n",
            " 4.44703259e-03 2.87250517e-03 4.20952787e-03 1.27229931e-03\n",
            " 1.30512636e-03 4.76611253e-03 3.46378120e-03 6.82569270e-04\n",
            " 1.94667284e-03 1.15410771e-03 3.05324070e-03 1.26366943e-03\n",
            " 1.52542355e-03 3.80304916e-03 4.00443009e-03 3.21508418e-03\n",
            " 3.33967892e-03 3.41876072e-04 1.04440004e-03 2.44942162e-03\n",
            " 2.83208986e-04 4.78972970e-03 2.97676599e-03 4.49801904e-03\n",
            " 1.18641174e-03]\n",
            "3940 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.64191447e-03 4.09436869e-03 3.95507355e-03 3.11947665e-03\n",
            " 7.03341964e-04 4.24218648e-03 1.35586746e-03 4.19931557e-03\n",
            " 4.21094625e-03 1.32737128e-05 4.50490772e-03 3.10435093e-03\n",
            " 1.23079467e-04 1.77619109e-03 7.67105180e-09 4.37321630e-03\n",
            " 1.14168537e-05 3.32711723e-04 6.57001293e-07 3.16364083e-03\n",
            " 2.84719031e-03 1.01413780e-03 2.84307428e-03 2.62960799e-04\n",
            " 1.07067720e-03 2.33109780e-03 4.03513568e-04 3.68332543e-04\n",
            " 3.62896689e-03 3.20002303e-03 9.71278302e-04 5.81255679e-04\n",
            " 9.18470503e-04 5.95547975e-05 4.18191946e-03 2.05472351e-03\n",
            " 1.78751389e-03 2.27043298e-03 3.19051891e-03 9.76579898e-05\n",
            " 2.84820743e-03 3.19051891e-03 1.19582800e-03 1.56515116e-03\n",
            " 4.23021148e-05 3.38139871e-03 2.76889048e-03 7.67105180e-09\n",
            " 1.20102087e-03 3.94962883e-03 1.89245649e-03 2.00382901e-03\n",
            " 4.59372190e-03 3.00392207e-03 4.32238384e-03 3.62896689e-03\n",
            " 1.94031520e-03 1.84541818e-04 4.12534463e-03 3.79287406e-03\n",
            " 6.54622337e-04 3.16422163e-03 7.56586655e-07 6.24644813e-05\n",
            " 6.43333093e-04 2.95419895e-03 2.69591058e-03 3.52664486e-04\n",
            " 1.68018941e-03 1.01367108e-03 4.58065127e-03 4.19729317e-03\n",
            " 3.05804857e-03 3.62896689e-03 3.50999686e-03 1.07566005e-03\n",
            " 1.40934666e-03 2.24059044e-03 2.12373555e-04 4.62039247e-17\n",
            " 3.86962394e-03 2.46993306e-04 2.29833560e-03 3.59737611e-03\n",
            " 3.08709908e-03 3.06901445e-03 3.00030324e-03 1.82167914e-03\n",
            " 2.26115077e-04 3.73041974e-03 3.46223800e-03 2.86912282e-04\n",
            " 1.63131886e-03 4.02606693e-03 2.39285115e-03 1.64797735e-04\n",
            " 3.37027287e-03 4.44136091e-03 2.58986864e-03 4.10908113e-03\n",
            " 2.19833566e-04 2.04417713e-03 4.18191946e-03 1.70705632e-03\n",
            " 2.43187646e-03 1.56415294e-03 1.34533610e-03 2.32454753e-03\n",
            " 3.64574839e-03 2.05879260e-03 3.46153897e-03 2.98814002e-03\n",
            " 3.18815741e-03 2.97658830e-06 1.18552568e-03 3.01990256e-03\n",
            " 1.32460578e-03 1.24950594e-05 2.13091622e-03 2.11360342e-04\n",
            " 3.59047494e-03 2.49363065e-03 1.27827928e-03 5.56726082e-04\n",
            " 2.42191372e-03 1.06994135e-03 1.72070445e-03 1.07800308e-03\n",
            " 3.73463415e-03 5.67515971e-05 6.36173245e-04 1.35222963e-03\n",
            " 1.27827928e-03 2.61043077e-03 3.72620366e-03 4.27258731e-03\n",
            " 1.97781903e-03 4.68506291e-03 3.56390785e-03 3.63745398e-04\n",
            " 3.77430651e-03 3.05620761e-03 2.19833566e-04 4.17756971e-03\n",
            " 3.35964645e-03 3.87871030e-03 5.08339337e-04 1.61226152e-03\n",
            " 1.26257749e-03 4.30774970e-03 7.03341964e-04 3.40753727e-03\n",
            " 2.81166699e-04 1.27827928e-03 2.29715347e-03 3.32533496e-03\n",
            " 1.92058236e-03 2.09853168e-04 4.18191946e-03 3.01990256e-03\n",
            " 1.25615767e-03 6.36368969e-04 1.16567301e-03 1.75445972e-04\n",
            " 2.17845147e-03 4.44395122e-03 2.76624250e-03 3.38139871e-03\n",
            " 2.84820743e-03 3.92158818e-03 2.08792013e-03 4.16693078e-04\n",
            " 2.51000453e-03 4.49018392e-03 3.89924896e-03 6.28652798e-04\n",
            " 2.42412448e-03 4.81199604e-04 3.38067098e-03 2.31529303e-03\n",
            " 2.61043077e-03 9.78373431e-04 2.05580861e-03 3.81916884e-03\n",
            " 3.78431193e-03 1.20882543e-03 3.95130780e-03 3.09917772e-03\n",
            " 4.60813557e-03 2.96616356e-03 9.07476982e-04 5.79823873e-04\n",
            " 4.50490772e-03 7.27155668e-04 3.07626881e-04 1.01576851e-03\n",
            " 1.87873087e-03 3.16364083e-03 7.36756950e-05 3.20617027e-06\n",
            " 5.69582995e-04 5.97835540e-06 1.76440453e-05 4.01493060e-05\n",
            " 1.13848790e-03 9.70098461e-04 4.20151063e-03 4.21094625e-03\n",
            " 1.09433753e-03 2.08381640e-03 3.66407118e-03 2.15019804e-04\n",
            " 3.90056556e-04 2.60682784e-03 1.61287212e-04 4.44136091e-03\n",
            " 2.86766193e-03 4.21094625e-03 1.27201977e-03 1.30386376e-03\n",
            " 4.76062200e-03 3.46471194e-03 6.79777471e-04 1.94142315e-03\n",
            " 1.14978483e-03 3.04781807e-03 1.26297735e-03 1.52470387e-03\n",
            " 3.80240744e-03 4.00194876e-03 3.21160894e-03 3.33823872e-03\n",
            " 3.41540975e-04 1.04357140e-03 2.44479704e-03 2.82317465e-04\n",
            " 2.97396815e-03 4.49587781e-03 1.18552568e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3950 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.63966690e-03 4.09231715e-03 3.94953857e-03 3.11802256e-03\n",
            " 7.02577588e-04 4.23790325e-03 1.35452420e-03 4.19160423e-03\n",
            " 4.20645216e-03 1.32509529e-05 3.09893691e-03 1.22785276e-04\n",
            " 1.77352572e-03 7.63007486e-09 4.37241502e-03 1.13780095e-05\n",
            " 3.32494603e-04 6.53059558e-07 3.15906715e-03 2.84411428e-03\n",
            " 1.01218062e-03 2.83717900e-03 2.62511172e-04 1.06948726e-03\n",
            " 2.32656405e-03 4.03191365e-04 3.68088925e-04 3.62717958e-03\n",
            " 3.19077751e-03 9.70644934e-04 5.80695427e-04 9.17360630e-04\n",
            " 5.94800315e-05 4.17517063e-03 2.05329122e-03 1.78156016e-03\n",
            " 2.26865769e-03 3.18912983e-03 9.71888347e-05 2.84391207e-03\n",
            " 3.18912983e-03 1.19494402e-03 1.56404768e-03 4.22415731e-05\n",
            " 3.37785276e-03 2.76625718e-03 7.63007486e-09 1.19948318e-03\n",
            " 3.94803625e-03 1.89021016e-03 1.99479136e-03 3.00189267e-03\n",
            " 4.31984009e-03 3.62717958e-03 1.93967181e-03 1.84179926e-04\n",
            " 4.12255980e-03 3.79082114e-03 6.54056510e-04 3.15836182e-03\n",
            " 7.52338793e-07 6.23266489e-05 6.42495818e-04 2.95344934e-03\n",
            " 2.69485702e-03 3.51901841e-04 1.67611391e-03 1.01366242e-03\n",
            " 4.19615875e-03 3.05434958e-03 3.62717958e-03 3.50315663e-03\n",
            " 1.07428990e-03 1.40779488e-03 2.23578169e-03 2.11946807e-04\n",
            " 4.58421971e-17 3.86221035e-03 2.46586733e-04 2.29413369e-03\n",
            " 3.59547234e-03 3.08364587e-03 3.06898174e-03 2.99766862e-03\n",
            " 1.81980068e-03 2.25844216e-04 3.72708183e-03 3.45946164e-03\n",
            " 2.86678516e-04 1.63004702e-03 4.02584107e-03 2.38939088e-03\n",
            " 1.64553772e-04 3.36480681e-03 4.43237686e-03 2.58812411e-03\n",
            " 4.10704535e-03 2.19495749e-04 2.04040782e-03 4.17517063e-03\n",
            " 1.70454256e-03 2.42976294e-03 1.56053289e-03 1.34442565e-03\n",
            " 2.32142822e-03 3.64422983e-03 2.05350829e-03 3.46094370e-03\n",
            " 2.98700507e-03 3.18397292e-03 2.96641417e-06 1.18385153e-03\n",
            " 3.01835251e-03 1.32238819e-03 1.24822443e-05 2.12779710e-03\n",
            " 2.11072800e-04 3.58508223e-03 2.49356647e-03 1.27667952e-03\n",
            " 5.55879777e-04 2.41724847e-03 1.06927485e-03 1.71922001e-03\n",
            " 1.07724151e-03 3.73452840e-03 5.66188747e-05 6.35115892e-04\n",
            " 1.34973639e-03 1.27667952e-03 2.60684079e-03 3.71862936e-03\n",
            " 4.26886322e-03 1.97500267e-03 3.56112033e-03 3.63346151e-04\n",
            " 3.76977107e-03 3.05429873e-03 2.19495749e-04 4.16995464e-03\n",
            " 3.35824233e-03 3.87486916e-03 5.06992837e-04 1.61122639e-03\n",
            " 1.25913497e-03 4.30357559e-03 7.02577588e-04 3.40584188e-03\n",
            " 2.80256508e-04 1.27667952e-03 2.29503828e-03 3.31938914e-03\n",
            " 1.91681925e-03 2.09695070e-04 4.17517063e-03 3.01835251e-03\n",
            " 1.25555661e-03 6.35639102e-04 1.16501778e-03 1.75222628e-04\n",
            " 2.17402454e-03 2.76408057e-03 3.37785276e-03 2.84391207e-03\n",
            " 3.91079817e-03 2.08504076e-03 4.16174179e-04 2.50708082e-03\n",
            " 3.89585514e-03 6.27300870e-04 2.41966206e-03 4.80263980e-04\n",
            " 3.37418091e-03 2.31613427e-03 2.60684079e-03 9.77107359e-04\n",
            " 2.05321271e-03 3.81412916e-03 3.78018106e-03 1.20569922e-03\n",
            " 3.94380512e-03 3.09601549e-03 2.96077964e-03 9.06374531e-04\n",
            " 5.79082883e-04 7.26444506e-04 3.07595130e-04 1.01485782e-03\n",
            " 1.87483535e-03 3.15906715e-03 7.35565829e-05 3.17756607e-06\n",
            " 5.67785892e-04 5.97030648e-06 1.75668981e-05 4.00621977e-05\n",
            " 1.13749212e-03 9.68279692e-04 4.19823607e-03 4.20645216e-03\n",
            " 1.09230365e-03 2.08283813e-03 3.66033616e-03 2.14772687e-04\n",
            " 3.89251034e-04 2.60201619e-03 1.60862686e-04 4.43237686e-03\n",
            " 2.86584322e-03 4.20645216e-03 1.27163822e-03 1.30311255e-03\n",
            " 3.45748498e-03 6.79755492e-04 1.94009169e-03 1.14582520e-03\n",
            " 3.04644222e-03 1.26245358e-03 1.52411096e-03 3.79704865e-03\n",
            " 3.99769563e-03 3.20584153e-03 3.33589795e-03 3.41114410e-04\n",
            " 1.04160449e-03 2.44312114e-03 2.81913277e-04 2.97054699e-03\n",
            " 1.18385153e-03]\n",
            "3960 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.63812503e-03 4.09062284e-03 3.94976147e-03 3.11925834e-03\n",
            " 7.02977277e-04 1.35473987e-03 4.18774858e-03 1.32509084e-05\n",
            " 3.09696845e-03 1.22429721e-04 1.77347437e-03 7.62228703e-09\n",
            " 1.13711785e-05 3.32330818e-04 6.54164573e-07 3.11041879e-03\n",
            " 2.84268025e-03 1.01198461e-03 2.83726867e-03 2.62120099e-04\n",
            " 1.07021886e-03 2.32647146e-03 4.02820764e-04 3.67438097e-04\n",
            " 3.62621885e-03 3.18721824e-03 9.70643968e-04 5.80539110e-04\n",
            " 9.17162170e-04 5.94619157e-05 4.16300383e-03 2.05375985e-03\n",
            " 1.78420402e-03 2.26841499e-03 3.18886064e-03 9.70026842e-05\n",
            " 2.84110243e-03 3.18886064e-03 1.19433622e-03 1.56273792e-03\n",
            " 4.22116791e-05 3.37772331e-03 2.76457683e-03 7.62228703e-09\n",
            " 1.19876988e-03 3.94470371e-03 1.88994279e-03 1.99114719e-03\n",
            " 3.00165388e-03 3.62621885e-03 1.93914782e-03 1.83966797e-04\n",
            " 4.11863395e-03 3.78816836e-03 6.53746477e-04 3.15713241e-03\n",
            " 7.49647468e-07 6.22576800e-05 6.41633775e-04 2.95324710e-03\n",
            " 2.69417867e-03 3.51769761e-04 1.67661946e-03 1.01328830e-03\n",
            " 4.19476957e-03 3.05151478e-03 3.62621885e-03 3.50154816e-03\n",
            " 1.07399295e-03 1.40637946e-03 2.23481155e-03 2.11966025e-04\n",
            " 4.57104251e-17 3.86152442e-03 2.46466855e-04 2.29394572e-03\n",
            " 3.59275088e-03 3.08272700e-03 3.06959723e-03 2.99725440e-03\n",
            " 1.81937224e-03 2.25539368e-04 3.72462394e-03 3.45919637e-03\n",
            " 2.86124772e-04 1.62999708e-03 4.02331399e-03 2.38927107e-03\n",
            " 1.64489648e-04 3.36062523e-03 2.58741203e-03 4.10677714e-03\n",
            " 2.19584805e-04 2.03912469e-03 4.16300383e-03 1.70488913e-03\n",
            " 2.43035392e-03 1.55980745e-03 1.34470181e-03 2.32064469e-03\n",
            " 3.64291378e-03 2.05380319e-03 3.45871970e-03 2.98692902e-03\n",
            " 3.18343713e-03 2.96333183e-06 1.18326969e-03 3.01705432e-03\n",
            " 1.32263523e-03 1.24622155e-05 2.12772154e-03 2.10876816e-04\n",
            " 3.58280426e-03 2.49050158e-03 1.27577034e-03 5.55568063e-04\n",
            " 2.41494285e-03 1.06893961e-03 1.71701849e-03 1.07679051e-03\n",
            " 3.73153863e-03 5.64562363e-05 6.34545581e-04 1.34929782e-03\n",
            " 1.27577034e-03 2.60494029e-03 3.71369167e-03 1.97243405e-03\n",
            " 3.55880336e-03 3.63089956e-04 3.76541970e-03 3.05417375e-03\n",
            " 2.19584805e-04 4.16825700e-03 3.35515155e-03 3.87111001e-03\n",
            " 5.06226653e-04 1.61081254e-03 1.25751997e-03 7.02977277e-04\n",
            " 3.40398085e-03 2.79819502e-04 1.27577034e-03 2.29427930e-03\n",
            " 3.31690491e-03 1.91490009e-03 2.09128665e-04 4.16300383e-03\n",
            " 3.01705432e-03 1.25525334e-03 6.34748577e-04 1.16392629e-03\n",
            " 1.75245447e-04 2.17359305e-03 2.76374100e-03 3.37772331e-03\n",
            " 2.84110243e-03 3.90691517e-03 2.08443686e-03 4.16115723e-04\n",
            " 2.50604175e-03 3.89269392e-03 6.26206903e-04 2.41800090e-03\n",
            " 4.79720294e-04 3.37274043e-03 2.31251267e-03 2.60494029e-03\n",
            " 9.76588157e-04 2.05058624e-03 3.79301712e-03 3.77863766e-03\n",
            " 1.20493009e-03 3.94302050e-03 3.09280892e-03 2.95868468e-03\n",
            " 9.05542941e-04 5.77532749e-04 7.26143650e-04 3.07368958e-04\n",
            " 1.01429861e-03 1.87427000e-03 3.11041879e-03 7.35205889e-05\n",
            " 3.16031354e-06 5.67009798e-04 5.97359462e-06 1.74933434e-05\n",
            " 4.00537876e-05 1.13692431e-03 9.65432574e-04 4.19345426e-03\n",
            " 1.09093126e-03 2.08245702e-03 3.65910774e-03 2.14689743e-04\n",
            " 3.88845855e-04 2.60167735e-03 1.60738527e-04 2.86552033e-03\n",
            " 1.27171142e-03 1.30332872e-03 3.45443374e-03 6.79700417e-04\n",
            " 1.93979737e-03 1.14508949e-03 3.04373595e-03 1.26279560e-03\n",
            " 1.52283753e-03 3.79785390e-03 3.99612251e-03 3.20480267e-03\n",
            " 3.33646795e-03 3.40645725e-04 1.03853747e-03 2.44283116e-03\n",
            " 2.81501374e-04 2.96513534e-03 1.18326969e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3970 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.63479773e-03 3.94675673e-03 3.11632355e-03 7.02228942e-04\n",
            " 1.35406573e-03 1.32221455e-05 3.09546924e-03 1.22394654e-04\n",
            " 1.77023040e-03 7.60744797e-09 1.13115579e-05 3.31908131e-04\n",
            " 6.51322973e-07 3.10604201e-03 2.84126768e-03 1.00944202e-03\n",
            " 2.83133213e-03 2.62054388e-04 1.06862229e-03 2.32532884e-03\n",
            " 4.02821035e-04 3.66593743e-04 3.62388387e-03 3.18136024e-03\n",
            " 9.70087553e-04 5.80620747e-04 9.17170517e-04 5.93170172e-05\n",
            " 2.05255801e-03 1.78316285e-03 2.26655643e-03 3.18664170e-03\n",
            " 9.69483150e-05 2.83941872e-03 3.18664170e-03 1.19380015e-03\n",
            " 1.56014251e-03 4.20777113e-05 3.37527971e-03 2.76146994e-03\n",
            " 7.60744797e-09 1.19871356e-03 3.94409490e-03 1.88735560e-03\n",
            " 1.99051157e-03 3.00133565e-03 3.62388387e-03 1.93696338e-03\n",
            " 1.83782368e-04 3.78665494e-03 6.53584247e-04 3.15407280e-03\n",
            " 7.50608194e-07 6.21341076e-05 6.40787877e-04 2.95241859e-03\n",
            " 2.69388210e-03 3.51519546e-04 1.67487489e-03 1.01214480e-03\n",
            " 3.05013297e-03 3.62388387e-03 3.49612358e-03 1.07370348e-03\n",
            " 1.40389472e-03 2.23299134e-03 2.11587001e-04 4.51632413e-17\n",
            " 3.85612903e-03 2.45877816e-04 2.29249363e-03 3.59040713e-03\n",
            " 3.08091359e-03 3.06764316e-03 2.99640125e-03 1.81839385e-03\n",
            " 2.24950305e-04 3.72455847e-03 3.45293832e-03 2.85545136e-04\n",
            " 1.62686552e-03 4.02361700e-03 2.38788390e-03 1.64332238e-04\n",
            " 3.35636858e-03 2.58614992e-03 2.19446866e-04 2.03725004e-03\n",
            " 1.70257523e-03 2.42891788e-03 1.55885596e-03 1.34466904e-03\n",
            " 2.31906598e-03 3.64149757e-03 2.04961371e-03 3.45588039e-03\n",
            " 2.98662645e-03 3.18171312e-03 2.95591319e-06 1.18244561e-03\n",
            " 3.01652557e-03 1.32190823e-03 1.24110417e-05 2.12625979e-03\n",
            " 2.10337071e-04 3.58231296e-03 2.48515011e-03 1.27370885e-03\n",
            " 5.54292562e-04 2.41425540e-03 1.06884579e-03 1.71521154e-03\n",
            " 1.07612621e-03 3.72767480e-03 5.63963113e-05 6.33947005e-04\n",
            " 1.34669742e-03 1.27370885e-03 2.60387277e-03 3.71093865e-03\n",
            " 1.96881583e-03 3.55344811e-03 3.62801884e-04 3.76360886e-03\n",
            " 3.05263143e-03 2.19446866e-04 3.34932801e-03 3.86695169e-03\n",
            " 5.05934746e-04 1.60883510e-03 1.25385050e-03 7.02228942e-04\n",
            " 3.40137833e-03 2.80056646e-04 1.27370885e-03 2.29288759e-03\n",
            " 3.31580944e-03 1.91080524e-03 2.08869245e-04 3.01652557e-03\n",
            " 1.25443511e-03 6.33201517e-04 1.16189917e-03 1.75263891e-04\n",
            " 2.17167433e-03 2.76312195e-03 3.37527971e-03 2.83941872e-03\n",
            " 3.90008285e-03 2.08415385e-03 4.15315932e-04 2.50577033e-03\n",
            " 3.88799596e-03 6.24978254e-04 2.42079785e-03 4.79467353e-04\n",
            " 3.36577464e-03 2.30852949e-03 2.60387277e-03 9.75080741e-04\n",
            " 2.04950356e-03 3.78701580e-03 3.77654178e-03 1.20388932e-03\n",
            " 3.94254943e-03 3.08965994e-03 2.95632645e-03 9.04436641e-04\n",
            " 5.76348326e-04 7.24479492e-04 3.06958676e-04 1.01365525e-03\n",
            " 1.86857299e-03 3.10604201e-03 7.33410908e-05 3.15380497e-06\n",
            " 5.66428025e-04 5.96676578e-06 1.74363720e-05 4.00295608e-05\n",
            " 1.13590774e-03 9.55794504e-04 1.08895014e-03 2.08018161e-03\n",
            " 3.65692040e-03 2.14044676e-04 3.88697781e-04 2.59906193e-03\n",
            " 1.60571189e-04 2.86081390e-03 1.27120286e-03 1.30289245e-03\n",
            " 3.45020892e-03 6.78200916e-04 1.93643871e-03 1.14364923e-03\n",
            " 3.04162972e-03 1.26178760e-03 1.52130975e-03 3.80025888e-03\n",
            " 3.99380277e-03 3.20400433e-03 3.33608221e-03 3.39941548e-04\n",
            " 1.02892935e-03 2.44086517e-03 2.80749650e-04 2.96146679e-03\n",
            " 1.18244561e-03]\n",
            "3980 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.63175442e-03 3.11309797e-03 7.02053603e-04 1.35321148e-03\n",
            " 1.31890675e-05 3.09235647e-03 1.22133989e-04 1.76767311e-03\n",
            " 7.57983852e-09 1.12555148e-05 3.31439677e-04 6.50047389e-07\n",
            " 3.10508226e-03 2.83911817e-03 1.00731414e-03 2.82918982e-03\n",
            " 2.61691909e-04 1.06725323e-03 2.32313519e-03 4.02783228e-04\n",
            " 3.65919990e-04 3.62098735e-03 3.17441004e-03 9.68821136e-04\n",
            " 5.80144628e-04 9.16868261e-04 5.91702544e-05 2.05126449e-03\n",
            " 1.78054558e-03 2.26387690e-03 3.18423609e-03 9.69493229e-05\n",
            " 2.83478538e-03 3.18423609e-03 1.19323281e-03 1.55907550e-03\n",
            " 4.19719495e-05 3.37463208e-03 2.75831637e-03 7.57983852e-09\n",
            " 1.19722130e-03 1.88583518e-03 1.98744016e-03 3.00079280e-03\n",
            " 3.62098735e-03 1.93676963e-03 1.83472053e-04 3.78581176e-03\n",
            " 6.52355498e-04 3.15189486e-03 7.46966379e-07 6.19786066e-05\n",
            " 6.40188151e-04 2.94963555e-03 2.69293061e-03 3.51016852e-04\n",
            " 1.67367608e-03 1.01097139e-03 3.04738092e-03 3.62098735e-03\n",
            " 3.49122237e-03 1.07323923e-03 1.40228175e-03 2.23075914e-03\n",
            " 2.11302284e-04 4.45481051e-17 2.45389115e-04 2.28883824e-03\n",
            " 3.59018922e-03 3.07836241e-03 3.06495231e-03 2.99506271e-03\n",
            " 1.81705616e-03 2.24599041e-04 3.72232837e-03 3.44607690e-03\n",
            " 2.85201027e-04 1.62593997e-03 2.38657545e-03 1.64146447e-04\n",
            " 3.35342895e-03 2.58404491e-03 2.19233385e-04 2.03586066e-03\n",
            " 1.70002699e-03 2.42763134e-03 1.55807887e-03 1.34445725e-03\n",
            " 2.31507680e-03 3.64014820e-03 2.04826921e-03 3.45108427e-03\n",
            " 2.98479191e-03 3.18228722e-03 2.94620107e-06 1.18057779e-03\n",
            " 3.01566727e-03 1.32103425e-03 1.23839179e-05 2.12469078e-03\n",
            " 2.10308835e-04 3.57960244e-03 2.48157087e-03 1.27155437e-03\n",
            " 5.53600850e-04 2.41571803e-03 1.06747647e-03 1.71567235e-03\n",
            " 1.07514348e-03 3.72345321e-03 5.63609488e-05 6.32985225e-04\n",
            " 1.34437047e-03 1.27155437e-03 2.60318857e-03 3.70770102e-03\n",
            " 1.96904907e-03 3.54685173e-03 3.62176120e-04 3.75867803e-03\n",
            " 3.05082899e-03 2.19233385e-04 3.34682226e-03 5.05228993e-04\n",
            " 1.60930952e-03 1.25330315e-03 7.02053603e-04 3.39683302e-03\n",
            " 2.79610804e-04 1.27155437e-03 2.29091738e-03 3.31433896e-03\n",
            " 1.90832686e-03 2.08843482e-04 3.01566727e-03 1.25505357e-03\n",
            " 6.31887143e-04 1.16046772e-03 1.75227205e-04 2.16932953e-03\n",
            " 2.75949025e-03 3.37463208e-03 2.83478538e-03 2.08334453e-03\n",
            " 4.14508301e-04 2.50385629e-03 6.23958611e-04 2.41925872e-03\n",
            " 4.78973632e-04 3.36435535e-03 2.30613585e-03 2.60318857e-03\n",
            " 9.72959595e-04 2.04883374e-03 3.78768769e-03 3.77445057e-03\n",
            " 1.20255384e-03 3.08870760e-03 2.95496889e-03 9.03963627e-04\n",
            " 5.76500478e-04 7.22597505e-04 3.06785111e-04 1.01231539e-03\n",
            " 1.86804155e-03 3.10508226e-03 7.31585818e-05 3.15006160e-06\n",
            " 5.65784787e-04 5.95673720e-06 1.73633503e-05 3.99393840e-05\n",
            " 1.13456344e-03 9.55826438e-04 1.08872659e-03 2.07809905e-03\n",
            " 3.65637491e-03 2.13345328e-04 3.88269744e-04 2.59847480e-03\n",
            " 1.60437142e-04 2.85941795e-03 1.26996035e-03 1.30174017e-03\n",
            " 3.44640066e-03 6.76592914e-04 1.93287760e-03 1.14160927e-03\n",
            " 3.03722425e-03 1.26057777e-03 1.51884728e-03 3.20135889e-03\n",
            " 3.33540320e-03 3.39188342e-04 1.02896184e-03 2.43933367e-03\n",
            " 2.80336298e-04 2.96149192e-03 1.18057779e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3990 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.62884859e-03 3.11147142e-03 7.01596185e-04 1.35167000e-03\n",
            " 1.31670514e-05 3.09032068e-03 1.21680092e-04 1.76677947e-03\n",
            " 7.53103291e-09 1.12337512e-05 3.30661477e-04 6.46173950e-07\n",
            " 3.10232601e-03 2.83657699e-03 1.00587956e-03 2.82527976e-03\n",
            " 2.61229075e-04 1.06691415e-03 2.32056817e-03 4.02686305e-04\n",
            " 3.65491369e-04 3.60432692e-03 3.17205334e-03 9.66899685e-04\n",
            " 5.79968240e-04 9.15955621e-04 5.90803943e-05 2.05005419e-03\n",
            " 1.77838725e-03 2.26296212e-03 3.17362742e-03 9.68300149e-05\n",
            " 2.83268235e-03 3.17362742e-03 1.19274855e-03 1.55808947e-03\n",
            " 4.19101864e-05 3.37532560e-03 2.75643499e-03 7.53103291e-09\n",
            " 1.19633240e-03 1.88449562e-03 1.98647553e-03 2.99999459e-03\n",
            " 3.60432692e-03 1.93543575e-03 1.83386484e-04 6.51853333e-04\n",
            " 3.14834497e-03 7.43366463e-07 6.18771398e-05 6.39930177e-04\n",
            " 2.94786738e-03 2.69290237e-03 3.50779382e-04 1.67262183e-03\n",
            " 1.00978850e-03 3.04494548e-03 3.48843440e-03 1.07213599e-03\n",
            " 1.40084979e-03 2.22892973e-03 2.10873435e-04 4.42835382e-17\n",
            " 2.45141817e-04 2.28721519e-03 3.58828318e-03 3.07498973e-03\n",
            " 3.06441281e-03 2.99027479e-03 1.81393894e-03 2.24336321e-04\n",
            " 3.44351614e-03 2.84899714e-04 1.62561011e-03 2.38514305e-03\n",
            " 1.63893752e-04 3.35137069e-03 2.58290209e-03 2.18829117e-04\n",
            " 2.03338374e-03 1.69958095e-03 2.42462283e-03 1.55711198e-03\n",
            " 1.34407293e-03 2.31366005e-03 2.04331500e-03 3.45109017e-03\n",
            " 2.98176348e-03 3.17787625e-03 2.93762553e-06 1.17881923e-03\n",
            " 3.01191360e-03 1.32062779e-03 1.23602423e-05 2.12409024e-03\n",
            " 2.10136936e-04 3.57621640e-03 2.47982138e-03 1.27024392e-03\n",
            " 5.53132116e-04 2.41227655e-03 1.06676923e-03 1.71310265e-03\n",
            " 1.07408211e-03 5.63066312e-05 6.31962573e-04 1.34247463e-03\n",
            " 1.27024392e-03 2.59962277e-03 1.96731742e-03 3.54456385e-03\n",
            " 3.61652457e-04 3.04821655e-03 2.18829117e-04 3.34398224e-03\n",
            " 5.04326429e-04 1.60835708e-03 1.25242060e-03 7.01596185e-04\n",
            " 3.39046273e-03 2.79104455e-04 1.27024392e-03 2.29083245e-03\n",
            " 3.31270640e-03 1.90698737e-03 2.08696565e-04 3.01191360e-03\n",
            " 1.25472108e-03 6.31037876e-04 1.16008491e-03 1.75131419e-04\n",
            " 2.16821255e-03 2.75882846e-03 3.37532560e-03 2.83268235e-03\n",
            " 2.08230731e-03 4.14058825e-04 2.50263363e-03 6.22660185e-04\n",
            " 2.41630095e-03 4.78448026e-04 3.36140023e-03 2.30311875e-03\n",
            " 2.59962277e-03 9.71782119e-04 2.04786256e-03 1.20134714e-03\n",
            " 3.08775995e-03 2.95212960e-03 9.02751609e-04 5.76137978e-04\n",
            " 7.21832004e-04 3.06500406e-04 1.01137379e-03 1.86735300e-03\n",
            " 3.10232601e-03 7.30548112e-05 3.13345629e-06 5.64373101e-04\n",
            " 5.93773194e-06 1.73100839e-05 3.99250768e-05 1.13354146e-03\n",
            " 9.55228863e-04 1.08803852e-03 2.07575575e-03 2.13042157e-04\n",
            " 3.87825665e-04 2.59566682e-03 1.60120898e-04 2.85855314e-03\n",
            " 1.26905769e-03 1.30047467e-03 3.44471447e-03 6.75891797e-04\n",
            " 1.93076659e-03 1.13997383e-03 3.03465568e-03 1.26019900e-03\n",
            " 1.51816561e-03 3.19774409e-03 3.33453647e-03 3.38799472e-04\n",
            " 1.02830229e-03 2.43846386e-03 2.79891610e-04 2.95918643e-03\n",
            " 1.17881923e-03]\n",
            "4000 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.62686119e-03 3.10683411e-03 7.01758190e-04 1.34949259e-03\n",
            " 1.31308153e-05 3.08783340e-03 1.21700389e-04 1.76183444e-03\n",
            " 7.48510034e-09 1.11487368e-05 3.29972417e-04 6.42031412e-07\n",
            " 3.10192565e-03 2.83404607e-03 1.00342783e-03 2.81775311e-03\n",
            " 2.60608844e-04 1.06618557e-03 2.31955616e-03 4.02607449e-04\n",
            " 3.65063716e-04 3.16788778e-03 9.63198237e-04 5.79752296e-04\n",
            " 9.15222668e-04 5.89392977e-05 2.04915617e-03 1.77589995e-03\n",
            " 2.26362746e-03 3.15177801e-03 9.67289281e-05 2.82584082e-03\n",
            " 3.15177801e-03 1.19245972e-03 1.55615471e-03 4.16983843e-05\n",
            " 3.37438439e-03 2.75156552e-03 7.48510034e-09 1.19602136e-03\n",
            " 1.88324006e-03 1.98227880e-03 2.99958251e-03 1.93501505e-03\n",
            " 1.83269642e-04 6.51055939e-04 3.14436075e-03 7.41174560e-07\n",
            " 6.17124645e-05 6.39531585e-04 2.94554744e-03 2.69182541e-03\n",
            " 3.50393421e-04 1.67089848e-03 1.00854584e-03 3.04208021e-03\n",
            " 1.07107798e-03 1.39990690e-03 2.22484721e-03 2.10216391e-04\n",
            " 4.31996074e-17 2.44440431e-04 2.28765683e-03 3.07502775e-03\n",
            " 3.06284236e-03 2.98708236e-03 1.81085821e-03 2.24189676e-04\n",
            " 2.84608298e-04 1.62454900e-03 2.38150920e-03 1.63705565e-04\n",
            " 3.34764016e-03 2.57999389e-03 2.18519623e-04 2.03025873e-03\n",
            " 1.69713515e-03 2.42097132e-03 1.55711692e-03 1.34392147e-03\n",
            " 2.30701718e-03 2.03808352e-03 2.98052384e-03 3.17625571e-03\n",
            " 2.92342553e-06 1.17618747e-03 3.01155488e-03 1.31999890e-03\n",
            " 1.23443081e-05 2.12339757e-03 2.10130509e-04 2.47842506e-03\n",
            " 1.26666792e-03 5.52743770e-04 2.41236259e-03 1.06586822e-03\n",
            " 1.71332896e-03 1.07309069e-03 5.62768411e-05 6.31343298e-04\n",
            " 1.33839731e-03 1.26666792e-03 2.59635681e-03 1.96618420e-03\n",
            " 3.61613194e-04 3.04529744e-03 2.18519623e-04 3.34122015e-03\n",
            " 5.03623155e-04 1.60839845e-03 1.25202426e-03 7.01758190e-04\n",
            " 2.78338243e-04 1.26666792e-03 2.28964758e-03 3.31093797e-03\n",
            " 1.90221057e-03 2.08626316e-04 3.01155488e-03 1.25299193e-03\n",
            " 6.30580393e-04 1.15906559e-03 1.75105258e-04 2.16456140e-03\n",
            " 2.75720864e-03 3.37438439e-03 2.82584082e-03 2.08144340e-03\n",
            " 4.12476863e-04 2.50164905e-03 6.21307464e-04 2.41386805e-03\n",
            " 4.77686912e-04 3.35847510e-03 2.30236198e-03 2.59635681e-03\n",
            " 9.71099948e-04 2.04689358e-03 1.19954868e-03 3.08653610e-03\n",
            " 2.95098568e-03 9.01360598e-04 5.75885001e-04 7.18984070e-04\n",
            " 3.06292692e-04 1.00995695e-03 1.86716217e-03 3.10192565e-03\n",
            " 7.27011234e-05 3.12891087e-06 5.63379468e-04 5.92154822e-06\n",
            " 1.72701802e-05 3.98362001e-05 1.13194165e-03 9.54876136e-04\n",
            " 1.08769756e-03 2.07268834e-03 2.11742314e-04 3.87026394e-04\n",
            " 2.59496759e-03 1.59905764e-04 2.85556368e-03 1.26854627e-03\n",
            " 1.30015850e-03 6.73199818e-04 1.92513812e-03 1.13682011e-03\n",
            " 3.02996346e-03 1.25830414e-03 1.51709305e-03 3.19300023e-03\n",
            " 3.33407509e-03 3.38428748e-04 1.02791759e-03 2.43512000e-03\n",
            " 2.79494107e-04 2.95850382e-03 1.17618747e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4010 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.62443336e-03 3.10500363e-03 7.01266705e-04 1.34809400e-03\n",
            " 1.31137519e-05 3.08761965e-03 1.21477811e-04 1.76035546e-03\n",
            " 7.46006796e-09 1.11377424e-05 3.29848147e-04 6.37485368e-07\n",
            " 3.10164649e-03 2.83282444e-03 1.00226139e-03 2.81585586e-03\n",
            " 2.60238659e-04 1.06525458e-03 2.31785032e-03 4.02615630e-04\n",
            " 3.64491537e-04 9.62498740e-04 5.79532373e-04 9.14515434e-04\n",
            " 5.88605451e-05 2.04824613e-03 1.77517673e-03 2.26266407e-03\n",
            " 3.14955652e-03 9.65412828e-05 2.82611697e-03 3.14955652e-03\n",
            " 1.19187906e-03 1.55392512e-03 4.16650885e-05 2.75085813e-03\n",
            " 7.46006796e-09 1.19571755e-03 1.88051609e-03 1.97989114e-03\n",
            " 2.99408496e-03 1.93390433e-03 1.83094452e-04 6.51089393e-04\n",
            " 3.14305278e-03 7.40913865e-07 6.16502989e-05 6.38893240e-04\n",
            " 2.94345923e-03 2.69077666e-03 3.50181541e-04 1.67014813e-03\n",
            " 1.00737201e-03 3.03898522e-03 1.07036347e-03 1.39813019e-03\n",
            " 2.22244431e-03 2.10078075e-04 4.30836523e-17 2.44257940e-04\n",
            " 2.28651080e-03 3.07375077e-03 3.06225219e-03 2.98449236e-03\n",
            " 1.80959868e-03 2.23921212e-04 2.84439837e-04 1.62398376e-03\n",
            " 2.37997584e-03 1.63561236e-04 2.58009820e-03 2.18251001e-04\n",
            " 2.02792933e-03 1.69596274e-03 2.41910162e-03 1.55629601e-03\n",
            " 1.34019019e-03 2.30480827e-03 2.03690538e-03 2.97985840e-03\n",
            " 2.91931464e-06 1.17542727e-03 3.01050793e-03 1.31936038e-03\n",
            " 1.23261024e-05 2.12214542e-03 2.10004572e-04 2.47726934e-03\n",
            " 1.26578666e-03 5.52545005e-04 2.40980651e-03 1.06549531e-03\n",
            " 1.71194675e-03 1.07255587e-03 5.62413672e-05 6.30723403e-04\n",
            " 1.33687438e-03 1.26578666e-03 2.59525802e-03 1.96532308e-03\n",
            " 3.61482186e-04 3.04136694e-03 2.18251001e-04 5.02758155e-04\n",
            " 1.60754446e-03 1.25139562e-03 7.01266705e-04 2.77856911e-04\n",
            " 1.26578666e-03 2.28779281e-03 1.89875461e-03 2.08445968e-04\n",
            " 3.01050793e-03 1.25254574e-03 6.29821396e-04 1.15788164e-03\n",
            " 1.75070729e-04 2.16301306e-03 2.75565472e-03 2.82611697e-03\n",
            " 2.07994061e-03 4.12265431e-04 2.49928744e-03 6.21016122e-04\n",
            " 2.41170852e-03 4.77275018e-04 2.29941169e-03 2.59525802e-03\n",
            " 9.70437394e-04 2.04523830e-03 1.19832650e-03 3.08483182e-03\n",
            " 2.95027524e-03 8.99556122e-04 5.75869761e-04 7.18643367e-04\n",
            " 3.06067165e-04 1.00813572e-03 1.86595727e-03 3.10164649e-03\n",
            " 7.26420003e-05 3.11292071e-06 5.62433211e-04 5.92833869e-06\n",
            " 1.72448009e-05 3.98015180e-05 1.13121502e-03 9.54385987e-04\n",
            " 1.08771619e-03 2.07113293e-03 2.11556728e-04 3.86611579e-04\n",
            " 2.59339202e-03 1.59604479e-04 2.85523098e-03 1.26774075e-03\n",
            " 1.29935907e-03 6.72827135e-04 1.92413715e-03 1.13579669e-03\n",
            " 3.02838080e-03 1.25681797e-03 1.51612845e-03 3.38057726e-04\n",
            " 1.02737007e-03 2.43405410e-03 2.79204285e-04 2.95823968e-03\n",
            " 1.17542727e-03]\n",
            "4020 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.62380502e-03 7.01414456e-04 1.34746753e-03 1.30854650e-05\n",
            " 1.21316744e-04 1.75842400e-03 7.43458530e-09 1.11090067e-05\n",
            " 3.29283638e-04 6.35831759e-07 2.83315476e-03 1.00198055e-03\n",
            " 2.81458027e-03 2.59958371e-04 1.06575495e-03 2.31783787e-03\n",
            " 4.02511676e-04 3.64161682e-04 9.60653329e-04 5.79424316e-04\n",
            " 9.14382985e-04 5.87405239e-05 2.04781648e-03 1.77623809e-03\n",
            " 2.26261607e-03 9.65213113e-05 2.82183414e-03 1.19169196e-03\n",
            " 1.55253669e-03 4.15999760e-05 2.74864526e-03 7.43458530e-09\n",
            " 1.19581404e-03 1.87924025e-03 1.97884158e-03 2.99424201e-03\n",
            " 1.93287857e-03 1.82909626e-04 6.50642002e-04 7.39657824e-07\n",
            " 6.16100571e-05 6.38565471e-04 2.94159945e-03 2.68998134e-03\n",
            " 3.49973559e-04 1.66811221e-03 1.00685731e-03 3.03795157e-03\n",
            " 1.07002139e-03 1.39722623e-03 2.22038406e-03 2.09728135e-04\n",
            " 4.27280587e-17 2.43826871e-04 2.28519680e-03 2.98287713e-03\n",
            " 1.80820378e-03 2.23744525e-04 2.84307191e-04 1.62316443e-03\n",
            " 2.37884522e-03 1.63466355e-04 2.57830180e-03 2.18138735e-04\n",
            " 2.02643838e-03 1.69531661e-03 2.41784139e-03 1.55613901e-03\n",
            " 1.34024641e-03 2.30224641e-03 2.03608843e-03 2.98044410e-03\n",
            " 2.91445429e-06 1.17382882e-03 3.01023002e-03 1.31905521e-03\n",
            " 1.23088988e-05 2.12151664e-03 2.09912674e-04 2.47653314e-03\n",
            " 1.26448302e-03 5.52228351e-04 2.40925794e-03 1.06487696e-03\n",
            " 1.71179409e-03 1.07175376e-03 5.61718145e-05 6.30287531e-04\n",
            " 1.33553685e-03 1.26448302e-03 2.59482713e-03 1.96411177e-03\n",
            " 3.61252716e-04 3.04005032e-03 2.18138735e-04 5.02435043e-04\n",
            " 1.60717317e-03 1.25113523e-03 7.01414456e-04 2.77498652e-04\n",
            " 1.26448302e-03 2.28696128e-03 1.89671796e-03 2.08152653e-04\n",
            " 3.01023002e-03 1.24839207e-03 6.29413223e-04 1.15757376e-03\n",
            " 1.75089495e-04 2.16163343e-03 2.75504843e-03 2.82183414e-03\n",
            " 2.07945613e-03 4.11852710e-04 2.49930178e-03 6.20356005e-04\n",
            " 2.41061975e-03 4.77013997e-04 2.29852869e-03 2.59482713e-03\n",
            " 9.70066148e-04 2.04475199e-03 1.19718697e-03 2.94928447e-03\n",
            " 8.98923822e-04 5.75395125e-04 7.17826286e-04 3.05923868e-04\n",
            " 1.00770249e-03 1.86604898e-03 7.25257404e-05 3.10763906e-06\n",
            " 5.62191246e-04 5.92209049e-06 1.72222986e-05 3.97816306e-05\n",
            " 1.13038247e-03 9.53735575e-04 1.08737099e-03 2.06877227e-03\n",
            " 2.11069244e-04 3.86461872e-04 2.59080036e-03 1.59524746e-04\n",
            " 2.85418867e-03 1.26712853e-03 1.29836628e-03 6.72224220e-04\n",
            " 1.92229646e-03 1.13456501e-03 3.02656670e-03 1.25615474e-03\n",
            " 1.51555477e-03 3.37740727e-04 1.02667044e-03 2.43288443e-03\n",
            " 2.78969329e-04 2.95660375e-03 1.17382882e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4030 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[2.62117355e-03 7.01259266e-04 1.34656558e-03 1.30768507e-05\n",
            " 1.21237034e-04 1.75809578e-03 7.39413372e-09 1.10898884e-05\n",
            " 3.29007335e-04 6.32382084e-07 2.83374164e-03 1.00095938e-03\n",
            " 2.81379193e-03 2.59403875e-04 1.06453561e-03 2.31674742e-03\n",
            " 4.02242015e-04 3.63708956e-04 9.60006461e-04 5.79427633e-04\n",
            " 9.13674425e-04 5.87143251e-05 2.04668698e-03 1.77607792e-03\n",
            " 2.26161031e-03 9.65041402e-05 2.81758933e-03 1.19097778e-03\n",
            " 1.55176026e-03 4.15608181e-05 2.74773379e-03 7.39413372e-09\n",
            " 1.19427191e-03 1.87916726e-03 1.97854904e-03 1.93290644e-03\n",
            " 1.82825077e-04 6.50408810e-04 7.39968053e-07 6.15826496e-05\n",
            " 6.37774007e-04 2.93915536e-03 2.68841382e-03 3.49967007e-04\n",
            " 1.66850099e-03 1.00468680e-03 1.06884761e-03 1.39557132e-03\n",
            " 2.21785752e-03 2.09585017e-04 4.25395681e-17 2.43602990e-04\n",
            " 2.28541206e-03 1.80615045e-03 2.23586457e-04 2.84138777e-04\n",
            " 1.62361241e-03 2.37652715e-03 1.63191329e-04 2.57784153e-03\n",
            " 2.17726716e-04 2.02442076e-03 1.69356657e-03 2.41402850e-03\n",
            " 1.55479370e-03 1.33797364e-03 2.30162129e-03 2.03515937e-03\n",
            " 2.90899221e-06 1.17298255e-03 1.31851144e-03 1.23024458e-05\n",
            " 2.12096680e-03 2.09738798e-04 2.47487792e-03 1.26339174e-03\n",
            " 5.52062177e-04 2.40593358e-03 1.06491120e-03 1.71085629e-03\n",
            " 1.07120317e-03 5.60984254e-05 6.29125683e-04 1.33466651e-03\n",
            " 1.26339174e-03 2.59167834e-03 1.96349691e-03 3.61056625e-04\n",
            " 2.17726716e-04 5.01849435e-04 1.60673816e-03 1.25091586e-03\n",
            " 7.01259266e-04 2.77336384e-04 1.26339174e-03 2.28587354e-03\n",
            " 1.89526678e-03 2.07977416e-04 1.24822460e-03 6.29071455e-04\n",
            " 1.15708450e-03 1.74899082e-04 2.16055359e-03 2.75314375e-03\n",
            " 2.81758933e-03 2.07772941e-03 4.11536911e-04 2.49820103e-03\n",
            " 6.20010867e-04 2.40869737e-03 4.76220790e-04 2.29424627e-03\n",
            " 2.59167834e-03 9.69101098e-04 2.04267940e-03 1.19582058e-03\n",
            " 8.97683960e-04 5.74790790e-04 7.17336923e-04 3.05524543e-04\n",
            " 1.00689120e-03 1.86549106e-03 7.24796052e-05 3.10260273e-06\n",
            " 5.61937316e-04 5.92253254e-06 1.72101947e-05 3.97504435e-05\n",
            " 1.12947180e-03 9.53356972e-04 1.08696041e-03 2.06757996e-03\n",
            " 2.10832384e-04 3.86118381e-04 2.58775748e-03 1.59331822e-04\n",
            " 2.85317201e-03 1.26647187e-03 1.29753464e-03 6.71757593e-04\n",
            " 1.92042527e-03 1.13388942e-03 1.25528839e-03 1.51483899e-03\n",
            " 3.37278397e-04 1.02625508e-03 2.43178056e-03 2.78622847e-04\n",
            " 1.17298255e-03]\n",
            "4040 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[7.01100295e-04 1.34602162e-03 1.30503189e-05 1.20867827e-04\n",
            " 1.75516172e-03 7.34258761e-09 1.10115320e-05 3.28223465e-04\n",
            " 6.32168154e-07 9.98177433e-04 2.59130760e-04 1.06343680e-03\n",
            " 2.31574262e-03 4.02137464e-04 3.63478596e-04 9.58587668e-04\n",
            " 5.78800574e-04 9.13316518e-04 5.85926215e-05 2.04578264e-03\n",
            " 1.77345287e-03 2.26077642e-03 9.64250110e-05 1.19081466e-03\n",
            " 1.55068489e-03 4.13434533e-05 7.34258761e-09 1.19264312e-03\n",
            " 1.87730089e-03 1.97783465e-03 1.93338833e-03 1.82743797e-04\n",
            " 6.49704493e-04 7.37663332e-07 6.14553850e-05 6.37646072e-04\n",
            " 3.49651269e-04 1.66773587e-03 1.00272479e-03 1.06853279e-03\n",
            " 1.39493994e-03 2.21502892e-03 2.09536664e-04 4.16216802e-17\n",
            " 2.42893613e-04 2.28463785e-03 1.80506047e-03 2.23160989e-04\n",
            " 2.83850185e-04 1.62309207e-03 2.37398007e-03 1.63041822e-04\n",
            " 2.57545146e-03 2.17147540e-04 2.02323479e-03 1.69116771e-03\n",
            " 2.41200772e-03 1.55439077e-03 1.33814068e-03 2.29669931e-03\n",
            " 2.01884618e-03 2.89702774e-06 1.17084594e-03 1.31803532e-03\n",
            " 1.22827836e-05 2.12041910e-03 2.09676572e-04 2.47298760e-03\n",
            " 1.26077745e-03 5.51714885e-04 2.40404427e-03 1.06441639e-03\n",
            " 1.71048831e-03 1.07099562e-03 5.60741830e-05 6.28766091e-04\n",
            " 1.33216296e-03 1.26077745e-03 2.58774637e-03 1.96281942e-03\n",
            " 3.60963171e-04 2.17147540e-04 5.01399099e-04 1.60660664e-03\n",
            " 1.25104989e-03 7.01100295e-04 2.77190992e-04 1.26077745e-03\n",
            " 2.28329925e-03 1.89093374e-03 2.07932208e-04 1.24909098e-03\n",
            " 6.28611268e-04 1.15620221e-03 1.74799387e-04 2.15728623e-03\n",
            " 2.07640042e-03 4.10195477e-04 2.49630623e-03 6.17885766e-04\n",
            " 2.40777801e-03 4.75770784e-04 2.28905635e-03 2.58774637e-03\n",
            " 9.68892867e-04 2.04209259e-03 1.19407301e-03 8.97035186e-04\n",
            " 5.74608892e-04 7.14994235e-04 3.04927958e-04 1.00534622e-03\n",
            " 1.86484786e-03 7.21964928e-05 3.08980718e-06 5.61625954e-04\n",
            " 5.90856956e-06 1.71766545e-05 3.96893759e-05 1.12827916e-03\n",
            " 9.52982576e-04 1.08645008e-03 2.06677156e-03 2.09644928e-04\n",
            " 3.85564370e-04 2.58407561e-03 1.59262172e-04 1.26609105e-03\n",
            " 1.29745859e-03 6.69206594e-04 1.91521350e-03 1.13104443e-03\n",
            " 1.25444547e-03 1.51313302e-03 3.37080468e-04 1.02585598e-03\n",
            " 2.42902889e-03 2.78170840e-04 1.17084594e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4050 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[7.00837621e-04 1.34491185e-03 1.30407434e-05 1.20636112e-04\n",
            " 1.75424727e-03 7.29289287e-09 1.09907648e-05 3.27947070e-04\n",
            " 6.28935411e-07 9.96704174e-04 2.58729080e-04 1.06313829e-03\n",
            " 2.31205153e-03 4.01971087e-04 3.63026571e-04 9.57493637e-04\n",
            " 5.78592529e-04 9.12102686e-04 5.85570413e-05 2.04507707e-03\n",
            " 1.77201902e-03 2.26168017e-03 9.63412680e-05 1.19048192e-03\n",
            " 1.55107284e-03 4.12848477e-05 7.29289287e-09 1.19115498e-03\n",
            " 1.87567202e-03 1.97618501e-03 1.93243351e-03 1.82493801e-04\n",
            " 6.49584260e-04 7.37502735e-07 6.14418560e-05 6.37164982e-04\n",
            " 3.49232265e-04 1.66739678e-03 1.00126959e-03 1.06686385e-03\n",
            " 1.39434505e-03 2.21151557e-03 2.09407839e-04 4.13463403e-17\n",
            " 2.42714790e-04 2.28373762e-03 1.80347242e-03 2.22742779e-04\n",
            " 2.83745912e-04 1.62293047e-03 2.37089515e-03 1.62826839e-04\n",
            " 2.16594054e-04 2.02070957e-03 1.69069861e-03 1.55416614e-03\n",
            " 1.33826711e-03 2.29502149e-03 2.01581490e-03 2.88947637e-06\n",
            " 1.16936473e-03 1.31727972e-03 1.22583473e-05 2.11943651e-03\n",
            " 2.09586550e-04 1.25976176e-03 5.51842967e-04 1.06413563e-03\n",
            " 1.71097088e-03 1.07070684e-03 5.60531085e-05 6.27907888e-04\n",
            " 1.33047043e-03 1.25976176e-03 1.96190622e-03 3.60841633e-04\n",
            " 2.16594054e-04 5.00174739e-04 1.60610929e-03 1.25091880e-03\n",
            " 7.00837621e-04 2.76768824e-04 1.25976176e-03 2.28102950e-03\n",
            " 1.88904815e-03 2.07848268e-04 1.24913545e-03 6.27724892e-04\n",
            " 1.15480809e-03 1.74729116e-04 2.15612149e-03 2.07553077e-03\n",
            " 4.09806378e-04 6.16301709e-04 4.74850596e-04 2.28453653e-03\n",
            " 9.68024832e-04 2.04196282e-03 1.19295529e-03 8.95503944e-04\n",
            " 5.74391963e-04 7.14213286e-04 3.04327751e-04 1.00462132e-03\n",
            " 1.86447910e-03 7.20774686e-05 3.08504903e-06 5.60995018e-04\n",
            " 5.89172331e-06 1.71474756e-05 3.96296936e-05 1.12768071e-03\n",
            " 9.52909024e-04 1.08636425e-03 2.06508967e-03 2.09365377e-04\n",
            " 3.85090897e-04 1.58928303e-04 1.26431940e-03 1.29643520e-03\n",
            " 6.68449781e-04 1.91261448e-03 1.13010048e-03 1.25306220e-03\n",
            " 1.51228161e-03 3.36693733e-04 1.02578115e-03 2.77660541e-04\n",
            " 1.16936473e-03]\n",
            "4060 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[7.00783782e-04 1.34449876e-03 1.30299155e-05 1.20452531e-04\n",
            " 1.75251755e-03 7.27749480e-09 1.09519033e-05 3.27499977e-04\n",
            " 6.26491629e-07 9.94796166e-04 2.58524460e-04 1.06208873e-03\n",
            " 4.01931194e-04 3.62720450e-04 9.56750048e-04 5.78541072e-04\n",
            " 9.11241564e-04 5.85104076e-05 2.04436434e-03 1.77013602e-03\n",
            " 9.62882773e-05 1.19031870e-03 1.54982471e-03 4.11863926e-05\n",
            " 7.27749480e-09 1.19049086e-03 1.87525517e-03 1.97604917e-03\n",
            " 1.93253886e-03 1.82349136e-04 6.48997067e-04 7.36398945e-07\n",
            " 6.13412216e-05 6.36728630e-04 3.49103678e-04 1.66610362e-03\n",
            " 1.00102672e-03 1.06640894e-03 1.39271625e-03 2.09257396e-04\n",
            " 4.09113994e-17 2.42413039e-04 1.80223211e-03 2.22357685e-04\n",
            " 2.83609726e-04 1.62266173e-03 1.62719075e-04 2.16391850e-04\n",
            " 2.01879582e-03 1.68944460e-03 1.55392516e-03 1.33822173e-03\n",
            " 2.01348556e-03 2.88280264e-06 1.16893114e-03 1.31630506e-03\n",
            " 1.22358002e-05 2.09500330e-04 1.25805679e-03 5.51510071e-04\n",
            " 1.06392525e-03 1.71084313e-03 1.07011190e-03 5.60405295e-05\n",
            " 6.27348873e-04 1.32837501e-03 1.25805679e-03 1.96112797e-03\n",
            " 3.60623716e-04 2.16391850e-04 4.99639018e-04 1.60599862e-03\n",
            " 1.25078425e-03 7.00783782e-04 2.76619961e-04 1.25805679e-03\n",
            " 1.88554332e-03 2.07815552e-04 1.24959925e-03 6.26767742e-04\n",
            " 1.15362443e-03 1.74680244e-04 2.07481118e-03 4.09138342e-04\n",
            " 6.15157330e-04 4.74668572e-04 9.67302980e-04 2.04139823e-03\n",
            " 1.19180491e-03 8.94976484e-04 5.74412108e-04 7.12927254e-04\n",
            " 3.04030467e-04 1.00379889e-03 1.86463928e-03 7.19461053e-05\n",
            " 3.08068123e-06 5.60658432e-04 5.87723647e-06 1.71159492e-05\n",
            " 3.96147354e-05 1.12693502e-03 9.52861415e-04 1.08610926e-03\n",
            " 2.06333856e-03 2.08851009e-04 3.84739668e-04 1.58794145e-04\n",
            " 1.26355860e-03 1.29580844e-03 6.67218080e-04 1.91030074e-03\n",
            " 1.12828010e-03 1.25238025e-03 1.51155177e-03 3.36308138e-04\n",
            " 1.02573490e-03 2.77276268e-04 1.16893114e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4070 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[7.00498898e-04 1.34332156e-03 1.30147636e-05 1.20412786e-04\n",
            " 1.75119195e-03 7.25852961e-09 1.09207091e-05 3.27226105e-04\n",
            " 6.25181036e-07 9.93408320e-04 2.58367953e-04 1.06116548e-03\n",
            " 4.01648575e-04 3.62492413e-04 9.55720190e-04 5.78352976e-04\n",
            " 9.10714823e-04 5.84482817e-05 1.76875797e-03 9.61679760e-05\n",
            " 1.18987063e-03 1.54955253e-03 4.11238384e-05 7.25852961e-09\n",
            " 1.18964923e-03 1.87415870e-03 1.82212390e-04 6.48715216e-04\n",
            " 7.35887736e-07 6.13023770e-05 6.36395830e-04 3.48825884e-04\n",
            " 1.66587671e-03 1.00051499e-03 1.06583956e-03 1.39215156e-03\n",
            " 2.09078102e-04 4.06405790e-17 2.42158315e-04 1.80112874e-03\n",
            " 2.22235220e-04 2.83533076e-04 1.62217775e-03 1.62596127e-04\n",
            " 2.16182309e-04 1.68880064e-03 1.55297089e-03 1.33814973e-03\n",
            " 2.87778145e-06 1.16798650e-03 1.31576891e-03 1.22132865e-05\n",
            " 2.09409364e-04 1.25697496e-03 5.51338684e-04 1.06357921e-03\n",
            " 1.71058640e-03 1.06964070e-03 5.60137755e-05 6.26831729e-04\n",
            " 1.32722145e-03 1.25697496e-03 3.60586451e-04 2.16182309e-04\n",
            " 4.99117279e-04 1.60550464e-03 1.25051445e-03 7.00498898e-04\n",
            " 2.76169728e-04 1.25697496e-03 1.88435681e-03 2.07689057e-04\n",
            " 1.24952152e-03 6.26063361e-04 1.15299716e-03 1.74554446e-04\n",
            " 4.08744606e-04 6.14282663e-04 4.74103251e-04 9.66760549e-04\n",
            " 1.19055284e-03 8.94344100e-04 5.74173418e-04 7.12071736e-04\n",
            " 3.03852373e-04 1.00322228e-03 1.86453069e-03 7.18431868e-05\n",
            " 3.07480293e-06 5.60378480e-04 5.86660354e-06 1.70877795e-05\n",
            " 3.95660008e-05 1.12639815e-03 9.52416311e-04 1.08569055e-03\n",
            " 2.08528911e-04 3.84372655e-04 1.58615679e-04 1.26308624e-03\n",
            " 1.29547150e-03 6.66262655e-04 1.12693127e-03 1.25160002e-03\n",
            " 1.51088192e-03 3.36014119e-04 1.02525031e-03 2.76942359e-04\n",
            " 1.16798650e-03]\n",
            "4080 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[7.00450678e-04 1.34226222e-03 1.29960322e-05 1.20407670e-04\n",
            " 7.24146815e-09 1.08948386e-05 3.26681724e-04 6.22503481e-07\n",
            " 9.92419060e-04 2.58241623e-04 1.05993315e-03 4.01667351e-04\n",
            " 3.62105144e-04 9.55443154e-04 5.78126124e-04 9.10276991e-04\n",
            " 5.83699390e-05 9.61146003e-05 1.18970795e-03 1.54872633e-03\n",
            " 4.10559961e-05 7.24146815e-09 1.18931103e-03 1.82158994e-04\n",
            " 6.48559054e-04 7.34928864e-07 6.12241237e-05 6.35990013e-04\n",
            " 3.48748047e-04 1.00027683e-03 1.06556578e-03 1.39100816e-03\n",
            " 2.09007081e-04 4.03992832e-17 2.41930443e-04 2.21942397e-04\n",
            " 2.83220484e-04 1.62507006e-04 2.16135655e-04 1.55296094e-03\n",
            " 1.33807105e-03 2.87316866e-06 1.16676404e-03 1.31492048e-03\n",
            " 1.21988615e-05 2.09371420e-04 1.25566992e-03 5.50932409e-04\n",
            " 1.06340714e-03 1.06952170e-03 5.60044259e-05 6.26491202e-04\n",
            " 1.32569819e-03 1.25566992e-03 3.60413675e-04 2.16135655e-04\n",
            " 4.98882406e-04 1.60533857e-03 1.24998414e-03 7.00450678e-04\n",
            " 2.76130242e-04 1.25566992e-03 2.07689515e-04 1.24983173e-03\n",
            " 6.25685444e-04 1.15225330e-03 1.74548992e-04 4.08167009e-04\n",
            " 6.14114499e-04 4.74029973e-04 9.66486834e-04 1.18984871e-03\n",
            " 8.94058311e-04 5.74074644e-04 7.11301138e-04 3.03621427e-04\n",
            " 1.00257924e-03 7.17140264e-05 3.07739736e-06 5.60334582e-04\n",
            " 5.86615944e-06 1.70647062e-05 3.95474391e-05 1.12573902e-03\n",
            " 9.51969254e-04 1.08550762e-03 2.08252752e-04 3.84156573e-04\n",
            " 1.58518845e-04 1.26297644e-03 1.29524186e-03 6.65522194e-04\n",
            " 1.12574610e-03 1.25011177e-03 1.51040727e-03 3.35658101e-04\n",
            " 1.02474881e-03 2.76656640e-04 1.16676404e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4090 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[7.00149675e-04 1.29906799e-05 1.20435741e-04 7.23555254e-09\n",
            " 1.08909123e-05 3.26565705e-04 6.21754830e-07 9.91891083e-04\n",
            " 2.57991352e-04 1.05964032e-03 4.01598563e-04 3.61832084e-04\n",
            " 9.55223159e-04 5.77788688e-04 9.09865680e-04 5.83371666e-05\n",
            " 9.62037517e-05 1.18935831e-03 4.10524978e-05 7.23555254e-09\n",
            " 1.18865342e-03 1.82072174e-04 6.48202656e-04 7.34729975e-07\n",
            " 6.12117556e-05 6.35595958e-04 3.48482407e-04 9.99557011e-04\n",
            " 1.06534807e-03 2.08966852e-04 4.03523531e-17 2.41776761e-04\n",
            " 2.21805232e-04 2.83010024e-04 1.62443204e-04 2.16072051e-04\n",
            " 2.87106940e-06 1.16614131e-03 1.21913494e-05 2.09278778e-04\n",
            " 1.25531678e-03 5.50816565e-04 1.06309516e-03 1.06897173e-03\n",
            " 5.60047487e-05 6.26178583e-04 1.25531678e-03 3.60317398e-04\n",
            " 2.16072051e-04 4.98763561e-04 1.24999750e-03 7.00149675e-04\n",
            " 2.76159418e-04 1.25531678e-03 2.07705810e-04 1.24964225e-03\n",
            " 6.25279470e-04 1.15186785e-03 1.74537720e-04 4.08011121e-04\n",
            " 6.14358946e-04 4.73818276e-04 9.66055966e-04 1.18889993e-03\n",
            " 8.93596428e-04 5.74258061e-04 7.11309954e-04 3.03505380e-04\n",
            " 1.00212838e-03 7.16783054e-05 3.08363418e-06 5.60601793e-04\n",
            " 5.86830980e-06 1.70535484e-05 3.95149062e-05 1.12534097e-03\n",
            " 9.52002992e-04 1.08566441e-03 2.08185697e-04 3.84069899e-04\n",
            " 1.58523067e-04 1.26269397e-03 6.65253694e-04 1.12628847e-03\n",
            " 1.24895424e-03 3.35316946e-04 1.02475943e-03 2.76477275e-04\n",
            " 1.16614131e-03]\n",
            "4100 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[6.99901432e-04 1.29855316e-05 1.20292569e-04 7.23000633e-09\n",
            " 1.08631750e-05 3.26421554e-04 6.20972368e-07 9.90878578e-04\n",
            " 2.57965609e-04 1.05940194e-03 4.01590280e-04 3.61777261e-04\n",
            " 9.54856287e-04 5.77794606e-04 9.09774711e-04 5.83201673e-05\n",
            " 9.60416100e-05 4.09817778e-05 7.23000633e-09 1.82009650e-04\n",
            " 6.48178046e-04 7.34387509e-07 6.11417871e-05 6.35327839e-04\n",
            " 3.48432957e-04 9.99448200e-04 1.06534199e-03 2.08851386e-04\n",
            " 4.00499059e-17 2.41604157e-04 2.21746080e-04 2.82963218e-04\n",
            " 1.62410029e-04 2.15988365e-04 2.86645526e-06 1.16610466e-03\n",
            " 1.21875544e-05 2.09143343e-04 5.50506288e-04 1.06288309e-03\n",
            " 1.06906675e-03 5.59776022e-05 6.25969599e-04 3.60255101e-04\n",
            " 2.15988365e-04 4.98386140e-04 6.99901432e-04 2.75946708e-04\n",
            " 2.07588594e-04 6.25174930e-04 1.15212561e-03 1.74471024e-04\n",
            " 4.07576543e-04 6.13857011e-04 4.73655704e-04 9.65964911e-04\n",
            " 8.93570876e-04 5.74069738e-04 7.10410889e-04 3.03457660e-04\n",
            " 1.00208080e-03 7.15882983e-05 3.07339457e-06 5.60020475e-04\n",
            " 5.85774289e-06 1.70451061e-05 3.95111744e-05 1.12484268e-03\n",
            " 9.51332253e-04 1.08509991e-03 2.07782085e-04 3.83836310e-04\n",
            " 1.58433008e-04 6.64536721e-04 1.12420859e-03 3.35214491e-04\n",
            " 1.02407947e-03 2.76348611e-04 1.16610466e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4110 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[6.99835832e-04 1.29747288e-05 1.20264841e-04 7.19645411e-09\n",
            " 1.08550640e-05 3.26141636e-04 6.20425347e-07 9.90684030e-04\n",
            " 2.57839456e-04 4.01575392e-04 3.61612976e-04 9.54464790e-04\n",
            " 5.77689993e-04 9.09413262e-04 5.82687705e-05 9.60737187e-05\n",
            " 4.09610195e-05 7.19645411e-09 1.81938036e-04 6.47877076e-04\n",
            " 7.33643828e-07 6.11186902e-05 6.34752354e-04 3.48359911e-04\n",
            " 9.99185254e-04 2.08885568e-04 3.99432173e-17 2.41492232e-04\n",
            " 2.21639611e-04 2.82820898e-04 1.62316868e-04 2.15792322e-04\n",
            " 2.86389121e-06 1.21796647e-05 2.09139526e-04 5.50399745e-04\n",
            " 5.59815826e-05 6.25541319e-04 3.60249926e-04 2.15792322e-04\n",
            " 4.98226792e-04 6.99835832e-04 2.75813146e-04 2.07593923e-04\n",
            " 6.24914240e-04 1.74475687e-04 4.07368128e-04 6.13731408e-04\n",
            " 4.73392991e-04 9.65568279e-04 8.92897894e-04 5.74049419e-04\n",
            " 7.10065975e-04 3.03420357e-04 1.00168751e-03 7.15491516e-05\n",
            " 3.07434709e-06 5.59945258e-04 5.84802880e-06 1.70369111e-05\n",
            " 3.94832026e-05 9.51328804e-04 2.07672116e-04 3.83703410e-04\n",
            " 1.58375997e-04 6.64263682e-04 3.35067987e-04 1.02407558e-03\n",
            " 2.76229953e-04]\n",
            "4120 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[6.99705769e-04 1.29739567e-05 1.20145812e-04 7.19605277e-09\n",
            " 1.08364039e-05 3.26177987e-04 6.19589381e-07 2.57898754e-04\n",
            " 4.01608808e-04 3.61557147e-04 5.77744116e-04 5.82665158e-05\n",
            " 9.58864415e-05 4.09235065e-05 7.19605277e-09 1.81962524e-04\n",
            " 6.47944031e-04 7.33309903e-07 6.10574745e-05 6.34594695e-04\n",
            " 3.48397444e-04 2.08731194e-04 3.97842004e-17 2.41470725e-04\n",
            " 2.21639779e-04 2.82838765e-04 1.62345866e-04 2.15776974e-04\n",
            " 2.86185049e-06 1.21731171e-05 2.09097456e-04 5.50270469e-04\n",
            " 5.59683837e-05 6.25589809e-04 3.60225250e-04 2.15776974e-04\n",
            " 4.98179933e-04 6.99705769e-04 2.75636835e-04 2.07525869e-04\n",
            " 6.24736858e-04 1.74436455e-04 4.07227865e-04 6.13039436e-04\n",
            " 4.73432240e-04 5.73924238e-04 3.03394048e-04 7.15139795e-05\n",
            " 3.06198013e-06 5.59263130e-04 5.84235097e-06 1.70264304e-05\n",
            " 3.94953953e-05 2.07472905e-04 3.83723853e-04 1.58283006e-04\n",
            " 6.63975611e-04 3.34992985e-04 2.76103045e-04]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4130 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[1.29742533e-05 1.20141299e-04 7.19083807e-09 1.08385423e-05\n",
            " 3.26147166e-04 6.20024445e-07 2.57839613e-04 4.01563840e-04\n",
            " 3.61388488e-04 5.82699009e-05 9.59061569e-05 4.09291622e-05\n",
            " 7.19083807e-09 1.81913542e-04 7.32618688e-07 6.10589406e-05\n",
            " 3.48382412e-04 2.08759671e-04 3.98086175e-17 2.41462807e-04\n",
            " 2.21561041e-04 2.82775048e-04 1.62310062e-04 2.15705731e-04\n",
            " 2.86157449e-06 1.21654525e-05 2.09086787e-04 5.50165723e-04\n",
            " 5.59692445e-05 3.60180944e-04 2.15705731e-04 4.98187197e-04\n",
            " 2.75544799e-04 2.07507274e-04 1.74410685e-04 4.07241048e-04\n",
            " 4.73360767e-04 3.03307206e-04 7.15238724e-05 3.06260942e-06\n",
            " 5.59318772e-04 5.84291903e-06 1.70180635e-05 3.94918025e-05\n",
            " 2.07526172e-04 3.83720969e-04 1.58269502e-04 3.34808358e-04\n",
            " 2.76009779e-04]\n",
            "4140 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[1.29712583e-05 1.20179484e-04 7.17953995e-09 1.08387996e-05\n",
            " 3.25987889e-04 6.20144570e-07 2.57669984e-04 5.82540182e-05\n",
            " 9.59853235e-05 4.09280599e-05 7.17953995e-09 1.81847874e-04\n",
            " 7.32259746e-07 6.10701407e-05 2.08823061e-04 3.98143134e-17\n",
            " 2.41382030e-04 2.21490554e-04 2.82728155e-04 1.62228181e-04\n",
            " 2.15596019e-04 2.86008733e-06 1.21609431e-05 2.09099251e-04\n",
            " 5.59826756e-05 2.15596019e-04 2.75558673e-04 2.07527595e-04\n",
            " 1.74428402e-04 3.03169570e-04 7.15122573e-05 3.06844964e-06\n",
            " 5.84388513e-06 1.70167847e-05 3.94719536e-05 2.07550012e-04\n",
            " 1.58219279e-04 3.34650813e-04 2.75922801e-04]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4150 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[1.29761015e-05 1.20129004e-04 7.19529202e-09 1.08398100e-05\n",
            " 6.21121028e-07 5.82760227e-05 9.58046119e-05 4.09343862e-05\n",
            " 7.19529202e-09 1.81892207e-04 7.32117357e-07 6.10684395e-05\n",
            " 2.08778607e-04 3.98390264e-17 1.62299546e-04 2.86239357e-06\n",
            " 1.21607567e-05 2.09147744e-04 5.59832955e-05 2.15813886e-04\n",
            " 2.07504217e-04 1.74436138e-04 7.15408023e-05 3.05606434e-06\n",
            " 5.84065599e-06 1.70211009e-05 3.95006164e-05 2.07592152e-04\n",
            " 1.58228599e-04]\n",
            "4160 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[1.29736761e-05 7.19071620e-09 1.08407415e-05 6.21194232e-07\n",
            " 5.82638422e-05 9.58257203e-05 4.09345201e-05 7.19071620e-09\n",
            " 7.32301052e-07 6.10816848e-05 3.98652763e-17 2.86201076e-06\n",
            " 1.21541659e-05 5.59922706e-05 7.15359453e-05 3.05933201e-06\n",
            " 5.84215892e-06 1.70208800e-05 3.94891780e-05]\n",
            "4170 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n",
            "[7.08732991e-09 1.07964914e-05 6.07516768e-07 7.08732991e-09\n",
            " 7.32295427e-07 3.95897744e-17 2.85262440e-06 3.05920385e-06\n",
            " 5.85454350e-06]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giQ0CkAWU3j8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2410857-4cca-4b29-9452-7f652b1ff3d5"
      },
      "source": [
        "train_size = 50\n",
        "\n",
        "dataset_size = X.shape[0]\n",
        "target_score = 0.95\n",
        "score = 0\n",
        "step = 10\n",
        "\n",
        "X_train = X[:train_size]\n",
        "y_train = y[:train_size]\n",
        "X_pool = X[train_size:]\n",
        "y_pool = y[train_size:]\n",
        "\n",
        "scores = [0]\n",
        "train_szs = [0]\n",
        "\n",
        "while score < target_score and train_size <= dataset_size:\n",
        "    vec = CountVectorizer(ngram_range=(1, 1))\n",
        "    bow = vec.fit_transform(X_train)\n",
        "    clf = LogisticRegression()\n",
        "    clf = clf.fit(bow,y_train)\n",
        "    pred = clf.predict(vec.transform(X_test))\n",
        "    \n",
        "    print(\"{0} train samples\".format(train_size))\n",
        "    print(classification_report(pred, y_test))\n",
        "    score = f1_score(pred, y_test)\n",
        "    scores.append(score)\n",
        "    train_szs.append(train_size)\n",
        "    \n",
        "    pred_probs = clf.predict_proba(vec.transform(X_pool))\n",
        "    #print(pred_probs)\n",
        "    #confidences = [get_confidence(probs) for probs in pred_probs]\n",
        "    probs_sort = np.sort(pred_probs, axis=1)[:, ::-1]\n",
        "    \n",
        "    confidences = probs_sort[:, 0] - probs_sort[:, 1]\n",
        "    \n",
        "    X_train = np.concatenate([X_train, X_pool[np.argsort(confidences)[:step]]])\n",
        "    y_train = np.concatenate([y_train, y_pool[np.argsort(confidences)[:step]]])\n",
        "    X_pool = X_pool[np.argsort(confidences)[:step]]\n",
        "    y_pool = y_pool[np.argsort(confidences)[:step]]\n",
        "    train_size += step\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.93      1392\n",
            "           1       0.01      1.00      0.01         1\n",
            "\n",
            "    accuracy                           0.88      1393\n",
            "   macro avg       0.50      0.94      0.47      1393\n",
            "weighted avg       1.00      0.88      0.93      1393\n",
            "\n",
            "60 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.94      1378\n",
            "           1       0.09      1.00      0.16        15\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.54      0.94      0.55      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "70 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1375\n",
            "           1       0.10      1.00      0.19        18\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.55      0.94      0.56      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "80 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1374\n",
            "           1       0.11      1.00      0.20        19\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.55      0.94      0.57      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "90 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1374\n",
            "           1       0.11      1.00      0.20        19\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.55      0.94      0.57      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1374\n",
            "           1       0.11      1.00      0.20        19\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.55      0.94      0.57      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "110 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1374\n",
            "           1       0.11      1.00      0.20        19\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.55      0.94      0.57      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "120 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1374\n",
            "           1       0.11      1.00      0.20        19\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.55      0.94      0.57      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "130 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1374\n",
            "           1       0.11      1.00      0.20        19\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.55      0.94      0.57      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "140 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1373\n",
            "           1       0.11      1.00      0.21        20\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.56      0.94      0.57      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "150 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1373\n",
            "           1       0.11      1.00      0.21        20\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.56      0.94      0.57      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "160 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1371\n",
            "           1       0.13      1.00      0.22        22\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.56      0.94      0.58      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "170 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1371\n",
            "           1       0.13      1.00      0.22        22\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.56      0.94      0.58      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "180 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1371\n",
            "           1       0.13      1.00      0.22        22\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.56      0.94      0.58      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "190 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1369\n",
            "           1       0.14      1.00      0.24        24\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.94      0.59      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "200 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1369\n",
            "           1       0.14      1.00      0.24        24\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.94      0.59      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "210 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1369\n",
            "           1       0.14      1.00      0.24        24\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.94      0.59      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "220 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1369\n",
            "           1       0.14      1.00      0.24        24\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.94      0.59      1393\n",
            "weighted avg       0.99      0.89      0.93      1393\n",
            "\n",
            "230 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "240 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "250 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "260 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "270 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "280 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "290 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "300 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "310 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "320 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "330 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "340 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "350 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "360 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "370 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "380 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "390 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "400 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "410 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "420 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "430 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1368\n",
            "           1       0.14      1.00      0.25        25\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.95      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "440 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1367\n",
            "           1       0.14      0.96      0.25        26\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.93      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "450 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1367\n",
            "           1       0.14      0.96      0.25        26\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.93      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "460 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1366\n",
            "           1       0.15      0.96      0.26        27\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.93      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "470 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1366\n",
            "           1       0.15      0.96      0.26        27\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.93      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "480 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1366\n",
            "           1       0.15      0.96      0.26        27\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.93      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "490 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1366\n",
            "           1       0.15      0.96      0.26        27\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.93      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "500 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1366\n",
            "           1       0.15      0.96      0.26        27\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.57      0.93      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "510 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1365\n",
            "           1       0.15      0.96      0.27        28\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "520 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1365\n",
            "           1       0.15      0.96      0.27        28\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.60      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "530 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "540 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "550 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "560 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "570 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "580 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "590 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "600 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "610 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "620 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "630 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "640 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1364\n",
            "           1       0.16      0.97      0.27        29\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "650 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1363\n",
            "           1       0.17      0.97      0.28        30\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "660 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1363\n",
            "           1       0.17      0.97      0.28        30\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "670 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1363\n",
            "           1       0.17      0.97      0.28        30\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "680 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1363\n",
            "           1       0.17      0.97      0.28        30\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.93      0.61      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "690 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "700 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "710 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "720 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "730 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "740 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "750 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "760 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "770 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "780 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "790 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "800 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "810 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "820 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "830 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "840 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "850 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "860 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "870 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "880 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "890 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "900 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "910 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "920 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "930 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "940 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "950 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "960 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "970 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "980 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "990 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1010 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1020 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1030 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1040 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1050 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1060 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1070 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1080 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1090 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1100 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1110 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1120 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1130 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1140 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1362\n",
            "           1       0.17      0.97      0.29        31\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.93      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1150 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1361\n",
            "           1       0.17      0.94      0.29        32\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.92      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1160 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1361\n",
            "           1       0.17      0.94      0.29        32\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.92      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1170 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1361\n",
            "           1       0.17      0.94      0.29        32\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.92      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1180 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1361\n",
            "           1       0.17      0.94      0.29        32\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.92      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1190 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1361\n",
            "           1       0.17      0.94      0.29        32\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.92      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1200 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1361\n",
            "           1       0.17      0.94      0.29        32\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.92      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1210 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1361\n",
            "           1       0.17      0.94      0.29        32\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.92      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1220 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1361\n",
            "           1       0.17      0.94      0.29        32\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.92      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1230 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1361\n",
            "           1       0.17      0.94      0.29        32\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.58      0.92      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1240 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1360\n",
            "           1       0.18      0.94      0.30        33\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.92      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1250 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1360\n",
            "           1       0.18      0.94      0.30        33\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.92      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1260 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1360\n",
            "           1       0.18      0.94      0.30        33\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.92      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1270 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1360\n",
            "           1       0.18      0.94      0.30        33\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.92      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1280 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1360\n",
            "           1       0.18      0.94      0.30        33\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.92      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1290 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1360\n",
            "           1       0.18      0.94      0.30        33\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.92      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1300 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1360\n",
            "           1       0.18      0.94      0.30        33\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.92      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1310 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1360\n",
            "           1       0.18      0.94      0.30        33\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.92      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1320 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1330 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1340 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1350 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1360 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1370 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1380 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1390 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1400 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1410 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1420 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1430 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1440 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1450 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1460 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1470 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1480 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1490 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1500 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1510 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1359\n",
            "           1       0.18      0.91      0.30        34\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1520 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1530 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1540 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1550 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1560 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1570 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1580 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1590 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1600 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1610 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1620 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1630 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1640 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1358\n",
            "           1       0.18      0.91      0.30        35\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.90      0.62      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1650 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1357\n",
            "           1       0.18      0.89      0.30        36\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.89      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1660 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1357\n",
            "           1       0.18      0.89      0.30        36\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.89      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n",
            "1670 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94      1357\n",
            "           1       0.18      0.89      0.30        36\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.59      0.89      0.62      1393\n",
            "weighted avg       0.98      0.89      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1680 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1690 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1700 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1710 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1720 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1730 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1740 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1750 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1760 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1770 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1780 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1790 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1800 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1810 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1820 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1830 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1840 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1850 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1860 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1870 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1880 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1890 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1900 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1910 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1920 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1930 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1940 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1950 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1960 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1970 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1980 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "1990 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "2000 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2010 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "2020 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "2030 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2040 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "2050 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "2060 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2070 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "2080 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "2090 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2100 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "2110 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n",
            "2120 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1356\n",
            "           1       0.19      0.89      0.31        37\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.59      0.89      0.63      1393\n",
            "weighted avg       0.98      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2130 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2140 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2150 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2160 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2170 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2180 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2190 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2200 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2210 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2220 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2230 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2240 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2250 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2260 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2270 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2280 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2290 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2300 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2310 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2320 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2330 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2340 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2350 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2360 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2370 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2380 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2390 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2400 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2410 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2420 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2430 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2440 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2450 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2460 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2470 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2480 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2490 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2500 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2510 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2520 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2530 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2540 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2550 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2560 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2570 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2580 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2590 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2600 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2610 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2620 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2630 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1355\n",
            "           1       0.19      0.89      0.32        38\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.63      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2640 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2650 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2660 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2670 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2680 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2690 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2700 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2710 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2720 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2730 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2740 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2750 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2760 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2770 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2780 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2790 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2800 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2810 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2820 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2830 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1354\n",
            "           1       0.20      0.90      0.33        39\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2840 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2850 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2860 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2870 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2880 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2890 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2900 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2910 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2920 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2930 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2940 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2950 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2960 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2970 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2980 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "2990 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3000 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3010 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3020 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3030 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3040 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1353\n",
            "           1       0.21      0.90      0.33        40\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3050 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3060 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3070 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3080 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3090 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3100 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3110 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3120 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3130 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3140 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3150 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3160 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3170 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3180 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3190 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3200 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3210 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.94      1352\n",
            "           1       0.21      0.90      0.34        41\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.60      0.90      0.64      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3220 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3230 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3240 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3250 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3260 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3270 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3280 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3290 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3300 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3310 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3320 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3330 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3340 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3350 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3360 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3370 train samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3380 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3390 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3400 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3410 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3420 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3430 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3440 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3450 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3460 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3470 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3480 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3490 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3500 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3510 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3520 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3530 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3540 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3550 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3560 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3570 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3580 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3590 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3600 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3610 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3620 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3630 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3640 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3650 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3660 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3670 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3680 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3690 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3700 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3710 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3720 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3730 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3740 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3750 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3760 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3770 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3780 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3790 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3800 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3810 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3820 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3830 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3840 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3850 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3860 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3870 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3880 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3890 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3900 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3910 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3920 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3930 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3940 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3950 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3960 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3970 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3980 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "3990 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4000 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "4010 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4020 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "4030 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4040 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "4050 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4060 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "4070 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4080 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "4090 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4100 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "4110 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4120 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "4130 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4140 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "4150 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4160 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n",
            "4170 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95      1351\n",
            "           1       0.22      0.90      0.35        42\n",
            "\n",
            "    accuracy                           0.90      1393\n",
            "   macro avg       0.61      0.90      0.65      1393\n",
            "weighted avg       0.97      0.90      0.93      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgZV0UtvQHxh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "0febc087-f1e0-44e8-ce7e-5ff60af0c89e"
      },
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(X)\n",
        "clf = clf.fit(bow,y)\n",
        "pred = clf.predict(vec.transform(X_test))\n",
        "\n",
        "print(\"{0} train samples\".format(dataset_size))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4179 train samples\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      1241\n",
            "           1       0.85      0.97      0.91       152\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.92      0.98      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0gzH2H2QHxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXRql2klQHxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6a6268ad-a84f-444d-88ea-62cae7a8afc5"
      },
      "source": [
        "plt.plot(train_szs,scores)\n",
        "plt.plot(train_szs, [0.95 for sz in train_szs])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2010b18240>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDyzm_arQHxo",
        "colab_type": "text"
      },
      "source": [
        "Можно видеть, что для достижения лучшего качества на этом датасете дсотаточно обучиться на 300 правильно выбранных примерах."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cfF2vvMQHxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}