{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "sem7_transformer.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8-pFO-UL_6g",
        "colab_type": "text"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQsgPzP0L_6k",
        "colab_type": "text"
      },
      "source": [
        "* Кодирование производится с помощью BiLSTM (не принципиально)\n",
        "* Веса $a_i$ обычно в сумме равны $1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO8CpybTL_6m",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/lizagonch/NLP/blob/master/sem7_transformers/images/attention.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdt4e_DGL_6n",
        "colab_type": "text"
      },
      "source": [
        "Визуализируя веса, можно понимать стратегию получения результата (от каких частей контекста зависела каждая из частей выхода).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKNf6sXHL_6p",
        "colab_type": "text"
      },
      "source": [
        "Пример визуализации весов $attention$ в задаче машинного перевода"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3tRC99iL_6q",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/lizagonch/NLP/blob/master/sem7_transformers/images/attention_matrix.png?raw=1\" alt=\"Drawing\" style=\"width: 480px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EC5mqQwL_6s",
        "colab_type": "text"
      },
      "source": [
        "При использовании BiLSTM каждый вектор $h_j$ хранит информацию о всей последовательности, но в наибольшей степени о $j$-м слове и его соседях.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrZvNNXML_6u",
        "colab_type": "text"
      },
      "source": [
        "Далее при текущем выходе $y_{t−1}$ (с вектором $s_{t−1}$) для вектора каждого входного слова $h_j$ считается $a_{tj}$ – вклад в генерацию следующего выходного вектора ($attention$):\n",
        "\n",
        "$$a_{tj} = \\frac {e^{e_{tj}}} {\\sum_k e^{e_{tk}}}$$\n",
        "\n",
        "где $e_{tj} = f (s_{t−1}, h_j )$ – модель выравнивания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYC2oUzRL_6w",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "􏰀Модель выравнивания предсказывает то, насколько хорошо соотносятся входное слово в позиции j и выходное в позиции t (обычно это простая модель, например, однослойная сеть)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Rh63puL_6x",
        "colab_type": "text"
      },
      "source": [
        "#### Multi-head attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFUGvMMzL_6z",
        "colab_type": "text"
      },
      "source": [
        "Вход: вектор запроса и несколько пар векторов ключей и значений (ключ и значение обычно совпадают)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAxUYc8rL_60",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/lizagonch/NLP/blob/master/sem7_transformers/images/multi-head-attention.png?raw=1\" alt=\"Drawing\" style=\"width: 400px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwd4BhajL_61",
        "colab_type": "text"
      },
      "source": [
        "Для запроса и каждого ключа считается вес (линейный слой)\n",
        "Значения суммируются с этими весами в итоговый вектор"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCyZL_QML_61",
        "colab_type": "text"
      },
      "source": [
        "Идея: обучать несколько $attention$, в надежде, что они станут отвечать за разные признаки слов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjHSfxEJL_63",
        "colab_type": "text"
      },
      "source": [
        "Результаты пропустим через однослойную сеть, получим на выходе один вектор той же размерности, что и входные вектора."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ft6Gr_tL_64",
        "colab_type": "text"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s3SnubOL_65",
        "colab_type": "text"
      },
      "source": [
        "Состоит из encoder и decoder, в каждом используются $multi$-$head\\ attention$ и полносвязные (свёрточные) слои (нет RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdVi6s1_L_66",
        "colab_type": "text"
      },
      "source": [
        "Для каждого слова в encoder формируется вектор на основе нескольких слоёв $multi$-$head\\ attention$, который передаётся в декодер."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewvxCEQwL_67",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "􏰀На основании векторов энкодера, а также выходных векторов для уже обработанных слов получается вектор для текущего слова. В обоих случаях используется $multi$-$head\\ attention$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUn81Y-BL_67",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/lizagonch/NLP/blob/master/sem7_transformers/images/transformer.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSbma_DsL_68",
        "colab_type": "text"
      },
      "source": [
        "$Positional\\ encoding$ – дополнительный вектор признаков для каждого слова, представляющий собой набор значений синусов и косинусов с разными периодами от позиции слова в предложении"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXYEYoCwL_68",
        "colab_type": "text"
      },
      "source": [
        "В трансформере и в encoder, и в decoder можно использовать несколько последовательных слоёв $multi$-$head\\ attention$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X969W5jL_69",
        "colab_type": "text"
      },
      "source": [
        "Для большей выразительности и качества добавляют полносвязные слои, а также дропаут, нормализацию по слою и residual connections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH0gn0YqL_6-",
        "colab_type": "text"
      },
      "source": [
        "Важная особенность: обучение модели внутри предложения можно распараллелить, в отличие от RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBs3hpy0L_6_",
        "colab_type": "text"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGEIsdTgL_7A",
        "colab_type": "text"
      },
      "source": [
        "$BERT\\ (Bidirectional\\ Encoder\\ Representations\\ from\\ Transformers)\\ -$ многослойный двунаправленный transformer-encoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8IymsmyL_7A",
        "colab_type": "text"
      },
      "source": [
        "#### Model architecture "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRhKfdMZL_7B",
        "colab_type": "text"
      },
      "source": [
        "Модель BERT основана на архитектуре Transformer и является усовершенствованием модели GPT от OpenAI.\n",
        "Модель, в отличие от GPT является двунаправленной.\n",
        "\n",
        "Ссылка на оригинальную статью: https://arxiv.org/abs/1810.04805"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgx1tUZRL_7C",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/lizagonch/NLP/blob/master/sem7_transformers/images/bert_model.png?raw=1\" alt=\"Drawing\" style=\"width: 550px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWwRycrDL_7C",
        "colab_type": "text"
      },
      "source": [
        "Основные параметры модели:\n",
        "* L – количество $transformer$-блоков \n",
        "* H – размер скрытого представления,\n",
        "* A – количество параллельных слоев в $multi$-$head$ $attention$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr69Fhz0L_7E",
        "colab_type": "text"
      },
      "source": [
        "Существует две основные модели от Google:\n",
        "\n",
        "* $BERT_{BASE}$: \n",
        "    * L = 12\n",
        "    * H = 768\n",
        "    * A = 12, \n",
        "    * Total = 110M\n",
        "$$$$\n",
        "* $BERT_{LARGE}$: \n",
        "    * L = 24\n",
        "    * H = 1024\n",
        "    * A = 16, \n",
        "    * Total = 340M\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4qUZH_JL_7F",
        "colab_type": "text"
      },
      "source": [
        "Модель обучается на двух задачах: \n",
        "* Masked Language Modeling.\n",
        "* Next sentence prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vOmPV7NL_7G",
        "colab_type": "text"
      },
      "source": [
        "#### Masked Language Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb0198VAL_7I",
        "colab_type": "text"
      },
      "source": [
        "В отличие от обычного Language Modeling, где предсказывается каждое следующее слово на каждом шаге, в задаче Masked Language Modeling случайные токены заменяются на специальный токен [MASK] и предсказываются только эти \"замаскированные\" токены."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mAPPd00L_7J",
        "colab_type": "text"
      },
      "source": [
        "* 80% времени обучения: Заменим слово на [MASK].\n",
        "    * my dog is hairy → my dog is [MASK]\n",
        "* 10% времени обучения: Заменим слово на другое случайное слово \n",
        "    * my dog is hairy → my dog is apple\n",
        "* 10% времени обучения: оставим предложение без изменений. Цель этого - сделать модель смещенной в сторону слова, которое действительно встречалось в корпусе в данном предложении. \n",
        "    * my dog is hairy → my dog is hairy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUyak_74L_7K",
        "colab_type": "text"
      },
      "source": [
        "#### Next sentence prediction "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFW8TF9WL_7M",
        "colab_type": "text"
      },
      "source": [
        "Next sentence prediction $-$ задача бинарной классификации. По паре предложений требуется определить, является ли второе предложение продолжением первого."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vw9bf2fL_7P",
        "colab_type": "text"
      },
      "source": [
        "* Input =[CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]\n",
        "    * Label = IsNext\n",
        "$$$$\n",
        "* Input =[CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds [SEP]\n",
        "    * Label = NotNext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8mNGrfOL_7R",
        "colab_type": "text"
      },
      "source": [
        "#### BERT Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vasnn_4CL_7S",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим на эмбеддинги, получаемые с помощью модели BERT. \n",
        "\n",
        "Будем использовать модель $BERT_{base}$ из реализации pytorch_pretrained_bert от HuggingFace. \n",
        "Ссылка на их гитхаб: https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkzkaBpbL_7U",
        "colab_type": "text"
      },
      "source": [
        "Примеры текстов взяты из туториала (https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oQFVMvcMQyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "309f2ef5-6cf2-49c4-e8d8-5c181f644154"
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 12.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 10.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 10.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.243)\n",
            "Collecting regex (from pytorch_pretrained_bert)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/60/d9782c56ceefa76033a00e1f84cd8c586c75e6e7fea2cd45ee8b46a386c5/regex-2019.08.19-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.2.0)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.243 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.243)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch_pretrained_bert) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.243->boto3->pytorch_pretrained_bert) (1.12.0)\n",
            "Installing collected packages: regex, pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.8.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzg9MN26L_7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8edb576-b904-4cf4-ed23-604b9ec9ede0"
      },
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# % matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 915803.00B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGINiAHLL_7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a52e8a50-7a43-4006-8a28-391c0e447eb9"
      },
      "source": [
        "text = \"Here is the sentence I want embeddings for.\"\n",
        "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "print (marked_text)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank. [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imoBSUViL_7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "94361a97-28b1-4ff1-fae9-dd3ddbd9d5d1"
      },
      "source": [
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "print (tokenized_text)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L93H7VE2L_7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cfbe32a3-c1ea-468b-a0cc-2104a15547b6"
      },
      "source": [
        "list(tokenizer.vocab.keys())[5000:5020]\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['knight',\n",
              " 'lap',\n",
              " 'survey',\n",
              " 'ma',\n",
              " '##ow',\n",
              " 'noise',\n",
              " 'billy',\n",
              " '##ium',\n",
              " 'shooting',\n",
              " 'guide',\n",
              " 'bedroom',\n",
              " 'priest',\n",
              " 'resistance',\n",
              " 'motor',\n",
              " 'homes',\n",
              " 'sounded',\n",
              " 'giant',\n",
              " '##mer',\n",
              " '150',\n",
              " 'scenes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s8SRb2oL_7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "eba75ab8-700e-4719-ea34-4dae49c0bf04"
      },
      "source": [
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print (tup)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('[CLS]', 101)\n",
            "('after', 2044)\n",
            "('stealing', 11065)\n",
            "('money', 2769)\n",
            "('from', 2013)\n",
            "('the', 1996)\n",
            "('bank', 2924)\n",
            "('vault', 11632)\n",
            "(',', 1010)\n",
            "('the', 1996)\n",
            "('bank', 2924)\n",
            "('robber', 27307)\n",
            "('was', 2001)\n",
            "('seen', 2464)\n",
            "('fishing', 5645)\n",
            "('on', 2006)\n",
            "('the', 1996)\n",
            "('mississippi', 5900)\n",
            "('river', 2314)\n",
            "('bank', 2924)\n",
            "('.', 1012)\n",
            "('[SEP]', 102)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTUgPv_QL_7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a527d3d6-dc9b-44b8-b549-b58dcc9f234b"
      },
      "source": [
        "segments_ids = [1] * len(tokenized_text)\n",
        "print (segments_ids)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwYZF2O1L_70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b51956fa-4da8-4299-a583-7efe6c721633"
      },
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b84MygdqL_76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict hidden states features for each layer\n",
        "with torch.no_grad():\n",
        "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gujixuiyL_8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7c830983-ae75-4f08-fbc4-9e0c9f23e9db"
      },
      "source": [
        "print (\"Number of layers:\", len(encoded_layers))\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 22\n",
            "Number of hidden units: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD5bZpeQL_8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "bc4be926-b851-4976-9748-cf16ffa055a3"
      },
      "source": [
        "# For the 5th token in our sentence, select its feature values from layer 5.\n",
        "token_i = 5\n",
        "layer_i = 5\n",
        "vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "\n",
        "# Plot the values as a histogram to show their distribution.\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.hist(vec, bins=200)\n",
        "plt.show()\n",
        "print (vec.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAJCCAYAAADky0LWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPLadIYLL_8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c2771b71-8d22-4dd4-e18c-7b303d76aaff"
      },
      "source": [
        "# Convert the hidden state embeddings into single token vectors\n",
        "\n",
        "# Holds the list of 12 layer embeddings for each token\n",
        "# Will have the shape: [# tokens, # layers, # features]\n",
        "token_embeddings = [] \n",
        "\n",
        "# For each token in the sentence...\n",
        "for token_i in range(len(tokenized_text)):\n",
        "  \n",
        "  # Holds 12 layers of hidden states for each token \n",
        "    hidden_layers = [] \n",
        "  \n",
        "  # For each of the 12 layers...\n",
        "    for layer_i in range(len(encoded_layers)):\n",
        "    \n",
        "    # Lookup the vector for `token_i` in `layer_i`\n",
        "        vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "\n",
        "        hidden_layers.append(vec)\n",
        "    \n",
        "    token_embeddings.append(hidden_layers)\n",
        "\n",
        "# Sanity check the dimensions:\n",
        "print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
        "print (\"Number of layers per token:\", len(token_embeddings[0]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tokens in sequence: 22\n",
            "Number of layers per token: 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRtXlTBTL_8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\n",
        "\n",
        "summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMIhxyLnL_8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_embedding = torch.mean(encoded_layers[11], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT_z7H3rL_8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "39bfbeb1-e8ba-4a25-da28-35dc8af36215"
      },
      "source": [
        "print (\"Our final sentence embedding vector of shape:\"), sentence_embedding[0].shape[0]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our final sentence embedding vector of shape:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOzKguS4L_8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7747a6a-cec8-4783-ac61-960009aa63f1"
      },
      "source": [
        "print (text)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOJXuqrpL_8b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "ebe1b0ce-cee1-46bc-8077-b8e71db53c05"
      },
      "source": [
        "for i,x in enumerate(tokenized_text):\n",
        "    print (i,x)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 after\n",
            "2 stealing\n",
            "3 money\n",
            "4 from\n",
            "5 the\n",
            "6 bank\n",
            "7 vault\n",
            "8 ,\n",
            "9 the\n",
            "10 bank\n",
            "11 robber\n",
            "12 was\n",
            "13 seen\n",
            "14 fishing\n",
            "15 on\n",
            "16 the\n",
            "17 mississippi\n",
            "18 river\n",
            "19 bank\n",
            "20 .\n",
            "21 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OitdZrn3L_8f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9f1ab092-3a5a-4f64-937a-61fb5bb31ce0"
      },
      "source": [
        "print (\"First fifteen values of 'bank' as in 'bank robber':\")\n",
        "summed_last_4_layers[10][:15]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First fifteen values of 'bank' as in 'bank robber':\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.1868, -1.5298, -1.3770,  1.0648,  3.1446,  1.4003, -4.2407,  1.3946,\n",
              "        -0.1170, -1.8777,  0.1091, -0.3862,  0.6744,  2.1924, -4.5306])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq67gkz2L_8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e6efedbb-8f86-459e-ff24-39e0642ef7bf"
      },
      "source": [
        "print (\"First fifteen values of 'bank' as in 'bank vault':\")\n",
        "summed_last_4_layers[6][:15]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First fifteen values of 'bank' as in 'bank vault':\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.1319, -2.1413, -1.6260,  0.8638,  3.3173,  0.1797, -4.4853,  3.1215,\n",
              "        -0.9740, -3.1780,  0.1045, -1.5481,  0.4758,  1.1703, -4.4859])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfrjlznnL_8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9eae4717-5b92-4740-8e53-caff832fc3f8"
      },
      "source": [
        "print (\"First fifteen values of 'bank' as in 'river bank':\")\n",
        "summed_last_4_layers[19][:15]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First fifteen values of 'bank' as in 'river bank':\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.1295, -1.4724, -0.7296, -0.0901,  2.4970,  0.5330,  0.9742,  5.1834,\n",
              "        -1.0692, -1.5941,  1.9261,  0.7119, -0.9809,  1.2127, -2.9812])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJbgnsSkL_8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"river bank\"\n",
        "different_bank = cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[19].reshape(1,-1))[0][0]\n",
        "\n",
        "# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"bank vault\" \n",
        "same_bank = cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[6].reshape(1,-1))[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRPw7XTiL_8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "433e7960-7a02-4166-f899-c7f95d72099d"
      },
      "source": [
        "print (\"Similarity of 'bank' as in 'bank robber' to 'bank' as in 'bank vault':\",  same_bank)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity of 'bank' as in 'bank robber' to 'bank' as in 'bank vault': 0.9456752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLdX-mflL_80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f757788-e276-4896-c596-00f4c4aeaa6c"
      },
      "source": [
        "print (\"Similarity of 'bank' as in 'bank robber' to 'bank' as in 'river bank':\",  different_bank)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity of 'bank' as in 'bank robber' to 'bank' as in 'river bank': 0.67973316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSThzXVcL_83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}