{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "bert_text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8KT0SQteIO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1fd9987f-b690-4488-e625-26b517bc9758"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUt4oFEqeXTh",
        "colab_type": "code",
        "outputId": "be5c3be9-085c-4900-921d-9cd43e72d953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install overrides"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (2.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CI6Cyjleeha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "059be261-f71d-4092-dd1b-b970228f0100"
      },
      "source": [
        "!pip install allennlp"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.17.3)\n",
            "Requirement already satisfied: parsimonious>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.8.1)\n",
            "Requirement already satisfied: flaky in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.1)\n",
            "Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.3)\n",
            "Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from allennlp) (5.6)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n",
            "Requirement already satisfied: pytorch-transformers==1.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.0)\n",
            "Requirement already satisfied: spacy<2.2,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.1.8)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9)\n",
            "Requirement already satisfied: pytorch-pretrained-bert>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.6.2)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
            "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.14.0)\n",
            "Requirement already satisfied: numpydoc>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.9.1)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.0+cu100)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.10.2)\n",
            "Requirement already satisfied: responses>=0.7 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.10.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.21.3)\n",
            "Requirement already satisfied: conllu==1.3.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.1)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.21.0)\n",
            "Requirement already satisfied: flask-cors>=3.0.7 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.8)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.1.1)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from parsimonious>=0.8.0->allennlp) (1.12.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.7)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp) (0.1.83)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp) (2019.8.19)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.2)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.4)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.9.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.3.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (7.0.8)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.10.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (0.16.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (2.10.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (7.2.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (41.4.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.2 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.13.2)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.14.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask>=1.0.2->allennlp) (1.1.1)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.15.2)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.7.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.2)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (19.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTPD3POmeIO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from typing import *\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "from overrides import overrides\n",
        "\n",
        "## В AllenNLP каждый обучающий пример должен быть представлен как объект типа Instance, содержащий различные Fields.\n",
        "from allennlp.data import Instance\n",
        "## Существует множество различных способов представить слово в виде индексов. \n",
        "## Например, можно создать словарь уникальных слов, где каждое слово имеет свой id. \n",
        "## Или же можно проиндексировать каждый уникальный символ, тогда слово будет представлено последовательностью этих индексов.\n",
        "## AllenNLP использует абстракцию TokenIndexer для этого представления.\n",
        "from allennlp.data.token_indexers import TokenIndexer\n",
        "from allennlp.data.tokenizers import Token\n",
        "from allennlp.nn import util as nn_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-PBh_i5eIO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "        \n",
        "config = Config(\n",
        "    testing=True,\n",
        "    seed=1,\n",
        "    batch_size=64,\n",
        "    lr=3e-4,\n",
        "    epochs=2,\n",
        "    hidden_sz=64,\n",
        "    max_seq_len=100, # necessary to limit memory usage\n",
        "    max_vocab_size=100000,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBq9S-_ceIPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.common.checks import ConfigurationError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1zfdKE_eIPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_GPU = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilAxROBBeIPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZC5k4s9eIPN",
        "colab_type": "text"
      },
      "source": [
        "Set random seed manually to replicate results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwNK3LjheIPO",
        "colab_type": "code",
        "outputId": "31672063-5863-43c3-fd03-eee00998f56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.manual_seed(config.seed)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0f9ff851b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKx4VILdeIPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmVcvt15It-F",
        "colab_type": "text"
      },
      "source": [
        "В большинстве случаев пайплайн AllenNLP состоит из следующих элементов:\n",
        "\n",
        "**DatasetReader**: Извлекает необходимую информацию из входных данных и представляет ее в виде последовательности объектов типа Instance.\n",
        "\n",
        "**Model**: Модель, которая будет обучаться.\n",
        "\n",
        "**Iterator**: Делит данные на батчи.\n",
        "\n",
        "**Trainer**: Определяет процесс обучения модели.\n",
        "\n",
        "(**Predictor**: Генерирует предсказания для сырых текстовых примеров.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8ij95SieIPU",
        "colab_type": "text"
      },
      "source": [
        "# Загрузка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvnFifwBsCAl",
        "colab_type": "text"
      },
      "source": [
        "В большинстве случаев для решения задач с помощью AllenNLP, нужно реализовать два класса. Первый - **DatasetReader**, который заключает всю логику чтения данных из файла и их преобразования в список Instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyfZWSTueIPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.dataset_readers import DatasetReader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWHm49joHDZg",
        "colab_type": "text"
      },
      "source": [
        "**TokenIndexer** содержит правила преобразования токенов в индексы, \n",
        "Словарь (**Vocabulary**) содержит соответствующие отображения строк в целые числа.\n",
        "Например, индексатов для токена может указывать, что токен должен быть прдставлен как последовательность составляющих его индексов, в этом случае **Vocabulary** будет содержать отображения вида *{character -> id}*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncE8w3MYeIPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.vocabulary import Vocabulary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-la40bAkeIPa",
        "colab_type": "text"
      },
      "source": [
        "### Подготовка dataset-а"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9qYijNpeIPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\",\n",
        "              \"threat\", \"insult\", \"identity_hate\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75uD8ZgIzHYr",
        "colab_type": "text"
      },
      "source": [
        "**DatasetReader** одна из важнейших частей пайплайна. \n",
        "\n",
        "**DatasetReader** включает следующие пункты:\n",
        "\n",
        "1.   чтение данных;\n",
        "2.   выделение важной информации из данных;\n",
        "3.   преобразование данных в список объектов типа Instances.\n",
        "\n",
        "В AllenNLP нет класса Dataset. DatasetReaders представляет собой схему для преобразования сырых данных в список Instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3enDcN-J4cF",
        "colab_type": "text"
      },
      "source": [
        "Field отвечают за преобразование данных в тензоры, можно определить свой класс Field.\n",
        "\n",
        "В AllenNLP уже определено несколько типов полей, один из самых важных - **TextField**.\n",
        "\n",
        "**TextField** преобразует последовательность токенов в целые числа. \n",
        "\n",
        "**НО!** он не производит препроцессинг, не токенизирует предложение и т.д., это нужно делать самостоятельно.\n",
        "\n",
        "Есть дополнительный аргумент **token indexer**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPBubzQYIdLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.fields import TextField, MetadataField, ArrayField"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbB-SpoMeIPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class JigsawDatasetReader(DatasetReader):\n",
        "  ## Параметр dict с TokenIndexer, который определяет, как конвертировать токены в индексы. \n",
        "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
        "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
        "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
        "        super().__init__(lazy=False)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    ##  Обрабатывает сам текст, метки классов, метаданные и т.д. \n",
        "    @overrides\n",
        "    def text_to_instance(self, tokens: List[Token], id: str=None,\n",
        "                         labels: np.ndarray=None) -> Instance:\n",
        "        sentence_field = TextField(tokens, self.token_indexers)\n",
        "        fields = {\"tokens\": sentence_field}\n",
        "        \n",
        "        id_field = MetadataField(id)\n",
        "        fields[\"id\"] = id_field\n",
        "        \n",
        "        if labels is None:\n",
        "            labels = np.zeros(len(label_cols))\n",
        "        label_field = ArrayField(array=labels)\n",
        "        fields[\"label\"] = label_field\n",
        "\n",
        "        return Instance(fields)\n",
        "\n",
        "    ## _read получает имя файла, считывает данные, преобразует их в список объекто типа Instances.\n",
        "    @overrides\n",
        "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
        "        df = pd.read_csv(file_path)\n",
        "        if config.testing: df = df.head(1000)\n",
        "        for i, row in df.iterrows():\n",
        "            yield self.text_to_instance(\n",
        "                [Token(x) for x in self.tokenizer(row[\"comment_text\"])],\n",
        "                row[\"id\"], row[label_cols].values,\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u2rjXEr6t7X",
        "colab_type": "text"
      },
      "source": [
        "Итак, **DatasetReader** считывает входные данные и преобразует их в список *Instances*. *Instances* состоят из *Fields*, которые определяют сами данные и способ их обработки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKEsfY_reIPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HqE0hWEVgyVW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "734018ef-90a7-4a7b-fcc0-7318afe2ece7"
      },
      "source": [
        "! wget https://www.dropbox.com/s/ezddhu2okrxmfop/test_proced.csv\n",
        "! wget https://www.dropbox.com/s/fwilrzm2vhs48m2/test.csv\n",
        "! wget https://www.dropbox.com/s/51dbf7zg9m4q61c/train.csv\n",
        "! wget https://www.dropbox.com/s/1qi10pqo1afh0i0/valid.csv"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-29 20:54:47--  https://www.dropbox.com/s/ezddhu2okrxmfop/test_proced.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601f:1::a27d:901\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ezddhu2okrxmfop/test_proced.csv [following]\n",
            "--2019-10-29 20:54:48--  https://www.dropbox.com/s/raw/ezddhu2okrxmfop/test_proced.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc59578ab722dc9cf6d38bf74c07.dl.dropboxusercontent.com/cd/0/inline/ArVAOl4Rs-RsRX7_m0GuV4Txl7JGgxcLROBGesnfiyJWzAlFcmfdcxHsaTzB3I1fifpgkVhcEfbdRghuo0EiS1Q0KmQr685ulXdnBYmdaQkWQSxRJrRZR4LyKaXsZTZm52M/file# [following]\n",
            "--2019-10-29 20:54:48--  https://uc59578ab722dc9cf6d38bf74c07.dl.dropboxusercontent.com/cd/0/inline/ArVAOl4Rs-RsRX7_m0GuV4Txl7JGgxcLROBGesnfiyJWzAlFcmfdcxHsaTzB3I1fifpgkVhcEfbdRghuo0EiS1Q0KmQr685ulXdnBYmdaQkWQSxRJrRZR4LyKaXsZTZm52M/file\n",
            "Resolving uc59578ab722dc9cf6d38bf74c07.dl.dropboxusercontent.com (uc59578ab722dc9cf6d38bf74c07.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to uc59578ab722dc9cf6d38bf74c07.dl.dropboxusercontent.com (uc59578ab722dc9cf6d38bf74c07.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 111302 (109K) [text/plain]\n",
            "Saving to: ‘test_proced.csv.1’\n",
            "\n",
            "test_proced.csv.1   100%[===================>] 108.69K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-10-29 20:54:49 (1.50 MB/s) - ‘test_proced.csv.1’ saved [111302/111302]\n",
            "\n",
            "--2019-10-29 20:54:49--  https://www.dropbox.com/s/fwilrzm2vhs48m2/test.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601f:1::a27d:901\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/fwilrzm2vhs48m2/test.csv [following]\n",
            "--2019-10-29 20:54:50--  https://www.dropbox.com/s/raw/fwilrzm2vhs48m2/test.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc4893a02e2fe6510592e0ab2d1.dl.dropboxusercontent.com/cd/0/inline/ArXEZ5cOm35vj0v6GWJbka8hTwhI_vGhF_fgBm1NTn6XjRNoEhmTMsI3bMt6_ZhlSPzYSsEJbnAIPsB9a2C2rawYydBVRMvZImSqpEzu1sqjTv-dIsmocUFH7CpPl7ca76c/file# [following]\n",
            "--2019-10-29 20:54:50--  https://ucc4893a02e2fe6510592e0ab2d1.dl.dropboxusercontent.com/cd/0/inline/ArXEZ5cOm35vj0v6GWJbka8hTwhI_vGhF_fgBm1NTn6XjRNoEhmTMsI3bMt6_ZhlSPzYSsEJbnAIPsB9a2C2rawYydBVRMvZImSqpEzu1sqjTv-dIsmocUFH7CpPl7ca76c/file\n",
            "Resolving ucc4893a02e2fe6510592e0ab2d1.dl.dropboxusercontent.com (ucc4893a02e2fe6510592e0ab2d1.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to ucc4893a02e2fe6510592e0ab2d1.dl.dropboxusercontent.com (ucc4893a02e2fe6510592e0ab2d1.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8197 (8.0K) [text/plain]\n",
            "Saving to: ‘test.csv.1’\n",
            "\n",
            "test.csv.1          100%[===================>]   8.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-10-29 20:54:50 (177 MB/s) - ‘test.csv.1’ saved [8197/8197]\n",
            "\n",
            "--2019-10-29 20:54:51--  https://www.dropbox.com/s/51dbf7zg9m4q61c/train.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601f:1::a27d:901\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/51dbf7zg9m4q61c/train.csv [following]\n",
            "--2019-10-29 20:54:52--  https://www.dropbox.com/s/raw/51dbf7zg9m4q61c/train.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc330e03b97a48321e801e61d68c.dl.dropboxusercontent.com/cd/0/inline/ArUmCLTJ2-WeTedfdt0WkY6h6Xey7qz7WHRhcwb1Tf2dOHQCM8Z3m1-EHmNuD6fXE89E7jSkBAt7qweHWW_JDztTHsAh01S1Rc0YIeWJ54bZn3DtsmvH69WeGU9wnf0Vkvw/file# [following]\n",
            "--2019-10-29 20:54:52--  https://uc330e03b97a48321e801e61d68c.dl.dropboxusercontent.com/cd/0/inline/ArUmCLTJ2-WeTedfdt0WkY6h6Xey7qz7WHRhcwb1Tf2dOHQCM8Z3m1-EHmNuD6fXE89E7jSkBAt7qweHWW_JDztTHsAh01S1Rc0YIeWJ54bZn3DtsmvH69WeGU9wnf0Vkvw/file\n",
            "Resolving uc330e03b97a48321e801e61d68c.dl.dropboxusercontent.com (uc330e03b97a48321e801e61d68c.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to uc330e03b97a48321e801e61d68c.dl.dropboxusercontent.com (uc330e03b97a48321e801e61d68c.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120463 (118K) [text/plain]\n",
            "Saving to: ‘train.csv.1’\n",
            "\n",
            "train.csv.1         100%[===================>] 117.64K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-10-29 20:54:52 (1.41 MB/s) - ‘train.csv.1’ saved [120463/120463]\n",
            "\n",
            "--2019-10-29 20:54:53--  https://www.dropbox.com/s/1qi10pqo1afh0i0/valid.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601f:1::a27d:901\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/1qi10pqo1afh0i0/valid.csv [following]\n",
            "--2019-10-29 20:54:53--  https://www.dropbox.com/s/raw/1qi10pqo1afh0i0/valid.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc04584c284f9cbd28549fbf1dea.dl.dropboxusercontent.com/cd/0/inline/ArVz9mu3T85qZtA3oDSBcqLoc6X2I6KM7l5EHoIhv4ovFHTqBX0g21Ck1Jhgi2LV8usTAljhHDw9lWmydRss7wqB8Dzx8IkhkPy0VbGi9JVUig5r5DTK_g_IuPI9qiPyJkA/file# [following]\n",
            "--2019-10-29 20:54:54--  https://uc04584c284f9cbd28549fbf1dea.dl.dropboxusercontent.com/cd/0/inline/ArVz9mu3T85qZtA3oDSBcqLoc6X2I6KM7l5EHoIhv4ovFHTqBX0g21Ck1Jhgi2LV8usTAljhHDw9lWmydRss7wqB8Dzx8IkhkPy0VbGi9JVUig5r5DTK_g_IuPI9qiPyJkA/file\n",
            "Resolving uc04584c284f9cbd28549fbf1dea.dl.dropboxusercontent.com (uc04584c284f9cbd28549fbf1dea.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to uc04584c284f9cbd28549fbf1dea.dl.dropboxusercontent.com (uc04584c284f9cbd28549fbf1dea.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11505 (11K) [text/plain]\n",
            "Saving to: ‘valid.csv.1’\n",
            "\n",
            "valid.csv.1         100%[===================>]  11.24K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-10-29 20:54:54 (276 MB/s) - ‘valid.csv.1’ saved [11505/11505]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJjbm6xjeIPg",
        "colab_type": "text"
      },
      "source": [
        "### Подготовка обработчиков токенов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqWwSaerSBIM",
        "colab_type": "text"
      },
      "source": [
        "**PretrainedBertIndexer** - TokenIndexer, соответствующий предобученной модели Bert."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADgglqHgeIPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.token_indexers import PretrainedBertIndexer\n",
        "\n",
        "token_indexer = PretrainedBertIndexer(\n",
        "    pretrained_model=\"bert-base-uncased\",\n",
        "    max_pieces=config.max_seq_len,\n",
        "    do_lowercase=True,\n",
        " )\n",
        "\n",
        "def tokenizer(s: str):\n",
        "    return token_indexer.wordpiece_tokenizer(s)[:config.max_seq_len - 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g2LTlL4eIPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reader = JigsawDatasetReader(\n",
        "    tokenizer=tokenizer,\n",
        "    token_indexers={\"tokens\": token_indexer}\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiKOdSPOeIPm",
        "colab_type": "code",
        "outputId": "6e39f007-c481-4954-995e-fe9c1c2b5f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_ds, test_ds = (reader.read(fname) for fname in [\"train.csv\", \"test_proced.csv\"])\n",
        "val_ds = None"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "77it [00:00, 766.10it/s]\u001b[A\n",
            "175it [00:00, 818.78it/s]\u001b[A\n",
            "267it [00:00, 892.98it/s]\u001b[A\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "88it [00:00, 873.83it/s]\u001b[A\n",
            "176it [00:00, 875.37it/s]\u001b[A\n",
            "251it [00:00, 881.20it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dryv3PCXeIPo",
        "colab_type": "code",
        "outputId": "74d83a99-d660-4b62-a5c9-1bb6f6ad4bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_ds)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "267"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESwxOkTOeIPq",
        "colab_type": "code",
        "outputId": "77f7796e-3efd-4d91-bb07-742c33c26917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train_ds[:10]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<allennlp.data.instance.Instance at 0x7f0f7d2ed6d8>,\n",
              " <allennlp.data.instance.Instance at 0x7f0f7d2ed7f0>,\n",
              " <allennlp.data.instance.Instance at 0x7f0f7d2ed908>,\n",
              " <allennlp.data.instance.Instance at 0x7f0f7d2eda20>,\n",
              " <allennlp.data.instance.Instance at 0x7f0f7d3198d0>,\n",
              " <allennlp.data.instance.Instance at 0x7f0f7d3199e8>,\n",
              " <allennlp.data.instance.Instance at 0x7f0f7d31eb00>,\n",
              " <allennlp.data.instance.Instance at 0x7f0f7d31ea90>,\n",
              " <allennlp.data.instance.Instance at 0x7f0f7d31ec50>,\n",
              " <allennlp.data.instance.Instance at 0x7f0f7d31ed68>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGTB9tYMeIPv",
        "colab_type": "code",
        "outputId": "3ae4d144-fa92-4b8e-9627-1efac5bc9089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vars(train_ds[0].fields[\"tokens\"])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_indexed_tokens': None,\n",
              " '_indexer_name_to_indexed_token': None,\n",
              " '_token_index_to_indexer_name': None,\n",
              " '_token_indexers': {'tokens': <allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer at 0x7f0f7d78e8d0>},\n",
              " 'tokens': [[UNK],\n",
              "  [UNK],\n",
              "  the,\n",
              "  edit,\n",
              "  ##s,\n",
              "  made,\n",
              "  under,\n",
              "  my,\n",
              "  user,\n",
              "  ##name,\n",
              "  [UNK],\n",
              "  [UNK],\n",
              "  [UNK],\n",
              "  were,\n",
              "  reverted,\n",
              "  ##?,\n",
              "  [UNK],\n",
              "  weren,\n",
              "  ##',\n",
              "  ##t,\n",
              "  van,\n",
              "  ##dal,\n",
              "  ##isms,\n",
              "  ##,,\n",
              "  just,\n",
              "  closure,\n",
              "  on,\n",
              "  some,\n",
              "  [UNK],\n",
              "  after,\n",
              "  [UNK],\n",
              "  voted,\n",
              "  at,\n",
              "  [UNK],\n",
              "  [UNK],\n",
              "  [UNK],\n",
              "  [UNK],\n",
              "  [UNK],\n",
              "  please,\n",
              "  don,\n",
              "  ##',\n",
              "  ##t,\n",
              "  remove,\n",
              "  the,\n",
              "  template,\n",
              "  from,\n",
              "  the,\n",
              "  talk,\n",
              "  page,\n",
              "  since,\n",
              "  [UNK],\n",
              "  retired,\n",
              "  now,\n",
              "  ##.,\n",
              "  ##8,\n",
              "  ##9,\n",
              "  ##.,\n",
              "  ##20,\n",
              "  ##5,\n",
              "  ##.,\n",
              "  ##38,\n",
              "  ##.,\n",
              "  ##27]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtnjnrysT5gW",
        "colab_type": "text"
      },
      "source": [
        "Предполагалось, что здесь будут тензоры, но, чтобы конвертировать поля (fields) в тензоры, нужно создать словарь (vocabulary) для наших данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GCscNtueIP2",
        "colab_type": "text"
      },
      "source": [
        "### Подготовка словаря (vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59otDih6eIP3",
        "colab_type": "text"
      },
      "source": [
        "В нашем случае не нужно строить словарь Bert indexer сам задает нужно отображение токенов в индексы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6scNf6ueIP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Vocabulary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiKQpquoeIP7",
        "colab_type": "text"
      },
      "source": [
        "### Подготовка итератора"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uZ9yWJreIP7",
        "colab_type": "text"
      },
      "source": [
        "Итератор отвечает за деление данных на батчи и их подготовку для модели.\n",
        "\n",
        "В AllenNLP определно несколько удобных итераторов. Будем использовать **BucketIterator**. Он группирует предложения приблизительно одинаковой длины для минимизации паддинга."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDfD8DyceIP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import BucketIterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iILoEyZ4eIP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterator = BucketIterator(batch_size=config.batch_size, \n",
        "                          sorting_keys=[(\"tokens\", \"num_tokens\")],\n",
        "                         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYwaRe0AeIP_",
        "colab_type": "text"
      },
      "source": [
        "Обязательно нужно напомнить итератору, что все Instances проиндексированы в нашем словаре (vocabulary), т.е., что все строки были преобразованы в целые числа, используя заданное ранее отображение."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWVNlDj6eIQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterator.index_with(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcpLAMhveIQC",
        "colab_type": "text"
      },
      "source": [
        "### Подготовленные данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tfMiSVDeIQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = next(iter(iterator(train_ds)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVg3V6gDeIQE",
        "colab_type": "code",
        "outputId": "834339d9-a703-4152-ed82-dc2b3eb4f653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': ['00a54f5b8d29a2b7',\n",
              "  '0037fe4f8f5cdcfb',\n",
              "  '0023daf96917e0d0',\n",
              "  '000897889268bc93',\n",
              "  '008faa76dd3eb890',\n",
              "  '005de39c51ef844a',\n",
              "  '009a3333aa4ac011',\n",
              "  '00a00eb46f78b1d2',\n",
              "  '00190820581d90ce',\n",
              "  '00a656a81c6f0903',\n",
              "  '0002bcb3da6cb337',\n",
              "  '00908f946bd2fd05',\n",
              "  '006a4e493b506d1e',\n",
              "  '001ffdcc3e7fb49c',\n",
              "  '00a3073791a5feaa',\n",
              "  '004d912a00f79c89',\n",
              "  '0057e30091cf3e81',\n",
              "  '005fb1983ff191e9',\n",
              "  '0036e50f42d0b679',\n",
              "  '009ce66bcd5de288',\n",
              "  '006eaaaca322e12d',\n",
              "  '008fdd0ca51cdadc',\n",
              "  '004af8a71399a4dc',\n",
              "  '009d0fe5e7ee720a',\n",
              "  '0007e25b2121310b',\n",
              "  '0086998b34865f93',\n",
              "  '006b888560bcdfcd',\n",
              "  '00128363e367d703',\n",
              "  '004b97c80705a548',\n",
              "  '006a263a08b593c5',\n",
              "  '00040093b2687caa',\n",
              "  '00025465d4725e87',\n",
              "  '000c6a3f0cd3ba8e',\n",
              "  '006e87872c8b370c',\n",
              "  '00a9d33dea92c45c',\n",
              "  '00472b8e2d38d1ea',\n",
              "  '009cb63b1bd5daf9',\n",
              "  '000bfd0867774845',\n",
              "  '002b90cc8a94c76b',\n",
              "  '0083ead5c8afc356',\n",
              "  '0091798f05a311af',\n",
              "  '003bd094feef5263',\n",
              "  '00582dcd527c8d7d',\n",
              "  '0083790fbfe5014d',\n",
              "  '001325b8b20ea8aa',\n",
              "  '004a789c03eda830',\n",
              "  '007a5055c23cc5a6',\n",
              "  '007810bde7d6ebd4',\n",
              "  '0020fd96ed3b8c8b',\n",
              "  '0001d958c54c6e35',\n",
              "  '003217c3eb469ba9',\n",
              "  '00054a5e18b50dd4',\n",
              "  '009df88828f523c4',\n",
              "  '00a1aabcab9d44a0',\n",
              "  '002e2d3db2b597c4',\n",
              "  '00637960a7ec3436',\n",
              "  '00803f08f55bdcad',\n",
              "  '0097dd5c29bf7a15',\n",
              "  '0084d905b6f19f2b',\n",
              "  '0036621e4c7e10b5',\n",
              "  '0040017ef6277334',\n",
              "  '00397b264deba890',\n",
              "  '0009801bd85e5806',\n",
              "  '005ba6af463ab6cf'],\n",
              " 'label': tensor([[0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 1., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [1., 1., 1., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 1., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [1., 1., 1., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 1., 0., 1., 1.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 1., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 1., 0., 1., 1.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0.]]),\n",
              " 'tokens': {'mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [1, 1, 1,  ..., 0, 0, 0],\n",
              "          [1, 1, 1,  ..., 1, 1, 1],\n",
              "          [1, 1, 1,  ..., 1, 1, 0]]),\n",
              "  'tokens': tensor([[  101,   100,  2005,  ...,     0,     0,     0],\n",
              "          [  101,   100,  3752,  ...,     0,     0,     0],\n",
              "          [  101,   100,   100,  ...,     0,     0,     0],\n",
              "          ...,\n",
              "          [  101,   100,  2064,  ...,     0,     0,     0],\n",
              "          [  101,   100,   100,  ...,  2592, 29632,   102],\n",
              "          [  101,   100,   100,  ...,   100,   102,     0]]),\n",
              "  'tokens-offsets': tensor([[ 1,  2,  3,  ...,  0,  0,  0],\n",
              "          [ 1,  2,  3,  ...,  0,  0,  0],\n",
              "          [ 1,  2,  3,  ...,  0,  0,  0],\n",
              "          ...,\n",
              "          [ 1,  2,  3,  ...,  0,  0,  0],\n",
              "          [ 1,  2,  3,  ..., 20, 21, 22],\n",
              "          [ 1,  2,  3,  ..., 20, 21,  0]]),\n",
              "  'tokens-type-ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0],\n",
              "          [0, 0, 0,  ..., 0, 0, 0]])}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0-7fuO5eIQH",
        "colab_type": "code",
        "outputId": "f77a747e-ce9c-4cc1-e78e-572913dde8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "batch[\"tokens\"][\"tokens\"]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,   100,  2005,  ...,     0,     0,     0],\n",
              "        [  101,   100,  3752,  ...,     0,     0,     0],\n",
              "        [  101,   100,   100,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,   100,  2064,  ...,     0,     0,     0],\n",
              "        [  101,   100,   100,  ...,  2592, 29632,   102],\n",
              "        [  101,   100,   100,  ...,   100,   102,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNT75MgPeIQK",
        "colab_type": "code",
        "outputId": "913219d7-e81e-4966-99cd-429618d5bad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch[\"tokens\"][\"tokens\"].shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRtBCpmUeIQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BayjQwG2eIQN",
        "colab_type": "text"
      },
      "source": [
        "# Подготовка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKoOMnbdeIQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxV2BQckZf2V",
        "colab_type": "text"
      },
      "source": [
        "Помимо класса **DatasetReader**, обычно нужно реализовать класс **Model**, который является модулем PyTorch. На вход подается тензор, на выходе словарь выходных тензоров (включающий training loss, которую нужно оптимизировать).\n",
        "\n",
        "AllenNLP модели обычно состоят из:\n",
        "\n",
        "token embedder;\n",
        "\n",
        "encoder;\n",
        "\n",
        "(Для seq-to-seq моделей) decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1tK9yajeIQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.models import Model\n",
        "\n",
        "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
        "from allennlp.nn.util import get_text_field_mask\n",
        "from allennlp.modules.text_field_embedders import TextFieldEmbedder\n",
        "\n",
        "class BaselineModel(Model):\n",
        "    def __init__(self, word_embeddings: TextFieldEmbedder,\n",
        "                 encoder: Seq2VecEncoder,\n",
        "                 out_sz: int=len(label_cols)):\n",
        "      ## Конструктору класса нужно передать словарь (vocab)\n",
        "        super().__init__(vocab)\n",
        "        self.word_embeddings = word_embeddings\n",
        "        self.encoder = encoder\n",
        "        self.projection = nn.Linear(self.encoder.get_output_dim(), out_sz)\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "        \n",
        "    def forward(self, tokens: Dict[str, torch.Tensor],\n",
        "                id: Any, label: torch.Tensor) -> torch.Tensor:\n",
        "        ## Из-за паддинга нужно вводить маску, чтобы модель видела только информативные части предложений. \n",
        "        mask = get_text_field_mask(tokens)\n",
        "        embeddings = self.word_embeddings(tokens)\n",
        "        state = self.encoder(embeddings, mask)\n",
        "        class_logits = self.projection(state)\n",
        "        \n",
        "        output = {\"class_logits\": class_logits}\n",
        "        output[\"loss\"] = self.loss(class_logits, label)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnFJaC9UeIQR",
        "colab_type": "text"
      },
      "source": [
        "### Готовим эмбеддинги"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxMgLc7deIQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders.bert_token_embedder import PretrainedBertEmbedder\n",
        "\n",
        "bert_embedder = PretrainedBertEmbedder(\n",
        "        pretrained_model=\"bert-base-uncased\",\n",
        "        top_layer_only=True, # conserve memory\n",
        ")\n",
        "word_embeddings: TextFieldEmbedder = BasicTextFieldEmbedder({\"tokens\": bert_embedder},\n",
        "                                                            # Чтобы игнорировать замаскированные занчения\n",
        "                                                           allow_unmatched_keys = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgBHnZ1meIQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BERT_DIM = word_embeddings.get_output_dim()\n",
        "\n",
        "class BertSentencePooler(Seq2VecEncoder):\n",
        "    def forward(self, embs: torch.tensor, \n",
        "                mask: torch.tensor=None) -> torch.tensor:\n",
        "\n",
        "        return embs[:, 0]\n",
        "    \n",
        "    @overrides\n",
        "    def get_output_dim(self) -> int:\n",
        "        return BERT_DIM\n",
        "    \n",
        "encoder = BertSentencePooler(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CPsj7O2eIQX",
        "colab_type": "text"
      },
      "source": [
        "Строим модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuGF7eJUeIQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BaselineModel(\n",
        "    word_embeddings, \n",
        "    encoder, \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkyRcrWLeIQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if USE_GPU: model.cuda()\n",
        "else: model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNMAz6pxeIQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRaKbHZ7eIQd",
        "colab_type": "text"
      },
      "source": [
        "# Проверим модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzqjX63VeIQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = nn_util.move_to_device(batch, 0 if USE_GPU else -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89EYKpAReIQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = batch[\"tokens\"]\n",
        "labels = batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W180tTmeIQh",
        "colab_type": "code",
        "outputId": "7dd97219-e87f-49a1-a195-d134efce3096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "tokens"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 0]]),\n",
              " 'tokens': tensor([[  101,   100,  2005,  ...,     0,     0,     0],\n",
              "         [  101,   100,  3752,  ...,     0,     0,     0],\n",
              "         [  101,   100,   100,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,   100,  2064,  ...,     0,     0,     0],\n",
              "         [  101,   100,   100,  ...,  2592, 29632,   102],\n",
              "         [  101,   100,   100,  ...,   100,   102,     0]]),\n",
              " 'tokens-offsets': tensor([[ 1,  2,  3,  ...,  0,  0,  0],\n",
              "         [ 1,  2,  3,  ...,  0,  0,  0],\n",
              "         [ 1,  2,  3,  ...,  0,  0,  0],\n",
              "         ...,\n",
              "         [ 1,  2,  3,  ...,  0,  0,  0],\n",
              "         [ 1,  2,  3,  ..., 20, 21, 22],\n",
              "         [ 1,  2,  3,  ..., 20, 21,  0]]),\n",
              " 'tokens-type-ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RRiSFj8eIQk",
        "colab_type": "code",
        "outputId": "2db14233-112e-440f-8879-1407d95c844a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "mask = get_text_field_mask(tokens)\n",
        "mask"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R3nBY2weIQn",
        "colab_type": "code",
        "outputId": "f03c35d9-3575-497c-8739-ef9111d1928b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "embeddings = model.word_embeddings(tokens)\n",
        "state = model.encoder(embeddings, mask)\n",
        "class_logits = model.projection(state)\n",
        "class_logits"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1145,  0.0215, -0.5080, -0.1537, -0.1508,  0.2334],\n",
              "        [ 0.1976, -0.0708, -0.5108, -0.2801,  0.0134,  0.0271],\n",
              "        [ 0.0355, -0.2590, -0.5887, -0.2327,  0.3112,  0.0500],\n",
              "        [ 0.0603, -0.1349, -0.4211, -0.2369,  0.2386,  0.1047],\n",
              "        [ 0.2617,  0.3407, -0.2248, -0.0359, -0.0774, -0.2127],\n",
              "        [ 0.2123,  0.0323, -0.3265, -0.4256,  0.0512,  0.2372],\n",
              "        [-0.0228,  0.0486, -0.3513, -0.1816, -0.0951,  0.1991],\n",
              "        [ 0.5909,  0.4791,  0.1234,  0.2549, -0.3621, -0.2005],\n",
              "        [-0.0272, -0.0012, -0.5064, -0.4777,  0.1700, -0.0691],\n",
              "        [-0.0246, -0.1369, -0.5717, -0.1650, -0.0271,  0.2038],\n",
              "        [ 0.0760,  0.1233, -0.4525, -0.3145,  0.2415,  0.0473],\n",
              "        [-0.1123, -0.1083, -0.2333, -0.4683,  0.1232,  0.1124],\n",
              "        [ 0.0139,  0.0444, -0.3812, -0.4663,  0.1955, -0.2172],\n",
              "        [-0.0663, -0.1316, -0.5453, -0.3915,  0.0501,  0.1232],\n",
              "        [-0.0659, -0.2313, -0.4383, -0.4111,  0.1205, -0.0384],\n",
              "        [ 0.0496, -0.0408, -0.4771, -0.3222, -0.0834,  0.2687],\n",
              "        [-0.0050, -0.0825, -0.3567, -0.3351,  0.0841,  0.0080],\n",
              "        [ 0.0871,  0.1772, -0.0943, -0.2778,  0.1177,  0.0346],\n",
              "        [ 0.0917, -0.0985, -0.5286, -0.2642, -0.0319,  0.2093],\n",
              "        [-0.0118, -0.3101, -0.1749, -0.3387, -0.2105,  0.0614],\n",
              "        [ 0.0813, -0.1232, -0.0788, -0.0062, -0.2365, -0.0073],\n",
              "        [-0.0511, -0.0734, -0.4305, -0.3398,  0.0507, -0.0440],\n",
              "        [ 0.0800,  0.0105, -0.0552,  0.0333, -0.4422,  0.1325],\n",
              "        [ 0.2411,  0.1966, -0.3624,  0.1520, -0.5199, -0.0472],\n",
              "        [ 0.1179, -0.0455, -0.1842, -0.1533, -0.1601,  0.1803],\n",
              "        [-0.0821, -0.2051, -0.4233, -0.4935,  0.1238, -0.0528],\n",
              "        [-0.1264, -0.1958, -0.3280, -0.4833,  0.1056,  0.0379],\n",
              "        [-0.1000, -0.1380, -0.3966, -0.3897, -0.0422,  0.1399],\n",
              "        [ 0.0956, -0.0503, -0.3178, -0.4278,  0.0410,  0.0690],\n",
              "        [ 0.0762, -0.0734, -0.4839, -0.0621, -0.0916,  0.2021],\n",
              "        [ 0.1258,  0.0620, -0.5631, -0.0182,  0.1795,  0.1783],\n",
              "        [-0.0347, -0.1146, -0.3484, -0.4288,  0.0920,  0.0394],\n",
              "        [ 0.2121,  0.1204, -0.5017, -0.0701,  0.0018,  0.2843],\n",
              "        [ 0.0069,  0.1630, -0.5122, -0.3741, -0.1649, -0.1039],\n",
              "        [ 0.1053,  0.2732, -0.2602,  0.0691, -0.0697,  0.3033],\n",
              "        [-0.0393,  0.0592, -0.3357, -0.4814, -0.1033, -0.1036],\n",
              "        [-0.0079,  0.0128, -0.4063, -0.1124, -0.3211,  0.0438],\n",
              "        [-0.0524, -0.1185, -0.3405, -0.5069,  0.1152, -0.0101],\n",
              "        [ 0.1184, -0.0405, -0.3368, -0.2422, -0.0175,  0.0671],\n",
              "        [ 0.0803,  0.3503, -0.3406, -0.1436,  0.1742, -0.2106],\n",
              "        [ 0.3140,  0.2009, -0.2601, -0.0507, -0.0991,  0.4182],\n",
              "        [ 0.0086,  0.0323, -0.4474, -0.3051,  0.0876,  0.1813],\n",
              "        [ 0.0477, -0.0495, -0.4948, -0.3522, -0.0520,  0.0049],\n",
              "        [-0.0756, -0.1774, -0.3189, -0.4477,  0.1067, -0.0056],\n",
              "        [-0.0938, -0.0021, -0.2637, -0.4851, -0.0789,  0.0100],\n",
              "        [ 0.1006,  0.0746, -0.4071, -0.1645, -0.1802,  0.4078],\n",
              "        [-0.0628, -0.0981, -0.3043, -0.4575,  0.0091, -0.0055],\n",
              "        [ 0.0737,  0.1613, -0.4493, -0.2744, -0.0784,  0.1872],\n",
              "        [-0.0362, -0.2227, -0.3268, -0.4958, -0.0226, -0.0934],\n",
              "        [ 0.0283, -0.1568, -0.2515, -0.4173,  0.0350,  0.0533],\n",
              "        [-0.0182, -0.1220, -0.3853, -0.4053,  0.0913,  0.0828],\n",
              "        [ 0.0060, -0.0525, -0.2531, -0.4367, -0.0843,  0.0345],\n",
              "        [-0.0195, -0.1141, -0.4835, -0.2806, -0.0875,  0.1087],\n",
              "        [-0.0314,  0.0472, -0.2500, -0.3504, -0.2299,  0.1495],\n",
              "        [-0.0397, -0.2333, -0.3672, -0.4789,  0.1233, -0.0463],\n",
              "        [ 0.3537,  0.1223, -0.3657, -0.0212,  0.0582, -0.0167],\n",
              "        [ 0.0744,  0.1180, -0.2707, -0.1847, -0.0365,  0.0222],\n",
              "        [ 0.0661, -0.0945, -0.3502, -0.5494,  0.0039, -0.1528],\n",
              "        [ 0.1171, -0.0349, -0.4963, -0.0883, -0.0726,  0.0551],\n",
              "        [-0.0481, -0.1906, -0.3895, -0.5706,  0.1290, -0.1072],\n",
              "        [-0.0255, -0.0041, -0.4499, -0.2678, -0.1791, -0.0326],\n",
              "        [ 0.0785, -0.0203, -0.4801, -0.2922, -0.0307,  0.1187],\n",
              "        [ 0.1667,  0.3346, -0.4083, -0.0236, -0.0968,  0.1667],\n",
              "        [ 0.0054, -0.0895, -0.5325, -0.2839,  0.0040,  0.0843]],\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyhCAr19eIQp",
        "colab_type": "code",
        "outputId": "67008790-359e-4af1-ae9e-bb535a847e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model(**batch)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_logits': tensor([[ 0.0688,  0.1159, -0.4146, -0.0672, -0.3661,  0.1553],\n",
              "         [ 0.1483,  0.0911, -0.3735, -0.5372,  0.0036, -0.0632],\n",
              "         [ 0.0740, -0.0963, -0.4739, -0.0403,  0.3503,  0.0397],\n",
              "         [ 0.0645, -0.0680, -0.5565, -0.2188,  0.2389,  0.0317],\n",
              "         [ 0.7737,  0.4068, -0.0085,  0.2519, -0.2855, -0.2457],\n",
              "         [ 0.0905, -0.0771, -0.3815, -0.2523,  0.1467,  0.0729],\n",
              "         [-0.1899,  0.2512, -0.1674, -0.2583, -0.0818,  0.1700],\n",
              "         [ 0.4894,  0.4504, -0.0246, -0.2127, -0.1714,  0.0332],\n",
              "         [ 0.1698, -0.0262, -0.4746, -0.0137, -0.0602,  0.0724],\n",
              "         [-0.1229, -0.1556, -0.4624, -0.4269,  0.0276,  0.0286],\n",
              "         [-0.0507, -0.1426, -0.2402, -0.2189,  0.3800,  0.0253],\n",
              "         [-0.0325, -0.0888, -0.2879, -0.4762,  0.1077,  0.0559],\n",
              "         [-0.1679, -0.1422, -0.4375, -0.4351,  0.2096, -0.0198],\n",
              "         [ 0.0596, -0.0994, -0.4359, -0.3350,  0.1306,  0.0740],\n",
              "         [-0.0465, -0.0735, -0.3893, -0.4971,  0.1423, -0.0697],\n",
              "         [ 0.2280, -0.0279, -0.5325,  0.0981, -0.2685,  0.0363],\n",
              "         [ 0.0314, -0.1397, -0.3881, -0.4375,  0.1081, -0.0588],\n",
              "         [ 0.0275,  0.1154, -0.0898, -0.2247,  0.1145,  0.0468],\n",
              "         [ 0.1277,  0.0116, -0.4888, -0.3523,  0.0888,  0.0137],\n",
              "         [-0.0650, -0.1969, -0.2871, -0.5498,  0.1691, -0.0594],\n",
              "         [-0.0128,  0.2345, -0.1778, -0.3168,  0.0723,  0.0449],\n",
              "         [-0.0884, -0.2329, -0.4600, -0.5047, -0.0379,  0.0437],\n",
              "         [-0.0845,  0.0065, -0.3086, -0.2770, -0.1064,  0.1515],\n",
              "         [ 0.0808,  0.0825, -0.3476, -0.1068, -0.1842, -0.1366],\n",
              "         [ 0.0842, -0.0122, -0.4578, -0.1613,  0.0059,  0.2453],\n",
              "         [-0.1701, -0.2873, -0.4659, -0.4762,  0.0618,  0.0203],\n",
              "         [ 0.1531, -0.2173, -0.0030, -0.2300, -0.2742, -0.0067],\n",
              "         [ 0.0453, -0.1844, -0.5144, -0.2759, -0.0700,  0.0385],\n",
              "         [ 0.0259, -0.0808, -0.3814, -0.4752, -0.0164,  0.0503],\n",
              "         [-0.0828, -0.0112, -0.4720, -0.3131,  0.0142,  0.2506],\n",
              "         [ 0.1696,  0.1637, -0.5090,  0.0779,  0.1513,  0.3181],\n",
              "         [-0.0389, -0.1338, -0.3717, -0.4949,  0.0404,  0.0079],\n",
              "         [ 0.1420,  0.1004, -0.3354, -0.0813, -0.0021, -0.0240],\n",
              "         [ 0.1519,  0.1114, -0.3066, -0.3478, -0.1987, -0.1282],\n",
              "         [ 0.3023, -0.0319, -0.3589,  0.0376, -0.1458,  0.4401],\n",
              "         [-0.0188, -0.1071, -0.3220, -0.5355,  0.0869, -0.0790],\n",
              "         [-0.0228, -0.0099, -0.3584, -0.0426, -0.1260,  0.1219],\n",
              "         [-0.0939, -0.0675, -0.5191, -0.3272,  0.0986, -0.0263],\n",
              "         [ 0.1048,  0.1959, -0.1002, -0.0084, -0.0045,  0.1694],\n",
              "         [-0.1019,  0.1979, -0.2503, -0.3796,  0.0118, -0.1476],\n",
              "         [ 0.2882,  0.2084, -0.2366,  0.1286, -0.0661,  0.1854],\n",
              "         [ 0.1060,  0.0658, -0.4039, -0.2427, -0.1370,  0.1427],\n",
              "         [-0.0033, -0.1194, -0.3621, -0.4052,  0.0196, -0.0179],\n",
              "         [-0.1167, -0.0979, -0.4070, -0.3526,  0.0205,  0.1093],\n",
              "         [-0.1919, -0.0777, -0.2279, -0.3876, -0.1363,  0.1266],\n",
              "         [ 0.2134,  0.0793, -0.3640, -0.2726, -0.0918,  0.1970],\n",
              "         [-0.0215, -0.1785, -0.4507, -0.3685, -0.0727,  0.0524],\n",
              "         [ 0.1633, -0.0345, -0.2829, -0.1957, -0.2246,  0.0930],\n",
              "         [-0.0488, -0.1543, -0.2977, -0.4725,  0.0371, -0.0432],\n",
              "         [-0.0614, -0.2265, -0.3715, -0.3942, -0.0746,  0.1246],\n",
              "         [ 0.0196, -0.1175, -0.2095, -0.3838,  0.1514,  0.0402],\n",
              "         [-0.0776, -0.1519, -0.2474, -0.5012,  0.0992, -0.0140],\n",
              "         [ 0.1633, -0.0847, -0.3626, -0.3959, -0.0513, -0.0643],\n",
              "         [ 0.2253, -0.1010, -0.0876, -0.1368, -0.4298,  0.0130],\n",
              "         [-0.0102, -0.1346, -0.4272, -0.4563,  0.0541, -0.0616],\n",
              "         [ 0.2972, -0.1203, -0.2799, -0.0130, -0.0775,  0.0055],\n",
              "         [-0.0836, -0.0683, -0.2200, -0.4604,  0.0368,  0.0918],\n",
              "         [ 0.0578, -0.2111, -0.4672, -0.5057,  0.0498,  0.0286],\n",
              "         [ 0.0603, -0.0046, -0.4262, -0.1470, -0.1665, -0.0243],\n",
              "         [-0.1963, -0.1770, -0.4648, -0.6048,  0.0864,  0.0526],\n",
              "         [ 0.0290, -0.0920, -0.3498, -0.3803, -0.1165,  0.0423],\n",
              "         [ 0.1002, -0.1236, -0.4259, -0.1643, -0.1930,  0.0358],\n",
              "         [-0.1140,  0.1100, -0.3979, -0.1407, -0.2558,  0.2389],\n",
              "         [ 0.0954,  0.0146, -0.5239,  0.0220,  0.0160,  0.2909]],\n",
              "        grad_fn=<AddmmBackward>),\n",
              " 'loss': tensor(0.6586, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvQO0DLNeIQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = model(**batch)[\"loss\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWhiGpdGeIQu",
        "colab_type": "code",
        "outputId": "cec05d7e-aa92-4b41-ca06-c29bd8ed2e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6578, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnt3JpFFeIQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v0ulQXleIQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyUkMXxreIQ5",
        "colab_type": "text"
      },
      "source": [
        "# Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np1ofdCWeIQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL9ZWVweeIQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Используем класс Trainer из AllenNLP\n",
        "from allennlp.training.trainer import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    iterator=iterator,\n",
        "    train_dataset=train_ds,\n",
        "    cuda_device=0 if USE_GPU else -1,\n",
        "    num_epochs=config.epochs,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuRLHnpfeIQ9",
        "colab_type": "code",
        "outputId": "fcef284a-4f8b-4d02-8aeb-b73a62fe5fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "metrics = trainer.train()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 378, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 356, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 438, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "loss: 0.6710 ||:  20%|██        | 1/5 [00:21<01:24, 21.24s/it]\u001b[A\n",
            "loss: 0.6574 ||:  40%|████      | 2/5 [00:26<00:49, 16.38s/it]\u001b[A\n",
            "loss: 0.6492 ||:  60%|██████    | 3/5 [00:30<00:25, 12.66s/it]\u001b[A\n",
            "loss: 0.6411 ||:  80%|████████  | 4/5 [00:52<00:15, 15.59s/it]\u001b[A\n",
            "loss: 0.6324 ||: 100%|██████████| 5/5 [01:03<00:00, 14.02s/it]\u001b[A\n",
            "\u001b[Aunable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 378, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 356, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 438, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "loss: 0.5768 ||:  20%|██        | 1/5 [00:20<01:23, 20.94s/it]\u001b[A\n",
            "loss: 0.5706 ||:  40%|████      | 2/5 [00:43<01:03, 21.31s/it]\u001b[A\n",
            "loss: 0.5629 ||:  60%|██████    | 3/5 [00:47<00:32, 16.10s/it]\u001b[A\n",
            "loss: 0.5605 ||:  80%|████████  | 4/5 [00:52<00:12, 12.81s/it]\u001b[A\n",
            "loss: 0.5521 ||: 100%|██████████| 5/5 [01:02<00:00, 12.15s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SxvG1_OeIQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hveBrUqEeIRA",
        "colab_type": "text"
      },
      "source": [
        "# Генерация предиктора"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jg0qjNVh3Jd",
        "colab_type": "text"
      },
      "source": [
        "AllenNLP содержит абстракцию **Predictor**, которая получает на вход данные, конвертирует их в Instances, скармливает модели и возвращает результат. \n",
        "\n",
        "В AllenNLP есть только один реализованный предиктор **SentenceTaggerPredictor**. Для большинства задач предиктор нужно реализовать самостоятельно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ0DHwW9eIRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import DataIterator\n",
        "from tqdm import tqdm\n",
        "from scipy.special import expit # the sigmoid function\n",
        "\n",
        "def tonp(tsr): return tsr.detach().cpu().numpy()\n",
        "\n",
        "class Predictor:\n",
        "    def __init__(self, model: Model, iterator: DataIterator,\n",
        "                 cuda_device: int=-1) -> None:\n",
        "        self.model = model\n",
        "        self.iterator = iterator\n",
        "        self.cuda_device = cuda_device\n",
        "        \n",
        "    def _extract_data(self, batch) -> np.ndarray:\n",
        "        out_dict = self.model(**batch)\n",
        "        return expit(tonp(out_dict[\"class_logits\"]))\n",
        "    \n",
        "    def predict(self, ds: Iterable[Instance]) -> np.ndarray:\n",
        "        pred_generator = self.iterator(ds, num_epochs=1, shuffle=False)\n",
        "        self.model.eval()\n",
        "        pred_generator_tqdm = tqdm(pred_generator,\n",
        "                                   total=self.iterator.get_num_batches(ds))\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for batch in pred_generator_tqdm:\n",
        "                batch = nn_util.move_to_device(batch, self.cuda_device)\n",
        "                preds.append(self._extract_data(batch))\n",
        "        return np.concatenate(preds, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muss1jwzeIRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import BasicIterator\n",
        "# проходим по всему набору данных, не меняя порядка\n",
        "seq_iterator = BasicIterator(batch_size=64)\n",
        "seq_iterator.index_with(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLSm256AeIRD",
        "colab_type": "code",
        "outputId": "6b7f199f-20e2-45da-c8e5-ac8808a3740b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "predictor = Predictor(model, seq_iterator, cuda_device=0 if USE_GPU else -1)\n",
        "train_preds = predictor.predict(train_ds) \n",
        "test_preds = predictor.predict(test_ds) "
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:21<01:24, 21.18s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:42<01:03, 21.17s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [01:03<00:42, 21.16s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [01:24<00:21, 21.14s/it]\u001b[A\n",
            "100%|██████████| 5/5 [01:28<00:00, 15.94s/it]\u001b[A\n",
            "\u001b[A\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 1/4 [00:21<01:03, 21.13s/it]\u001b[A\n",
            " 50%|█████     | 2/4 [00:42<00:42, 21.13s/it]\u001b[A\n",
            " 75%|███████▌  | 3/4 [01:03<00:21, 21.13s/it]\u001b[A\n",
            "100%|██████████| 4/4 [01:23<00:00, 20.69s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXWVhnjfeIRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "01a5b81c-7736-40cc-83e9-0f3ff08c0596"
      },
      "source": [
        "test_preds\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4129021 , 0.38936403, 0.28252792, 0.35432905, 0.40151322,\n",
              "        0.4339282 ],\n",
              "       [0.3979461 , 0.3819608 , 0.34652203, 0.31746748, 0.4500172 ,\n",
              "        0.40407592],\n",
              "       [0.42484435, 0.3842783 , 0.3517712 , 0.3583979 , 0.3973712 ,\n",
              "        0.43223068],\n",
              "       ...,\n",
              "       [0.39026165, 0.379195  , 0.31677172, 0.34768498, 0.40115   ,\n",
              "        0.41660818],\n",
              "       [0.40983585, 0.36331385, 0.35998017, 0.33345345, 0.37998417,\n",
              "        0.43453267],\n",
              "       [0.41559297, 0.4271993 , 0.34390524, 0.42004392, 0.3018501 ,\n",
              "        0.46570572]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xohQQZGok5vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_test = pd.read_csv(\"test_proced.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyNeVQpVmNnr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a069aa96-5a65-4d82-d6eb-9fe96d59d8ca"
      },
      "source": [
        "check_test.head()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0001ea8717f6de06</td>\n",
              "      <td>Thank you for understanding. I think very high...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000247e83dcc1211</td>\n",
              "      <td>:Dear god this site is horrible.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0002f87b16116a7f</td>\n",
              "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0003e1cccfd5a40a</td>\n",
              "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00059ace3e3e9a53</td>\n",
              "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0001ea8717f6de06  ...             0\n",
              "1  000247e83dcc1211  ...             0\n",
              "2  0002f87b16116a7f  ...             0\n",
              "3  0003e1cccfd5a40a  ...             0\n",
              "4  00059ace3e3e9a53  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQDT1yxImPW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}